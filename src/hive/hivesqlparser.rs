// Generated from HiveSqlParser.g4 by ANTLR 4.8
#![allow(dead_code)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(nonstandard_style)]
#![allow(unused_imports)]
#![allow(unused_mut)]
#![allow(unused_braces)]
use crate::PredictionContextCache;
use crate::parser::{Parser, BaseParser, ParserRecog, ParserNodeType};
use crate::token_stream::TokenStream;
use crate::TokenSource;
use crate::parser_atn_simulator::ParserATNSimulator;
use crate::errors::*;
use crate::rule_context::{BaseRuleContext, CustomRuleContext, RuleContext};
use crate::recognizer::{Recognizer,Actions};
use crate::atn_deserializer::ATNDeserializer;
use crate::dfa::DFA;
use crate::atn::{ATN, INVALID_ALT};
use crate::error_strategy::{ErrorStrategy, DefaultErrorStrategy};
use crate::parser_rule_context::{BaseParserRuleContext, ParserRuleContext,cast,cast_mut};
use crate::tree::*;
use crate::token::{TOKEN_EOF,OwningToken,Token};
use crate::int_stream::EOF;
use crate::vocabulary::{Vocabulary,VocabularyImpl};
use crate::token_factory::{CommonTokenFactory,TokenFactory, TokenAware};
use super::hivesqlparserlistener::*;
use crate::lazy_static;
use crate::{TidAble,TidExt};

use std::marker::PhantomData;
use std::sync::Arc;
use std::rc::Rc;
use std::convert::TryFrom;
use std::cell::RefCell;
use std::ops::{DerefMut, Deref};
use std::borrow::{Borrow,BorrowMut};
use std::any::{Any,TypeId};

		pub const KW_ABORT:isize=1; 
		pub const KW_ACTIVATE:isize=2; 
		pub const KW_ACTIVE:isize=3; 
		pub const KW_ADD:isize=4; 
		pub const KW_ADMIN:isize=5; 
		pub const KW_AFTER:isize=6; 
		pub const KW_ALL:isize=7; 
		pub const KW_ALLOC_FRACTION:isize=8; 
		pub const KW_ALTER:isize=9; 
		pub const KW_ANALYZE:isize=10; 
		pub const KW_AND:isize=11; 
		pub const KW_ANTI:isize=12; 
		pub const KW_ANY:isize=13; 
		pub const KW_APPLICATION:isize=14; 
		pub const KW_ARCHIVE:isize=15; 
		pub const KW_ARRAY:isize=16; 
		pub const KW_AS:isize=17; 
		pub const KW_ASC:isize=18; 
		pub const KW_AST:isize=19; 
		pub const KW_AT:isize=20; 
		pub const KW_AUTHORIZATION:isize=21; 
		pub const KW_AUTOCOMMIT:isize=22; 
		pub const KW_BATCH:isize=23; 
		pub const KW_BEFORE:isize=24; 
		pub const KW_BETWEEN:isize=25; 
		pub const KW_BIGINT:isize=26; 
		pub const KW_BINARY:isize=27; 
		pub const KW_BOOLEAN:isize=28; 
		pub const KW_BOTH:isize=29; 
		pub const KW_BUCKET:isize=30; 
		pub const KW_BUCKETS:isize=31; 
		pub const KW_BY:isize=32; 
		pub const KW_CACHE:isize=33; 
		pub const KW_CASCADE:isize=34; 
		pub const KW_CASE:isize=35; 
		pub const KW_CAST:isize=36; 
		pub const KW_CBO:isize=37; 
		pub const KW_CHANGE:isize=38; 
		pub const KW_CHAR:isize=39; 
		pub const KW_CHECK:isize=40; 
		pub const KW_CLUSTER:isize=41; 
		pub const KW_CLUSTERED:isize=42; 
		pub const KW_CLUSTERSTATUS:isize=43; 
		pub const KW_COLLECTION:isize=44; 
		pub const KW_COLUMN:isize=45; 
		pub const KW_COLUMNS:isize=46; 
		pub const KW_COMMENT:isize=47; 
		pub const KW_COMMIT:isize=48; 
		pub const KW_COMPACT:isize=49; 
		pub const KW_COMPACTIONS:isize=50; 
		pub const KW_COMPACT_ID:isize=51; 
		pub const KW_COMPUTE:isize=52; 
		pub const KW_CONCATENATE:isize=53; 
		pub const KW_CONF:isize=54; 
		pub const KW_CONSTRAINT:isize=55; 
		pub const KW_CONTINUE:isize=56; 
		pub const KW_COST:isize=57; 
		pub const KW_CREATE:isize=58; 
		pub const KW_CRON:isize=59; 
		pub const KW_CROSS:isize=60; 
		pub const KW_CUBE:isize=61; 
		pub const KW_CURRENT:isize=62; 
		pub const KW_CURRENT_DATE:isize=63; 
		pub const KW_CURRENT_TIMESTAMP:isize=64; 
		pub const KW_CURSOR:isize=65; 
		pub const KW_DATA:isize=66; 
		pub const KW_DATABASE:isize=67; 
		pub const KW_DATABASES:isize=68; 
		pub const KW_DATACONNECTOR:isize=69; 
		pub const KW_DATACONNECTORS:isize=70; 
		pub const KW_DATE:isize=71; 
		pub const KW_DATETIME:isize=72; 
		pub const KW_DAY:isize=73; 
		pub const KW_DAYOFWEEK:isize=74; 
		pub const KW_DBPROPERTIES:isize=75; 
		pub const KW_DCPROPERTIES:isize=76; 
		pub const KW_DDL:isize=77; 
		pub const KW_DEBUG:isize=78; 
		pub const KW_DECIMAL:isize=79; 
		pub const KW_DEFAULT:isize=80; 
		pub const KW_DEFERRED:isize=81; 
		pub const KW_DEFINED:isize=82; 
		pub const KW_DELETE:isize=83; 
		pub const KW_DELIMITED:isize=84; 
		pub const KW_DEPENDENCY:isize=85; 
		pub const KW_DESC:isize=86; 
		pub const KW_DESCRIBE:isize=87; 
		pub const KW_DETAIL:isize=88; 
		pub const KW_DIRECTORIES:isize=89; 
		pub const KW_DIRECTORY:isize=90; 
		pub const KW_DISABLE:isize=91; 
		pub const KW_DISTINCT:isize=92; 
		pub const KW_DISTRIBUTE:isize=93; 
		pub const KW_DISTRIBUTED:isize=94; 
		pub const KW_DO:isize=95; 
		pub const KW_DOUBLE:isize=96; 
		pub const KW_DROP:isize=97; 
		pub const KW_DUMP:isize=98; 
		pub const KW_ELEM_TYPE:isize=99; 
		pub const KW_ELSE:isize=100; 
		pub const KW_ENABLE:isize=101; 
		pub const KW_END:isize=102; 
		pub const KW_ENFORCED:isize=103; 
		pub const KW_ESCAPED:isize=104; 
		pub const KW_EVERY:isize=105; 
		pub const KW_EXCEPT:isize=106; 
		pub const KW_EXCHANGE:isize=107; 
		pub const KW_EXCLUSIVE:isize=108; 
		pub const KW_EXECUTE:isize=109; 
		pub const KW_EXECUTED:isize=110; 
		pub const KW_EXISTS:isize=111; 
		pub const KW_EXPIRE_SNAPSHOTS:isize=112; 
		pub const KW_EXPLAIN:isize=113; 
		pub const KW_EXPORT:isize=114; 
		pub const KW_EXPRESSION:isize=115; 
		pub const KW_EXTENDED:isize=116; 
		pub const KW_EXTERNAL:isize=117; 
		pub const KW_EXTRACT:isize=118; 
		pub const KW_FALSE:isize=119; 
		pub const KW_FETCH:isize=120; 
		pub const KW_FIELDS:isize=121; 
		pub const KW_FILE:isize=122; 
		pub const KW_FILEFORMAT:isize=123; 
		pub const KW_FIRST:isize=124; 
		pub const KW_FLOAT:isize=125; 
		pub const KW_FLOOR:isize=126; 
		pub const KW_FOLLOWING:isize=127; 
		pub const KW_FOR:isize=128; 
		pub const KW_FORCE:isize=129; 
		pub const KW_FOREIGN:isize=130; 
		pub const KW_FORMAT:isize=131; 
		pub const KW_FORMATTED:isize=132; 
		pub const KW_FROM:isize=133; 
		pub const KW_FULL:isize=134; 
		pub const KW_FUNCTION:isize=135; 
		pub const KW_FUNCTIONS:isize=136; 
		pub const KW_GRANT:isize=137; 
		pub const KW_GROUP:isize=138; 
		pub const KW_GROUPING:isize=139; 
		pub const KW_HAVING:isize=140; 
		pub const KW_HOLD_DDLTIME:isize=141; 
		pub const KW_HOUR:isize=142; 
		pub const KW_IDXPROPERTIES:isize=143; 
		pub const KW_IF:isize=144; 
		pub const KW_IGNORE:isize=145; 
		pub const KW_IMPORT:isize=146; 
		pub const KW_IN:isize=147; 
		pub const KW_INDEX:isize=148; 
		pub const KW_INDEXES:isize=149; 
		pub const KW_INNER:isize=150; 
		pub const KW_INPATH:isize=151; 
		pub const KW_INPUTDRIVER:isize=152; 
		pub const KW_INPUTFORMAT:isize=153; 
		pub const KW_INSERT:isize=154; 
		pub const KW_INT:isize=155; 
		pub const KW_INTERSECT:isize=156; 
		pub const KW_INTERVAL:isize=157; 
		pub const KW_INTO:isize=158; 
		pub const KW_IS:isize=159; 
		pub const KW_ISOLATION:isize=160; 
		pub const KW_ITEMS:isize=161; 
		pub const KW_JAR:isize=162; 
		pub const KW_JOIN:isize=163; 
		pub const KW_JOINCOST:isize=164; 
		pub const KW_KEY:isize=165; 
		pub const KW_KEYS:isize=166; 
		pub const KW_KEY_TYPE:isize=167; 
		pub const KW_KILL:isize=168; 
		pub const KW_LAST:isize=169; 
		pub const KW_LATERAL:isize=170; 
		pub const KW_LEADING:isize=171; 
		pub const KW_LEFT:isize=172; 
		pub const KW_LESS:isize=173; 
		pub const KW_LEVEL:isize=174; 
		pub const KW_LIKE:isize=175; 
		pub const KW_LIMIT:isize=176; 
		pub const KW_LINES:isize=177; 
		pub const KW_LOAD:isize=178; 
		pub const KW_LOCAL:isize=179; 
		pub const KW_LOCATION:isize=180; 
		pub const KW_LOCK:isize=181; 
		pub const KW_LOCKS:isize=182; 
		pub const KW_LOGICAL:isize=183; 
		pub const KW_LONG:isize=184; 
		pub const KW_MACRO:isize=185; 
		pub const KW_MANAGED:isize=186; 
		pub const KW_MANAGEDLOCATION:isize=187; 
		pub const KW_MANAGEMENT:isize=188; 
		pub const KW_MAP:isize=189; 
		pub const KW_MAPJOIN:isize=190; 
		pub const KW_MAPPING:isize=191; 
		pub const KW_MATCHED:isize=192; 
		pub const KW_MATERIALIZED:isize=193; 
		pub const KW_MERGE:isize=194; 
		pub const KW_METADATA:isize=195; 
		pub const KW_MINUS:isize=196; 
		pub const KW_MINUTE:isize=197; 
		pub const KW_MONTH:isize=198; 
		pub const KW_MORE:isize=199; 
		pub const KW_MOVE:isize=200; 
		pub const KW_MSCK:isize=201; 
		pub const KW_NONE:isize=202; 
		pub const KW_NORELY:isize=203; 
		pub const KW_NOSCAN:isize=204; 
		pub const KW_NOT:isize=205; 
		pub const KW_NOVALIDATE:isize=206; 
		pub const KW_NO_DROP:isize=207; 
		pub const KW_NULL:isize=208; 
		pub const KW_NULLS:isize=209; 
		pub const KW_OF:isize=210; 
		pub const KW_OFFLINE:isize=211; 
		pub const KW_OFFSET:isize=212; 
		pub const KW_ON:isize=213; 
		pub const KW_ONLY:isize=214; 
		pub const KW_OPERATOR:isize=215; 
		pub const KW_OPTION:isize=216; 
		pub const KW_OR:isize=217; 
		pub const KW_ORDER:isize=218; 
		pub const KW_OUT:isize=219; 
		pub const KW_OUTER:isize=220; 
		pub const KW_OUTPUTDRIVER:isize=221; 
		pub const KW_OUTPUTFORMAT:isize=222; 
		pub const KW_OVER:isize=223; 
		pub const KW_OVERWRITE:isize=224; 
		pub const KW_OWNER:isize=225; 
		pub const KW_PARTITION:isize=226; 
		pub const KW_PARTITIONED:isize=227; 
		pub const KW_PARTITIONS:isize=228; 
		pub const KW_PATH:isize=229; 
		pub const KW_PERCENT:isize=230; 
		pub const KW_PKFK_JOIN:isize=231; 
		pub const KW_PLAN:isize=232; 
		pub const KW_PLANS:isize=233; 
		pub const KW_PLUS:isize=234; 
		pub const KW_POOL:isize=235; 
		pub const KW_PRECEDING:isize=236; 
		pub const KW_PRECISION:isize=237; 
		pub const KW_PREPARE:isize=238; 
		pub const KW_PRESERVE:isize=239; 
		pub const KW_PRIMARY:isize=240; 
		pub const KW_PRINCIPALS:isize=241; 
		pub const KW_PROCEDURE:isize=242; 
		pub const KW_PROTECTION:isize=243; 
		pub const KW_PURGE:isize=244; 
		pub const KW_QUALIFY:isize=245; 
		pub const KW_QUARTER:isize=246; 
		pub const KW_QUERY:isize=247; 
		pub const KW_QUERY_PARALLELISM:isize=248; 
		pub const KW_RANGE:isize=249; 
		pub const KW_READ:isize=250; 
		pub const KW_READONLY:isize=251; 
		pub const KW_READS:isize=252; 
		pub const KW_REAL:isize=253; 
		pub const KW_REBUILD:isize=254; 
		pub const KW_RECORDREADER:isize=255; 
		pub const KW_RECORDWRITER:isize=256; 
		pub const KW_REDUCE:isize=257; 
		pub const KW_REFERENCES:isize=258; 
		pub const KW_REGEXP:isize=259; 
		pub const KW_RELOAD:isize=260; 
		pub const KW_RELY:isize=261; 
		pub const KW_REMOTE:isize=262; 
		pub const KW_RENAME:isize=263; 
		pub const KW_REOPTIMIZATION:isize=264; 
		pub const KW_REPAIR:isize=265; 
		pub const KW_REPL:isize=266; 
		pub const KW_REPLACE:isize=267; 
		pub const KW_REPLICATION:isize=268; 
		pub const KW_RESOURCE:isize=269; 
		pub const KW_RESPECT:isize=270; 
		pub const KW_RESTRICT:isize=271; 
		pub const KW_REVOKE:isize=272; 
		pub const KW_REWRITE:isize=273; 
		pub const KW_RIGHT:isize=274; 
		pub const KW_RLIKE:isize=275; 
		pub const KW_ROLE:isize=276; 
		pub const KW_ROLES:isize=277; 
		pub const KW_ROLLBACK:isize=278; 
		pub const KW_ROLLUP:isize=279; 
		pub const KW_ROW:isize=280; 
		pub const KW_ROWS:isize=281; 
		pub const KW_SCHEDULED:isize=282; 
		pub const KW_SCHEDULING_POLICY:isize=283; 
		pub const KW_SCHEMA:isize=284; 
		pub const KW_SCHEMAS:isize=285; 
		pub const KW_SECOND:isize=286; 
		pub const KW_SELECT:isize=287; 
		pub const KW_SEMI:isize=288; 
		pub const KW_SERDE:isize=289; 
		pub const KW_SERDEPROPERTIES:isize=290; 
		pub const KW_SERVER:isize=291; 
		pub const KW_SET:isize=292; 
		pub const KW_SETS:isize=293; 
		pub const KW_SET_CURRENT_SNAPSHOT:isize=294; 
		pub const KW_SHARED:isize=295; 
		pub const KW_SHOW:isize=296; 
		pub const KW_SHOW_DATABASE:isize=297; 
		pub const KW_SKEWED:isize=298; 
		pub const KW_SMALLINT:isize=299; 
		pub const KW_SNAPSHOT:isize=300; 
		pub const KW_SOME:isize=301; 
		pub const KW_SORT:isize=302; 
		pub const KW_SORTED:isize=303; 
		pub const KW_SPEC:isize=304; 
		pub const KW_SSL:isize=305; 
		pub const KW_START:isize=306; 
		pub const KW_STATISTICS:isize=307; 
		pub const KW_STATUS:isize=308; 
		pub const KW_STORED:isize=309; 
		pub const KW_STREAMTABLE:isize=310; 
		pub const KW_STRING:isize=311; 
		pub const KW_STRUCT:isize=312; 
		pub const KW_SUMMARY:isize=313; 
		pub const KW_SYNC:isize=314; 
		pub const KW_SYSTEM_TIME:isize=315; 
		pub const KW_SYSTEM_VERSION:isize=316; 
		pub const KW_TABLE:isize=317; 
		pub const KW_TABLES:isize=318; 
		pub const KW_TABLESAMPLE:isize=319; 
		pub const KW_TBLPROPERTIES:isize=320; 
		pub const KW_TEMPORARY:isize=321; 
		pub const KW_TERMINATED:isize=322; 
		pub const KW_THEN:isize=323; 
		pub const KW_TIME:isize=324; 
		pub const KW_TIMESTAMP:isize=325; 
		pub const KW_TIMESTAMPLOCALTZ:isize=326; 
		pub const KW_TIMESTAMPTZ:isize=327; 
		pub const KW_TINYINT:isize=328; 
		pub const KW_TO:isize=329; 
		pub const KW_TOUCH:isize=330; 
		pub const KW_TRAILING:isize=331; 
		pub const KW_TRANSACTION:isize=332; 
		pub const KW_TRANSACTIONAL:isize=333; 
		pub const KW_TRANSACTIONS:isize=334; 
		pub const KW_TRANSFORM:isize=335; 
		pub const KW_TRIGGER:isize=336; 
		pub const KW_TRIM:isize=337; 
		pub const KW_TRUE:isize=338; 
		pub const KW_TRUNCATE:isize=339; 
		pub const KW_TYPE:isize=340; 
		pub const KW_UNARCHIVE:isize=341; 
		pub const KW_UNBOUNDED:isize=342; 
		pub const KW_UNDO:isize=343; 
		pub const KW_UNION:isize=344; 
		pub const KW_UNIONTYPE:isize=345; 
		pub const KW_UNIQUE:isize=346; 
		pub const KW_UNIQUEJOIN:isize=347; 
		pub const KW_UNKNOWN:isize=348; 
		pub const KW_UNLOCK:isize=349; 
		pub const KW_UNMANAGED:isize=350; 
		pub const KW_UNSET:isize=351; 
		pub const KW_UNSIGNED:isize=352; 
		pub const KW_UPDATE:isize=353; 
		pub const KW_URI:isize=354; 
		pub const KW_URL:isize=355; 
		pub const KW_USE:isize=356; 
		pub const KW_USER:isize=357; 
		pub const KW_USING:isize=358; 
		pub const KW_UTC:isize=359; 
		pub const KW_UTCTIMESTAMP:isize=360; 
		pub const KW_VALIDATE:isize=361; 
		pub const KW_VALUES:isize=362; 
		pub const KW_VALUE_TYPE:isize=363; 
		pub const KW_VARCHAR:isize=364; 
		pub const KW_VECTORIZATION:isize=365; 
		pub const KW_VIEW:isize=366; 
		pub const KW_VIEWS:isize=367; 
		pub const KW_WAIT:isize=368; 
		pub const KW_WEEK:isize=369; 
		pub const KW_WHEN:isize=370; 
		pub const KW_WHERE:isize=371; 
		pub const KW_WHILE:isize=372; 
		pub const KW_WINDOW:isize=373; 
		pub const KW_WITH:isize=374; 
		pub const KW_WITHIN:isize=375; 
		pub const KW_WORK:isize=376; 
		pub const KW_WORKLOAD:isize=377; 
		pub const KW_WRITE:isize=378; 
		pub const KW_YEAR:isize=379; 
		pub const KW_ZONE:isize=380; 
		pub const DOT:isize=381; 
		pub const COLON:isize=382; 
		pub const COMMA:isize=383; 
		pub const SEMICOLON:isize=384; 
		pub const LPAREN:isize=385; 
		pub const RPAREN:isize=386; 
		pub const LSQUARE:isize=387; 
		pub const RSQUARE:isize=388; 
		pub const LCURLY:isize=389; 
		pub const RCURLY:isize=390; 
		pub const EQUAL:isize=391; 
		pub const EQUAL_NS:isize=392; 
		pub const NOTEQUAL:isize=393; 
		pub const LESSTHANOREQUALTO:isize=394; 
		pub const LESSTHAN:isize=395; 
		pub const GREATERTHANOREQUALTO:isize=396; 
		pub const GREATERTHAN:isize=397; 
		pub const DIVIDE:isize=398; 
		pub const PLUS:isize=399; 
		pub const MINUS:isize=400; 
		pub const STAR:isize=401; 
		pub const MOD:isize=402; 
		pub const DIV:isize=403; 
		pub const AMPERSAND:isize=404; 
		pub const TILDE:isize=405; 
		pub const BITWISEOR:isize=406; 
		pub const CONCATENATE:isize=407; 
		pub const BITWISEXOR:isize=408; 
		pub const QUESTION:isize=409; 
		pub const DOLLAR:isize=410; 
		pub const StringLiteral:isize=411; 
		pub const CharSetLiteral:isize=412; 
		pub const IntegralLiteral:isize=413; 
		pub const NumberLiteral:isize=414; 
		pub const ByteLengthLiteral:isize=415; 
		pub const Number:isize=416; 
		pub const Identifier:isize=417; 
		pub const CharSetName:isize=418; 
		pub const WHITE_SPACE:isize=419; 
		pub const LINE_COMMENT:isize=420; 
		pub const QUERY_HINT:isize=421; 
		pub const SHOW_HINT:isize=422; 
		pub const HIDDEN_HINT:isize=423;
	pub const RULE_program:usize = 0; 
	pub const RULE_statement:usize = 1; 
	pub const RULE_explainStatement:usize = 2; 
	pub const RULE_explainOption:usize = 3; 
	pub const RULE_vectorizationOnly:usize = 4; 
	pub const RULE_vectorizatonDetail:usize = 5; 
	pub const RULE_execStatement:usize = 6; 
	pub const RULE_loadStatement:usize = 7; 
	pub const RULE_replicationClause:usize = 8; 
	pub const RULE_exportStatement:usize = 9; 
	pub const RULE_importStatement:usize = 10; 
	pub const RULE_replDumpStatement:usize = 11; 
	pub const RULE_replDbPolicy:usize = 12; 
	pub const RULE_replLoadStatement:usize = 13; 
	pub const RULE_replConfigs:usize = 14; 
	pub const RULE_replConfigsList:usize = 15; 
	pub const RULE_replTableLevelPolicy:usize = 16; 
	pub const RULE_replStatusStatement:usize = 17; 
	pub const RULE_ddlStatement:usize = 18; 
	pub const RULE_ifExists:usize = 19; 
	pub const RULE_restrictOrCascade:usize = 20; 
	pub const RULE_ifNotExists:usize = 21; 
	pub const RULE_force:usize = 22; 
	pub const RULE_rewriteEnabled:usize = 23; 
	pub const RULE_rewriteDisabled:usize = 24; 
	pub const RULE_storedAsDirs:usize = 25; 
	pub const RULE_orReplace:usize = 26; 
	pub const RULE_createDatabaseStatement:usize = 27; 
	pub const RULE_dbLocation:usize = 28; 
	pub const RULE_dbManagedLocation:usize = 29; 
	pub const RULE_dbProperties:usize = 30; 
	pub const RULE_dbPropertiesList:usize = 31; 
	pub const RULE_dbConnectorName:usize = 32; 
	pub const RULE_switchDatabaseStatement:usize = 33; 
	pub const RULE_dropDatabaseStatement:usize = 34; 
	pub const RULE_databaseComment:usize = 35; 
	pub const RULE_truncateTableStatement:usize = 36; 
	pub const RULE_dropTableStatement:usize = 37; 
	pub const RULE_inputFileFormat:usize = 38; 
	pub const RULE_tabTypeExpr:usize = 39; 
	pub const RULE_partTypeExpr:usize = 40; 
	pub const RULE_tabPartColTypeExpr:usize = 41; 
	pub const RULE_descStatement:usize = 42; 
	pub const RULE_analyzeStatement:usize = 43; 
	pub const RULE_from_in:usize = 44; 
	pub const RULE_db_schema:usize = 45; 
	pub const RULE_showStatement:usize = 46; 
	pub const RULE_showTablesFilterExpr:usize = 47; 
	pub const RULE_lockStatement:usize = 48; 
	pub const RULE_lockDatabase:usize = 49; 
	pub const RULE_lockMode:usize = 50; 
	pub const RULE_unlockStatement:usize = 51; 
	pub const RULE_unlockDatabase:usize = 52; 
	pub const RULE_createRoleStatement:usize = 53; 
	pub const RULE_dropRoleStatement:usize = 54; 
	pub const RULE_grantPrivileges:usize = 55; 
	pub const RULE_revokePrivileges:usize = 56; 
	pub const RULE_grantRole:usize = 57; 
	pub const RULE_revokeRole:usize = 58; 
	pub const RULE_showRoleGrants:usize = 59; 
	pub const RULE_showRoles:usize = 60; 
	pub const RULE_showCurrentRole:usize = 61; 
	pub const RULE_setRole:usize = 62; 
	pub const RULE_showGrants:usize = 63; 
	pub const RULE_showRolePrincipals:usize = 64; 
	pub const RULE_privilegeIncludeColObject:usize = 65; 
	pub const RULE_privilegeObject:usize = 66; 
	pub const RULE_privObject:usize = 67; 
	pub const RULE_privObjectCols:usize = 68; 
	pub const RULE_privilegeList:usize = 69; 
	pub const RULE_privlegeDef:usize = 70; 
	pub const RULE_privilegeType:usize = 71; 
	pub const RULE_principalSpecification:usize = 72; 
	pub const RULE_principalName:usize = 73; 
	pub const RULE_withGrantOption:usize = 74; 
	pub const RULE_grantOptionFor:usize = 75; 
	pub const RULE_adminOptionFor:usize = 76; 
	pub const RULE_withAdminOption:usize = 77; 
	pub const RULE_metastoreCheck:usize = 78; 
	pub const RULE_resourceList:usize = 79; 
	pub const RULE_resource:usize = 80; 
	pub const RULE_resourceType:usize = 81; 
	pub const RULE_createFunctionStatement:usize = 82; 
	pub const RULE_dropFunctionStatement:usize = 83; 
	pub const RULE_reloadFunctionsStatement:usize = 84; 
	pub const RULE_createMacroStatement:usize = 85; 
	pub const RULE_dropMacroStatement:usize = 86; 
	pub const RULE_createIndexStatement:usize = 87; 
	pub const RULE_dropIndexStatement:usize = 88; 
	pub const RULE_createViewStatement:usize = 89; 
	pub const RULE_viewPartition:usize = 90; 
	pub const RULE_viewOrganization:usize = 91; 
	pub const RULE_viewClusterSpec:usize = 92; 
	pub const RULE_viewComplexSpec:usize = 93; 
	pub const RULE_viewDistSpec:usize = 94; 
	pub const RULE_viewSortSpec:usize = 95; 
	pub const RULE_dropViewStatement:usize = 96; 
	pub const RULE_createMaterializedViewStatement:usize = 97; 
	pub const RULE_dropMaterializedViewStatement:usize = 98; 
	pub const RULE_createScheduledQueryStatement:usize = 99; 
	pub const RULE_dropScheduledQueryStatement:usize = 100; 
	pub const RULE_alterScheduledQueryStatement:usize = 101; 
	pub const RULE_alterScheduledQueryChange:usize = 102; 
	pub const RULE_scheduleSpec:usize = 103; 
	pub const RULE_executedAsSpec:usize = 104; 
	pub const RULE_definedAsSpec:usize = 105; 
	pub const RULE_showFunctionIdentifier:usize = 106; 
	pub const RULE_showStmtIdentifier:usize = 107; 
	pub const RULE_tableComment:usize = 108; 
	pub const RULE_createTablePartitionSpec:usize = 109; 
	pub const RULE_createTablePartitionColumnTypeSpec:usize = 110; 
	pub const RULE_createTablePartitionColumnSpec:usize = 111; 
	pub const RULE_partitionTransformSpec:usize = 112; 
	pub const RULE_columnNameTransformConstraint:usize = 113; 
	pub const RULE_partitionTransformType:usize = 114; 
	pub const RULE_tableBuckets:usize = 115; 
	pub const RULE_tableImplBuckets:usize = 116; 
	pub const RULE_tableSkewed:usize = 117; 
	pub const RULE_rowFormat:usize = 118; 
	pub const RULE_recordReader:usize = 119; 
	pub const RULE_recordWriter:usize = 120; 
	pub const RULE_rowFormatSerde:usize = 121; 
	pub const RULE_rowFormatDelimited:usize = 122; 
	pub const RULE_tableRowFormat:usize = 123; 
	pub const RULE_tablePropertiesPrefixed:usize = 124; 
	pub const RULE_tableProperties:usize = 125; 
	pub const RULE_tablePropertiesList:usize = 126; 
	pub const RULE_keyValueProperty:usize = 127; 
	pub const RULE_keyProperty:usize = 128; 
	pub const RULE_tableRowFormatFieldIdentifier:usize = 129; 
	pub const RULE_tableRowFormatCollItemsIdentifier:usize = 130; 
	pub const RULE_tableRowFormatMapKeysIdentifier:usize = 131; 
	pub const RULE_tableRowFormatLinesIdentifier:usize = 132; 
	pub const RULE_tableRowNullFormat:usize = 133; 
	pub const RULE_tableFileFormat:usize = 134; 
	pub const RULE_tableLocation:usize = 135; 
	pub const RULE_columnNameTypeList:usize = 136; 
	pub const RULE_columnNameTypeOrConstraintList:usize = 137; 
	pub const RULE_columnNameColonTypeList:usize = 138; 
	pub const RULE_columnNameList:usize = 139; 
	pub const RULE_columnName:usize = 140; 
	pub const RULE_extColumnName:usize = 141; 
	pub const RULE_columnNameOrderList:usize = 142; 
	pub const RULE_columnParenthesesList:usize = 143; 
	pub const RULE_enableValidateSpecification:usize = 144; 
	pub const RULE_enableSpecification:usize = 145; 
	pub const RULE_validateSpecification:usize = 146; 
	pub const RULE_enforcedSpecification:usize = 147; 
	pub const RULE_relySpecification:usize = 148; 
	pub const RULE_createConstraint:usize = 149; 
	pub const RULE_alterConstraintWithName:usize = 150; 
	pub const RULE_tableLevelConstraint:usize = 151; 
	pub const RULE_pkUkConstraint:usize = 152; 
	pub const RULE_checkConstraint:usize = 153; 
	pub const RULE_createForeignKey:usize = 154; 
	pub const RULE_alterForeignKeyWithName:usize = 155; 
	pub const RULE_skewedValueElement:usize = 156; 
	pub const RULE_skewedColumnValuePairList:usize = 157; 
	pub const RULE_skewedColumnValuePair:usize = 158; 
	pub const RULE_skewedColumnValues:usize = 159; 
	pub const RULE_skewedColumnValue:usize = 160; 
	pub const RULE_skewedValueLocationElement:usize = 161; 
	pub const RULE_orderSpecification:usize = 162; 
	pub const RULE_nullOrdering:usize = 163; 
	pub const RULE_columnNameOrder:usize = 164; 
	pub const RULE_columnNameCommentList:usize = 165; 
	pub const RULE_columnNameComment:usize = 166; 
	pub const RULE_orderSpecificationRewrite:usize = 167; 
	pub const RULE_columnRefOrder:usize = 168; 
	pub const RULE_columnNameType:usize = 169; 
	pub const RULE_columnNameTypeOrConstraint:usize = 170; 
	pub const RULE_tableConstraint:usize = 171; 
	pub const RULE_columnNameTypeConstraint:usize = 172; 
	pub const RULE_columnConstraint:usize = 173; 
	pub const RULE_foreignKeyConstraint:usize = 174; 
	pub const RULE_colConstraint:usize = 175; 
	pub const RULE_alterColumnConstraint:usize = 176; 
	pub const RULE_alterForeignKeyConstraint:usize = 177; 
	pub const RULE_alterColConstraint:usize = 178; 
	pub const RULE_columnConstraintType:usize = 179; 
	pub const RULE_defaultVal:usize = 180; 
	pub const RULE_tableConstraintType:usize = 181; 
	pub const RULE_constraintOptsCreate:usize = 182; 
	pub const RULE_constraintOptsAlter:usize = 183; 
	pub const RULE_columnNameColonType:usize = 184; 
	pub const RULE_colType:usize = 185; 
	pub const RULE_colTypeList:usize = 186; 
	pub const RULE_type:usize = 187; 
	pub const RULE_primitiveType:usize = 188; 
	pub const RULE_listType:usize = 189; 
	pub const RULE_structType:usize = 190; 
	pub const RULE_mapType:usize = 191; 
	pub const RULE_unionType:usize = 192; 
	pub const RULE_setOperator:usize = 193; 
	pub const RULE_queryStatementExpression:usize = 194; 
	pub const RULE_queryStatementExpressionBody:usize = 195; 
	pub const RULE_withClause:usize = 196; 
	pub const RULE_cteStatement:usize = 197; 
	pub const RULE_fromStatement:usize = 198; 
	pub const RULE_singleFromStatement:usize = 199; 
	pub const RULE_regularBody:usize = 200; 
	pub const RULE_atomSelectStatement:usize = 201; 
	pub const RULE_selectStatement:usize = 202; 
	pub const RULE_setOpSelectStatement:usize = 203; 
	pub const RULE_selectStatementWithCTE:usize = 204; 
	pub const RULE_body:usize = 205; 
	pub const RULE_insertClause:usize = 206; 
	pub const RULE_destination:usize = 207; 
	pub const RULE_limitClause:usize = 208; 
	pub const RULE_deleteStatement:usize = 209; 
	pub const RULE_columnAssignmentClause:usize = 210; 
	pub const RULE_precedencePlusExpressionOrDefault:usize = 211; 
	pub const RULE_setColumnsClause:usize = 212; 
	pub const RULE_updateStatement:usize = 213; 
	pub const RULE_sqlTransactionStatement:usize = 214; 
	pub const RULE_startTransactionStatement:usize = 215; 
	pub const RULE_transactionMode:usize = 216; 
	pub const RULE_transactionAccessMode:usize = 217; 
	pub const RULE_isolationLevel:usize = 218; 
	pub const RULE_levelOfIsolation:usize = 219; 
	pub const RULE_commitStatement:usize = 220; 
	pub const RULE_rollbackStatement:usize = 221; 
	pub const RULE_setAutoCommitStatement:usize = 222; 
	pub const RULE_abortTransactionStatement:usize = 223; 
	pub const RULE_abortCompactionStatement:usize = 224; 
	pub const RULE_mergeStatement:usize = 225; 
	pub const RULE_whenClauses:usize = 226; 
	pub const RULE_whenNotMatchedClause:usize = 227; 
	pub const RULE_whenMatchedAndClause:usize = 228; 
	pub const RULE_whenMatchedThenClause:usize = 229; 
	pub const RULE_updateOrDelete:usize = 230; 
	pub const RULE_killQueryStatement:usize = 231; 
	pub const RULE_compactionId:usize = 232; 
	pub const RULE_compactionPool:usize = 233; 
	pub const RULE_compactionType:usize = 234; 
	pub const RULE_compactionStatus:usize = 235; 
	pub const RULE_alterStatement:usize = 236; 
	pub const RULE_alterTableStatementSuffix:usize = 237; 
	pub const RULE_alterTblPartitionStatementSuffix:usize = 238; 
	pub const RULE_alterStatementPartitionKeyType:usize = 239; 
	pub const RULE_alterViewStatementSuffix:usize = 240; 
	pub const RULE_alterMaterializedViewStatementSuffix:usize = 241; 
	pub const RULE_alterMaterializedViewSuffixRewrite:usize = 242; 
	pub const RULE_alterMaterializedViewSuffixRebuild:usize = 243; 
	pub const RULE_alterDatabaseStatementSuffix:usize = 244; 
	pub const RULE_alterDatabaseSuffixProperties:usize = 245; 
	pub const RULE_alterDatabaseSuffixSetOwner:usize = 246; 
	pub const RULE_alterDatabaseSuffixSetLocation:usize = 247; 
	pub const RULE_alterDatabaseSuffixSetManagedLocation:usize = 248; 
	pub const RULE_alterStatementSuffixRename:usize = 249; 
	pub const RULE_alterStatementSuffixAddCol:usize = 250; 
	pub const RULE_alterStatementSuffixAddConstraint:usize = 251; 
	pub const RULE_alterStatementSuffixUpdateColumns:usize = 252; 
	pub const RULE_alterStatementSuffixProtections:usize = 253; 
	pub const RULE_alterStatementSuffixDropConstraint:usize = 254; 
	pub const RULE_alterStatementSuffixRenameCol:usize = 255; 
	pub const RULE_alterStatementSuffixUpdateStatsCol:usize = 256; 
	pub const RULE_alterStatementSuffixUpdateStats:usize = 257; 
	pub const RULE_alterStatementChangeColPosition:usize = 258; 
	pub const RULE_alterStatementSuffixAddPartitions:usize = 259; 
	pub const RULE_alterStatementSuffixAddPartitionsElement:usize = 260; 
	pub const RULE_alterStatementSuffixTouch:usize = 261; 
	pub const RULE_alterStatementSuffixArchive:usize = 262; 
	pub const RULE_alterStatementSuffixUnArchive:usize = 263; 
	pub const RULE_partitionLocation:usize = 264; 
	pub const RULE_alterStatementSuffixDropPartitions:usize = 265; 
	pub const RULE_alterStatementSuffixProperties:usize = 266; 
	pub const RULE_alterViewSuffixProperties:usize = 267; 
	pub const RULE_alterStatementSuffixSerdeProperties:usize = 268; 
	pub const RULE_tablePartitionPrefix:usize = 269; 
	pub const RULE_alterStatementSuffixFileFormat:usize = 270; 
	pub const RULE_alterStatementSuffixClusterbySortby:usize = 271; 
	pub const RULE_alterTblPartitionStatementSuffixSkewedLocation:usize = 272; 
	pub const RULE_skewedLocations:usize = 273; 
	pub const RULE_skewedLocationsList:usize = 274; 
	pub const RULE_skewedLocationMap:usize = 275; 
	pub const RULE_alterStatementSuffixLocation:usize = 276; 
	pub const RULE_alterStatementSuffixSkewedby:usize = 277; 
	pub const RULE_alterStatementSuffixExchangePartition:usize = 278; 
	pub const RULE_alterStatementSuffixRenamePart:usize = 279; 
	pub const RULE_alterStatementSuffixStatsPart:usize = 280; 
	pub const RULE_alterStatementSuffixMergeFiles:usize = 281; 
	pub const RULE_alterStatementSuffixBucketNum:usize = 282; 
	pub const RULE_blocking:usize = 283; 
	pub const RULE_compactPool:usize = 284; 
	pub const RULE_alterStatementSuffixCompact:usize = 285; 
	pub const RULE_alterStatementSuffixSetOwner:usize = 286; 
	pub const RULE_alterStatementSuffixSetPartSpec:usize = 287; 
	pub const RULE_alterStatementSuffixExecute:usize = 288; 
	pub const RULE_alterIndexStatementSuffix:usize = 289; 
	pub const RULE_fileFormat:usize = 290; 
	pub const RULE_alterDataConnectorStatementSuffix:usize = 291; 
	pub const RULE_alterDataConnectorSuffixProperties:usize = 292; 
	pub const RULE_alterDataConnectorSuffixSetOwner:usize = 293; 
	pub const RULE_alterDataConnectorSuffixSetUrl:usize = 294; 
	pub const RULE_likeTableOrFile:usize = 295; 
	pub const RULE_createTableStatement:usize = 296; 
	pub const RULE_createDataConnectorStatement:usize = 297; 
	pub const RULE_dataConnectorComment:usize = 298; 
	pub const RULE_dataConnectorUrl:usize = 299; 
	pub const RULE_dataConnectorType:usize = 300; 
	pub const RULE_dcProperties:usize = 301; 
	pub const RULE_dropDataConnectorStatement:usize = 302; 
	pub const RULE_tableAllColumns:usize = 303; 
	pub const RULE_tableOrColumn:usize = 304; 
	pub const RULE_defaultValue:usize = 305; 
	pub const RULE_expressionList:usize = 306; 
	pub const RULE_aliasList:usize = 307; 
	pub const RULE_fromClause:usize = 308; 
	pub const RULE_fromSource:usize = 309; 
	pub const RULE_atomjoinSource:usize = 310; 
	pub const RULE_joinSource:usize = 311; 
	pub const RULE_joinSourcePart:usize = 312; 
	pub const RULE_uniqueJoinSource:usize = 313; 
	pub const RULE_uniqueJoinExpr:usize = 314; 
	pub const RULE_uniqueJoinToken:usize = 315; 
	pub const RULE_joinToken:usize = 316; 
	pub const RULE_lateralView:usize = 317; 
	pub const RULE_tableAlias:usize = 318; 
	pub const RULE_tableBucketSample:usize = 319; 
	pub const RULE_splitSample:usize = 320; 
	pub const RULE_tableSample:usize = 321; 
	pub const RULE_tableSource:usize = 322; 
	pub const RULE_asOfClause:usize = 323; 
	pub const RULE_uniqueJoinTableSource:usize = 324; 
	pub const RULE_tableName:usize = 325; 
	pub const RULE_viewName:usize = 326; 
	pub const RULE_subQuerySource:usize = 327; 
	pub const RULE_partitioningSpec:usize = 328; 
	pub const RULE_partitionTableFunctionSource:usize = 329; 
	pub const RULE_partitionedTableFunction:usize = 330; 
	pub const RULE_whereClause:usize = 331; 
	pub const RULE_searchCondition:usize = 332; 
	pub const RULE_valuesSource:usize = 333; 
	pub const RULE_valuesClause:usize = 334; 
	pub const RULE_valuesTableConstructor:usize = 335; 
	pub const RULE_valueRowConstructor:usize = 336; 
	pub const RULE_firstValueRowConstructor:usize = 337; 
	pub const RULE_virtualTableSource:usize = 338; 
	pub const RULE_selectClause:usize = 339; 
	pub const RULE_all_distinct:usize = 340; 
	pub const RULE_selectList:usize = 341; 
	pub const RULE_selectTrfmClause:usize = 342; 
	pub const RULE_selectItem:usize = 343; 
	pub const RULE_trfmClause:usize = 344; 
	pub const RULE_selectExpression:usize = 345; 
	pub const RULE_selectExpressionList:usize = 346; 
	pub const RULE_window_clause:usize = 347; 
	pub const RULE_window_defn:usize = 348; 
	pub const RULE_window_specification:usize = 349; 
	pub const RULE_window_frame:usize = 350; 
	pub const RULE_window_range_expression:usize = 351; 
	pub const RULE_window_value_expression:usize = 352; 
	pub const RULE_window_frame_start_boundary:usize = 353; 
	pub const RULE_window_frame_boundary:usize = 354; 
	pub const RULE_groupByClause:usize = 355; 
	pub const RULE_groupby_expression:usize = 356; 
	pub const RULE_groupByEmpty:usize = 357; 
	pub const RULE_rollupStandard:usize = 358; 
	pub const RULE_rollupOldSyntax:usize = 359; 
	pub const RULE_groupingSetExpression:usize = 360; 
	pub const RULE_groupingSetExpressionMultiple:usize = 361; 
	pub const RULE_groupingExpressionSingle:usize = 362; 
	pub const RULE_havingClause:usize = 363; 
	pub const RULE_qualifyClause:usize = 364; 
	pub const RULE_havingCondition:usize = 365; 
	pub const RULE_expressionsInParenthesis:usize = 366; 
	pub const RULE_expressionsNotInParenthesis:usize = 367; 
	pub const RULE_expressionPart:usize = 368; 
	pub const RULE_expressionOrDefault:usize = 369; 
	pub const RULE_firstExpressionsWithAlias:usize = 370; 
	pub const RULE_expressionWithAlias:usize = 371; 
	pub const RULE_expressions:usize = 372; 
	pub const RULE_columnRefOrderInParenthesis:usize = 373; 
	pub const RULE_columnRefOrderNotInParenthesis:usize = 374; 
	pub const RULE_orderByClause:usize = 375; 
	pub const RULE_clusterByClause:usize = 376; 
	pub const RULE_partitionByClause:usize = 377; 
	pub const RULE_distributeByClause:usize = 378; 
	pub const RULE_sortByClause:usize = 379; 
	pub const RULE_trimFunction:usize = 380; 
	pub const RULE_function_:usize = 381; 
	pub const RULE_null_treatment:usize = 382; 
	pub const RULE_functionName:usize = 383; 
	pub const RULE_castExpression:usize = 384; 
	pub const RULE_caseExpression:usize = 385; 
	pub const RULE_whenExpression:usize = 386; 
	pub const RULE_floorExpression:usize = 387; 
	pub const RULE_floorDateQualifiers:usize = 388; 
	pub const RULE_extractExpression:usize = 389; 
	pub const RULE_timeQualifiers:usize = 390; 
	pub const RULE_constant:usize = 391; 
	pub const RULE_prepareStmtParam:usize = 392; 
	pub const RULE_parameterIdx:usize = 393; 
	pub const RULE_stringLiteralSequence:usize = 394; 
	pub const RULE_charSetStringLiteral:usize = 395; 
	pub const RULE_dateLiteral:usize = 396; 
	pub const RULE_timestampLiteral:usize = 397; 
	pub const RULE_timestampLocalTZLiteral:usize = 398; 
	pub const RULE_intervalValue:usize = 399; 
	pub const RULE_intervalLiteral:usize = 400; 
	pub const RULE_intervalExpression:usize = 401; 
	pub const RULE_intervalQualifiers:usize = 402; 
	pub const RULE_expression:usize = 403; 
	pub const RULE_atomExpression:usize = 404; 
	pub const RULE_precedenceFieldExpression:usize = 405; 
	pub const RULE_precedenceUnaryOperator:usize = 406; 
	pub const RULE_precedenceUnaryPrefixExpression:usize = 407; 
	pub const RULE_precedenceBitwiseXorOperator:usize = 408; 
	pub const RULE_precedenceBitwiseXorExpression:usize = 409; 
	pub const RULE_precedenceStarOperator:usize = 410; 
	pub const RULE_precedenceStarExpression:usize = 411; 
	pub const RULE_precedencePlusOperator:usize = 412; 
	pub const RULE_precedencePlusExpression:usize = 413; 
	pub const RULE_precedenceConcatenateOperator:usize = 414; 
	pub const RULE_precedenceConcatenateExpression:usize = 415; 
	pub const RULE_precedenceAmpersandOperator:usize = 416; 
	pub const RULE_precedenceAmpersandExpression:usize = 417; 
	pub const RULE_precedenceBitwiseOrOperator:usize = 418; 
	pub const RULE_precedenceBitwiseOrExpression:usize = 419; 
	pub const RULE_precedenceRegexpOperator:usize = 420; 
	pub const RULE_precedenceSimilarOperator:usize = 421; 
	pub const RULE_subQueryExpression:usize = 422; 
	pub const RULE_precedenceSimilarExpression:usize = 423; 
	pub const RULE_precedenceSimilarExpressionMain:usize = 424; 
	pub const RULE_precedenceSimilarExpressionPart:usize = 425; 
	pub const RULE_precedenceSimilarExpressionAtom:usize = 426; 
	pub const RULE_precedenceSimilarExpressionQuantifierPredicate:usize = 427; 
	pub const RULE_quantifierType:usize = 428; 
	pub const RULE_precedenceSimilarExpressionIn:usize = 429; 
	pub const RULE_precedenceSimilarExpressionPartNot:usize = 430; 
	pub const RULE_precedenceDistinctOperator:usize = 431; 
	pub const RULE_precedenceEqualOperator:usize = 432; 
	pub const RULE_precedenceEqualExpression:usize = 433; 
	pub const RULE_isCondition:usize = 434; 
	pub const RULE_precedenceUnarySuffixExpression:usize = 435; 
	pub const RULE_precedenceNotOperator:usize = 436; 
	pub const RULE_precedenceNotExpression:usize = 437; 
	pub const RULE_precedenceAndOperator:usize = 438; 
	pub const RULE_precedenceAndExpression:usize = 439; 
	pub const RULE_precedenceOrOperator:usize = 440; 
	pub const RULE_precedenceOrExpression:usize = 441; 
	pub const RULE_booleanValue:usize = 442; 
	pub const RULE_booleanValueTok:usize = 443; 
	pub const RULE_tableOrPartition:usize = 444; 
	pub const RULE_partitionSpec:usize = 445; 
	pub const RULE_partitionVal:usize = 446; 
	pub const RULE_partitionSelectorSpec:usize = 447; 
	pub const RULE_partitionSelectorVal:usize = 448; 
	pub const RULE_partitionSelectorOperator:usize = 449; 
	pub const RULE_subQuerySelectorOperator:usize = 450; 
	pub const RULE_sysFuncNames:usize = 451; 
	pub const RULE_descFuncNames:usize = 452; 
	pub const RULE_id_:usize = 453; 
	pub const RULE_functionIdentifier:usize = 454; 
	pub const RULE_principalIdentifier:usize = 455; 
	pub const RULE_nonReserved:usize = 456; 
	pub const RULE_sql11ReservedKeywordsUsedAsFunctionName:usize = 457; 
	pub const RULE_hint:usize = 458; 
	pub const RULE_hintList:usize = 459; 
	pub const RULE_hintItem:usize = 460; 
	pub const RULE_hintName:usize = 461; 
	pub const RULE_hintArgs:usize = 462; 
	pub const RULE_hintArgName:usize = 463; 
	pub const RULE_prepareStatement:usize = 464; 
	pub const RULE_executeStatement:usize = 465; 
	pub const RULE_executeParamList:usize = 466; 
	pub const RULE_resourcePlanDdlStatements:usize = 467; 
	pub const RULE_rpAssign:usize = 468; 
	pub const RULE_rpAssignList:usize = 469; 
	pub const RULE_rpUnassign:usize = 470; 
	pub const RULE_rpUnassignList:usize = 471; 
	pub const RULE_createResourcePlanStatement:usize = 472; 
	pub const RULE_withReplace:usize = 473; 
	pub const RULE_activate:usize = 474; 
	pub const RULE_enable:usize = 475; 
	pub const RULE_disable:usize = 476; 
	pub const RULE_unmanaged:usize = 477; 
	pub const RULE_alterResourcePlanStatement:usize = 478; 
	pub const RULE_globalWmStatement:usize = 479; 
	pub const RULE_replaceResourcePlanStatement:usize = 480; 
	pub const RULE_dropResourcePlanStatement:usize = 481; 
	pub const RULE_poolPath:usize = 482; 
	pub const RULE_triggerExpression:usize = 483; 
	pub const RULE_triggerExpressionStandalone:usize = 484; 
	pub const RULE_triggerOrExpression:usize = 485; 
	pub const RULE_triggerAndExpression:usize = 486; 
	pub const RULE_triggerAtomExpression:usize = 487; 
	pub const RULE_triggerLiteral:usize = 488; 
	pub const RULE_comparisionOperator:usize = 489; 
	pub const RULE_triggerActionExpression:usize = 490; 
	pub const RULE_triggerActionExpressionStandalone:usize = 491; 
	pub const RULE_createTriggerStatement:usize = 492; 
	pub const RULE_alterTriggerStatement:usize = 493; 
	pub const RULE_dropTriggerStatement:usize = 494; 
	pub const RULE_poolAssign:usize = 495; 
	pub const RULE_poolAssignList:usize = 496; 
	pub const RULE_createPoolStatement:usize = 497; 
	pub const RULE_alterPoolStatement:usize = 498; 
	pub const RULE_dropPoolStatement:usize = 499; 
	pub const RULE_createMappingStatement:usize = 500; 
	pub const RULE_alterMappingStatement:usize = 501; 
	pub const RULE_dropMappingStatement:usize = 502;
	pub const ruleNames: [&'static str; 503] =  [
		"program", "statement", "explainStatement", "explainOption", "vectorizationOnly", 
		"vectorizatonDetail", "execStatement", "loadStatement", "replicationClause", 
		"exportStatement", "importStatement", "replDumpStatement", "replDbPolicy", 
		"replLoadStatement", "replConfigs", "replConfigsList", "replTableLevelPolicy", 
		"replStatusStatement", "ddlStatement", "ifExists", "restrictOrCascade", 
		"ifNotExists", "force", "rewriteEnabled", "rewriteDisabled", "storedAsDirs", 
		"orReplace", "createDatabaseStatement", "dbLocation", "dbManagedLocation", 
		"dbProperties", "dbPropertiesList", "dbConnectorName", "switchDatabaseStatement", 
		"dropDatabaseStatement", "databaseComment", "truncateTableStatement", 
		"dropTableStatement", "inputFileFormat", "tabTypeExpr", "partTypeExpr", 
		"tabPartColTypeExpr", "descStatement", "analyzeStatement", "from_in", 
		"db_schema", "showStatement", "showTablesFilterExpr", "lockStatement", 
		"lockDatabase", "lockMode", "unlockStatement", "unlockDatabase", "createRoleStatement", 
		"dropRoleStatement", "grantPrivileges", "revokePrivileges", "grantRole", 
		"revokeRole", "showRoleGrants", "showRoles", "showCurrentRole", "setRole", 
		"showGrants", "showRolePrincipals", "privilegeIncludeColObject", "privilegeObject", 
		"privObject", "privObjectCols", "privilegeList", "privlegeDef", "privilegeType", 
		"principalSpecification", "principalName", "withGrantOption", "grantOptionFor", 
		"adminOptionFor", "withAdminOption", "metastoreCheck", "resourceList", 
		"resource", "resourceType", "createFunctionStatement", "dropFunctionStatement", 
		"reloadFunctionsStatement", "createMacroStatement", "dropMacroStatement", 
		"createIndexStatement", "dropIndexStatement", "createViewStatement", "viewPartition", 
		"viewOrganization", "viewClusterSpec", "viewComplexSpec", "viewDistSpec", 
		"viewSortSpec", "dropViewStatement", "createMaterializedViewStatement", 
		"dropMaterializedViewStatement", "createScheduledQueryStatement", "dropScheduledQueryStatement", 
		"alterScheduledQueryStatement", "alterScheduledQueryChange", "scheduleSpec", 
		"executedAsSpec", "definedAsSpec", "showFunctionIdentifier", "showStmtIdentifier", 
		"tableComment", "createTablePartitionSpec", "createTablePartitionColumnTypeSpec", 
		"createTablePartitionColumnSpec", "partitionTransformSpec", "columnNameTransformConstraint", 
		"partitionTransformType", "tableBuckets", "tableImplBuckets", "tableSkewed", 
		"rowFormat", "recordReader", "recordWriter", "rowFormatSerde", "rowFormatDelimited", 
		"tableRowFormat", "tablePropertiesPrefixed", "tableProperties", "tablePropertiesList", 
		"keyValueProperty", "keyProperty", "tableRowFormatFieldIdentifier", "tableRowFormatCollItemsIdentifier", 
		"tableRowFormatMapKeysIdentifier", "tableRowFormatLinesIdentifier", "tableRowNullFormat", 
		"tableFileFormat", "tableLocation", "columnNameTypeList", "columnNameTypeOrConstraintList", 
		"columnNameColonTypeList", "columnNameList", "columnName", "extColumnName", 
		"columnNameOrderList", "columnParenthesesList", "enableValidateSpecification", 
		"enableSpecification", "validateSpecification", "enforcedSpecification", 
		"relySpecification", "createConstraint", "alterConstraintWithName", "tableLevelConstraint", 
		"pkUkConstraint", "checkConstraint", "createForeignKey", "alterForeignKeyWithName", 
		"skewedValueElement", "skewedColumnValuePairList", "skewedColumnValuePair", 
		"skewedColumnValues", "skewedColumnValue", "skewedValueLocationElement", 
		"orderSpecification", "nullOrdering", "columnNameOrder", "columnNameCommentList", 
		"columnNameComment", "orderSpecificationRewrite", "columnRefOrder", "columnNameType", 
		"columnNameTypeOrConstraint", "tableConstraint", "columnNameTypeConstraint", 
		"columnConstraint", "foreignKeyConstraint", "colConstraint", "alterColumnConstraint", 
		"alterForeignKeyConstraint", "alterColConstraint", "columnConstraintType", 
		"defaultVal", "tableConstraintType", "constraintOptsCreate", "constraintOptsAlter", 
		"columnNameColonType", "colType", "colTypeList", "type", "primitiveType", 
		"listType", "structType", "mapType", "unionType", "setOperator", "queryStatementExpression", 
		"queryStatementExpressionBody", "withClause", "cteStatement", "fromStatement", 
		"singleFromStatement", "regularBody", "atomSelectStatement", "selectStatement", 
		"setOpSelectStatement", "selectStatementWithCTE", "body", "insertClause", 
		"destination", "limitClause", "deleteStatement", "columnAssignmentClause", 
		"precedencePlusExpressionOrDefault", "setColumnsClause", "updateStatement", 
		"sqlTransactionStatement", "startTransactionStatement", "transactionMode", 
		"transactionAccessMode", "isolationLevel", "levelOfIsolation", "commitStatement", 
		"rollbackStatement", "setAutoCommitStatement", "abortTransactionStatement", 
		"abortCompactionStatement", "mergeStatement", "whenClauses", "whenNotMatchedClause", 
		"whenMatchedAndClause", "whenMatchedThenClause", "updateOrDelete", "killQueryStatement", 
		"compactionId", "compactionPool", "compactionType", "compactionStatus", 
		"alterStatement", "alterTableStatementSuffix", "alterTblPartitionStatementSuffix", 
		"alterStatementPartitionKeyType", "alterViewStatementSuffix", "alterMaterializedViewStatementSuffix", 
		"alterMaterializedViewSuffixRewrite", "alterMaterializedViewSuffixRebuild", 
		"alterDatabaseStatementSuffix", "alterDatabaseSuffixProperties", "alterDatabaseSuffixSetOwner", 
		"alterDatabaseSuffixSetLocation", "alterDatabaseSuffixSetManagedLocation", 
		"alterStatementSuffixRename", "alterStatementSuffixAddCol", "alterStatementSuffixAddConstraint", 
		"alterStatementSuffixUpdateColumns", "alterStatementSuffixProtections", 
		"alterStatementSuffixDropConstraint", "alterStatementSuffixRenameCol", 
		"alterStatementSuffixUpdateStatsCol", "alterStatementSuffixUpdateStats", 
		"alterStatementChangeColPosition", "alterStatementSuffixAddPartitions", 
		"alterStatementSuffixAddPartitionsElement", "alterStatementSuffixTouch", 
		"alterStatementSuffixArchive", "alterStatementSuffixUnArchive", "partitionLocation", 
		"alterStatementSuffixDropPartitions", "alterStatementSuffixProperties", 
		"alterViewSuffixProperties", "alterStatementSuffixSerdeProperties", "tablePartitionPrefix", 
		"alterStatementSuffixFileFormat", "alterStatementSuffixClusterbySortby", 
		"alterTblPartitionStatementSuffixSkewedLocation", "skewedLocations", "skewedLocationsList", 
		"skewedLocationMap", "alterStatementSuffixLocation", "alterStatementSuffixSkewedby", 
		"alterStatementSuffixExchangePartition", "alterStatementSuffixRenamePart", 
		"alterStatementSuffixStatsPart", "alterStatementSuffixMergeFiles", "alterStatementSuffixBucketNum", 
		"blocking", "compactPool", "alterStatementSuffixCompact", "alterStatementSuffixSetOwner", 
		"alterStatementSuffixSetPartSpec", "alterStatementSuffixExecute", "alterIndexStatementSuffix", 
		"fileFormat", "alterDataConnectorStatementSuffix", "alterDataConnectorSuffixProperties", 
		"alterDataConnectorSuffixSetOwner", "alterDataConnectorSuffixSetUrl", 
		"likeTableOrFile", "createTableStatement", "createDataConnectorStatement", 
		"dataConnectorComment", "dataConnectorUrl", "dataConnectorType", "dcProperties", 
		"dropDataConnectorStatement", "tableAllColumns", "tableOrColumn", "defaultValue", 
		"expressionList", "aliasList", "fromClause", "fromSource", "atomjoinSource", 
		"joinSource", "joinSourcePart", "uniqueJoinSource", "uniqueJoinExpr", 
		"uniqueJoinToken", "joinToken", "lateralView", "tableAlias", "tableBucketSample", 
		"splitSample", "tableSample", "tableSource", "asOfClause", "uniqueJoinTableSource", 
		"tableName", "viewName", "subQuerySource", "partitioningSpec", "partitionTableFunctionSource", 
		"partitionedTableFunction", "whereClause", "searchCondition", "valuesSource", 
		"valuesClause", "valuesTableConstructor", "valueRowConstructor", "firstValueRowConstructor", 
		"virtualTableSource", "selectClause", "all_distinct", "selectList", "selectTrfmClause", 
		"selectItem", "trfmClause", "selectExpression", "selectExpressionList", 
		"window_clause", "window_defn", "window_specification", "window_frame", 
		"window_range_expression", "window_value_expression", "window_frame_start_boundary", 
		"window_frame_boundary", "groupByClause", "groupby_expression", "groupByEmpty", 
		"rollupStandard", "rollupOldSyntax", "groupingSetExpression", "groupingSetExpressionMultiple", 
		"groupingExpressionSingle", "havingClause", "qualifyClause", "havingCondition", 
		"expressionsInParenthesis", "expressionsNotInParenthesis", "expressionPart", 
		"expressionOrDefault", "firstExpressionsWithAlias", "expressionWithAlias", 
		"expressions", "columnRefOrderInParenthesis", "columnRefOrderNotInParenthesis", 
		"orderByClause", "clusterByClause", "partitionByClause", "distributeByClause", 
		"sortByClause", "trimFunction", "function_", "null_treatment", "functionName", 
		"castExpression", "caseExpression", "whenExpression", "floorExpression", 
		"floorDateQualifiers", "extractExpression", "timeQualifiers", "constant", 
		"prepareStmtParam", "parameterIdx", "stringLiteralSequence", "charSetStringLiteral", 
		"dateLiteral", "timestampLiteral", "timestampLocalTZLiteral", "intervalValue", 
		"intervalLiteral", "intervalExpression", "intervalQualifiers", "expression", 
		"atomExpression", "precedenceFieldExpression", "precedenceUnaryOperator", 
		"precedenceUnaryPrefixExpression", "precedenceBitwiseXorOperator", "precedenceBitwiseXorExpression", 
		"precedenceStarOperator", "precedenceStarExpression", "precedencePlusOperator", 
		"precedencePlusExpression", "precedenceConcatenateOperator", "precedenceConcatenateExpression", 
		"precedenceAmpersandOperator", "precedenceAmpersandExpression", "precedenceBitwiseOrOperator", 
		"precedenceBitwiseOrExpression", "precedenceRegexpOperator", "precedenceSimilarOperator", 
		"subQueryExpression", "precedenceSimilarExpression", "precedenceSimilarExpressionMain", 
		"precedenceSimilarExpressionPart", "precedenceSimilarExpressionAtom", 
		"precedenceSimilarExpressionQuantifierPredicate", "quantifierType", "precedenceSimilarExpressionIn", 
		"precedenceSimilarExpressionPartNot", "precedenceDistinctOperator", "precedenceEqualOperator", 
		"precedenceEqualExpression", "isCondition", "precedenceUnarySuffixExpression", 
		"precedenceNotOperator", "precedenceNotExpression", "precedenceAndOperator", 
		"precedenceAndExpression", "precedenceOrOperator", "precedenceOrExpression", 
		"booleanValue", "booleanValueTok", "tableOrPartition", "partitionSpec", 
		"partitionVal", "partitionSelectorSpec", "partitionSelectorVal", "partitionSelectorOperator", 
		"subQuerySelectorOperator", "sysFuncNames", "descFuncNames", "id_", "functionIdentifier", 
		"principalIdentifier", "nonReserved", "sql11ReservedKeywordsUsedAsFunctionName", 
		"hint", "hintList", "hintItem", "hintName", "hintArgs", "hintArgName", 
		"prepareStatement", "executeStatement", "executeParamList", "resourcePlanDdlStatements", 
		"rpAssign", "rpAssignList", "rpUnassign", "rpUnassignList", "createResourcePlanStatement", 
		"withReplace", "activate", "enable", "disable", "unmanaged", "alterResourcePlanStatement", 
		"globalWmStatement", "replaceResourcePlanStatement", "dropResourcePlanStatement", 
		"poolPath", "triggerExpression", "triggerExpressionStandalone", "triggerOrExpression", 
		"triggerAndExpression", "triggerAtomExpression", "triggerLiteral", "comparisionOperator", 
		"triggerActionExpression", "triggerActionExpressionStandalone", "createTriggerStatement", 
		"alterTriggerStatement", "dropTriggerStatement", "poolAssign", "poolAssignList", 
		"createPoolStatement", "alterPoolStatement", "dropPoolStatement", "createMappingStatement", 
		"alterMappingStatement", "dropMappingStatement"
	];


	pub const _LITERAL_NAMES: [Option<&'static str>;411] = [
		None, Some("'ABORT'"), Some("'ACTIVATE'"), Some("'ACTIVE'"), Some("'ADD'"), 
		Some("'ADMIN'"), Some("'AFTER'"), Some("'ALL'"), Some("'ALLOC_FRACTION'"), 
		Some("'ALTER'"), Some("'ANALYZE'"), Some("'AND'"), Some("'ANTI'"), Some("'ANY'"), 
		Some("'APPLICATION'"), Some("'ARCHIVE'"), Some("'ARRAY'"), Some("'AS'"), 
		Some("'ASC'"), Some("'AST'"), Some("'AT'"), Some("'AUTHORIZATION'"), Some("'AUTOCOMMIT'"), 
		Some("'BATCH'"), Some("'BEFORE'"), Some("'BETWEEN'"), Some("'BIGINT'"), 
		Some("'BINARY'"), Some("'BOOLEAN'"), Some("'BOTH'"), Some("'BUCKET'"), 
		Some("'BUCKETS'"), Some("'BY'"), Some("'CACHE'"), Some("'CASCADE'"), Some("'CASE'"), 
		Some("'CAST'"), Some("'CBO'"), Some("'CHANGE'"), Some("'CHAR'"), Some("'CHECK'"), 
		Some("'CLUSTER'"), Some("'CLUSTERED'"), Some("'CLUSTERSTATUS'"), Some("'COLLECTION'"), 
		Some("'COLUMN'"), Some("'COLUMNS'"), Some("'COMMENT'"), Some("'COMMIT'"), 
		Some("'COMPACT'"), Some("'COMPACTIONS'"), Some("'COMPACTIONID'"), Some("'COMPUTE'"), 
		Some("'CONCATENATE'"), Some("'CONF'"), Some("'CONSTRAINT'"), Some("'CONTINUE'"), 
		Some("'COST'"), Some("'CREATE'"), Some("'CRON'"), Some("'CROSS'"), Some("'CUBE'"), 
		Some("'CURRENT'"), Some("'CURRENT_DATE'"), Some("'CURRENT_TIMESTAMP'"), 
		Some("'CURSOR'"), Some("'DATA'"), Some("'DATABASE'"), Some("'DATABASES'"), 
		Some("'CONNECTOR'"), Some("'CONNECTORS'"), Some("'DATE'"), Some("'DATETIME'"), 
		None, Some("'DAYOFWEEK'"), Some("'DBPROPERTIES'"), Some("'DCPROPERTIES'"), 
		Some("'DDL'"), Some("'DEBUG'"), None, Some("'DEFAULT'"), Some("'DEFERRED'"), 
		Some("'DEFINED'"), Some("'DELETE'"), Some("'DELIMITED'"), Some("'DEPENDENCY'"), 
		Some("'DESC'"), Some("'DESCRIBE'"), Some("'DETAIL'"), Some("'DIRECTORIES'"), 
		Some("'DIRECTORY'"), None, Some("'DISTINCT'"), Some("'DISTRIBUTE'"), Some("'DISTRIBUTED'"), 
		Some("'DO'"), Some("'DOUBLE'"), Some("'DROP'"), Some("'DUMP'"), Some("'$ELEM$'"), 
		Some("'ELSE'"), None, Some("'END'"), Some("'ENFORCED'"), Some("'ESCAPED'"), 
		Some("'EVERY'"), Some("'EXCEPT'"), Some("'EXCHANGE'"), Some("'EXCLUSIVE'"), 
		Some("'EXECUTE'"), Some("'EXECUTED'"), Some("'EXISTS'"), Some("'EXPIRE_SNAPSHOTS'"), 
		Some("'EXPLAIN'"), Some("'EXPORT'"), Some("'EXPRESSION'"), Some("'EXTENDED'"), 
		Some("'EXTERNAL'"), Some("'EXTRACT'"), Some("'FALSE'"), Some("'FETCH'"), 
		Some("'FIELDS'"), Some("'FILE'"), Some("'FILEFORMAT'"), Some("'FIRST'"), 
		Some("'FLOAT'"), Some("'FLOOR'"), Some("'FOLLOWING'"), Some("'FOR'"), 
		Some("'FORCE'"), Some("'FOREIGN'"), Some("'FORMAT'"), Some("'FORMATTED'"), 
		Some("'FROM'"), Some("'FULL'"), Some("'FUNCTION'"), Some("'FUNCTIONS'"), 
		Some("'GRANT'"), Some("'GROUP'"), Some("'GROUPING'"), Some("'HAVING'"), 
		Some("'HOLD_DDLTIME'"), None, Some("'IDXPROPERTIES'"), Some("'IF'"), Some("'IGNORE'"), 
		Some("'IMPORT'"), Some("'IN'"), Some("'INDEX'"), Some("'INDEXES'"), Some("'INNER'"), 
		Some("'INPATH'"), Some("'INPUTDRIVER'"), Some("'INPUTFORMAT'"), Some("'INSERT'"), 
		None, Some("'INTERSECT'"), Some("'INTERVAL'"), Some("'INTO'"), Some("'IS'"), 
		Some("'ISOLATION'"), Some("'ITEMS'"), Some("'JAR'"), Some("'JOIN'"), Some("'JOINCOST'"), 
		Some("'KEY'"), Some("'KEYS'"), Some("'$KEY$'"), Some("'KILL'"), Some("'LAST'"), 
		Some("'LATERAL'"), Some("'LEADING'"), Some("'LEFT'"), Some("'LESS'"), 
		Some("'LEVEL'"), Some("'LIKE'"), Some("'LIMIT'"), Some("'LINES'"), Some("'LOAD'"), 
		Some("'LOCAL'"), Some("'LOCATION'"), Some("'LOCK'"), Some("'LOCKS'"), 
		Some("'LOGICAL'"), Some("'LONG'"), Some("'MACRO'"), Some("'MANAGED'"), 
		Some("'MANAGEDLOCATION'"), Some("'MANAGEMENT'"), Some("'MAP'"), Some("'MAPJOIN'"), 
		Some("'MAPPING'"), Some("'MATCHED'"), Some("'MATERIALIZED'"), Some("'MERGE'"), 
		Some("'METADATA'"), Some("'MINUS'"), None, None, Some("'MORE'"), Some("'MOVE'"), 
		Some("'MSCK'"), Some("'NONE'"), Some("'NORELY'"), Some("'NOSCAN'"), None, 
		Some("'NOVALIDATE'"), Some("'NO_DROP'"), Some("'NULL'"), Some("'NULLS'"), 
		Some("'OF'"), Some("'OFFLINE'"), Some("'OFFSET'"), Some("'ON'"), Some("'ONLY'"), 
		Some("'OPERATOR'"), Some("'OPTION'"), Some("'OR'"), Some("'ORDER'"), Some("'OUT'"), 
		Some("'OUTER'"), Some("'OUTPUTDRIVER'"), Some("'OUTPUTFORMAT'"), Some("'OVER'"), 
		Some("'OVERWRITE'"), Some("'OWNER'"), Some("'PARTITION'"), Some("'PARTITIONED'"), 
		Some("'PARTITIONS'"), Some("'PATH'"), Some("'PERCENT'"), Some("'PKFK_JOIN'"), 
		Some("'PLAN'"), Some("'PLANS'"), Some("'PLUS'"), Some("'POOL'"), Some("'PRECEDING'"), 
		Some("'PRECISION'"), Some("'PREPARE'"), Some("'PRESERVE'"), Some("'PRIMARY'"), 
		Some("'PRINCIPALS'"), Some("'PROCEDURE'"), Some("'PROTECTION'"), Some("'PURGE'"), 
		Some("'QUALIFY'"), Some("'QUARTER'"), Some("'QUERY'"), Some("'QUERY_PARALLELISM'"), 
		Some("'RANGE'"), Some("'READ'"), Some("'READONLY'"), Some("'READS'"), 
		Some("'REAL'"), Some("'REBUILD'"), Some("'RECORDREADER'"), Some("'RECORDWRITER'"), 
		Some("'REDUCE'"), Some("'REFERENCES'"), Some("'REGEXP'"), Some("'RELOAD'"), 
		Some("'RELY'"), Some("'REMOTE'"), Some("'RENAME'"), Some("'REOPTIMIZATION'"), 
		Some("'REPAIR'"), Some("'REPL'"), Some("'REPLACE'"), Some("'REPLICATION'"), 
		Some("'RESOURCE'"), Some("'RESPECT'"), Some("'RESTRICT'"), Some("'REVOKE'"), 
		Some("'REWRITE'"), Some("'RIGHT'"), Some("'RLIKE'"), Some("'ROLE'"), Some("'ROLES'"), 
		Some("'ROLLBACK'"), Some("'ROLLUP'"), Some("'ROW'"), Some("'ROWS'"), Some("'SCHEDULED'"), 
		Some("'SCHEDULING_POLICY'"), Some("'SCHEMA'"), Some("'SCHEMAS'"), None, 
		Some("'SELECT'"), Some("'SEMI'"), Some("'SERDE'"), Some("'SERDEPROPERTIES'"), 
		Some("'SERVER'"), Some("'SET'"), Some("'SETS'"), Some("'SET_CURRENT_SNAPSHOT'"), 
		Some("'SHARED'"), Some("'SHOW'"), Some("'SHOW_DATABASE'"), Some("'SKEWED'"), 
		Some("'SMALLINT'"), Some("'SNAPSHOT'"), Some("'SOME'"), Some("'SORT'"), 
		Some("'SORTED'"), Some("'SPEC'"), Some("'SSL'"), Some("'START'"), Some("'STATISTICS'"), 
		Some("'STATUS'"), Some("'STORED'"), Some("'STREAMTABLE'"), Some("'STRING'"), 
		Some("'STRUCT'"), Some("'SUMMARY'"), Some("'SYNC'"), Some("'SYSTEM_TIME'"), 
		Some("'SYSTEM_VERSION'"), Some("'TABLE'"), Some("'TABLES'"), Some("'TABLESAMPLE'"), 
		Some("'TBLPROPERTIES'"), Some("'TEMPORARY'"), Some("'TERMINATED'"), Some("'THEN'"), 
		Some("'TIME'"), Some("'TIMESTAMP'"), Some("'TIMESTAMPLOCALTZ'"), Some("'TIMESTAMPTZ'"), 
		Some("'TINYINT'"), Some("'TO'"), Some("'TOUCH'"), Some("'TRAILING'"), 
		Some("'TRANSACTION'"), Some("'TRANSACTIONAL'"), Some("'TRANSACTIONS'"), 
		Some("'TRANSFORM'"), Some("'TRIGGER'"), Some("'TRIM'"), Some("'TRUE'"), 
		Some("'TRUNCATE'"), Some("'TYPE'"), Some("'UNARCHIVE'"), Some("'UNBOUNDED'"), 
		Some("'UNDO'"), Some("'UNION'"), Some("'UNIONTYPE'"), Some("'UNIQUE'"), 
		Some("'UNIQUEJOIN'"), Some("'UNKNOWN'"), Some("'UNLOCK'"), Some("'UNMANAGED'"), 
		Some("'UNSET'"), Some("'UNSIGNED'"), Some("'UPDATE'"), Some("'URI'"), 
		Some("'URL'"), Some("'USE'"), Some("'USER'"), Some("'USING'"), Some("'UTC'"), 
		Some("'UTC_TMESTAMP'"), Some("'VALIDATE'"), Some("'VALUES'"), Some("'$VALUE$'"), 
		Some("'VARCHAR'"), Some("'VECTORIZATION'"), Some("'VIEW'"), Some("'VIEWS'"), 
		Some("'WAIT'"), None, Some("'WHEN'"), Some("'WHERE'"), Some("'WHILE'"), 
		Some("'WINDOW'"), Some("'WITH'"), Some("'WITHIN'"), Some("'WORK'"), Some("'WORKLOAD'"), 
		Some("'WRITE'"), None, Some("'ZONE'"), Some("'.'"), Some("':'"), Some("','"), 
		Some("';'"), Some("'('"), Some("')'"), Some("'['"), Some("']'"), Some("'{'"), 
		Some("'}'"), None, Some("'<=>'"), None, Some("'<='"), Some("'<'"), Some("'>='"), 
		Some("'>'"), Some("'/'"), Some("'+'"), Some("'-'"), Some("'*'"), Some("'%'"), 
		Some("'DIV'"), Some("'&'"), Some("'~'"), Some("'|'"), Some("'||'"), Some("'^'"), 
		Some("'?'"), Some("'$'")
	];
	pub const _SYMBOLIC_NAMES: [Option<&'static str>;424]  = [
		None, Some("KW_ABORT"), Some("KW_ACTIVATE"), Some("KW_ACTIVE"), Some("KW_ADD"), 
		Some("KW_ADMIN"), Some("KW_AFTER"), Some("KW_ALL"), Some("KW_ALLOC_FRACTION"), 
		Some("KW_ALTER"), Some("KW_ANALYZE"), Some("KW_AND"), Some("KW_ANTI"), 
		Some("KW_ANY"), Some("KW_APPLICATION"), Some("KW_ARCHIVE"), Some("KW_ARRAY"), 
		Some("KW_AS"), Some("KW_ASC"), Some("KW_AST"), Some("KW_AT"), Some("KW_AUTHORIZATION"), 
		Some("KW_AUTOCOMMIT"), Some("KW_BATCH"), Some("KW_BEFORE"), Some("KW_BETWEEN"), 
		Some("KW_BIGINT"), Some("KW_BINARY"), Some("KW_BOOLEAN"), Some("KW_BOTH"), 
		Some("KW_BUCKET"), Some("KW_BUCKETS"), Some("KW_BY"), Some("KW_CACHE"), 
		Some("KW_CASCADE"), Some("KW_CASE"), Some("KW_CAST"), Some("KW_CBO"), 
		Some("KW_CHANGE"), Some("KW_CHAR"), Some("KW_CHECK"), Some("KW_CLUSTER"), 
		Some("KW_CLUSTERED"), Some("KW_CLUSTERSTATUS"), Some("KW_COLLECTION"), 
		Some("KW_COLUMN"), Some("KW_COLUMNS"), Some("KW_COMMENT"), Some("KW_COMMIT"), 
		Some("KW_COMPACT"), Some("KW_COMPACTIONS"), Some("KW_COMPACT_ID"), Some("KW_COMPUTE"), 
		Some("KW_CONCATENATE"), Some("KW_CONF"), Some("KW_CONSTRAINT"), Some("KW_CONTINUE"), 
		Some("KW_COST"), Some("KW_CREATE"), Some("KW_CRON"), Some("KW_CROSS"), 
		Some("KW_CUBE"), Some("KW_CURRENT"), Some("KW_CURRENT_DATE"), Some("KW_CURRENT_TIMESTAMP"), 
		Some("KW_CURSOR"), Some("KW_DATA"), Some("KW_DATABASE"), Some("KW_DATABASES"), 
		Some("KW_DATACONNECTOR"), Some("KW_DATACONNECTORS"), Some("KW_DATE"), 
		Some("KW_DATETIME"), Some("KW_DAY"), Some("KW_DAYOFWEEK"), Some("KW_DBPROPERTIES"), 
		Some("KW_DCPROPERTIES"), Some("KW_DDL"), Some("KW_DEBUG"), Some("KW_DECIMAL"), 
		Some("KW_DEFAULT"), Some("KW_DEFERRED"), Some("KW_DEFINED"), Some("KW_DELETE"), 
		Some("KW_DELIMITED"), Some("KW_DEPENDENCY"), Some("KW_DESC"), Some("KW_DESCRIBE"), 
		Some("KW_DETAIL"), Some("KW_DIRECTORIES"), Some("KW_DIRECTORY"), Some("KW_DISABLE"), 
		Some("KW_DISTINCT"), Some("KW_DISTRIBUTE"), Some("KW_DISTRIBUTED"), Some("KW_DO"), 
		Some("KW_DOUBLE"), Some("KW_DROP"), Some("KW_DUMP"), Some("KW_ELEM_TYPE"), 
		Some("KW_ELSE"), Some("KW_ENABLE"), Some("KW_END"), Some("KW_ENFORCED"), 
		Some("KW_ESCAPED"), Some("KW_EVERY"), Some("KW_EXCEPT"), Some("KW_EXCHANGE"), 
		Some("KW_EXCLUSIVE"), Some("KW_EXECUTE"), Some("KW_EXECUTED"), Some("KW_EXISTS"), 
		Some("KW_EXPIRE_SNAPSHOTS"), Some("KW_EXPLAIN"), Some("KW_EXPORT"), Some("KW_EXPRESSION"), 
		Some("KW_EXTENDED"), Some("KW_EXTERNAL"), Some("KW_EXTRACT"), Some("KW_FALSE"), 
		Some("KW_FETCH"), Some("KW_FIELDS"), Some("KW_FILE"), Some("KW_FILEFORMAT"), 
		Some("KW_FIRST"), Some("KW_FLOAT"), Some("KW_FLOOR"), Some("KW_FOLLOWING"), 
		Some("KW_FOR"), Some("KW_FORCE"), Some("KW_FOREIGN"), Some("KW_FORMAT"), 
		Some("KW_FORMATTED"), Some("KW_FROM"), Some("KW_FULL"), Some("KW_FUNCTION"), 
		Some("KW_FUNCTIONS"), Some("KW_GRANT"), Some("KW_GROUP"), Some("KW_GROUPING"), 
		Some("KW_HAVING"), Some("KW_HOLD_DDLTIME"), Some("KW_HOUR"), Some("KW_IDXPROPERTIES"), 
		Some("KW_IF"), Some("KW_IGNORE"), Some("KW_IMPORT"), Some("KW_IN"), Some("KW_INDEX"), 
		Some("KW_INDEXES"), Some("KW_INNER"), Some("KW_INPATH"), Some("KW_INPUTDRIVER"), 
		Some("KW_INPUTFORMAT"), Some("KW_INSERT"), Some("KW_INT"), Some("KW_INTERSECT"), 
		Some("KW_INTERVAL"), Some("KW_INTO"), Some("KW_IS"), Some("KW_ISOLATION"), 
		Some("KW_ITEMS"), Some("KW_JAR"), Some("KW_JOIN"), Some("KW_JOINCOST"), 
		Some("KW_KEY"), Some("KW_KEYS"), Some("KW_KEY_TYPE"), Some("KW_KILL"), 
		Some("KW_LAST"), Some("KW_LATERAL"), Some("KW_LEADING"), Some("KW_LEFT"), 
		Some("KW_LESS"), Some("KW_LEVEL"), Some("KW_LIKE"), Some("KW_LIMIT"), 
		Some("KW_LINES"), Some("KW_LOAD"), Some("KW_LOCAL"), Some("KW_LOCATION"), 
		Some("KW_LOCK"), Some("KW_LOCKS"), Some("KW_LOGICAL"), Some("KW_LONG"), 
		Some("KW_MACRO"), Some("KW_MANAGED"), Some("KW_MANAGEDLOCATION"), Some("KW_MANAGEMENT"), 
		Some("KW_MAP"), Some("KW_MAPJOIN"), Some("KW_MAPPING"), Some("KW_MATCHED"), 
		Some("KW_MATERIALIZED"), Some("KW_MERGE"), Some("KW_METADATA"), Some("KW_MINUS"), 
		Some("KW_MINUTE"), Some("KW_MONTH"), Some("KW_MORE"), Some("KW_MOVE"), 
		Some("KW_MSCK"), Some("KW_NONE"), Some("KW_NORELY"), Some("KW_NOSCAN"), 
		Some("KW_NOT"), Some("KW_NOVALIDATE"), Some("KW_NO_DROP"), Some("KW_NULL"), 
		Some("KW_NULLS"), Some("KW_OF"), Some("KW_OFFLINE"), Some("KW_OFFSET"), 
		Some("KW_ON"), Some("KW_ONLY"), Some("KW_OPERATOR"), Some("KW_OPTION"), 
		Some("KW_OR"), Some("KW_ORDER"), Some("KW_OUT"), Some("KW_OUTER"), Some("KW_OUTPUTDRIVER"), 
		Some("KW_OUTPUTFORMAT"), Some("KW_OVER"), Some("KW_OVERWRITE"), Some("KW_OWNER"), 
		Some("KW_PARTITION"), Some("KW_PARTITIONED"), Some("KW_PARTITIONS"), Some("KW_PATH"), 
		Some("KW_PERCENT"), Some("KW_PKFK_JOIN"), Some("KW_PLAN"), Some("KW_PLANS"), 
		Some("KW_PLUS"), Some("KW_POOL"), Some("KW_PRECEDING"), Some("KW_PRECISION"), 
		Some("KW_PREPARE"), Some("KW_PRESERVE"), Some("KW_PRIMARY"), Some("KW_PRINCIPALS"), 
		Some("KW_PROCEDURE"), Some("KW_PROTECTION"), Some("KW_PURGE"), Some("KW_QUALIFY"), 
		Some("KW_QUARTER"), Some("KW_QUERY"), Some("KW_QUERY_PARALLELISM"), Some("KW_RANGE"), 
		Some("KW_READ"), Some("KW_READONLY"), Some("KW_READS"), Some("KW_REAL"), 
		Some("KW_REBUILD"), Some("KW_RECORDREADER"), Some("KW_RECORDWRITER"), 
		Some("KW_REDUCE"), Some("KW_REFERENCES"), Some("KW_REGEXP"), Some("KW_RELOAD"), 
		Some("KW_RELY"), Some("KW_REMOTE"), Some("KW_RENAME"), Some("KW_REOPTIMIZATION"), 
		Some("KW_REPAIR"), Some("KW_REPL"), Some("KW_REPLACE"), Some("KW_REPLICATION"), 
		Some("KW_RESOURCE"), Some("KW_RESPECT"), Some("KW_RESTRICT"), Some("KW_REVOKE"), 
		Some("KW_REWRITE"), Some("KW_RIGHT"), Some("KW_RLIKE"), Some("KW_ROLE"), 
		Some("KW_ROLES"), Some("KW_ROLLBACK"), Some("KW_ROLLUP"), Some("KW_ROW"), 
		Some("KW_ROWS"), Some("KW_SCHEDULED"), Some("KW_SCHEDULING_POLICY"), Some("KW_SCHEMA"), 
		Some("KW_SCHEMAS"), Some("KW_SECOND"), Some("KW_SELECT"), Some("KW_SEMI"), 
		Some("KW_SERDE"), Some("KW_SERDEPROPERTIES"), Some("KW_SERVER"), Some("KW_SET"), 
		Some("KW_SETS"), Some("KW_SET_CURRENT_SNAPSHOT"), Some("KW_SHARED"), Some("KW_SHOW"), 
		Some("KW_SHOW_DATABASE"), Some("KW_SKEWED"), Some("KW_SMALLINT"), Some("KW_SNAPSHOT"), 
		Some("KW_SOME"), Some("KW_SORT"), Some("KW_SORTED"), Some("KW_SPEC"), 
		Some("KW_SSL"), Some("KW_START"), Some("KW_STATISTICS"), Some("KW_STATUS"), 
		Some("KW_STORED"), Some("KW_STREAMTABLE"), Some("KW_STRING"), Some("KW_STRUCT"), 
		Some("KW_SUMMARY"), Some("KW_SYNC"), Some("KW_SYSTEM_TIME"), Some("KW_SYSTEM_VERSION"), 
		Some("KW_TABLE"), Some("KW_TABLES"), Some("KW_TABLESAMPLE"), Some("KW_TBLPROPERTIES"), 
		Some("KW_TEMPORARY"), Some("KW_TERMINATED"), Some("KW_THEN"), Some("KW_TIME"), 
		Some("KW_TIMESTAMP"), Some("KW_TIMESTAMPLOCALTZ"), Some("KW_TIMESTAMPTZ"), 
		Some("KW_TINYINT"), Some("KW_TO"), Some("KW_TOUCH"), Some("KW_TRAILING"), 
		Some("KW_TRANSACTION"), Some("KW_TRANSACTIONAL"), Some("KW_TRANSACTIONS"), 
		Some("KW_TRANSFORM"), Some("KW_TRIGGER"), Some("KW_TRIM"), Some("KW_TRUE"), 
		Some("KW_TRUNCATE"), Some("KW_TYPE"), Some("KW_UNARCHIVE"), Some("KW_UNBOUNDED"), 
		Some("KW_UNDO"), Some("KW_UNION"), Some("KW_UNIONTYPE"), Some("KW_UNIQUE"), 
		Some("KW_UNIQUEJOIN"), Some("KW_UNKNOWN"), Some("KW_UNLOCK"), Some("KW_UNMANAGED"), 
		Some("KW_UNSET"), Some("KW_UNSIGNED"), Some("KW_UPDATE"), Some("KW_URI"), 
		Some("KW_URL"), Some("KW_USE"), Some("KW_USER"), Some("KW_USING"), Some("KW_UTC"), 
		Some("KW_UTCTIMESTAMP"), Some("KW_VALIDATE"), Some("KW_VALUES"), Some("KW_VALUE_TYPE"), 
		Some("KW_VARCHAR"), Some("KW_VECTORIZATION"), Some("KW_VIEW"), Some("KW_VIEWS"), 
		Some("KW_WAIT"), Some("KW_WEEK"), Some("KW_WHEN"), Some("KW_WHERE"), Some("KW_WHILE"), 
		Some("KW_WINDOW"), Some("KW_WITH"), Some("KW_WITHIN"), Some("KW_WORK"), 
		Some("KW_WORKLOAD"), Some("KW_WRITE"), Some("KW_YEAR"), Some("KW_ZONE"), 
		Some("DOT"), Some("COLON"), Some("COMMA"), Some("SEMICOLON"), Some("LPAREN"), 
		Some("RPAREN"), Some("LSQUARE"), Some("RSQUARE"), Some("LCURLY"), Some("RCURLY"), 
		Some("EQUAL"), Some("EQUAL_NS"), Some("NOTEQUAL"), Some("LESSTHANOREQUALTO"), 
		Some("LESSTHAN"), Some("GREATERTHANOREQUALTO"), Some("GREATERTHAN"), Some("DIVIDE"), 
		Some("PLUS"), Some("MINUS"), Some("STAR"), Some("MOD"), Some("DIV"), Some("AMPERSAND"), 
		Some("TILDE"), Some("BITWISEOR"), Some("CONCATENATE"), Some("BITWISEXOR"), 
		Some("QUESTION"), Some("DOLLAR"), Some("StringLiteral"), Some("CharSetLiteral"), 
		Some("IntegralLiteral"), Some("NumberLiteral"), Some("ByteLengthLiteral"), 
		Some("Number"), Some("Identifier"), Some("CharSetName"), Some("WHITE_SPACE"), 
		Some("LINE_COMMENT"), Some("QUERY_HINT"), Some("SHOW_HINT"), Some("HIDDEN_HINT")
	];
	lazy_static!{
	    static ref _shared_context_cache: Arc<PredictionContextCache> = Arc::new(PredictionContextCache::new());
		static ref VOCABULARY: Box<dyn Vocabulary> = Box::new(VocabularyImpl::new(_LITERAL_NAMES.iter(), _SYMBOLIC_NAMES.iter(), None));
	}


type BaseParserType<'input, I> =
	BaseParser<'input,HiveSqlParserExt<'input>, I, HiveSqlParserContextType , dyn HiveSqlParserListener<'input> + 'input >;

type TokenType<'input> = <LocalTokenFactory<'input> as TokenFactory<'input>>::Tok;
pub type LocalTokenFactory<'input> = CommonTokenFactory;

pub type HiveSqlParserTreeWalker<'input,'a> =
	ParseTreeWalker<'input, 'a, HiveSqlParserContextType , dyn HiveSqlParserListener<'input> + 'a>;

/// Parser for HiveSqlParser grammar
pub struct HiveSqlParser<'input,I,H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	base:BaseParserType<'input,I>,
	interpreter:Arc<ParserATNSimulator>,
	_shared_context_cache: Box<PredictionContextCache>,
    pub err_handler: H,
}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn get_serialized_atn() -> &'static str { _serializedATN }

    pub fn set_error_strategy(&mut self, strategy: H) {
        self.err_handler = strategy
    }

    pub fn with_strategy(input: I, strategy: H) -> Self {
		crate::recognizer::check_version("0","3");
		let interpreter = Arc::new(ParserATNSimulator::new(
			_ATN.clone(),
			_decision_to_DFA.clone(),
			_shared_context_cache.clone(),
		));
		Self {
			base: BaseParser::new_base_parser(
				input,
				Arc::clone(&interpreter),
				HiveSqlParserExt{
					_pd: Default::default(),
				}
			),
			interpreter,
            _shared_context_cache: Box::new(PredictionContextCache::new()),
            err_handler: strategy,
        }
    }

}

type DynStrategy<'input,I> = Box<dyn ErrorStrategy<'input,BaseParserType<'input,I>> + 'input>;

impl<'input, I> HiveSqlParser<'input, I, DynStrategy<'input,I>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn with_dyn_strategy(input: I) -> Self{
    	Self::with_strategy(input,Box::new(DefaultErrorStrategy::new()))
    }
}

impl<'input, I> HiveSqlParser<'input, I, DefaultErrorStrategy<'input,HiveSqlParserContextType>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn new(input: I) -> Self{
    	Self::with_strategy(input,DefaultErrorStrategy::new())
    }
}

/// Trait for monomorphized trait object that corresponds to the nodes of parse tree generated for HiveSqlParser
pub trait HiveSqlParserContext<'input>:
	for<'x> Listenable<dyn HiveSqlParserListener<'input> + 'x > + 
	ParserRuleContext<'input, TF=LocalTokenFactory<'input>, Ctx=HiveSqlParserContextType>
{}

crate::coerce_from!{ 'input : HiveSqlParserContext<'input> }

impl<'input> HiveSqlParserContext<'input> for TerminalNode<'input,HiveSqlParserContextType> {}
impl<'input> HiveSqlParserContext<'input> for ErrorNode<'input,HiveSqlParserContextType> {}

crate::tid! { impl<'input> TidAble<'input> for dyn HiveSqlParserContext<'input> + 'input }

crate::tid! { impl<'input> TidAble<'input> for dyn HiveSqlParserListener<'input> + 'input }

pub struct HiveSqlParserContextType;
crate::tid!{HiveSqlParserContextType}

impl<'input> ParserNodeType<'input> for HiveSqlParserContextType{
	type TF = LocalTokenFactory<'input>;
	type Type = dyn HiveSqlParserContext<'input> + 'input;
}

impl<'input, I, H> Deref for HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    type Target = BaseParserType<'input,I>;

    fn deref(&self) -> &Self::Target {
        &self.base
    }
}

impl<'input, I, H> DerefMut for HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.base
    }
}

pub struct HiveSqlParserExt<'input>{
	_pd: PhantomData<&'input str>,
}

impl<'input> HiveSqlParserExt<'input>{
}
crate::tid! { HiveSqlParserExt<'a> }

impl<'input> TokenAware<'input> for HiveSqlParserExt<'input>{
	type TF = LocalTokenFactory<'input>;
}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> ParserRecog<'input, BaseParserType<'input,I>> for HiveSqlParserExt<'input>{}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> Actions<'input, BaseParserType<'input,I>> for HiveSqlParserExt<'input>{
	fn get_grammar_file_name(&self) -> & str{ "HiveSqlParser.g4"}

   	fn get_rule_names(&self) -> &[& str] {&ruleNames}

   	fn get_vocabulary(&self) -> &dyn Vocabulary { &**VOCABULARY }
}
//------------------- program ----------------
pub type ProgramContextAll<'input> = ProgramContext<'input>;


pub type ProgramContext<'input> = BaseParserRuleContext<'input,ProgramContextExt<'input>>;

#[derive(Clone)]
pub struct ProgramContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ProgramContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ProgramContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_program(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_program(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ProgramContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_program }
	//fn type_rule_index() -> usize where Self: Sized { RULE_program }
}
crate::tid!{ProgramContextExt<'a>}

impl<'input> ProgramContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ProgramContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ProgramContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ProgramContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ProgramContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}
fn statement_all(&self) ->  Vec<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn statement(&self, i: usize) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ProgramContextAttrs<'input> for ProgramContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn program(&mut self,)
	-> Result<Rc<ProgramContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ProgramContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 0, RULE_program);
        let mut _localctx: Rc<ProgramContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1009);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << KW_ABORT) | (1usize << KW_ALTER) | (1usize << KW_ANALYZE))) != 0) || _la==KW_COMMIT || _la==KW_CREATE || ((((_la - 83)) & !0x3f) == 0 && ((1usize << (_la - 83)) & ((1usize << (KW_DELETE - 83)) | (1usize << (KW_DESC - 83)) | (1usize << (KW_DESCRIBE - 83)) | (1usize << (KW_DISABLE - 83)) | (1usize << (KW_DROP - 83)) | (1usize << (KW_ENABLE - 83)) | (1usize << (KW_EXECUTE - 83)) | (1usize << (KW_EXPLAIN - 83)) | (1usize << (KW_EXPORT - 83)))) != 0) || ((((_la - 133)) & !0x3f) == 0 && ((1usize << (_la - 133)) & ((1usize << (KW_FROM - 133)) | (1usize << (KW_GRANT - 133)) | (1usize << (KW_IMPORT - 133)) | (1usize << (KW_INSERT - 133)))) != 0) || ((((_la - 168)) & !0x3f) == 0 && ((1usize << (_la - 168)) & ((1usize << (KW_KILL - 168)) | (1usize << (KW_LOAD - 168)) | (1usize << (KW_LOCK - 168)) | (1usize << (KW_MAP - 168)) | (1usize << (KW_MERGE - 168)))) != 0) || _la==KW_MSCK || ((((_la - 238)) & !0x3f) == 0 && ((1usize << (_la - 238)) & ((1usize << (KW_PREPARE - 238)) | (1usize << (KW_REDUCE - 238)) | (1usize << (KW_RELOAD - 238)) | (1usize << (KW_REPL - 238)) | (1usize << (KW_REPLACE - 238)))) != 0) || ((((_la - 272)) & !0x3f) == 0 && ((1usize << (_la - 272)) & ((1usize << (KW_REVOKE - 272)) | (1usize << (KW_ROLLBACK - 272)) | (1usize << (KW_SELECT - 272)) | (1usize << (KW_SET - 272)) | (1usize << (KW_SHOW - 272)))) != 0) || _la==KW_START || ((((_la - 339)) & !0x3f) == 0 && ((1usize << (_la - 339)) & ((1usize << (KW_TRUNCATE - 339)) | (1usize << (KW_UNLOCK - 339)) | (1usize << (KW_UPDATE - 339)) | (1usize << (KW_USE - 339)) | (1usize << (KW_VALUES - 339)))) != 0) || _la==KW_WITH || _la==LPAREN {
				{
				{
				/*InvokeRule statement*/
				recog.base.set_state(1006);
				recog.statement()?;

				}
				}
				recog.base.set_state(1011);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1012);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- statement ----------------
pub type StatementContextAll<'input> = StatementContext<'input>;


pub type StatementContext<'input> = BaseParserRuleContext<'input,StatementContextExt<'input>>;

#[derive(Clone)]
pub struct StatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for StatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for StatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_statement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_statement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for StatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}
crate::tid!{StatementContextExt<'a>}

impl<'input> StatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<StatementContextExt<'input>>{

fn explainStatement(&self) -> Option<Rc<ExplainStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn execStatement(&self) -> Option<Rc<ExecStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token SEMICOLON
/// Returns `None` if there is no child corresponding to token SEMICOLON
fn SEMICOLON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(SEMICOLON, 0)
}

}

impl<'input> StatementContextAttrs<'input> for StatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn statement(&mut self,)
	-> Result<Rc<StatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 2, RULE_statement);
        let mut _localctx: Rc<StatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1016);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_EXPLAIN 
				=> {
					{
					/*InvokeRule explainStatement*/
					recog.base.set_state(1014);
					recog.explainStatement()?;

					}
				}

			 KW_ABORT | KW_ALTER | KW_ANALYZE | KW_COMMIT | KW_CREATE | KW_DELETE |
			 KW_DESC | KW_DESCRIBE | KW_DISABLE | KW_DROP | KW_ENABLE | KW_EXECUTE |
			 KW_EXPORT | KW_FROM | KW_GRANT | KW_IMPORT | KW_INSERT | KW_KILL | KW_LOAD |
			 KW_LOCK | KW_MAP | KW_MERGE | KW_MSCK | KW_PREPARE | KW_REDUCE | KW_RELOAD |
			 KW_REPL | KW_REPLACE | KW_REVOKE | KW_ROLLBACK | KW_SELECT | KW_SET |
			 KW_SHOW | KW_START | KW_TRUNCATE | KW_UNLOCK | KW_UPDATE | KW_USE | KW_VALUES |
			 KW_WITH | LPAREN 
				=> {
					{
					/*InvokeRule execStatement*/
					recog.base.set_state(1015);
					recog.execStatement()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(1019);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(2,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1018);
					recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- explainStatement ----------------
pub type ExplainStatementContextAll<'input> = ExplainStatementContext<'input>;


pub type ExplainStatementContext<'input> = BaseParserRuleContext<'input,ExplainStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ExplainStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExplainStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExplainStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_explainStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_explainStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExplainStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_explainStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_explainStatement }
}
crate::tid!{ExplainStatementContextExt<'a>}

impl<'input> ExplainStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExplainStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExplainStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExplainStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExplainStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_EXPLAIN
/// Returns `None` if there is no child corresponding to token KW_EXPLAIN
fn KW_EXPLAIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXPLAIN, 0)
}
fn execStatement(&self) -> Option<Rc<ExecStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_REWRITE
/// Returns `None` if there is no child corresponding to token KW_REWRITE
fn KW_REWRITE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REWRITE, 0)
}
fn queryStatementExpression(&self) -> Option<Rc<QueryStatementExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn explainOption_all(&self) ->  Vec<Rc<ExplainOptionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn explainOption(&self, i: usize) -> Option<Rc<ExplainOptionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ExplainStatementContextAttrs<'input> for ExplainStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn explainStatement(&mut self,)
	-> Result<Rc<ExplainStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExplainStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 4, RULE_explainStatement);
        let mut _localctx: Rc<ExplainStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1021);
			recog.base.match_token(KW_EXPLAIN,&mut recog.err_handler)?;

			recog.base.set_state(1031);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ABORT | KW_ALTER | KW_ANALYZE | KW_AST | KW_AUTHORIZATION | KW_CBO |
			 KW_COMMIT | KW_CREATE | KW_DDL | KW_DEBUG | KW_DELETE | KW_DEPENDENCY |
			 KW_DESC | KW_DESCRIBE | KW_DISABLE | KW_DROP | KW_ENABLE | KW_EXECUTE |
			 KW_EXPORT | KW_EXTENDED | KW_FORMATTED | KW_FROM | KW_GRANT | KW_IMPORT |
			 KW_INSERT | KW_KILL | KW_LOAD | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_MAP |
			 KW_MERGE | KW_MSCK | KW_PREPARE | KW_REDUCE | KW_RELOAD | KW_REOPTIMIZATION |
			 KW_REPL | KW_REPLACE | KW_REVOKE | KW_ROLLBACK | KW_SELECT | KW_SET |
			 KW_SHOW | KW_START | KW_TRUNCATE | KW_UNLOCK | KW_UPDATE | KW_USE | KW_VALUES |
			 KW_VECTORIZATION | KW_WITH | LPAREN 
				=> {
					{
					recog.base.set_state(1025);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(3,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule explainOption*/
							recog.base.set_state(1022);
							recog.explainOption()?;

							}
							} 
						}
						recog.base.set_state(1027);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(3,&mut recog.base)?;
					}
					/*InvokeRule execStatement*/
					recog.base.set_state(1028);
					recog.execStatement()?;

					}
				}

			 KW_REWRITE 
				=> {
					{
					recog.base.set_state(1029);
					recog.base.match_token(KW_REWRITE,&mut recog.err_handler)?;

					/*InvokeRule queryStatementExpression*/
					recog.base.set_state(1030);
					recog.queryStatementExpression()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- explainOption ----------------
pub type ExplainOptionContextAll<'input> = ExplainOptionContext<'input>;


pub type ExplainOptionContext<'input> = BaseParserRuleContext<'input,ExplainOptionContextExt<'input>>;

#[derive(Clone)]
pub struct ExplainOptionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExplainOptionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExplainOptionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_explainOption(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_explainOption(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExplainOptionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_explainOption }
	//fn type_rule_index() -> usize where Self: Sized { RULE_explainOption }
}
crate::tid!{ExplainOptionContextExt<'a>}

impl<'input> ExplainOptionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExplainOptionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExplainOptionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExplainOptionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExplainOptionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_EXTENDED
/// Returns `None` if there is no child corresponding to token KW_EXTENDED
fn KW_EXTENDED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXTENDED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FORMATTED
/// Returns `None` if there is no child corresponding to token KW_FORMATTED
fn KW_FORMATTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FORMATTED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEPENDENCY
/// Returns `None` if there is no child corresponding to token KW_DEPENDENCY
fn KW_DEPENDENCY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEPENDENCY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CBO
/// Returns `None` if there is no child corresponding to token KW_CBO
fn KW_CBO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CBO, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COST
/// Returns `None` if there is no child corresponding to token KW_COST
fn KW_COST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COST, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_JOINCOST
/// Returns `None` if there is no child corresponding to token KW_JOINCOST
fn KW_JOINCOST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_JOINCOST, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOGICAL
/// Returns `None` if there is no child corresponding to token KW_LOGICAL
fn KW_LOGICAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOGICAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AUTHORIZATION
/// Returns `None` if there is no child corresponding to token KW_AUTHORIZATION
fn KW_AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AUTHORIZATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ANALYZE
/// Returns `None` if there is no child corresponding to token KW_ANALYZE
fn KW_ANALYZE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ANALYZE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REOPTIMIZATION
/// Returns `None` if there is no child corresponding to token KW_REOPTIMIZATION
fn KW_REOPTIMIZATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REOPTIMIZATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCKS
/// Returns `None` if there is no child corresponding to token KW_LOCKS
fn KW_LOCKS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCKS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AST
/// Returns `None` if there is no child corresponding to token KW_AST
fn KW_AST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AST, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VECTORIZATION
/// Returns `None` if there is no child corresponding to token KW_VECTORIZATION
fn KW_VECTORIZATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VECTORIZATION, 0)
}
fn vectorizationOnly(&self) -> Option<Rc<VectorizationOnlyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn vectorizatonDetail(&self) -> Option<Rc<VectorizatonDetailContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEBUG
/// Returns `None` if there is no child corresponding to token KW_DEBUG
fn KW_DEBUG(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEBUG, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DDL
/// Returns `None` if there is no child corresponding to token KW_DDL
fn KW_DDL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DDL, 0)
}

}

impl<'input> ExplainOptionContextAttrs<'input> for ExplainOptionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn explainOption(&mut self,)
	-> Result<Rc<ExplainOptionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExplainOptionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 6, RULE_explainOption);
        let mut _localctx: Rc<ExplainOptionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1055);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_EXTENDED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1033);
					recog.base.match_token(KW_EXTENDED,&mut recog.err_handler)?;

					}
				}

			 KW_FORMATTED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1034);
					recog.base.match_token(KW_FORMATTED,&mut recog.err_handler)?;

					}
				}

			 KW_DEPENDENCY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(1035);
					recog.base.match_token(KW_DEPENDENCY,&mut recog.err_handler)?;

					}
				}

			 KW_CBO 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(1036);
					recog.base.match_token(KW_CBO,&mut recog.err_handler)?;

					recog.base.set_state(1038);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_COST || _la==KW_JOINCOST {
						{
						recog.base.set_state(1037);
						_la = recog.base.input.la(1);
						if { !(_la==KW_COST || _la==KW_JOINCOST) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					}
				}

			 KW_LOGICAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(1040);
					recog.base.match_token(KW_LOGICAL,&mut recog.err_handler)?;

					}
				}

			 KW_AUTHORIZATION 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(1041);
					recog.base.match_token(KW_AUTHORIZATION,&mut recog.err_handler)?;

					}
				}

			 KW_ANALYZE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(1042);
					recog.base.match_token(KW_ANALYZE,&mut recog.err_handler)?;

					}
				}

			 KW_REOPTIMIZATION 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(1043);
					recog.base.match_token(KW_REOPTIMIZATION,&mut recog.err_handler)?;

					}
				}

			 KW_LOCKS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					recog.base.set_state(1044);
					recog.base.match_token(KW_LOCKS,&mut recog.err_handler)?;

					}
				}

			 KW_AST 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					recog.base.set_state(1045);
					recog.base.match_token(KW_AST,&mut recog.err_handler)?;

					}
				}

			 KW_VECTORIZATION 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					recog.base.set_state(1046);
					recog.base.match_token(KW_VECTORIZATION,&mut recog.err_handler)?;

					recog.base.set_state(1048);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_ONLY {
						{
						/*InvokeRule vectorizationOnly*/
						recog.base.set_state(1047);
						recog.vectorizationOnly()?;

						}
					}

					recog.base.set_state(1051);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_DETAIL || _la==KW_EXPRESSION || _la==KW_OPERATOR || _la==KW_SUMMARY {
						{
						/*InvokeRule vectorizatonDetail*/
						recog.base.set_state(1050);
						recog.vectorizatonDetail()?;

						}
					}

					}
				}

			 KW_DEBUG 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					recog.base.set_state(1053);
					recog.base.match_token(KW_DEBUG,&mut recog.err_handler)?;

					}
				}

			 KW_DDL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					recog.base.set_state(1054);
					recog.base.match_token(KW_DDL,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- vectorizationOnly ----------------
pub type VectorizationOnlyContextAll<'input> = VectorizationOnlyContext<'input>;


pub type VectorizationOnlyContext<'input> = BaseParserRuleContext<'input,VectorizationOnlyContextExt<'input>>;

#[derive(Clone)]
pub struct VectorizationOnlyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for VectorizationOnlyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for VectorizationOnlyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_vectorizationOnly(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_vectorizationOnly(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for VectorizationOnlyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_vectorizationOnly }
	//fn type_rule_index() -> usize where Self: Sized { RULE_vectorizationOnly }
}
crate::tid!{VectorizationOnlyContextExt<'a>}

impl<'input> VectorizationOnlyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<VectorizationOnlyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,VectorizationOnlyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait VectorizationOnlyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<VectorizationOnlyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ONLY
/// Returns `None` if there is no child corresponding to token KW_ONLY
fn KW_ONLY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ONLY, 0)
}

}

impl<'input> VectorizationOnlyContextAttrs<'input> for VectorizationOnlyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn vectorizationOnly(&mut self,)
	-> Result<Rc<VectorizationOnlyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = VectorizationOnlyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 8, RULE_vectorizationOnly);
        let mut _localctx: Rc<VectorizationOnlyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1057);
			recog.base.match_token(KW_ONLY,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- vectorizatonDetail ----------------
pub type VectorizatonDetailContextAll<'input> = VectorizatonDetailContext<'input>;


pub type VectorizatonDetailContext<'input> = BaseParserRuleContext<'input,VectorizatonDetailContextExt<'input>>;

#[derive(Clone)]
pub struct VectorizatonDetailContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for VectorizatonDetailContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for VectorizatonDetailContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_vectorizatonDetail(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_vectorizatonDetail(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for VectorizatonDetailContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_vectorizatonDetail }
	//fn type_rule_index() -> usize where Self: Sized { RULE_vectorizatonDetail }
}
crate::tid!{VectorizatonDetailContextExt<'a>}

impl<'input> VectorizatonDetailContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<VectorizatonDetailContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,VectorizatonDetailContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait VectorizatonDetailContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<VectorizatonDetailContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SUMMARY
/// Returns `None` if there is no child corresponding to token KW_SUMMARY
fn KW_SUMMARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SUMMARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OPERATOR
/// Returns `None` if there is no child corresponding to token KW_OPERATOR
fn KW_OPERATOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OPERATOR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXPRESSION
/// Returns `None` if there is no child corresponding to token KW_EXPRESSION
fn KW_EXPRESSION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXPRESSION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DETAIL
/// Returns `None` if there is no child corresponding to token KW_DETAIL
fn KW_DETAIL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DETAIL, 0)
}

}

impl<'input> VectorizatonDetailContextAttrs<'input> for VectorizatonDetailContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn vectorizatonDetail(&mut self,)
	-> Result<Rc<VectorizatonDetailContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = VectorizatonDetailContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 10, RULE_vectorizatonDetail);
        let mut _localctx: Rc<VectorizatonDetailContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1059);
			_la = recog.base.input.la(1);
			if { !(_la==KW_DETAIL || _la==KW_EXPRESSION || _la==KW_OPERATOR || _la==KW_SUMMARY) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- execStatement ----------------
pub type ExecStatementContextAll<'input> = ExecStatementContext<'input>;


pub type ExecStatementContext<'input> = BaseParserRuleContext<'input,ExecStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ExecStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExecStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExecStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_execStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_execStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExecStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_execStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_execStatement }
}
crate::tid!{ExecStatementContextExt<'a>}

impl<'input> ExecStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExecStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExecStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExecStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExecStatementContextExt<'input>>{

fn queryStatementExpression(&self) -> Option<Rc<QueryStatementExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn loadStatement(&self) -> Option<Rc<LoadStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn exportStatement(&self) -> Option<Rc<ExportStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn importStatement(&self) -> Option<Rc<ImportStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn replDumpStatement(&self) -> Option<Rc<ReplDumpStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn replLoadStatement(&self) -> Option<Rc<ReplLoadStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn replStatusStatement(&self) -> Option<Rc<ReplStatusStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ddlStatement(&self) -> Option<Rc<DdlStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn deleteStatement(&self) -> Option<Rc<DeleteStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn updateStatement(&self) -> Option<Rc<UpdateStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sqlTransactionStatement(&self) -> Option<Rc<SqlTransactionStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn mergeStatement(&self) -> Option<Rc<MergeStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn prepareStatement(&self) -> Option<Rc<PrepareStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn executeStatement(&self) -> Option<Rc<ExecuteStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExecStatementContextAttrs<'input> for ExecStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn execStatement(&mut self,)
	-> Result<Rc<ExecStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExecStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 12, RULE_execStatement);
        let mut _localctx: Rc<ExecStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1075);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(9,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule queryStatementExpression*/
					recog.base.set_state(1061);
					recog.queryStatementExpression()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule loadStatement*/
					recog.base.set_state(1062);
					recog.loadStatement()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule exportStatement*/
					recog.base.set_state(1063);
					recog.exportStatement()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule importStatement*/
					recog.base.set_state(1064);
					recog.importStatement()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule replDumpStatement*/
					recog.base.set_state(1065);
					recog.replDumpStatement()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule replLoadStatement*/
					recog.base.set_state(1066);
					recog.replLoadStatement()?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule replStatusStatement*/
					recog.base.set_state(1067);
					recog.replStatusStatement()?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule ddlStatement*/
					recog.base.set_state(1068);
					recog.ddlStatement()?;

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule deleteStatement*/
					recog.base.set_state(1069);
					recog.deleteStatement()?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule updateStatement*/
					recog.base.set_state(1070);
					recog.updateStatement()?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule sqlTransactionStatement*/
					recog.base.set_state(1071);
					recog.sqlTransactionStatement()?;

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					/*InvokeRule mergeStatement*/
					recog.base.set_state(1072);
					recog.mergeStatement()?;

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					/*InvokeRule prepareStatement*/
					recog.base.set_state(1073);
					recog.prepareStatement()?;

					}
				}
			,
				14 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					/*InvokeRule executeStatement*/
					recog.base.set_state(1074);
					recog.executeStatement()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- loadStatement ----------------
pub type LoadStatementContextAll<'input> = LoadStatementContext<'input>;


pub type LoadStatementContext<'input> = BaseParserRuleContext<'input,LoadStatementContextExt<'input>>;

#[derive(Clone)]
pub struct LoadStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for LoadStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for LoadStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_loadStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_loadStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for LoadStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_loadStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_loadStatement }
}
crate::tid!{LoadStatementContextExt<'a>}

impl<'input> LoadStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LoadStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LoadStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LoadStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<LoadStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LOAD
/// Returns `None` if there is no child corresponding to token KW_LOAD
fn KW_LOAD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOAD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATA
/// Returns `None` if there is no child corresponding to token KW_DATA
fn KW_DATA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATA, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INPATH
/// Returns `None` if there is no child corresponding to token KW_INPATH
fn KW_INPATH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INPATH, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INTO
/// Returns `None` if there is no child corresponding to token KW_INTO
fn KW_INTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INTO, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableOrPartition(&self) -> Option<Rc<TableOrPartitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCAL
/// Returns `None` if there is no child corresponding to token KW_LOCAL
fn KW_LOCAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OVERWRITE
/// Returns `None` if there is no child corresponding to token KW_OVERWRITE
fn KW_OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OVERWRITE, 0)
}
fn inputFileFormat(&self) -> Option<Rc<InputFileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LoadStatementContextAttrs<'input> for LoadStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn loadStatement(&mut self,)
	-> Result<Rc<LoadStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LoadStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 14, RULE_loadStatement);
        let mut _localctx: Rc<LoadStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1077);
			recog.base.match_token(KW_LOAD,&mut recog.err_handler)?;

			recog.base.set_state(1078);
			recog.base.match_token(KW_DATA,&mut recog.err_handler)?;

			recog.base.set_state(1080);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_LOCAL {
				{
				recog.base.set_state(1079);
				recog.base.match_token(KW_LOCAL,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(1082);
			recog.base.match_token(KW_INPATH,&mut recog.err_handler)?;

			recog.base.set_state(1083);
			recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

			recog.base.set_state(1085);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_OVERWRITE {
				{
				recog.base.set_state(1084);
				recog.base.match_token(KW_OVERWRITE,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(1087);
			recog.base.match_token(KW_INTO,&mut recog.err_handler)?;

			recog.base.set_state(1088);
			recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

			/*InvokeRule tableOrPartition*/
			recog.base.set_state(1089);
			recog.tableOrPartition()?;

			recog.base.set_state(1091);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_INPUTFORMAT {
				{
				/*InvokeRule inputFileFormat*/
				recog.base.set_state(1090);
				recog.inputFileFormat()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- replicationClause ----------------
pub type ReplicationClauseContextAll<'input> = ReplicationClauseContext<'input>;


pub type ReplicationClauseContext<'input> = BaseParserRuleContext<'input,ReplicationClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ReplicationClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ReplicationClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ReplicationClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_replicationClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_replicationClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ReplicationClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_replicationClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_replicationClause }
}
crate::tid!{ReplicationClauseContextExt<'a>}

impl<'input> ReplicationClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReplicationClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReplicationClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ReplicationClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ReplicationClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_FOR
/// Returns `None` if there is no child corresponding to token KW_FOR
fn KW_FOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REPLICATION
/// Returns `None` if there is no child corresponding to token KW_REPLICATION
fn KW_REPLICATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPLICATION, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_METADATA
/// Returns `None` if there is no child corresponding to token KW_METADATA
fn KW_METADATA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_METADATA, 0)
}

}

impl<'input> ReplicationClauseContextAttrs<'input> for ReplicationClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn replicationClause(&mut self,)
	-> Result<Rc<ReplicationClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReplicationClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 16, RULE_replicationClause);
        let mut _localctx: Rc<ReplicationClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1093);
			recog.base.match_token(KW_FOR,&mut recog.err_handler)?;

			recog.base.set_state(1095);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_METADATA {
				{
				recog.base.set_state(1094);
				recog.base.match_token(KW_METADATA,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(1097);
			recog.base.match_token(KW_REPLICATION,&mut recog.err_handler)?;

			recog.base.set_state(1098);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(1099);
			recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

			recog.base.set_state(1100);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- exportStatement ----------------
pub type ExportStatementContextAll<'input> = ExportStatementContext<'input>;


pub type ExportStatementContext<'input> = BaseParserRuleContext<'input,ExportStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ExportStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExportStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExportStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_exportStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_exportStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExportStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_exportStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_exportStatement }
}
crate::tid!{ExportStatementContextExt<'a>}

impl<'input> ExportStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExportStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExportStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExportStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExportStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_EXPORT
/// Returns `None` if there is no child corresponding to token KW_EXPORT
fn KW_EXPORT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXPORT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableOrPartition(&self) -> Option<Rc<TableOrPartitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn replicationClause(&self) -> Option<Rc<ReplicationClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExportStatementContextAttrs<'input> for ExportStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn exportStatement(&mut self,)
	-> Result<Rc<ExportStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExportStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 18, RULE_exportStatement);
        let mut _localctx: Rc<ExportStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1102);
			recog.base.match_token(KW_EXPORT,&mut recog.err_handler)?;

			recog.base.set_state(1103);
			recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

			/*InvokeRule tableOrPartition*/
			recog.base.set_state(1104);
			recog.tableOrPartition()?;

			recog.base.set_state(1105);
			recog.base.match_token(KW_TO,&mut recog.err_handler)?;

			recog.base.set_state(1106);
			recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

			recog.base.set_state(1108);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_FOR {
				{
				/*InvokeRule replicationClause*/
				recog.base.set_state(1107);
				recog.replicationClause()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- importStatement ----------------
pub type ImportStatementContextAll<'input> = ImportStatementContext<'input>;


pub type ImportStatementContext<'input> = BaseParserRuleContext<'input,ImportStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ImportStatementContextExt<'input>{
	pub path: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ImportStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ImportStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_importStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_importStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ImportStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_importStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_importStatement }
}
crate::tid!{ImportStatementContextExt<'a>}

impl<'input> ImportStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ImportStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ImportStatementContextExt{
				path: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ImportStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ImportStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_IMPORT
/// Returns `None` if there is no child corresponding to token KW_IMPORT
fn KW_IMPORT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IMPORT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableOrPartition(&self) -> Option<Rc<TableOrPartitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableLocation(&self) -> Option<Rc<TableLocationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXTERNAL
/// Returns `None` if there is no child corresponding to token KW_EXTERNAL
fn KW_EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXTERNAL, 0)
}

}

impl<'input> ImportStatementContextAttrs<'input> for ImportStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn importStatement(&mut self,)
	-> Result<Rc<ImportStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ImportStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 20, RULE_importStatement);
        let mut _localctx: Rc<ImportStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1110);
			recog.base.match_token(KW_IMPORT,&mut recog.err_handler)?;

			recog.base.set_state(1116);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_EXTERNAL || _la==KW_TABLE {
				{
				recog.base.set_state(1112);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==KW_EXTERNAL {
					{
					recog.base.set_state(1111);
					recog.base.match_token(KW_EXTERNAL,&mut recog.err_handler)?;

					}
				}

				recog.base.set_state(1114);
				recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

				/*InvokeRule tableOrPartition*/
				recog.base.set_state(1115);
				recog.tableOrPartition()?;

				}
			}

			recog.base.set_state(1118);
			recog.base.match_token(KW_FROM,&mut recog.err_handler)?;

			recog.base.set_state(1119);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,ImportStatementContext >(&mut _localctx).path = Some(tmp.clone());
			  

			recog.base.set_state(1121);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_LOCATION {
				{
				/*InvokeRule tableLocation*/
				recog.base.set_state(1120);
				recog.tableLocation()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- replDumpStatement ----------------
pub type ReplDumpStatementContextAll<'input> = ReplDumpStatementContext<'input>;


pub type ReplDumpStatementContext<'input> = BaseParserRuleContext<'input,ReplDumpStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ReplDumpStatementContextExt<'input>{
	pub dbPolicy: Option<Rc<ReplDbPolicyContextAll<'input>>>,
	pub oldDbPolicy: Option<Rc<ReplDbPolicyContextAll<'input>>>,
	pub replConf: Option<Rc<ReplConfigsContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ReplDumpStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ReplDumpStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_replDumpStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_replDumpStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ReplDumpStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_replDumpStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_replDumpStatement }
}
crate::tid!{ReplDumpStatementContextExt<'a>}

impl<'input> ReplDumpStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReplDumpStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReplDumpStatementContextExt{
				dbPolicy: None, oldDbPolicy: None, replConf: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ReplDumpStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ReplDumpStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_REPL
/// Returns `None` if there is no child corresponding to token KW_REPL
fn KW_REPL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DUMP
/// Returns `None` if there is no child corresponding to token KW_DUMP
fn KW_DUMP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DUMP, 0)
}
fn replDbPolicy_all(&self) ->  Vec<Rc<ReplDbPolicyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn replDbPolicy(&self, i: usize) -> Option<Rc<ReplDbPolicyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_REPLACE
/// Returns `None` if there is no child corresponding to token KW_REPLACE
fn KW_REPLACE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
fn replConfigs(&self) -> Option<Rc<ReplConfigsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ReplDumpStatementContextAttrs<'input> for ReplDumpStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn replDumpStatement(&mut self,)
	-> Result<Rc<ReplDumpStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReplDumpStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 22, RULE_replDumpStatement);
        let mut _localctx: Rc<ReplDumpStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1123);
			recog.base.match_token(KW_REPL,&mut recog.err_handler)?;

			recog.base.set_state(1124);
			recog.base.match_token(KW_DUMP,&mut recog.err_handler)?;

			/*InvokeRule replDbPolicy*/
			recog.base.set_state(1125);
			let tmp = recog.replDbPolicy()?;
			 cast_mut::<_,ReplDumpStatementContext >(&mut _localctx).dbPolicy = Some(tmp.clone());
			  

			recog.base.set_state(1128);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(18,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1126);
					recog.base.match_token(KW_REPLACE,&mut recog.err_handler)?;

					/*InvokeRule replDbPolicy*/
					recog.base.set_state(1127);
					let tmp = recog.replDbPolicy()?;
					 cast_mut::<_,ReplDumpStatementContext >(&mut _localctx).oldDbPolicy = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			recog.base.set_state(1132);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(19,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1130);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					/*InvokeRule replConfigs*/
					recog.base.set_state(1131);
					let tmp = recog.replConfigs()?;
					 cast_mut::<_,ReplDumpStatementContext >(&mut _localctx).replConf = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- replDbPolicy ----------------
pub type ReplDbPolicyContextAll<'input> = ReplDbPolicyContext<'input>;


pub type ReplDbPolicyContext<'input> = BaseParserRuleContext<'input,ReplDbPolicyContextExt<'input>>;

#[derive(Clone)]
pub struct ReplDbPolicyContextExt<'input>{
	pub dbName: Option<Rc<Id_ContextAll<'input>>>,
	pub tablePolicy: Option<Rc<ReplTableLevelPolicyContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ReplDbPolicyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ReplDbPolicyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_replDbPolicy(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_replDbPolicy(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ReplDbPolicyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_replDbPolicy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_replDbPolicy }
}
crate::tid!{ReplDbPolicyContextExt<'a>}

impl<'input> ReplDbPolicyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReplDbPolicyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReplDbPolicyContextExt{
				dbName: None, tablePolicy: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ReplDbPolicyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ReplDbPolicyContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn replTableLevelPolicy(&self) -> Option<Rc<ReplTableLevelPolicyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ReplDbPolicyContextAttrs<'input> for ReplDbPolicyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn replDbPolicy(&mut self,)
	-> Result<Rc<ReplDbPolicyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReplDbPolicyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 24, RULE_replDbPolicy);
        let mut _localctx: Rc<ReplDbPolicyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(1134);
			let tmp = recog.id_()?;
			 cast_mut::<_,ReplDbPolicyContext >(&mut _localctx).dbName = Some(tmp.clone());
			  

			recog.base.set_state(1137);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DOT {
				{
				recog.base.set_state(1135);
				recog.base.match_token(DOT,&mut recog.err_handler)?;

				/*InvokeRule replTableLevelPolicy*/
				recog.base.set_state(1136);
				let tmp = recog.replTableLevelPolicy()?;
				 cast_mut::<_,ReplDbPolicyContext >(&mut _localctx).tablePolicy = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- replLoadStatement ----------------
pub type ReplLoadStatementContextAll<'input> = ReplLoadStatementContext<'input>;


pub type ReplLoadStatementContext<'input> = BaseParserRuleContext<'input,ReplLoadStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ReplLoadStatementContextExt<'input>{
	pub sourceDbPolicy: Option<Rc<ReplDbPolicyContextAll<'input>>>,
	pub dbName: Option<Rc<Id_ContextAll<'input>>>,
	pub replConf: Option<Rc<ReplConfigsContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ReplLoadStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ReplLoadStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_replLoadStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_replLoadStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ReplLoadStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_replLoadStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_replLoadStatement }
}
crate::tid!{ReplLoadStatementContextExt<'a>}

impl<'input> ReplLoadStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReplLoadStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReplLoadStatementContextExt{
				sourceDbPolicy: None, dbName: None, replConf: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ReplLoadStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ReplLoadStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_REPL
/// Returns `None` if there is no child corresponding to token KW_REPL
fn KW_REPL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOAD
/// Returns `None` if there is no child corresponding to token KW_LOAD
fn KW_LOAD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOAD, 0)
}
fn replDbPolicy(&self) -> Option<Rc<ReplDbPolicyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_INTO
/// Returns `None` if there is no child corresponding to token KW_INTO
fn KW_INTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INTO, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn replConfigs(&self) -> Option<Rc<ReplConfigsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ReplLoadStatementContextAttrs<'input> for ReplLoadStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn replLoadStatement(&mut self,)
	-> Result<Rc<ReplLoadStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReplLoadStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 26, RULE_replLoadStatement);
        let mut _localctx: Rc<ReplLoadStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1139);
			recog.base.match_token(KW_REPL,&mut recog.err_handler)?;

			recog.base.set_state(1140);
			recog.base.match_token(KW_LOAD,&mut recog.err_handler)?;

			/*InvokeRule replDbPolicy*/
			recog.base.set_state(1141);
			let tmp = recog.replDbPolicy()?;
			 cast_mut::<_,ReplLoadStatementContext >(&mut _localctx).sourceDbPolicy = Some(tmp.clone());
			  

			recog.base.set_state(1144);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_INTO {
				{
				recog.base.set_state(1142);
				recog.base.match_token(KW_INTO,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(1143);
				let tmp = recog.id_()?;
				 cast_mut::<_,ReplLoadStatementContext >(&mut _localctx).dbName = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1148);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(22,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1146);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					/*InvokeRule replConfigs*/
					recog.base.set_state(1147);
					let tmp = recog.replConfigs()?;
					 cast_mut::<_,ReplLoadStatementContext >(&mut _localctx).replConf = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- replConfigs ----------------
pub type ReplConfigsContextAll<'input> = ReplConfigsContext<'input>;


pub type ReplConfigsContext<'input> = BaseParserRuleContext<'input,ReplConfigsContextExt<'input>>;

#[derive(Clone)]
pub struct ReplConfigsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ReplConfigsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ReplConfigsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_replConfigs(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_replConfigs(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ReplConfigsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_replConfigs }
	//fn type_rule_index() -> usize where Self: Sized { RULE_replConfigs }
}
crate::tid!{ReplConfigsContextExt<'a>}

impl<'input> ReplConfigsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReplConfigsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReplConfigsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ReplConfigsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ReplConfigsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn replConfigsList(&self) -> Option<Rc<ReplConfigsListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> ReplConfigsContextAttrs<'input> for ReplConfigsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn replConfigs(&mut self,)
	-> Result<Rc<ReplConfigsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReplConfigsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 28, RULE_replConfigs);
        let mut _localctx: Rc<ReplConfigsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1150);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule replConfigsList*/
			recog.base.set_state(1151);
			recog.replConfigsList()?;

			recog.base.set_state(1152);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- replConfigsList ----------------
pub type ReplConfigsListContextAll<'input> = ReplConfigsListContext<'input>;


pub type ReplConfigsListContext<'input> = BaseParserRuleContext<'input,ReplConfigsListContextExt<'input>>;

#[derive(Clone)]
pub struct ReplConfigsListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ReplConfigsListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ReplConfigsListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_replConfigsList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_replConfigsList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ReplConfigsListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_replConfigsList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_replConfigsList }
}
crate::tid!{ReplConfigsListContextExt<'a>}

impl<'input> ReplConfigsListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReplConfigsListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReplConfigsListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ReplConfigsListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ReplConfigsListContextExt<'input>>{

fn keyValueProperty_all(&self) ->  Vec<Rc<KeyValuePropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn keyValueProperty(&self, i: usize) -> Option<Rc<KeyValuePropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ReplConfigsListContextAttrs<'input> for ReplConfigsListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn replConfigsList(&mut self,)
	-> Result<Rc<ReplConfigsListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReplConfigsListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 30, RULE_replConfigsList);
        let mut _localctx: Rc<ReplConfigsListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule keyValueProperty*/
			recog.base.set_state(1154);
			recog.keyValueProperty()?;

			recog.base.set_state(1159);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1155);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule keyValueProperty*/
				recog.base.set_state(1156);
				recog.keyValueProperty()?;

				}
				}
				recog.base.set_state(1161);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- replTableLevelPolicy ----------------
pub type ReplTableLevelPolicyContextAll<'input> = ReplTableLevelPolicyContext<'input>;


pub type ReplTableLevelPolicyContext<'input> = BaseParserRuleContext<'input,ReplTableLevelPolicyContextExt<'input>>;

#[derive(Clone)]
pub struct ReplTableLevelPolicyContextExt<'input>{
	pub replTablesIncludeList: Option<TokenType<'input>>,
	pub replTablesExcludeList: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ReplTableLevelPolicyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ReplTableLevelPolicyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_replTableLevelPolicy(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_replTableLevelPolicy(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ReplTableLevelPolicyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_replTableLevelPolicy }
	//fn type_rule_index() -> usize where Self: Sized { RULE_replTableLevelPolicy }
}
crate::tid!{ReplTableLevelPolicyContextExt<'a>}

impl<'input> ReplTableLevelPolicyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReplTableLevelPolicyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReplTableLevelPolicyContextExt{
				replTablesIncludeList: None, replTablesExcludeList: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ReplTableLevelPolicyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ReplTableLevelPolicyContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token StringLiteral in current rule
fn StringLiteral_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token StringLiteral, starting from 0.
/// Returns `None` if number of children corresponding to token StringLiteral is less or equal than `i`.
fn StringLiteral(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, i)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}

}

impl<'input> ReplTableLevelPolicyContextAttrs<'input> for ReplTableLevelPolicyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn replTableLevelPolicy(&mut self,)
	-> Result<Rc<ReplTableLevelPolicyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReplTableLevelPolicyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 32, RULE_replTableLevelPolicy);
        let mut _localctx: Rc<ReplTableLevelPolicyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1162);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,ReplTableLevelPolicyContext >(&mut _localctx).replTablesIncludeList = Some(tmp.clone());
			  

			recog.base.set_state(1165);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DOT {
				{
				recog.base.set_state(1163);
				recog.base.match_token(DOT,&mut recog.err_handler)?;

				recog.base.set_state(1164);
				let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
				 cast_mut::<_,ReplTableLevelPolicyContext >(&mut _localctx).replTablesExcludeList = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- replStatusStatement ----------------
pub type ReplStatusStatementContextAll<'input> = ReplStatusStatementContext<'input>;


pub type ReplStatusStatementContext<'input> = BaseParserRuleContext<'input,ReplStatusStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ReplStatusStatementContextExt<'input>{
	pub dbName: Option<Rc<Id_ContextAll<'input>>>,
	pub replConf: Option<Rc<ReplConfigsContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ReplStatusStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ReplStatusStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_replStatusStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_replStatusStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ReplStatusStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_replStatusStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_replStatusStatement }
}
crate::tid!{ReplStatusStatementContextExt<'a>}

impl<'input> ReplStatusStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReplStatusStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReplStatusStatementContextExt{
				dbName: None, replConf: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ReplStatusStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ReplStatusStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_REPL
/// Returns `None` if there is no child corresponding to token KW_REPL
fn KW_REPL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STATUS
/// Returns `None` if there is no child corresponding to token KW_STATUS
fn KW_STATUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STATUS, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
fn replConfigs(&self) -> Option<Rc<ReplConfigsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ReplStatusStatementContextAttrs<'input> for ReplStatusStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn replStatusStatement(&mut self,)
	-> Result<Rc<ReplStatusStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReplStatusStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 34, RULE_replStatusStatement);
        let mut _localctx: Rc<ReplStatusStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1167);
			recog.base.match_token(KW_REPL,&mut recog.err_handler)?;

			recog.base.set_state(1168);
			recog.base.match_token(KW_STATUS,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(1169);
			let tmp = recog.id_()?;
			 cast_mut::<_,ReplStatusStatementContext >(&mut _localctx).dbName = Some(tmp.clone());
			  

			recog.base.set_state(1172);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(25,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1170);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					/*InvokeRule replConfigs*/
					recog.base.set_state(1171);
					let tmp = recog.replConfigs()?;
					 cast_mut::<_,ReplStatusStatementContext >(&mut _localctx).replConf = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- ddlStatement ----------------
pub type DdlStatementContextAll<'input> = DdlStatementContext<'input>;


pub type DdlStatementContext<'input> = BaseParserRuleContext<'input,DdlStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DdlStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DdlStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DdlStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_ddlStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_ddlStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DdlStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_ddlStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_ddlStatement }
}
crate::tid!{DdlStatementContextExt<'a>}

impl<'input> DdlStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DdlStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DdlStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DdlStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DdlStatementContextExt<'input>>{

fn createDatabaseStatement(&self) -> Option<Rc<CreateDatabaseStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn switchDatabaseStatement(&self) -> Option<Rc<SwitchDatabaseStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropDatabaseStatement(&self) -> Option<Rc<DropDatabaseStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createTableStatement(&self) -> Option<Rc<CreateTableStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropTableStatement(&self) -> Option<Rc<DropTableStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn truncateTableStatement(&self) -> Option<Rc<TruncateTableStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatement(&self) -> Option<Rc<AlterStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn descStatement(&self) -> Option<Rc<DescStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn showStatement(&self) -> Option<Rc<ShowStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn metastoreCheck(&self) -> Option<Rc<MetastoreCheckContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createViewStatement(&self) -> Option<Rc<CreateViewStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createMaterializedViewStatement(&self) -> Option<Rc<CreateMaterializedViewStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createScheduledQueryStatement(&self) -> Option<Rc<CreateScheduledQueryStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterScheduledQueryStatement(&self) -> Option<Rc<AlterScheduledQueryStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropScheduledQueryStatement(&self) -> Option<Rc<DropScheduledQueryStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropViewStatement(&self) -> Option<Rc<DropViewStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropMaterializedViewStatement(&self) -> Option<Rc<DropMaterializedViewStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createFunctionStatement(&self) -> Option<Rc<CreateFunctionStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createMacroStatement(&self) -> Option<Rc<CreateMacroStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropFunctionStatement(&self) -> Option<Rc<DropFunctionStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn reloadFunctionsStatement(&self) -> Option<Rc<ReloadFunctionsStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropMacroStatement(&self) -> Option<Rc<DropMacroStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createIndexStatement(&self) -> Option<Rc<CreateIndexStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropIndexStatement(&self) -> Option<Rc<DropIndexStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn analyzeStatement(&self) -> Option<Rc<AnalyzeStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn lockStatement(&self) -> Option<Rc<LockStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unlockStatement(&self) -> Option<Rc<UnlockStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn lockDatabase(&self) -> Option<Rc<LockDatabaseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unlockDatabase(&self) -> Option<Rc<UnlockDatabaseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createRoleStatement(&self) -> Option<Rc<CreateRoleStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropRoleStatement(&self) -> Option<Rc<DropRoleStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn grantPrivileges(&self) -> Option<Rc<GrantPrivilegesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn revokePrivileges(&self) -> Option<Rc<RevokePrivilegesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn showGrants(&self) -> Option<Rc<ShowGrantsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn showRoleGrants(&self) -> Option<Rc<ShowRoleGrantsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn showRolePrincipals(&self) -> Option<Rc<ShowRolePrincipalsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn showRoles(&self) -> Option<Rc<ShowRolesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn grantRole(&self) -> Option<Rc<GrantRoleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn revokeRole(&self) -> Option<Rc<RevokeRoleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setRole(&self) -> Option<Rc<SetRoleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn showCurrentRole(&self) -> Option<Rc<ShowCurrentRoleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn abortTransactionStatement(&self) -> Option<Rc<AbortTransactionStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn abortCompactionStatement(&self) -> Option<Rc<AbortCompactionStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn killQueryStatement(&self) -> Option<Rc<KillQueryStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn resourcePlanDdlStatements(&self) -> Option<Rc<ResourcePlanDdlStatementsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createDataConnectorStatement(&self) -> Option<Rc<CreateDataConnectorStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropDataConnectorStatement(&self) -> Option<Rc<DropDataConnectorStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DdlStatementContextAttrs<'input> for DdlStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn ddlStatement(&mut self,)
	-> Result<Rc<DdlStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DdlStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 36, RULE_ddlStatement);
        let mut _localctx: Rc<DdlStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1221);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(26,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule createDatabaseStatement*/
					recog.base.set_state(1174);
					recog.createDatabaseStatement()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule switchDatabaseStatement*/
					recog.base.set_state(1175);
					recog.switchDatabaseStatement()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule dropDatabaseStatement*/
					recog.base.set_state(1176);
					recog.dropDatabaseStatement()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule createTableStatement*/
					recog.base.set_state(1177);
					recog.createTableStatement()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule dropTableStatement*/
					recog.base.set_state(1178);
					recog.dropTableStatement()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule truncateTableStatement*/
					recog.base.set_state(1179);
					recog.truncateTableStatement()?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule alterStatement*/
					recog.base.set_state(1180);
					recog.alterStatement()?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule descStatement*/
					recog.base.set_state(1181);
					recog.descStatement()?;

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule showStatement*/
					recog.base.set_state(1182);
					recog.showStatement()?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule metastoreCheck*/
					recog.base.set_state(1183);
					recog.metastoreCheck()?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule createViewStatement*/
					recog.base.set_state(1184);
					recog.createViewStatement()?;

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					/*InvokeRule createMaterializedViewStatement*/
					recog.base.set_state(1185);
					recog.createMaterializedViewStatement()?;

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					/*InvokeRule createScheduledQueryStatement*/
					recog.base.set_state(1186);
					recog.createScheduledQueryStatement()?;

					}
				}
			,
				14 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					/*InvokeRule alterScheduledQueryStatement*/
					recog.base.set_state(1187);
					recog.alterScheduledQueryStatement()?;

					}
				}
			,
				15 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					/*InvokeRule dropScheduledQueryStatement*/
					recog.base.set_state(1188);
					recog.dropScheduledQueryStatement()?;

					}
				}
			,
				16 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 16);
					recog.base.enter_outer_alt(None, 16);
					{
					/*InvokeRule dropViewStatement*/
					recog.base.set_state(1189);
					recog.dropViewStatement()?;

					}
				}
			,
				17 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 17);
					recog.base.enter_outer_alt(None, 17);
					{
					/*InvokeRule dropMaterializedViewStatement*/
					recog.base.set_state(1190);
					recog.dropMaterializedViewStatement()?;

					}
				}
			,
				18 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 18);
					recog.base.enter_outer_alt(None, 18);
					{
					/*InvokeRule createFunctionStatement*/
					recog.base.set_state(1191);
					recog.createFunctionStatement()?;

					}
				}
			,
				19 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 19);
					recog.base.enter_outer_alt(None, 19);
					{
					/*InvokeRule createMacroStatement*/
					recog.base.set_state(1192);
					recog.createMacroStatement()?;

					}
				}
			,
				20 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 20);
					recog.base.enter_outer_alt(None, 20);
					{
					/*InvokeRule dropFunctionStatement*/
					recog.base.set_state(1193);
					recog.dropFunctionStatement()?;

					}
				}
			,
				21 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 21);
					recog.base.enter_outer_alt(None, 21);
					{
					/*InvokeRule reloadFunctionsStatement*/
					recog.base.set_state(1194);
					recog.reloadFunctionsStatement()?;

					}
				}
			,
				22 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 22);
					recog.base.enter_outer_alt(None, 22);
					{
					/*InvokeRule dropMacroStatement*/
					recog.base.set_state(1195);
					recog.dropMacroStatement()?;

					}
				}
			,
				23 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 23);
					recog.base.enter_outer_alt(None, 23);
					{
					/*InvokeRule createIndexStatement*/
					recog.base.set_state(1196);
					recog.createIndexStatement()?;

					}
				}
			,
				24 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 24);
					recog.base.enter_outer_alt(None, 24);
					{
					/*InvokeRule dropIndexStatement*/
					recog.base.set_state(1197);
					recog.dropIndexStatement()?;

					}
				}
			,
				25 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 25);
					recog.base.enter_outer_alt(None, 25);
					{
					/*InvokeRule analyzeStatement*/
					recog.base.set_state(1198);
					recog.analyzeStatement()?;

					}
				}
			,
				26 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 26);
					recog.base.enter_outer_alt(None, 26);
					{
					/*InvokeRule lockStatement*/
					recog.base.set_state(1199);
					recog.lockStatement()?;

					}
				}
			,
				27 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 27);
					recog.base.enter_outer_alt(None, 27);
					{
					/*InvokeRule unlockStatement*/
					recog.base.set_state(1200);
					recog.unlockStatement()?;

					}
				}
			,
				28 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 28);
					recog.base.enter_outer_alt(None, 28);
					{
					/*InvokeRule lockDatabase*/
					recog.base.set_state(1201);
					recog.lockDatabase()?;

					}
				}
			,
				29 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 29);
					recog.base.enter_outer_alt(None, 29);
					{
					/*InvokeRule unlockDatabase*/
					recog.base.set_state(1202);
					recog.unlockDatabase()?;

					}
				}
			,
				30 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 30);
					recog.base.enter_outer_alt(None, 30);
					{
					/*InvokeRule createRoleStatement*/
					recog.base.set_state(1203);
					recog.createRoleStatement()?;

					}
				}
			,
				31 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 31);
					recog.base.enter_outer_alt(None, 31);
					{
					/*InvokeRule dropRoleStatement*/
					recog.base.set_state(1204);
					recog.dropRoleStatement()?;

					}
				}
			,
				32 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 32);
					recog.base.enter_outer_alt(None, 32);
					{
					/*InvokeRule grantPrivileges*/
					recog.base.set_state(1205);
					recog.grantPrivileges()?;

					}
				}
			,
				33 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 33);
					recog.base.enter_outer_alt(None, 33);
					{
					/*InvokeRule revokePrivileges*/
					recog.base.set_state(1206);
					recog.revokePrivileges()?;

					}
				}
			,
				34 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 34);
					recog.base.enter_outer_alt(None, 34);
					{
					/*InvokeRule showGrants*/
					recog.base.set_state(1207);
					recog.showGrants()?;

					}
				}
			,
				35 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 35);
					recog.base.enter_outer_alt(None, 35);
					{
					/*InvokeRule showRoleGrants*/
					recog.base.set_state(1208);
					recog.showRoleGrants()?;

					}
				}
			,
				36 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 36);
					recog.base.enter_outer_alt(None, 36);
					{
					/*InvokeRule showRolePrincipals*/
					recog.base.set_state(1209);
					recog.showRolePrincipals()?;

					}
				}
			,
				37 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 37);
					recog.base.enter_outer_alt(None, 37);
					{
					/*InvokeRule showRoles*/
					recog.base.set_state(1210);
					recog.showRoles()?;

					}
				}
			,
				38 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 38);
					recog.base.enter_outer_alt(None, 38);
					{
					/*InvokeRule grantRole*/
					recog.base.set_state(1211);
					recog.grantRole()?;

					}
				}
			,
				39 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 39);
					recog.base.enter_outer_alt(None, 39);
					{
					/*InvokeRule revokeRole*/
					recog.base.set_state(1212);
					recog.revokeRole()?;

					}
				}
			,
				40 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 40);
					recog.base.enter_outer_alt(None, 40);
					{
					/*InvokeRule setRole*/
					recog.base.set_state(1213);
					recog.setRole()?;

					}
				}
			,
				41 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 41);
					recog.base.enter_outer_alt(None, 41);
					{
					/*InvokeRule showCurrentRole*/
					recog.base.set_state(1214);
					recog.showCurrentRole()?;

					}
				}
			,
				42 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 42);
					recog.base.enter_outer_alt(None, 42);
					{
					/*InvokeRule abortTransactionStatement*/
					recog.base.set_state(1215);
					recog.abortTransactionStatement()?;

					}
				}
			,
				43 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 43);
					recog.base.enter_outer_alt(None, 43);
					{
					/*InvokeRule abortCompactionStatement*/
					recog.base.set_state(1216);
					recog.abortCompactionStatement()?;

					}
				}
			,
				44 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 44);
					recog.base.enter_outer_alt(None, 44);
					{
					/*InvokeRule killQueryStatement*/
					recog.base.set_state(1217);
					recog.killQueryStatement()?;

					}
				}
			,
				45 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 45);
					recog.base.enter_outer_alt(None, 45);
					{
					/*InvokeRule resourcePlanDdlStatements*/
					recog.base.set_state(1218);
					recog.resourcePlanDdlStatements()?;

					}
				}
			,
				46 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 46);
					recog.base.enter_outer_alt(None, 46);
					{
					/*InvokeRule createDataConnectorStatement*/
					recog.base.set_state(1219);
					recog.createDataConnectorStatement()?;

					}
				}
			,
				47 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 47);
					recog.base.enter_outer_alt(None, 47);
					{
					/*InvokeRule dropDataConnectorStatement*/
					recog.base.set_state(1220);
					recog.dropDataConnectorStatement()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- ifExists ----------------
pub type IfExistsContextAll<'input> = IfExistsContext<'input>;


pub type IfExistsContext<'input> = BaseParserRuleContext<'input,IfExistsContextExt<'input>>;

#[derive(Clone)]
pub struct IfExistsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for IfExistsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for IfExistsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_ifExists(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_ifExists(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for IfExistsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_ifExists }
	//fn type_rule_index() -> usize where Self: Sized { RULE_ifExists }
}
crate::tid!{IfExistsContextExt<'a>}

impl<'input> IfExistsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IfExistsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IfExistsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IfExistsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<IfExistsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_IF
/// Returns `None` if there is no child corresponding to token KW_IF
fn KW_IF(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IF, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXISTS
/// Returns `None` if there is no child corresponding to token KW_EXISTS
fn KW_EXISTS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXISTS, 0)
}

}

impl<'input> IfExistsContextAttrs<'input> for IfExistsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn ifExists(&mut self,)
	-> Result<Rc<IfExistsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IfExistsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 38, RULE_ifExists);
        let mut _localctx: Rc<IfExistsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1223);
			recog.base.match_token(KW_IF,&mut recog.err_handler)?;

			recog.base.set_state(1224);
			recog.base.match_token(KW_EXISTS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- restrictOrCascade ----------------
pub type RestrictOrCascadeContextAll<'input> = RestrictOrCascadeContext<'input>;


pub type RestrictOrCascadeContext<'input> = BaseParserRuleContext<'input,RestrictOrCascadeContextExt<'input>>;

#[derive(Clone)]
pub struct RestrictOrCascadeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RestrictOrCascadeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RestrictOrCascadeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_restrictOrCascade(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_restrictOrCascade(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RestrictOrCascadeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_restrictOrCascade }
	//fn type_rule_index() -> usize where Self: Sized { RULE_restrictOrCascade }
}
crate::tid!{RestrictOrCascadeContextExt<'a>}

impl<'input> RestrictOrCascadeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RestrictOrCascadeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RestrictOrCascadeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RestrictOrCascadeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RestrictOrCascadeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_RESTRICT
/// Returns `None` if there is no child corresponding to token KW_RESTRICT
fn KW_RESTRICT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RESTRICT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CASCADE
/// Returns `None` if there is no child corresponding to token KW_CASCADE
fn KW_CASCADE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CASCADE, 0)
}

}

impl<'input> RestrictOrCascadeContextAttrs<'input> for RestrictOrCascadeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn restrictOrCascade(&mut self,)
	-> Result<Rc<RestrictOrCascadeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RestrictOrCascadeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 40, RULE_restrictOrCascade);
        let mut _localctx: Rc<RestrictOrCascadeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1226);
			_la = recog.base.input.la(1);
			if { !(_la==KW_CASCADE || _la==KW_RESTRICT) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- ifNotExists ----------------
pub type IfNotExistsContextAll<'input> = IfNotExistsContext<'input>;


pub type IfNotExistsContext<'input> = BaseParserRuleContext<'input,IfNotExistsContextExt<'input>>;

#[derive(Clone)]
pub struct IfNotExistsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for IfNotExistsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for IfNotExistsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_ifNotExists(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_ifNotExists(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for IfNotExistsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_ifNotExists }
	//fn type_rule_index() -> usize where Self: Sized { RULE_ifNotExists }
}
crate::tid!{IfNotExistsContextExt<'a>}

impl<'input> IfNotExistsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IfNotExistsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IfNotExistsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IfNotExistsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<IfNotExistsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_IF
/// Returns `None` if there is no child corresponding to token KW_IF
fn KW_IF(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IF, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOT
/// Returns `None` if there is no child corresponding to token KW_NOT
fn KW_NOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXISTS
/// Returns `None` if there is no child corresponding to token KW_EXISTS
fn KW_EXISTS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXISTS, 0)
}

}

impl<'input> IfNotExistsContextAttrs<'input> for IfNotExistsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn ifNotExists(&mut self,)
	-> Result<Rc<IfNotExistsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IfNotExistsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 42, RULE_ifNotExists);
        let mut _localctx: Rc<IfNotExistsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1228);
			recog.base.match_token(KW_IF,&mut recog.err_handler)?;

			recog.base.set_state(1229);
			recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

			recog.base.set_state(1230);
			recog.base.match_token(KW_EXISTS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- force ----------------
pub type ForceContextAll<'input> = ForceContext<'input>;


pub type ForceContext<'input> = BaseParserRuleContext<'input,ForceContextExt<'input>>;

#[derive(Clone)]
pub struct ForceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ForceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ForceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_force(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_force(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ForceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_force }
	//fn type_rule_index() -> usize where Self: Sized { RULE_force }
}
crate::tid!{ForceContextExt<'a>}

impl<'input> ForceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ForceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ForceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ForceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ForceContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_FORCE
/// Returns `None` if there is no child corresponding to token KW_FORCE
fn KW_FORCE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FORCE, 0)
}

}

impl<'input> ForceContextAttrs<'input> for ForceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn force(&mut self,)
	-> Result<Rc<ForceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ForceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 44, RULE_force);
        let mut _localctx: Rc<ForceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1232);
			recog.base.match_token(KW_FORCE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rewriteEnabled ----------------
pub type RewriteEnabledContextAll<'input> = RewriteEnabledContext<'input>;


pub type RewriteEnabledContext<'input> = BaseParserRuleContext<'input,RewriteEnabledContextExt<'input>>;

#[derive(Clone)]
pub struct RewriteEnabledContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RewriteEnabledContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RewriteEnabledContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rewriteEnabled(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rewriteEnabled(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RewriteEnabledContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rewriteEnabled }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rewriteEnabled }
}
crate::tid!{RewriteEnabledContextExt<'a>}

impl<'input> RewriteEnabledContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RewriteEnabledContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RewriteEnabledContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RewriteEnabledContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RewriteEnabledContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ENABLE
/// Returns `None` if there is no child corresponding to token KW_ENABLE
fn KW_ENABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ENABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REWRITE
/// Returns `None` if there is no child corresponding to token KW_REWRITE
fn KW_REWRITE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REWRITE, 0)
}

}

impl<'input> RewriteEnabledContextAttrs<'input> for RewriteEnabledContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rewriteEnabled(&mut self,)
	-> Result<Rc<RewriteEnabledContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RewriteEnabledContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 46, RULE_rewriteEnabled);
        let mut _localctx: Rc<RewriteEnabledContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1234);
			recog.base.match_token(KW_ENABLE,&mut recog.err_handler)?;

			recog.base.set_state(1235);
			recog.base.match_token(KW_REWRITE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rewriteDisabled ----------------
pub type RewriteDisabledContextAll<'input> = RewriteDisabledContext<'input>;


pub type RewriteDisabledContext<'input> = BaseParserRuleContext<'input,RewriteDisabledContextExt<'input>>;

#[derive(Clone)]
pub struct RewriteDisabledContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RewriteDisabledContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RewriteDisabledContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rewriteDisabled(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rewriteDisabled(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RewriteDisabledContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rewriteDisabled }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rewriteDisabled }
}
crate::tid!{RewriteDisabledContextExt<'a>}

impl<'input> RewriteDisabledContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RewriteDisabledContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RewriteDisabledContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RewriteDisabledContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RewriteDisabledContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DISABLE
/// Returns `None` if there is no child corresponding to token KW_DISABLE
fn KW_DISABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REWRITE
/// Returns `None` if there is no child corresponding to token KW_REWRITE
fn KW_REWRITE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REWRITE, 0)
}

}

impl<'input> RewriteDisabledContextAttrs<'input> for RewriteDisabledContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rewriteDisabled(&mut self,)
	-> Result<Rc<RewriteDisabledContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RewriteDisabledContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 48, RULE_rewriteDisabled);
        let mut _localctx: Rc<RewriteDisabledContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1237);
			recog.base.match_token(KW_DISABLE,&mut recog.err_handler)?;

			recog.base.set_state(1238);
			recog.base.match_token(KW_REWRITE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- storedAsDirs ----------------
pub type StoredAsDirsContextAll<'input> = StoredAsDirsContext<'input>;


pub type StoredAsDirsContext<'input> = BaseParserRuleContext<'input,StoredAsDirsContextExt<'input>>;

#[derive(Clone)]
pub struct StoredAsDirsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for StoredAsDirsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for StoredAsDirsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_storedAsDirs(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_storedAsDirs(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for StoredAsDirsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_storedAsDirs }
	//fn type_rule_index() -> usize where Self: Sized { RULE_storedAsDirs }
}
crate::tid!{StoredAsDirsContextExt<'a>}

impl<'input> StoredAsDirsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StoredAsDirsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StoredAsDirsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StoredAsDirsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<StoredAsDirsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_STORED
/// Returns `None` if there is no child corresponding to token KW_STORED
fn KW_STORED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DIRECTORIES
/// Returns `None` if there is no child corresponding to token KW_DIRECTORIES
fn KW_DIRECTORIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DIRECTORIES, 0)
}

}

impl<'input> StoredAsDirsContextAttrs<'input> for StoredAsDirsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn storedAsDirs(&mut self,)
	-> Result<Rc<StoredAsDirsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StoredAsDirsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 50, RULE_storedAsDirs);
        let mut _localctx: Rc<StoredAsDirsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1240);
			recog.base.match_token(KW_STORED,&mut recog.err_handler)?;

			recog.base.set_state(1241);
			recog.base.match_token(KW_AS,&mut recog.err_handler)?;

			recog.base.set_state(1242);
			recog.base.match_token(KW_DIRECTORIES,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- orReplace ----------------
pub type OrReplaceContextAll<'input> = OrReplaceContext<'input>;


pub type OrReplaceContext<'input> = BaseParserRuleContext<'input,OrReplaceContextExt<'input>>;

#[derive(Clone)]
pub struct OrReplaceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for OrReplaceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for OrReplaceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_orReplace(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_orReplace(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for OrReplaceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_orReplace }
	//fn type_rule_index() -> usize where Self: Sized { RULE_orReplace }
}
crate::tid!{OrReplaceContextExt<'a>}

impl<'input> OrReplaceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OrReplaceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OrReplaceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait OrReplaceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<OrReplaceContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_OR
/// Returns `None` if there is no child corresponding to token KW_OR
fn KW_OR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REPLACE
/// Returns `None` if there is no child corresponding to token KW_REPLACE
fn KW_REPLACE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPLACE, 0)
}

}

impl<'input> OrReplaceContextAttrs<'input> for OrReplaceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn orReplace(&mut self,)
	-> Result<Rc<OrReplaceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OrReplaceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 52, RULE_orReplace);
        let mut _localctx: Rc<OrReplaceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1244);
			recog.base.match_token(KW_OR,&mut recog.err_handler)?;

			recog.base.set_state(1245);
			recog.base.match_token(KW_REPLACE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createDatabaseStatement ----------------
pub type CreateDatabaseStatementContextAll<'input> = CreateDatabaseStatementContext<'input>;


pub type CreateDatabaseStatementContext<'input> = BaseParserRuleContext<'input,CreateDatabaseStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateDatabaseStatementContextExt<'input>{
	pub name: Option<Rc<Id_ContextAll<'input>>>,
	pub dbprops: Option<Rc<DbPropertiesContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateDatabaseStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateDatabaseStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createDatabaseStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createDatabaseStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateDatabaseStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createDatabaseStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createDatabaseStatement }
}
crate::tid!{CreateDatabaseStatementContextExt<'a>}

impl<'input> CreateDatabaseStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateDatabaseStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateDatabaseStatementContextExt{
				name: None, dbprops: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateDatabaseStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateDatabaseStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
fn db_schema(&self) -> Option<Rc<Db_schemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifNotExists(&self) -> Option<Rc<IfNotExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn databaseComment(&self) -> Option<Rc<DatabaseCommentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dbLocation(&self) -> Option<Rc<DbLocationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dbManagedLocation(&self) -> Option<Rc<DbManagedLocationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DBPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_DBPROPERTIES
fn KW_DBPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DBPROPERTIES, 0)
}
fn dbProperties(&self) -> Option<Rc<DbPropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_REMOTE
/// Returns `None` if there is no child corresponding to token KW_REMOTE
fn KW_REMOTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REMOTE, 0)
}
fn dbConnectorName(&self) -> Option<Rc<DbConnectorNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateDatabaseStatementContextAttrs<'input> for CreateDatabaseStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createDatabaseStatement(&mut self,)
	-> Result<Rc<CreateDatabaseStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateDatabaseStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 54, RULE_createDatabaseStatement);
        let mut _localctx: Rc<CreateDatabaseStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1283);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(35,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1247);
					recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

					/*InvokeRule db_schema*/
					recog.base.set_state(1248);
					recog.db_schema()?;

					recog.base.set_state(1250);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_IF {
						{
						/*InvokeRule ifNotExists*/
						recog.base.set_state(1249);
						recog.ifNotExists()?;

						}
					}

					/*InvokeRule id_*/
					recog.base.set_state(1252);
					let tmp = recog.id_()?;
					 cast_mut::<_,CreateDatabaseStatementContext >(&mut _localctx).name = Some(tmp.clone());
					  

					recog.base.set_state(1254);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_COMMENT {
						{
						/*InvokeRule databaseComment*/
						recog.base.set_state(1253);
						recog.databaseComment()?;

						}
					}

					recog.base.set_state(1257);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_LOCATION {
						{
						/*InvokeRule dbLocation*/
						recog.base.set_state(1256);
						recog.dbLocation()?;

						}
					}

					recog.base.set_state(1260);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_MANAGEDLOCATION {
						{
						/*InvokeRule dbManagedLocation*/
						recog.base.set_state(1259);
						recog.dbManagedLocation()?;

						}
					}

					recog.base.set_state(1265);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(31,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1262);
							recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

							recog.base.set_state(1263);
							recog.base.match_token(KW_DBPROPERTIES,&mut recog.err_handler)?;

							/*InvokeRule dbProperties*/
							recog.base.set_state(1264);
							let tmp = recog.dbProperties()?;
							 cast_mut::<_,CreateDatabaseStatementContext >(&mut _localctx).dbprops = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1267);
					recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1268);
					recog.base.match_token(KW_REMOTE,&mut recog.err_handler)?;

					/*InvokeRule db_schema*/
					recog.base.set_state(1269);
					recog.db_schema()?;

					recog.base.set_state(1271);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_IF {
						{
						/*InvokeRule ifNotExists*/
						recog.base.set_state(1270);
						recog.ifNotExists()?;

						}
					}

					/*InvokeRule id_*/
					recog.base.set_state(1273);
					let tmp = recog.id_()?;
					 cast_mut::<_,CreateDatabaseStatementContext >(&mut _localctx).name = Some(tmp.clone());
					  

					recog.base.set_state(1275);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_COMMENT {
						{
						/*InvokeRule databaseComment*/
						recog.base.set_state(1274);
						recog.databaseComment()?;

						}
					}

					/*InvokeRule dbConnectorName*/
					recog.base.set_state(1277);
					recog.dbConnectorName()?;

					recog.base.set_state(1281);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(34,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1278);
							recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

							recog.base.set_state(1279);
							recog.base.match_token(KW_DBPROPERTIES,&mut recog.err_handler)?;

							/*InvokeRule dbProperties*/
							recog.base.set_state(1280);
							let tmp = recog.dbProperties()?;
							 cast_mut::<_,CreateDatabaseStatementContext >(&mut _localctx).dbprops = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dbLocation ----------------
pub type DbLocationContextAll<'input> = DbLocationContext<'input>;


pub type DbLocationContext<'input> = BaseParserRuleContext<'input,DbLocationContextExt<'input>>;

#[derive(Clone)]
pub struct DbLocationContextExt<'input>{
	pub locn: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DbLocationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DbLocationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dbLocation(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dbLocation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DbLocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dbLocation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dbLocation }
}
crate::tid!{DbLocationContextExt<'a>}

impl<'input> DbLocationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DbLocationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DbLocationContextExt{
				locn: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DbLocationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DbLocationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LOCATION
/// Returns `None` if there is no child corresponding to token KW_LOCATION
fn KW_LOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> DbLocationContextAttrs<'input> for DbLocationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dbLocation(&mut self,)
	-> Result<Rc<DbLocationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DbLocationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 56, RULE_dbLocation);
        let mut _localctx: Rc<DbLocationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1285);
			recog.base.match_token(KW_LOCATION,&mut recog.err_handler)?;

			recog.base.set_state(1286);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,DbLocationContext >(&mut _localctx).locn = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dbManagedLocation ----------------
pub type DbManagedLocationContextAll<'input> = DbManagedLocationContext<'input>;


pub type DbManagedLocationContext<'input> = BaseParserRuleContext<'input,DbManagedLocationContextExt<'input>>;

#[derive(Clone)]
pub struct DbManagedLocationContextExt<'input>{
	pub locn: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DbManagedLocationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DbManagedLocationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dbManagedLocation(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dbManagedLocation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DbManagedLocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dbManagedLocation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dbManagedLocation }
}
crate::tid!{DbManagedLocationContextExt<'a>}

impl<'input> DbManagedLocationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DbManagedLocationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DbManagedLocationContextExt{
				locn: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DbManagedLocationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DbManagedLocationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_MANAGEDLOCATION
/// Returns `None` if there is no child corresponding to token KW_MANAGEDLOCATION
fn KW_MANAGEDLOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MANAGEDLOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> DbManagedLocationContextAttrs<'input> for DbManagedLocationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dbManagedLocation(&mut self,)
	-> Result<Rc<DbManagedLocationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DbManagedLocationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 58, RULE_dbManagedLocation);
        let mut _localctx: Rc<DbManagedLocationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1288);
			recog.base.match_token(KW_MANAGEDLOCATION,&mut recog.err_handler)?;

			recog.base.set_state(1289);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,DbManagedLocationContext >(&mut _localctx).locn = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dbProperties ----------------
pub type DbPropertiesContextAll<'input> = DbPropertiesContext<'input>;


pub type DbPropertiesContext<'input> = BaseParserRuleContext<'input,DbPropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct DbPropertiesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DbPropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DbPropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dbProperties(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dbProperties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DbPropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dbProperties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dbProperties }
}
crate::tid!{DbPropertiesContextExt<'a>}

impl<'input> DbPropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DbPropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DbPropertiesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DbPropertiesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DbPropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn dbPropertiesList(&self) -> Option<Rc<DbPropertiesListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> DbPropertiesContextAttrs<'input> for DbPropertiesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dbProperties(&mut self,)
	-> Result<Rc<DbPropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DbPropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 60, RULE_dbProperties);
        let mut _localctx: Rc<DbPropertiesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1291);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule dbPropertiesList*/
			recog.base.set_state(1292);
			recog.dbPropertiesList()?;

			recog.base.set_state(1293);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dbPropertiesList ----------------
pub type DbPropertiesListContextAll<'input> = DbPropertiesListContext<'input>;


pub type DbPropertiesListContext<'input> = BaseParserRuleContext<'input,DbPropertiesListContextExt<'input>>;

#[derive(Clone)]
pub struct DbPropertiesListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DbPropertiesListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DbPropertiesListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dbPropertiesList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dbPropertiesList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DbPropertiesListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dbPropertiesList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dbPropertiesList }
}
crate::tid!{DbPropertiesListContextExt<'a>}

impl<'input> DbPropertiesListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DbPropertiesListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DbPropertiesListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DbPropertiesListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DbPropertiesListContextExt<'input>>{

fn keyValueProperty_all(&self) ->  Vec<Rc<KeyValuePropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn keyValueProperty(&self, i: usize) -> Option<Rc<KeyValuePropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> DbPropertiesListContextAttrs<'input> for DbPropertiesListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dbPropertiesList(&mut self,)
	-> Result<Rc<DbPropertiesListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DbPropertiesListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 62, RULE_dbPropertiesList);
        let mut _localctx: Rc<DbPropertiesListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule keyValueProperty*/
			recog.base.set_state(1295);
			recog.keyValueProperty()?;

			recog.base.set_state(1300);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1296);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule keyValueProperty*/
				recog.base.set_state(1297);
				recog.keyValueProperty()?;

				}
				}
				recog.base.set_state(1302);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dbConnectorName ----------------
pub type DbConnectorNameContextAll<'input> = DbConnectorNameContext<'input>;


pub type DbConnectorNameContext<'input> = BaseParserRuleContext<'input,DbConnectorNameContextExt<'input>>;

#[derive(Clone)]
pub struct DbConnectorNameContextExt<'input>{
	pub dcName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DbConnectorNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DbConnectorNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dbConnectorName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dbConnectorName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DbConnectorNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dbConnectorName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dbConnectorName }
}
crate::tid!{DbConnectorNameContextExt<'a>}

impl<'input> DbConnectorNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DbConnectorNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DbConnectorNameContextExt{
				dcName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DbConnectorNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DbConnectorNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_USING
/// Returns `None` if there is no child corresponding to token KW_USING
fn KW_USING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USING, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DbConnectorNameContextAttrs<'input> for DbConnectorNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dbConnectorName(&mut self,)
	-> Result<Rc<DbConnectorNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DbConnectorNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 64, RULE_dbConnectorName);
        let mut _localctx: Rc<DbConnectorNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1303);
			recog.base.match_token(KW_USING,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(1304);
			let tmp = recog.id_()?;
			 cast_mut::<_,DbConnectorNameContext >(&mut _localctx).dcName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- switchDatabaseStatement ----------------
pub type SwitchDatabaseStatementContextAll<'input> = SwitchDatabaseStatementContext<'input>;


pub type SwitchDatabaseStatementContext<'input> = BaseParserRuleContext<'input,SwitchDatabaseStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SwitchDatabaseStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SwitchDatabaseStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SwitchDatabaseStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_switchDatabaseStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_switchDatabaseStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SwitchDatabaseStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_switchDatabaseStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_switchDatabaseStatement }
}
crate::tid!{SwitchDatabaseStatementContextExt<'a>}

impl<'input> SwitchDatabaseStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SwitchDatabaseStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SwitchDatabaseStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SwitchDatabaseStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SwitchDatabaseStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_USE
/// Returns `None` if there is no child corresponding to token KW_USE
fn KW_USE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USE, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SwitchDatabaseStatementContextAttrs<'input> for SwitchDatabaseStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn switchDatabaseStatement(&mut self,)
	-> Result<Rc<SwitchDatabaseStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SwitchDatabaseStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 66, RULE_switchDatabaseStatement);
        let mut _localctx: Rc<SwitchDatabaseStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1306);
			recog.base.match_token(KW_USE,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(1307);
			recog.id_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropDatabaseStatement ----------------
pub type DropDatabaseStatementContextAll<'input> = DropDatabaseStatementContext<'input>;


pub type DropDatabaseStatementContext<'input> = BaseParserRuleContext<'input,DropDatabaseStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropDatabaseStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropDatabaseStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropDatabaseStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropDatabaseStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropDatabaseStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropDatabaseStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropDatabaseStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropDatabaseStatement }
}
crate::tid!{DropDatabaseStatementContextExt<'a>}

impl<'input> DropDatabaseStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropDatabaseStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropDatabaseStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DropDatabaseStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropDatabaseStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
fn db_schema(&self) -> Option<Rc<Db_schemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn restrictOrCascade(&self) -> Option<Rc<RestrictOrCascadeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DropDatabaseStatementContextAttrs<'input> for DropDatabaseStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropDatabaseStatement(&mut self,)
	-> Result<Rc<DropDatabaseStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropDatabaseStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 68, RULE_dropDatabaseStatement);
        let mut _localctx: Rc<DropDatabaseStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1309);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			/*InvokeRule db_schema*/
			recog.base.set_state(1310);
			recog.db_schema()?;

			recog.base.set_state(1312);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifExists*/
				recog.base.set_state(1311);
				recog.ifExists()?;

				}
			}

			/*InvokeRule id_*/
			recog.base.set_state(1314);
			recog.id_()?;

			recog.base.set_state(1316);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CASCADE || _la==KW_RESTRICT {
				{
				/*InvokeRule restrictOrCascade*/
				recog.base.set_state(1315);
				recog.restrictOrCascade()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- databaseComment ----------------
pub type DatabaseCommentContextAll<'input> = DatabaseCommentContext<'input>;


pub type DatabaseCommentContext<'input> = BaseParserRuleContext<'input,DatabaseCommentContextExt<'input>>;

#[derive(Clone)]
pub struct DatabaseCommentContextExt<'input>{
	pub comment: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DatabaseCommentContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DatabaseCommentContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_databaseComment(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_databaseComment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DatabaseCommentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_databaseComment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_databaseComment }
}
crate::tid!{DatabaseCommentContextExt<'a>}

impl<'input> DatabaseCommentContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DatabaseCommentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DatabaseCommentContextExt{
				comment: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DatabaseCommentContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DatabaseCommentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_COMMENT
/// Returns `None` if there is no child corresponding to token KW_COMMENT
fn KW_COMMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> DatabaseCommentContextAttrs<'input> for DatabaseCommentContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn databaseComment(&mut self,)
	-> Result<Rc<DatabaseCommentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DatabaseCommentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 70, RULE_databaseComment);
        let mut _localctx: Rc<DatabaseCommentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1318);
			recog.base.match_token(KW_COMMENT,&mut recog.err_handler)?;

			recog.base.set_state(1319);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,DatabaseCommentContext >(&mut _localctx).comment = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- truncateTableStatement ----------------
pub type TruncateTableStatementContextAll<'input> = TruncateTableStatementContext<'input>;


pub type TruncateTableStatementContext<'input> = BaseParserRuleContext<'input,TruncateTableStatementContextExt<'input>>;

#[derive(Clone)]
pub struct TruncateTableStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TruncateTableStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TruncateTableStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_truncateTableStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_truncateTableStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TruncateTableStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_truncateTableStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_truncateTableStatement }
}
crate::tid!{TruncateTableStatementContextExt<'a>}

impl<'input> TruncateTableStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TruncateTableStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TruncateTableStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TruncateTableStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TruncateTableStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TRUNCATE
/// Returns `None` if there is no child corresponding to token KW_TRUNCATE
fn KW_TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRUNCATE, 0)
}
fn tablePartitionPrefix(&self) -> Option<Rc<TablePartitionPrefixContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COLUMNS
/// Returns `None` if there is no child corresponding to token KW_COLUMNS
fn KW_COLUMNS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn force(&self) -> Option<Rc<ForceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TruncateTableStatementContextAttrs<'input> for TruncateTableStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn truncateTableStatement(&mut self,)
	-> Result<Rc<TruncateTableStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TruncateTableStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 72, RULE_truncateTableStatement);
        let mut _localctx: Rc<TruncateTableStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1321);
			recog.base.match_token(KW_TRUNCATE,&mut recog.err_handler)?;

			recog.base.set_state(1323);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_TABLE {
				{
				recog.base.set_state(1322);
				recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

				}
			}

			/*InvokeRule tablePartitionPrefix*/
			recog.base.set_state(1325);
			recog.tablePartitionPrefix()?;

			recog.base.set_state(1331);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COLUMNS {
				{
				recog.base.set_state(1326);
				recog.base.match_token(KW_COLUMNS,&mut recog.err_handler)?;

				recog.base.set_state(1327);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				/*InvokeRule columnNameList*/
				recog.base.set_state(1328);
				recog.columnNameList()?;

				recog.base.set_state(1329);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(1334);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_FORCE {
				{
				/*InvokeRule force*/
				recog.base.set_state(1333);
				recog.force()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropTableStatement ----------------
pub type DropTableStatementContextAll<'input> = DropTableStatementContext<'input>;


pub type DropTableStatementContext<'input> = BaseParserRuleContext<'input,DropTableStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropTableStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropTableStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropTableStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropTableStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropTableStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropTableStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropTableStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropTableStatement }
}
crate::tid!{DropTableStatementContextExt<'a>}

impl<'input> DropTableStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropTableStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropTableStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DropTableStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropTableStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_PURGE
/// Returns `None` if there is no child corresponding to token KW_PURGE
fn KW_PURGE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PURGE, 0)
}
fn replicationClause(&self) -> Option<Rc<ReplicationClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DropTableStatementContextAttrs<'input> for DropTableStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropTableStatement(&mut self,)
	-> Result<Rc<DropTableStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropTableStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 74, RULE_dropTableStatement);
        let mut _localctx: Rc<DropTableStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1336);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(1337);
			recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

			recog.base.set_state(1339);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifExists*/
				recog.base.set_state(1338);
				recog.ifExists()?;

				}
			}

			/*InvokeRule tableName*/
			recog.base.set_state(1341);
			recog.tableName()?;

			recog.base.set_state(1343);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PURGE {
				{
				recog.base.set_state(1342);
				recog.base.match_token(KW_PURGE,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(1346);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_FOR {
				{
				/*InvokeRule replicationClause*/
				recog.base.set_state(1345);
				recog.replicationClause()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- inputFileFormat ----------------
pub type InputFileFormatContextAll<'input> = InputFileFormatContext<'input>;


pub type InputFileFormatContext<'input> = BaseParserRuleContext<'input,InputFileFormatContextExt<'input>>;

#[derive(Clone)]
pub struct InputFileFormatContextExt<'input>{
	pub inFmt: Option<TokenType<'input>>,
	pub serdeCls: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for InputFileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for InputFileFormatContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_inputFileFormat(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_inputFileFormat(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for InputFileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_inputFileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_inputFileFormat }
}
crate::tid!{InputFileFormatContextExt<'a>}

impl<'input> InputFileFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<InputFileFormatContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,InputFileFormatContextExt{
				inFmt: None, serdeCls: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait InputFileFormatContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<InputFileFormatContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_INPUTFORMAT
/// Returns `None` if there is no child corresponding to token KW_INPUTFORMAT
fn KW_INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERDE
/// Returns `None` if there is no child corresponding to token KW_SERDE
fn KW_SERDE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERDE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token StringLiteral in current rule
fn StringLiteral_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token StringLiteral, starting from 0.
/// Returns `None` if number of children corresponding to token StringLiteral is less or equal than `i`.
fn StringLiteral(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, i)
}

}

impl<'input> InputFileFormatContextAttrs<'input> for InputFileFormatContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn inputFileFormat(&mut self,)
	-> Result<Rc<InputFileFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = InputFileFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 76, RULE_inputFileFormat);
        let mut _localctx: Rc<InputFileFormatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1348);
			recog.base.match_token(KW_INPUTFORMAT,&mut recog.err_handler)?;

			recog.base.set_state(1349);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,InputFileFormatContext >(&mut _localctx).inFmt = Some(tmp.clone());
			  

			recog.base.set_state(1350);
			recog.base.match_token(KW_SERDE,&mut recog.err_handler)?;

			recog.base.set_state(1351);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,InputFileFormatContext >(&mut _localctx).serdeCls = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tabTypeExpr ----------------
pub type TabTypeExprContextAll<'input> = TabTypeExprContext<'input>;


pub type TabTypeExprContext<'input> = BaseParserRuleContext<'input,TabTypeExprContextExt<'input>>;

#[derive(Clone)]
pub struct TabTypeExprContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TabTypeExprContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TabTypeExprContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tabTypeExpr(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tabTypeExpr(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TabTypeExprContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tabTypeExpr }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tabTypeExpr }
}
crate::tid!{TabTypeExprContextExt<'a>}

impl<'input> TabTypeExprContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TabTypeExprContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TabTypeExprContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TabTypeExprContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TabTypeExprContextExt<'input>>{

fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_ELEM_TYPE in current rule
fn KW_ELEM_TYPE_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_ELEM_TYPE, starting from 0.
/// Returns `None` if number of children corresponding to token KW_ELEM_TYPE is less or equal than `i`.
fn KW_ELEM_TYPE(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ELEM_TYPE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_KEY_TYPE in current rule
fn KW_KEY_TYPE_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_KEY_TYPE, starting from 0.
/// Returns `None` if number of children corresponding to token KW_KEY_TYPE is less or equal than `i`.
fn KW_KEY_TYPE(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KEY_TYPE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_VALUE_TYPE in current rule
fn KW_VALUE_TYPE_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_VALUE_TYPE, starting from 0.
/// Returns `None` if number of children corresponding to token KW_VALUE_TYPE is less or equal than `i`.
fn KW_VALUE_TYPE(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VALUE_TYPE, i)
}

}

impl<'input> TabTypeExprContextAttrs<'input> for TabTypeExprContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tabTypeExpr(&mut self,)
	-> Result<Rc<TabTypeExprContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TabTypeExprContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 78, RULE_tabTypeExpr);
        let mut _localctx: Rc<TabTypeExprContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(1353);
			recog.id_()?;

			recog.base.set_state(1356);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DOT {
				{
				recog.base.set_state(1354);
				recog.base.match_token(DOT,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(1355);
				recog.id_()?;

				}
			}

			recog.base.set_state(1371);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(48,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule id_*/
					recog.base.set_state(1358);
					recog.id_()?;

					recog.base.set_state(1368);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==DOT {
						{
						{
						recog.base.set_state(1359);
						recog.base.match_token(DOT,&mut recog.err_handler)?;

						recog.base.set_state(1364);
						recog.err_handler.sync(&mut recog.base)?;
						match  recog.interpreter.adaptive_predict(46,&mut recog.base)? {
							1 =>{
								{
								recog.base.set_state(1360);
								recog.base.match_token(KW_ELEM_TYPE,&mut recog.err_handler)?;

								}
							}
						,
							2 =>{
								{
								recog.base.set_state(1361);
								recog.base.match_token(KW_KEY_TYPE,&mut recog.err_handler)?;

								}
							}
						,
							3 =>{
								{
								recog.base.set_state(1362);
								recog.base.match_token(KW_VALUE_TYPE,&mut recog.err_handler)?;

								}
							}
						,
							4 =>{
								{
								/*InvokeRule id_*/
								recog.base.set_state(1363);
								recog.id_()?;

								}
							}

							_ => {}
						}
						}
						}
						recog.base.set_state(1370);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partTypeExpr ----------------
pub type PartTypeExprContextAll<'input> = PartTypeExprContext<'input>;


pub type PartTypeExprContext<'input> = BaseParserRuleContext<'input,PartTypeExprContextExt<'input>>;

#[derive(Clone)]
pub struct PartTypeExprContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartTypeExprContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartTypeExprContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partTypeExpr(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partTypeExpr(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartTypeExprContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partTypeExpr }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partTypeExpr }
}
crate::tid!{PartTypeExprContextExt<'a>}

impl<'input> PartTypeExprContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartTypeExprContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartTypeExprContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartTypeExprContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartTypeExprContextExt<'input>>{

fn tabTypeExpr(&self) -> Option<Rc<TabTypeExprContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartTypeExprContextAttrs<'input> for PartTypeExprContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partTypeExpr(&mut self,)
	-> Result<Rc<PartTypeExprContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartTypeExprContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 80, RULE_partTypeExpr);
        let mut _localctx: Rc<PartTypeExprContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tabTypeExpr*/
			recog.base.set_state(1373);
			recog.tabTypeExpr()?;

			recog.base.set_state(1375);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PARTITION {
				{
				/*InvokeRule partitionSpec*/
				recog.base.set_state(1374);
				recog.partitionSpec()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tabPartColTypeExpr ----------------
pub type TabPartColTypeExprContextAll<'input> = TabPartColTypeExprContext<'input>;


pub type TabPartColTypeExprContext<'input> = BaseParserRuleContext<'input,TabPartColTypeExprContextExt<'input>>;

#[derive(Clone)]
pub struct TabPartColTypeExprContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TabPartColTypeExprContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TabPartColTypeExprContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tabPartColTypeExpr(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tabPartColTypeExpr(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TabPartColTypeExprContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tabPartColTypeExpr }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tabPartColTypeExpr }
}
crate::tid!{TabPartColTypeExprContextExt<'a>}

impl<'input> TabPartColTypeExprContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TabPartColTypeExprContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TabPartColTypeExprContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TabPartColTypeExprContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TabPartColTypeExprContextExt<'input>>{

fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn extColumnName(&self) -> Option<Rc<ExtColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TabPartColTypeExprContextAttrs<'input> for TabPartColTypeExprContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tabPartColTypeExpr(&mut self,)
	-> Result<Rc<TabPartColTypeExprContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TabPartColTypeExprContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 82, RULE_tabPartColTypeExpr);
        let mut _localctx: Rc<TabPartColTypeExprContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableName*/
			recog.base.set_state(1377);
			recog.tableName()?;

			recog.base.set_state(1379);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PARTITION {
				{
				/*InvokeRule partitionSpec*/
				recog.base.set_state(1378);
				recog.partitionSpec()?;

				}
			}

			recog.base.set_state(1382);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(51,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule extColumnName*/
					recog.base.set_state(1381);
					recog.extColumnName()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- descStatement ----------------
pub type DescStatementContextAll<'input> = DescStatementContext<'input>;


pub type DescStatementContext<'input> = BaseParserRuleContext<'input,DescStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DescStatementContextExt<'input>{
	pub dbName: Option<Rc<Id_ContextAll<'input>>>,
	pub dcName: Option<Rc<Id_ContextAll<'input>>>,
	pub name: Option<Rc<DescFuncNamesContextAll<'input>>>,
	pub descOptions: Option<TokenType<'input>>,
	pub parttype: Option<Rc<TabPartColTypeExprContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DescStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DescStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_descStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_descStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DescStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_descStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_descStatement }
}
crate::tid!{DescStatementContextExt<'a>}

impl<'input> DescStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DescStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DescStatementContextExt{
				descOptions: None, 
				dbName: None, dcName: None, name: None, parttype: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DescStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DescStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DESCRIBE
/// Returns `None` if there is no child corresponding to token KW_DESCRIBE
fn KW_DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DESCRIBE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DESC
/// Returns `None` if there is no child corresponding to token KW_DESC
fn KW_DESC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DESC, 0)
}
fn db_schema(&self) -> Option<Rc<Db_schemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATACONNECTOR
/// Returns `None` if there is no child corresponding to token KW_DATACONNECTOR
fn KW_DATACONNECTOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATACONNECTOR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FUNCTION
/// Returns `None` if there is no child corresponding to token KW_FUNCTION
fn KW_FUNCTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FUNCTION, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn descFuncNames(&self) -> Option<Rc<DescFuncNamesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tabPartColTypeExpr(&self) -> Option<Rc<TabPartColTypeExprContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXTENDED
/// Returns `None` if there is no child corresponding to token KW_EXTENDED
fn KW_EXTENDED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXTENDED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FORMATTED
/// Returns `None` if there is no child corresponding to token KW_FORMATTED
fn KW_FORMATTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FORMATTED, 0)
}

}

impl<'input> DescStatementContextAttrs<'input> for DescStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn descStatement(&mut self,)
	-> Result<Rc<DescStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DescStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 84, RULE_descStatement);
        let mut _localctx: Rc<DescStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1384);
			_la = recog.base.input.la(1);
			if { !(_la==KW_DESC || _la==KW_DESCRIBE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(1407);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(56,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule db_schema*/
					recog.base.set_state(1385);
					recog.db_schema()?;

					recog.base.set_state(1387);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_EXTENDED {
						{
						recog.base.set_state(1386);
						recog.base.match_token(KW_EXTENDED,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule id_*/
					recog.base.set_state(1389);
					let tmp = recog.id_()?;
					 cast_mut::<_,DescStatementContext >(&mut _localctx).dbName = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					{
					recog.base.set_state(1391);
					recog.base.match_token(KW_DATACONNECTOR,&mut recog.err_handler)?;

					recog.base.set_state(1393);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_EXTENDED {
						{
						recog.base.set_state(1392);
						recog.base.match_token(KW_EXTENDED,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule id_*/
					recog.base.set_state(1395);
					let tmp = recog.id_()?;
					 cast_mut::<_,DescStatementContext >(&mut _localctx).dcName = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					{
					recog.base.set_state(1396);
					recog.base.match_token(KW_FUNCTION,&mut recog.err_handler)?;

					recog.base.set_state(1398);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_EXTENDED {
						{
						recog.base.set_state(1397);
						recog.base.match_token(KW_EXTENDED,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule descFuncNames*/
					recog.base.set_state(1400);
					let tmp = recog.descFuncNames()?;
					 cast_mut::<_,DescStatementContext >(&mut _localctx).name = Some(tmp.clone());
					  

					}
				}
			,
				4 =>{
					{
					recog.base.set_state(1403);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_FORMATTED 
						=> {
							{
							recog.base.set_state(1401);
							let tmp = recog.base.match_token(KW_FORMATTED,&mut recog.err_handler)?;
							 cast_mut::<_,DescStatementContext >(&mut _localctx).descOptions = Some(tmp.clone());
							  

							}
						}

					 KW_EXTENDED 
						=> {
							{
							recog.base.set_state(1402);
							let tmp = recog.base.match_token(KW_EXTENDED,&mut recog.err_handler)?;
							 cast_mut::<_,DescStatementContext >(&mut _localctx).descOptions = Some(tmp.clone());
							  

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					/*InvokeRule tabPartColTypeExpr*/
					recog.base.set_state(1405);
					let tmp = recog.tabPartColTypeExpr()?;
					 cast_mut::<_,DescStatementContext >(&mut _localctx).parttype = Some(tmp.clone());
					  

					}
				}
			,
				5 =>{
					{
					/*InvokeRule tabPartColTypeExpr*/
					recog.base.set_state(1406);
					let tmp = recog.tabPartColTypeExpr()?;
					 cast_mut::<_,DescStatementContext >(&mut _localctx).parttype = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- analyzeStatement ----------------
pub type AnalyzeStatementContextAll<'input> = AnalyzeStatementContext<'input>;


pub type AnalyzeStatementContext<'input> = BaseParserRuleContext<'input,AnalyzeStatementContextExt<'input>>;

#[derive(Clone)]
pub struct AnalyzeStatementContextExt<'input>{
	pub parttype: Option<Rc<TableOrPartitionContextAll<'input>>>,
	pub noscan: Option<TokenType<'input>>,
	pub statsColumnName: Option<Rc<ColumnNameListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AnalyzeStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AnalyzeStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_analyzeStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_analyzeStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AnalyzeStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_analyzeStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_analyzeStatement }
}
crate::tid!{AnalyzeStatementContextExt<'a>}

impl<'input> AnalyzeStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AnalyzeStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AnalyzeStatementContextExt{
				noscan: None, 
				parttype: None, statsColumnName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AnalyzeStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AnalyzeStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ANALYZE
/// Returns `None` if there is no child corresponding to token KW_ANALYZE
fn KW_ANALYZE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ANALYZE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableOrPartition(&self) -> Option<Rc<TableOrPartitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMPUTE
/// Returns `None` if there is no child corresponding to token KW_COMPUTE
fn KW_COMPUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMPUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STATISTICS
/// Returns `None` if there is no child corresponding to token KW_STATISTICS
fn KW_STATISTICS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STATISTICS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CACHE
/// Returns `None` if there is no child corresponding to token KW_CACHE
fn KW_CACHE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CACHE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_METADATA
/// Returns `None` if there is no child corresponding to token KW_METADATA
fn KW_METADATA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_METADATA, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FOR
/// Returns `None` if there is no child corresponding to token KW_FOR
fn KW_FOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COLUMNS
/// Returns `None` if there is no child corresponding to token KW_COLUMNS
fn KW_COLUMNS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOSCAN
/// Returns `None` if there is no child corresponding to token KW_NOSCAN
fn KW_NOSCAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOSCAN, 0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AnalyzeStatementContextAttrs<'input> for AnalyzeStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn analyzeStatement(&mut self,)
	-> Result<Rc<AnalyzeStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AnalyzeStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 86, RULE_analyzeStatement);
        let mut _localctx: Rc<AnalyzeStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1409);
			recog.base.match_token(KW_ANALYZE,&mut recog.err_handler)?;

			recog.base.set_state(1410);
			recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

			/*InvokeRule tableOrPartition*/
			recog.base.set_state(1411);
			let tmp = recog.tableOrPartition()?;
			 cast_mut::<_,AnalyzeStatementContext >(&mut _localctx).parttype = Some(tmp.clone());
			  

			recog.base.set_state(1424);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_COMPUTE 
				=> {
					{
					recog.base.set_state(1412);
					recog.base.match_token(KW_COMPUTE,&mut recog.err_handler)?;

					recog.base.set_state(1413);
					recog.base.match_token(KW_STATISTICS,&mut recog.err_handler)?;

					recog.base.set_state(1420);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_NOSCAN 
						=> {
					    	{
					    	recog.base.set_state(1414);
					    	let tmp = recog.base.match_token(KW_NOSCAN,&mut recog.err_handler)?;
					    	 cast_mut::<_,AnalyzeStatementContext >(&mut _localctx).noscan = Some(tmp.clone());
					    	  

					    	}
					    }

					 KW_FOR 
						=> {
					    	{
					    	recog.base.set_state(1415);
					    	recog.base.match_token(KW_FOR,&mut recog.err_handler)?;

					    	recog.base.set_state(1416);
					    	recog.base.match_token(KW_COLUMNS,&mut recog.err_handler)?;

					    	recog.base.set_state(1418);
					    	recog.err_handler.sync(&mut recog.base)?;
					    	match  recog.interpreter.adaptive_predict(57,&mut recog.base)? {
					    		x if x == 1=>{
					    			{
					    			/*InvokeRule columnNameList*/
					    			recog.base.set_state(1417);
					    			let tmp = recog.columnNameList()?;
					    			 cast_mut::<_,AnalyzeStatementContext >(&mut _localctx).statsColumnName = Some(tmp.clone());
					    			  

					    			}
					    		}

					    		_ => {}
					    	}
					    	}
					    }

					 EOF | KW_ABORT | KW_ALTER | KW_ANALYZE | KW_COMMIT | KW_CREATE | KW_DELETE |
					 KW_DESC | KW_DESCRIBE | KW_DISABLE | KW_DROP | KW_ENABLE | KW_EXECUTE |
					 KW_EXPLAIN | KW_EXPORT | KW_FROM | KW_GRANT | KW_IMPORT | KW_INSERT |
					 KW_KILL | KW_LOAD | KW_LOCK | KW_MAP | KW_MERGE | KW_MSCK | KW_PREPARE |
					 KW_REDUCE | KW_RELOAD | KW_REPL | KW_REPLACE | KW_REVOKE | KW_ROLLBACK |
					 KW_SELECT | KW_SET | KW_SHOW | KW_START | KW_TRUNCATE | KW_UNLOCK |
					 KW_UPDATE | KW_USE | KW_VALUES | KW_WITH | SEMICOLON | LPAREN 
						=> {
					    }

						_ => {}
					}
					}
				}

			 KW_CACHE 
				=> {
					{
					recog.base.set_state(1422);
					recog.base.match_token(KW_CACHE,&mut recog.err_handler)?;

					recog.base.set_state(1423);
					recog.base.match_token(KW_METADATA,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- from_in ----------------
pub type From_inContextAll<'input> = From_inContext<'input>;


pub type From_inContext<'input> = BaseParserRuleContext<'input,From_inContextExt<'input>>;

#[derive(Clone)]
pub struct From_inContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for From_inContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for From_inContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_from_in(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_from_in(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for From_inContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_from_in }
	//fn type_rule_index() -> usize where Self: Sized { RULE_from_in }
}
crate::tid!{From_inContextExt<'a>}

impl<'input> From_inContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<From_inContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,From_inContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait From_inContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<From_inContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IN
/// Returns `None` if there is no child corresponding to token KW_IN
fn KW_IN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IN, 0)
}

}

impl<'input> From_inContextAttrs<'input> for From_inContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn from_in(&mut self,)
	-> Result<Rc<From_inContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = From_inContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 88, RULE_from_in);
        let mut _localctx: Rc<From_inContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1426);
			_la = recog.base.input.la(1);
			if { !(_la==KW_FROM || _la==KW_IN) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- db_schema ----------------
pub type Db_schemaContextAll<'input> = Db_schemaContext<'input>;


pub type Db_schemaContext<'input> = BaseParserRuleContext<'input,Db_schemaContextExt<'input>>;

#[derive(Clone)]
pub struct Db_schemaContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Db_schemaContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Db_schemaContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_db_schema(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_db_schema(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Db_schemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_db_schema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_db_schema }
}
crate::tid!{Db_schemaContextExt<'a>}

impl<'input> Db_schemaContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Db_schemaContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Db_schemaContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Db_schemaContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Db_schemaContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DATABASE
/// Returns `None` if there is no child corresponding to token KW_DATABASE
fn KW_DATABASE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SCHEMA
/// Returns `None` if there is no child corresponding to token KW_SCHEMA
fn KW_SCHEMA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SCHEMA, 0)
}

}

impl<'input> Db_schemaContextAttrs<'input> for Db_schemaContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn db_schema(&mut self,)
	-> Result<Rc<Db_schemaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Db_schemaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 90, RULE_db_schema);
        let mut _localctx: Rc<Db_schemaContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1428);
			_la = recog.base.input.la(1);
			if { !(_la==KW_DATABASE || _la==KW_SCHEMA) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- showStatement ----------------
pub type ShowStatementContextAll<'input> = ShowStatementContext<'input>;


pub type ShowStatementContext<'input> = BaseParserRuleContext<'input,ShowStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ShowStatementContextExt<'input>{
	pub isExtended: Option<TokenType<'input>>,
	pub db_name: Option<Rc<Id_ContextAll<'input>>>,
	pub filter: Option<Rc<ShowTablesFilterExprContextAll<'input>>>,
	pub tabName: Option<Rc<TableNameContextAll<'input>>>,
	pub prptyName: Option<TokenType<'input>>,
	pub dbName: Option<Rc<Id_ContextAll<'input>>>,
	pub parttype: Option<Rc<PartTypeExprContextAll<'input>>>,
	pub rp_name: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ShowStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ShowStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_showStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_showStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ShowStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_showStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_showStatement }
}
crate::tid!{ShowStatementContextExt<'a>}

impl<'input> ShowStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ShowStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ShowStatementContextExt{
				isExtended: None, prptyName: None, 
				db_name: None, filter: None, tabName: None, dbName: None, parttype: None, rp_name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ShowStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ShowStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SHOW
/// Returns `None` if there is no child corresponding to token KW_SHOW
fn KW_SHOW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATABASES
/// Returns `None` if there is no child corresponding to token KW_DATABASES
fn KW_DATABASES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATABASES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SCHEMAS
/// Returns `None` if there is no child corresponding to token KW_SCHEMAS
fn KW_SCHEMAS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SCHEMAS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LIKE
/// Returns `None` if there is no child corresponding to token KW_LIKE
fn KW_LIKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LIKE, 0)
}
fn showStmtIdentifier(&self) -> Option<Rc<ShowStmtIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLES
/// Returns `None` if there is no child corresponding to token KW_TABLES
fn KW_TABLES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLES, 0)
}
fn from_in_all(&self) ->  Vec<Rc<From_inContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn from_in(&self, i: usize) -> Option<Rc<From_inContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_EXTENDED
/// Returns `None` if there is no child corresponding to token KW_EXTENDED
fn KW_EXTENDED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXTENDED, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn showTablesFilterExpr(&self) -> Option<Rc<ShowTablesFilterExprContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_VIEWS
/// Returns `None` if there is no child corresponding to token KW_VIEWS
fn KW_VIEWS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VIEWS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MATERIALIZED
/// Returns `None` if there is no child corresponding to token KW_MATERIALIZED
fn KW_MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COLUMNS
/// Returns `None` if there is no child corresponding to token KW_COLUMNS
fn KW_COLUMNS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLUMNS, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_SORTED
/// Returns `None` if there is no child corresponding to token KW_SORTED
fn KW_SORTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SORTED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FUNCTIONS
/// Returns `None` if there is no child corresponding to token KW_FUNCTIONS
fn KW_FUNCTIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FUNCTIONS, 0)
}
fn showFunctionIdentifier(&self) -> Option<Rc<ShowFunctionIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_PARTITIONS
/// Returns `None` if there is no child corresponding to token KW_PARTITIONS
fn KW_PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITIONS, 0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orderByClause(&self) -> Option<Rc<OrderByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn limitClause(&self) -> Option<Rc<LimitClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
fn db_schema(&self) -> Option<Rc<Db_schemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TBLPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_TBLPROPERTIES
fn KW_TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TBLPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCKS
/// Returns `None` if there is no child corresponding to token KW_LOCKS
fn KW_LOCKS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCKS, 0)
}
fn partTypeExpr(&self) -> Option<Rc<PartTypeExprContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMPACTIONS
/// Returns `None` if there is no child corresponding to token KW_COMPACTIONS
fn KW_COMPACTIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMPACTIONS, 0)
}
fn compactionId(&self) -> Option<Rc<CompactionIdContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn compactionPool(&self) -> Option<Rc<CompactionPoolContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn compactionType(&self) -> Option<Rc<CompactionTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn compactionStatus(&self) -> Option<Rc<CompactionStatusContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRANSACTIONS
/// Returns `None` if there is no child corresponding to token KW_TRANSACTIONS
fn KW_TRANSACTIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRANSACTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CONF
/// Returns `None` if there is no child corresponding to token KW_CONF
fn KW_CONF(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONF, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RESOURCE
/// Returns `None` if there is no child corresponding to token KW_RESOURCE
fn KW_RESOURCE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RESOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PLAN
/// Returns `None` if there is no child corresponding to token KW_PLAN
fn KW_PLAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PLAN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PLANS
/// Returns `None` if there is no child corresponding to token KW_PLANS
fn KW_PLANS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PLANS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATACONNECTORS
/// Returns `None` if there is no child corresponding to token KW_DATACONNECTORS
fn KW_DATACONNECTORS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATACONNECTORS, 0)
}

}

impl<'input> ShowStatementContextAttrs<'input> for ShowStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn showStatement(&mut self,)
	-> Result<Rc<ShowStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ShowStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 92, RULE_showStatement);
        let mut _localctx: Rc<ShowStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1611);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(97,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1430);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1431);
					_la = recog.base.input.la(1);
					if { !(_la==KW_DATABASES || _la==KW_SCHEMAS) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(1434);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_LIKE {
						{
						recog.base.set_state(1432);
						recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

						/*InvokeRule showStmtIdentifier*/
						recog.base.set_state(1433);
						recog.showStmtIdentifier()?;

						}
					}

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1436);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1438);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_EXTENDED {
						{
						recog.base.set_state(1437);
						let tmp = recog.base.match_token(KW_EXTENDED,&mut recog.err_handler)?;
						 cast_mut::<_,ShowStatementContext >(&mut _localctx).isExtended = Some(tmp.clone());
						  

						}
					}

					recog.base.set_state(1440);
					recog.base.match_token(KW_TABLES,&mut recog.err_handler)?;

					recog.base.set_state(1444);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(62,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule from_in*/
							recog.base.set_state(1441);
							recog.from_in()?;

							/*InvokeRule id_*/
							recog.base.set_state(1442);
							let tmp = recog.id_()?;
							 cast_mut::<_,ShowStatementContext >(&mut _localctx).db_name = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					recog.base.set_state(1447);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(63,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule showTablesFilterExpr*/
							recog.base.set_state(1446);
							let tmp = recog.showTablesFilterExpr()?;
							 cast_mut::<_,ShowStatementContext >(&mut _localctx).filter = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(1449);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1450);
					recog.base.match_token(KW_VIEWS,&mut recog.err_handler)?;

					recog.base.set_state(1454);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(64,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule from_in*/
							recog.base.set_state(1451);
							recog.from_in()?;

							/*InvokeRule id_*/
							recog.base.set_state(1452);
							let tmp = recog.id_()?;
							 cast_mut::<_,ShowStatementContext >(&mut _localctx).db_name = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					recog.base.set_state(1459);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(65,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1456);
							recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

							/*InvokeRule showStmtIdentifier*/
							recog.base.set_state(1457);
							recog.showStmtIdentifier()?;

							}
						}

						x if x == 2=>{
							{
							/*InvokeRule showStmtIdentifier*/
							recog.base.set_state(1458);
							recog.showStmtIdentifier()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(1461);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1462);
					recog.base.match_token(KW_MATERIALIZED,&mut recog.err_handler)?;

					recog.base.set_state(1463);
					recog.base.match_token(KW_VIEWS,&mut recog.err_handler)?;

					recog.base.set_state(1467);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(66,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule from_in*/
							recog.base.set_state(1464);
							recog.from_in()?;

							/*InvokeRule id_*/
							recog.base.set_state(1465);
							let tmp = recog.id_()?;
							 cast_mut::<_,ShowStatementContext >(&mut _localctx).db_name = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					recog.base.set_state(1472);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(67,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1469);
							recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

							/*InvokeRule showStmtIdentifier*/
							recog.base.set_state(1470);
							recog.showStmtIdentifier()?;

							}
						}

						x if x == 2=>{
							{
							/*InvokeRule showStmtIdentifier*/
							recog.base.set_state(1471);
							recog.showStmtIdentifier()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(1474);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1476);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_SORTED {
						{
						recog.base.set_state(1475);
						recog.base.match_token(KW_SORTED,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1478);
					recog.base.match_token(KW_COLUMNS,&mut recog.err_handler)?;

					/*InvokeRule from_in*/
					recog.base.set_state(1479);
					recog.from_in()?;

					/*InvokeRule tableName*/
					recog.base.set_state(1480);
					recog.tableName()?;

					recog.base.set_state(1484);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(69,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule from_in*/
							recog.base.set_state(1481);
							recog.from_in()?;

							/*InvokeRule id_*/
							recog.base.set_state(1482);
							let tmp = recog.id_()?;
							 cast_mut::<_,ShowStatementContext >(&mut _localctx).db_name = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					recog.base.set_state(1489);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(70,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1486);
							recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

							/*InvokeRule showStmtIdentifier*/
							recog.base.set_state(1487);
							recog.showStmtIdentifier()?;

							}
						}

						x if x == 2=>{
							{
							/*InvokeRule showStmtIdentifier*/
							recog.base.set_state(1488);
							recog.showStmtIdentifier()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(1491);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1492);
					recog.base.match_token(KW_FUNCTIONS,&mut recog.err_handler)?;

					recog.base.set_state(1495);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_LIKE {
						{
						recog.base.set_state(1493);
						recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

						/*InvokeRule showFunctionIdentifier*/
						recog.base.set_state(1494);
						recog.showFunctionIdentifier()?;

						}
					}

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(1497);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1498);
					recog.base.match_token(KW_PARTITIONS,&mut recog.err_handler)?;

					/*InvokeRule tableName*/
					recog.base.set_state(1499);
					let tmp = recog.tableName()?;
					 cast_mut::<_,ShowStatementContext >(&mut _localctx).tabName = Some(tmp.clone());
					  

					recog.base.set_state(1501);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1500);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(1504);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_WHERE {
						{
						/*InvokeRule whereClause*/
						recog.base.set_state(1503);
						recog.whereClause()?;

						}
					}

					recog.base.set_state(1507);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_ORDER {
						{
						/*InvokeRule orderByClause*/
						recog.base.set_state(1506);
						recog.orderByClause()?;

						}
					}

					recog.base.set_state(1510);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_LIMIT {
						{
						/*InvokeRule limitClause*/
						recog.base.set_state(1509);
						recog.limitClause()?;

						}
					}

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(1512);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1513);
					recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1519);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_DATABASE | KW_SCHEMA 
						=> {
							{
							/*InvokeRule db_schema*/
							recog.base.set_state(1514);
							recog.db_schema()?;

							/*InvokeRule id_*/
							recog.base.set_state(1515);
							let tmp = recog.id_()?;
							 cast_mut::<_,ShowStatementContext >(&mut _localctx).db_name = Some(tmp.clone());
							  

							}
						}

					 KW_TABLE 
						=> {
							{
							recog.base.set_state(1517);
							recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

							/*InvokeRule tableName*/
							recog.base.set_state(1518);
							let tmp = recog.tableName()?;
							 cast_mut::<_,ShowStatementContext >(&mut _localctx).tabName = Some(tmp.clone());
							  

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					recog.base.set_state(1521);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1522);
					recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

					recog.base.set_state(1523);
					recog.base.match_token(KW_EXTENDED,&mut recog.err_handler)?;

					recog.base.set_state(1527);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_FROM || _la==KW_IN {
						{
						/*InvokeRule from_in*/
						recog.base.set_state(1524);
						recog.from_in()?;

						/*InvokeRule id_*/
						recog.base.set_state(1525);
						let tmp = recog.id_()?;
						 cast_mut::<_,ShowStatementContext >(&mut _localctx).db_name = Some(tmp.clone());
						  

						}
					}

					recog.base.set_state(1529);
					recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

					/*InvokeRule showStmtIdentifier*/
					recog.base.set_state(1530);
					recog.showStmtIdentifier()?;

					recog.base.set_state(1532);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1531);
						recog.partitionSpec()?;

						}
					}

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					recog.base.set_state(1534);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1535);
					recog.base.match_token(KW_TBLPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule tableName*/
					recog.base.set_state(1536);
					recog.tableName()?;

					recog.base.set_state(1540);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(79,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1537);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(1538);
							let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
							 cast_mut::<_,ShowStatementContext >(&mut _localctx).prptyName = Some(tmp.clone());
							  

							recog.base.set_state(1539);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					recog.base.set_state(1542);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1543);
					recog.base.match_token(KW_LOCKS,&mut recog.err_handler)?;

					recog.base.set_state(1555);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(83,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule db_schema*/
							recog.base.set_state(1544);
							recog.db_schema()?;

							/*InvokeRule id_*/
							recog.base.set_state(1545);
							let tmp = recog.id_()?;
							 cast_mut::<_,ShowStatementContext >(&mut _localctx).dbName = Some(tmp.clone());
							  

							recog.base.set_state(1547);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_EXTENDED {
								{
								recog.base.set_state(1546);
								let tmp = recog.base.match_token(KW_EXTENDED,&mut recog.err_handler)?;
								 cast_mut::<_,ShowStatementContext >(&mut _localctx).isExtended = Some(tmp.clone());
								  

								}
							}

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(1550);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(81,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule partTypeExpr*/
									recog.base.set_state(1549);
									let tmp = recog.partTypeExpr()?;
									 cast_mut::<_,ShowStatementContext >(&mut _localctx).parttype = Some(tmp.clone());
									  

									}
								}

								_ => {}
							}
							recog.base.set_state(1553);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_EXTENDED {
								{
								recog.base.set_state(1552);
								let tmp = recog.base.match_token(KW_EXTENDED,&mut recog.err_handler)?;
								 cast_mut::<_,ShowStatementContext >(&mut _localctx).isExtended = Some(tmp.clone());
								  

								}
							}

							}
						}

						_ => {}
					}
					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					recog.base.set_state(1557);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1558);
					recog.base.match_token(KW_COMPACTIONS,&mut recog.err_handler)?;

					recog.base.set_state(1595);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(95,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule compactionId*/
							recog.base.set_state(1559);
							recog.compactionId()?;

							}
						}
					,
						2 =>{
							{
							/*InvokeRule db_schema*/
							recog.base.set_state(1560);
							recog.db_schema()?;

							/*InvokeRule id_*/
							recog.base.set_state(1561);
							let tmp = recog.id_()?;
							 cast_mut::<_,ShowStatementContext >(&mut _localctx).dbName = Some(tmp.clone());
							  

							recog.base.set_state(1563);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_POOL {
								{
								/*InvokeRule compactionPool*/
								recog.base.set_state(1562);
								recog.compactionPool()?;

								}
							}

							recog.base.set_state(1566);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_TYPE {
								{
								/*InvokeRule compactionType*/
								recog.base.set_state(1565);
								recog.compactionType()?;

								}
							}

							recog.base.set_state(1569);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_STATUS {
								{
								/*InvokeRule compactionStatus*/
								recog.base.set_state(1568);
								recog.compactionStatus()?;

								}
							}

							recog.base.set_state(1572);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_ORDER {
								{
								/*InvokeRule orderByClause*/
								recog.base.set_state(1571);
								recog.orderByClause()?;

								}
							}

							recog.base.set_state(1575);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_LIMIT {
								{
								/*InvokeRule limitClause*/
								recog.base.set_state(1574);
								recog.limitClause()?;

								}
							}

							}
						}
					,
						3 =>{
							{
							recog.base.set_state(1578);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(89,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule partTypeExpr*/
									recog.base.set_state(1577);
									let tmp = recog.partTypeExpr()?;
									 cast_mut::<_,ShowStatementContext >(&mut _localctx).parttype = Some(tmp.clone());
									  

									}
								}

								_ => {}
							}
							recog.base.set_state(1581);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_POOL {
								{
								/*InvokeRule compactionPool*/
								recog.base.set_state(1580);
								recog.compactionPool()?;

								}
							}

							recog.base.set_state(1584);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_TYPE {
								{
								/*InvokeRule compactionType*/
								recog.base.set_state(1583);
								recog.compactionType()?;

								}
							}

							recog.base.set_state(1587);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_STATUS {
								{
								/*InvokeRule compactionStatus*/
								recog.base.set_state(1586);
								recog.compactionStatus()?;

								}
							}

							recog.base.set_state(1590);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_ORDER {
								{
								/*InvokeRule orderByClause*/
								recog.base.set_state(1589);
								recog.orderByClause()?;

								}
							}

							recog.base.set_state(1593);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_LIMIT {
								{
								/*InvokeRule limitClause*/
								recog.base.set_state(1592);
								recog.limitClause()?;

								}
							}

							}
						}

						_ => {}
					}
					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					recog.base.set_state(1597);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1598);
					recog.base.match_token(KW_TRANSACTIONS,&mut recog.err_handler)?;

					}
				}
			,
				14 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					recog.base.set_state(1599);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1600);
					recog.base.match_token(KW_CONF,&mut recog.err_handler)?;

					recog.base.set_state(1601);
					recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

					}
				}
			,
				15 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					recog.base.set_state(1602);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1603);
					recog.base.match_token(KW_RESOURCE,&mut recog.err_handler)?;

					recog.base.set_state(1607);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_PLAN 
						=> {
							{
							recog.base.set_state(1604);
							recog.base.match_token(KW_PLAN,&mut recog.err_handler)?;

							/*InvokeRule id_*/
							recog.base.set_state(1605);
							let tmp = recog.id_()?;
							 cast_mut::<_,ShowStatementContext >(&mut _localctx).rp_name = Some(tmp.clone());
							  

							}
						}

					 KW_PLANS 
						=> {
							{
							recog.base.set_state(1606);
							recog.base.match_token(KW_PLANS,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}
			,
				16 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 16);
					recog.base.enter_outer_alt(None, 16);
					{
					recog.base.set_state(1609);
					recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1610);
					recog.base.match_token(KW_DATACONNECTORS,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- showTablesFilterExpr ----------------
pub type ShowTablesFilterExprContextAll<'input> = ShowTablesFilterExprContext<'input>;


pub type ShowTablesFilterExprContext<'input> = BaseParserRuleContext<'input,ShowTablesFilterExprContextExt<'input>>;

#[derive(Clone)]
pub struct ShowTablesFilterExprContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ShowTablesFilterExprContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ShowTablesFilterExprContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_showTablesFilterExpr(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_showTablesFilterExpr(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ShowTablesFilterExprContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_showTablesFilterExpr }
	//fn type_rule_index() -> usize where Self: Sized { RULE_showTablesFilterExpr }
}
crate::tid!{ShowTablesFilterExprContextExt<'a>}

impl<'input> ShowTablesFilterExprContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ShowTablesFilterExprContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ShowTablesFilterExprContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ShowTablesFilterExprContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ShowTablesFilterExprContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_WHERE
/// Returns `None` if there is no child corresponding to token KW_WHERE
fn KW_WHERE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WHERE, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LIKE
/// Returns `None` if there is no child corresponding to token KW_LIKE
fn KW_LIKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LIKE, 0)
}
fn showStmtIdentifier(&self) -> Option<Rc<ShowStmtIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ShowTablesFilterExprContextAttrs<'input> for ShowTablesFilterExprContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn showTablesFilterExpr(&mut self,)
	-> Result<Rc<ShowTablesFilterExprContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ShowTablesFilterExprContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 94, RULE_showTablesFilterExpr);
        let mut _localctx: Rc<ShowTablesFilterExprContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1621);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_WHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1613);
					recog.base.match_token(KW_WHERE,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(1614);
					recog.id_()?;

					recog.base.set_state(1615);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(1616);
					recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

					}
				}

			 KW_LIKE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1618);
					recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

					/*InvokeRule showStmtIdentifier*/
					recog.base.set_state(1619);
					recog.showStmtIdentifier()?;

					}
				}

			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT | KW_BATCH |
			 KW_BEFORE | KW_BUCKET | KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CBO |
			 KW_CHANGE | KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS |
			 KW_COLLECTION | KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS |
			 KW_COMPUTE | KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_DATA |
			 KW_DATABASES | KW_DATETIME | KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES |
			 KW_DCPROPERTIES | KW_DEBUG | KW_DEFAULT | KW_DEFERRED | KW_DEFINED |
			 KW_DELIMITED | KW_DEPENDENCY | KW_DESC | KW_DETAIL | KW_DIRECTORIES |
			 KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE | KW_DISTRIBUTED | KW_DO |
			 KW_DUMP | KW_ELEM_TYPE | KW_ENABLE | KW_ENFORCED | KW_ESCAPED | KW_EVERY |
			 KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED | KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN |
			 KW_EXPORT | KW_EXPRESSION | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST |
			 KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_HOLD_DDLTIME | KW_HOUR |
			 KW_IDXPROPERTIES | KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER |
			 KW_INPUTFORMAT | KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY |
			 KW_KEYS | KW_KEY_TYPE | KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES |
			 KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED |
			 KW_MANAGEDLOCATION | KW_MANAGEMENT | KW_MAPJOIN | KW_MAPPING | KW_MATCHED |
			 KW_MATERIALIZED | KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK |
			 KW_NORELY | KW_NOSCAN | KW_NOVALIDATE | KW_NO_DROP | KW_NULLS | KW_OFFLINE |
			 KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT |
			 KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH |
			 KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION |
			 KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY |
			 KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD | KW_RELY |
			 KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL | KW_REPLACE |
			 KW_REPLICATION | KW_RESOURCE | KW_RESPECT | KW_RESTRICT | KW_REWRITE |
			 KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY | KW_SCHEMA |
			 KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER |
			 KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW | KW_SHOW_DATABASE |
			 KW_SKEWED | KW_SNAPSHOT | KW_SORT | KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS |
			 KW_STATUS | KW_STORED | KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY |
			 KW_SYSTEM_TIME | KW_SYSTEM_VERSION | KW_TABLES | KW_TBLPROPERTIES | KW_TEMPORARY |
			 KW_TERMINATED | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH | KW_TRANSACTION |
			 KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TYPE | KW_UNARCHIVE |
			 KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK | KW_UNMANAGED | KW_UNSET |
			 KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC | KW_UTCTIMESTAMP | KW_VALIDATE |
			 KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW | KW_VIEWS | KW_WAIT | KW_WEEK |
			 KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD | KW_WRITE | KW_YEAR | KW_ZONE |
			 StringLiteral | Identifier 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule showStmtIdentifier*/
					recog.base.set_state(1620);
					recog.showStmtIdentifier()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- lockStatement ----------------
pub type LockStatementContextAll<'input> = LockStatementContext<'input>;


pub type LockStatementContext<'input> = BaseParserRuleContext<'input,LockStatementContextExt<'input>>;

#[derive(Clone)]
pub struct LockStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for LockStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for LockStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_lockStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_lockStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for LockStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_lockStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_lockStatement }
}
crate::tid!{LockStatementContextExt<'a>}

impl<'input> LockStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LockStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LockStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LockStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<LockStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LOCK
/// Returns `None` if there is no child corresponding to token KW_LOCK
fn KW_LOCK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn lockMode(&self) -> Option<Rc<LockModeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LockStatementContextAttrs<'input> for LockStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn lockStatement(&mut self,)
	-> Result<Rc<LockStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LockStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 96, RULE_lockStatement);
        let mut _localctx: Rc<LockStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1623);
			recog.base.match_token(KW_LOCK,&mut recog.err_handler)?;

			recog.base.set_state(1624);
			recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(1625);
			recog.tableName()?;

			recog.base.set_state(1627);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PARTITION {
				{
				/*InvokeRule partitionSpec*/
				recog.base.set_state(1626);
				recog.partitionSpec()?;

				}
			}

			/*InvokeRule lockMode*/
			recog.base.set_state(1629);
			recog.lockMode()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- lockDatabase ----------------
pub type LockDatabaseContextAll<'input> = LockDatabaseContext<'input>;


pub type LockDatabaseContext<'input> = BaseParserRuleContext<'input,LockDatabaseContextExt<'input>>;

#[derive(Clone)]
pub struct LockDatabaseContextExt<'input>{
	pub dbName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for LockDatabaseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for LockDatabaseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_lockDatabase(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_lockDatabase(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for LockDatabaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_lockDatabase }
	//fn type_rule_index() -> usize where Self: Sized { RULE_lockDatabase }
}
crate::tid!{LockDatabaseContextExt<'a>}

impl<'input> LockDatabaseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LockDatabaseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LockDatabaseContextExt{
				dbName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LockDatabaseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<LockDatabaseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LOCK
/// Returns `None` if there is no child corresponding to token KW_LOCK
fn KW_LOCK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCK, 0)
}
fn db_schema(&self) -> Option<Rc<Db_schemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn lockMode(&self) -> Option<Rc<LockModeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LockDatabaseContextAttrs<'input> for LockDatabaseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn lockDatabase(&mut self,)
	-> Result<Rc<LockDatabaseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LockDatabaseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 98, RULE_lockDatabase);
        let mut _localctx: Rc<LockDatabaseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1631);
			recog.base.match_token(KW_LOCK,&mut recog.err_handler)?;

			/*InvokeRule db_schema*/
			recog.base.set_state(1632);
			recog.db_schema()?;

			/*InvokeRule id_*/
			recog.base.set_state(1633);
			let tmp = recog.id_()?;
			 cast_mut::<_,LockDatabaseContext >(&mut _localctx).dbName = Some(tmp.clone());
			  

			/*InvokeRule lockMode*/
			recog.base.set_state(1634);
			recog.lockMode()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- lockMode ----------------
pub type LockModeContextAll<'input> = LockModeContext<'input>;


pub type LockModeContext<'input> = BaseParserRuleContext<'input,LockModeContextExt<'input>>;

#[derive(Clone)]
pub struct LockModeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for LockModeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for LockModeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_lockMode(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_lockMode(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for LockModeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_lockMode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_lockMode }
}
crate::tid!{LockModeContextExt<'a>}

impl<'input> LockModeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LockModeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LockModeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LockModeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<LockModeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SHARED
/// Returns `None` if there is no child corresponding to token KW_SHARED
fn KW_SHARED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SHARED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXCLUSIVE
/// Returns `None` if there is no child corresponding to token KW_EXCLUSIVE
fn KW_EXCLUSIVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXCLUSIVE, 0)
}

}

impl<'input> LockModeContextAttrs<'input> for LockModeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn lockMode(&mut self,)
	-> Result<Rc<LockModeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LockModeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 100, RULE_lockMode);
        let mut _localctx: Rc<LockModeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1636);
			_la = recog.base.input.la(1);
			if { !(_la==KW_EXCLUSIVE || _la==KW_SHARED) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unlockStatement ----------------
pub type UnlockStatementContextAll<'input> = UnlockStatementContext<'input>;


pub type UnlockStatementContext<'input> = BaseParserRuleContext<'input,UnlockStatementContextExt<'input>>;

#[derive(Clone)]
pub struct UnlockStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for UnlockStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for UnlockStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unlockStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_unlockStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for UnlockStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unlockStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unlockStatement }
}
crate::tid!{UnlockStatementContextExt<'a>}

impl<'input> UnlockStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnlockStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnlockStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnlockStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<UnlockStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UNLOCK
/// Returns `None` if there is no child corresponding to token KW_UNLOCK
fn KW_UNLOCK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNLOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnlockStatementContextAttrs<'input> for UnlockStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unlockStatement(&mut self,)
	-> Result<Rc<UnlockStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnlockStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 102, RULE_unlockStatement);
        let mut _localctx: Rc<UnlockStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1638);
			recog.base.match_token(KW_UNLOCK,&mut recog.err_handler)?;

			recog.base.set_state(1639);
			recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(1640);
			recog.tableName()?;

			recog.base.set_state(1642);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PARTITION {
				{
				/*InvokeRule partitionSpec*/
				recog.base.set_state(1641);
				recog.partitionSpec()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unlockDatabase ----------------
pub type UnlockDatabaseContextAll<'input> = UnlockDatabaseContext<'input>;


pub type UnlockDatabaseContext<'input> = BaseParserRuleContext<'input,UnlockDatabaseContextExt<'input>>;

#[derive(Clone)]
pub struct UnlockDatabaseContextExt<'input>{
	pub dbName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for UnlockDatabaseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for UnlockDatabaseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unlockDatabase(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_unlockDatabase(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for UnlockDatabaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unlockDatabase }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unlockDatabase }
}
crate::tid!{UnlockDatabaseContextExt<'a>}

impl<'input> UnlockDatabaseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnlockDatabaseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnlockDatabaseContextExt{
				dbName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait UnlockDatabaseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<UnlockDatabaseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UNLOCK
/// Returns `None` if there is no child corresponding to token KW_UNLOCK
fn KW_UNLOCK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNLOCK, 0)
}
fn db_schema(&self) -> Option<Rc<Db_schemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnlockDatabaseContextAttrs<'input> for UnlockDatabaseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unlockDatabase(&mut self,)
	-> Result<Rc<UnlockDatabaseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnlockDatabaseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 104, RULE_unlockDatabase);
        let mut _localctx: Rc<UnlockDatabaseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1644);
			recog.base.match_token(KW_UNLOCK,&mut recog.err_handler)?;

			/*InvokeRule db_schema*/
			recog.base.set_state(1645);
			recog.db_schema()?;

			/*InvokeRule id_*/
			recog.base.set_state(1646);
			let tmp = recog.id_()?;
			 cast_mut::<_,UnlockDatabaseContext >(&mut _localctx).dbName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createRoleStatement ----------------
pub type CreateRoleStatementContextAll<'input> = CreateRoleStatementContext<'input>;


pub type CreateRoleStatementContext<'input> = BaseParserRuleContext<'input,CreateRoleStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateRoleStatementContextExt<'input>{
	pub roleName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateRoleStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateRoleStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createRoleStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createRoleStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateRoleStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createRoleStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createRoleStatement }
}
crate::tid!{CreateRoleStatementContextExt<'a>}

impl<'input> CreateRoleStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateRoleStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateRoleStatementContextExt{
				roleName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateRoleStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateRoleStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLE
/// Returns `None` if there is no child corresponding to token KW_ROLE
fn KW_ROLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLE, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateRoleStatementContextAttrs<'input> for CreateRoleStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createRoleStatement(&mut self,)
	-> Result<Rc<CreateRoleStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateRoleStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 106, RULE_createRoleStatement);
        let mut _localctx: Rc<CreateRoleStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1648);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(1649);
			recog.base.match_token(KW_ROLE,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(1650);
			let tmp = recog.id_()?;
			 cast_mut::<_,CreateRoleStatementContext >(&mut _localctx).roleName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropRoleStatement ----------------
pub type DropRoleStatementContextAll<'input> = DropRoleStatementContext<'input>;


pub type DropRoleStatementContext<'input> = BaseParserRuleContext<'input,DropRoleStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropRoleStatementContextExt<'input>{
	pub roleName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropRoleStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropRoleStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropRoleStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropRoleStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropRoleStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropRoleStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropRoleStatement }
}
crate::tid!{DropRoleStatementContextExt<'a>}

impl<'input> DropRoleStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropRoleStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropRoleStatementContextExt{
				roleName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DropRoleStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropRoleStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLE
/// Returns `None` if there is no child corresponding to token KW_ROLE
fn KW_ROLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLE, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DropRoleStatementContextAttrs<'input> for DropRoleStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropRoleStatement(&mut self,)
	-> Result<Rc<DropRoleStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropRoleStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 108, RULE_dropRoleStatement);
        let mut _localctx: Rc<DropRoleStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1652);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(1653);
			recog.base.match_token(KW_ROLE,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(1654);
			let tmp = recog.id_()?;
			 cast_mut::<_,DropRoleStatementContext >(&mut _localctx).roleName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- grantPrivileges ----------------
pub type GrantPrivilegesContextAll<'input> = GrantPrivilegesContext<'input>;


pub type GrantPrivilegesContext<'input> = BaseParserRuleContext<'input,GrantPrivilegesContextExt<'input>>;

#[derive(Clone)]
pub struct GrantPrivilegesContextExt<'input>{
	pub privList: Option<Rc<PrivilegeListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for GrantPrivilegesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for GrantPrivilegesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_grantPrivileges(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_grantPrivileges(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for GrantPrivilegesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_grantPrivileges }
	//fn type_rule_index() -> usize where Self: Sized { RULE_grantPrivileges }
}
crate::tid!{GrantPrivilegesContextExt<'a>}

impl<'input> GrantPrivilegesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GrantPrivilegesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GrantPrivilegesContextExt{
				privList: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GrantPrivilegesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<GrantPrivilegesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_GRANT
/// Returns `None` if there is no child corresponding to token KW_GRANT
fn KW_GRANT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GRANT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
fn principalSpecification(&self) -> Option<Rc<PrincipalSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn privilegeList(&self) -> Option<Rc<PrivilegeListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn privilegeObject(&self) -> Option<Rc<PrivilegeObjectContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn withGrantOption(&self) -> Option<Rc<WithGrantOptionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GrantPrivilegesContextAttrs<'input> for GrantPrivilegesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn grantPrivileges(&mut self,)
	-> Result<Rc<GrantPrivilegesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GrantPrivilegesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 110, RULE_grantPrivileges);
        let mut _localctx: Rc<GrantPrivilegesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1656);
			recog.base.match_token(KW_GRANT,&mut recog.err_handler)?;

			/*InvokeRule privilegeList*/
			recog.base.set_state(1657);
			let tmp = recog.privilegeList()?;
			 cast_mut::<_,GrantPrivilegesContext >(&mut _localctx).privList = Some(tmp.clone());
			  

			recog.base.set_state(1659);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ON {
				{
				/*InvokeRule privilegeObject*/
				recog.base.set_state(1658);
				recog.privilegeObject()?;

				}
			}

			recog.base.set_state(1661);
			recog.base.match_token(KW_TO,&mut recog.err_handler)?;

			/*InvokeRule principalSpecification*/
			recog.base.set_state(1662);
			recog.principalSpecification()?;

			recog.base.set_state(1664);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(102,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule withGrantOption*/
					recog.base.set_state(1663);
					recog.withGrantOption()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- revokePrivileges ----------------
pub type RevokePrivilegesContextAll<'input> = RevokePrivilegesContext<'input>;


pub type RevokePrivilegesContext<'input> = BaseParserRuleContext<'input,RevokePrivilegesContextExt<'input>>;

#[derive(Clone)]
pub struct RevokePrivilegesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RevokePrivilegesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RevokePrivilegesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_revokePrivileges(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_revokePrivileges(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RevokePrivilegesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_revokePrivileges }
	//fn type_rule_index() -> usize where Self: Sized { RULE_revokePrivileges }
}
crate::tid!{RevokePrivilegesContextExt<'a>}

impl<'input> RevokePrivilegesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RevokePrivilegesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RevokePrivilegesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RevokePrivilegesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RevokePrivilegesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_REVOKE
/// Returns `None` if there is no child corresponding to token KW_REVOKE
fn KW_REVOKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REVOKE, 0)
}
fn privilegeList(&self) -> Option<Rc<PrivilegeListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}
fn principalSpecification(&self) -> Option<Rc<PrincipalSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn grantOptionFor(&self) -> Option<Rc<GrantOptionForContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn privilegeObject(&self) -> Option<Rc<PrivilegeObjectContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RevokePrivilegesContextAttrs<'input> for RevokePrivilegesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn revokePrivileges(&mut self,)
	-> Result<Rc<RevokePrivilegesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RevokePrivilegesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 112, RULE_revokePrivileges);
        let mut _localctx: Rc<RevokePrivilegesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1666);
			recog.base.match_token(KW_REVOKE,&mut recog.err_handler)?;

			recog.base.set_state(1668);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_GRANT {
				{
				/*InvokeRule grantOptionFor*/
				recog.base.set_state(1667);
				recog.grantOptionFor()?;

				}
			}

			/*InvokeRule privilegeList*/
			recog.base.set_state(1670);
			recog.privilegeList()?;

			recog.base.set_state(1672);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ON {
				{
				/*InvokeRule privilegeObject*/
				recog.base.set_state(1671);
				recog.privilegeObject()?;

				}
			}

			recog.base.set_state(1674);
			recog.base.match_token(KW_FROM,&mut recog.err_handler)?;

			/*InvokeRule principalSpecification*/
			recog.base.set_state(1675);
			recog.principalSpecification()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- grantRole ----------------
pub type GrantRoleContextAll<'input> = GrantRoleContext<'input>;


pub type GrantRoleContext<'input> = BaseParserRuleContext<'input,GrantRoleContextExt<'input>>;

#[derive(Clone)]
pub struct GrantRoleContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for GrantRoleContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for GrantRoleContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_grantRole(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_grantRole(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for GrantRoleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_grantRole }
	//fn type_rule_index() -> usize where Self: Sized { RULE_grantRole }
}
crate::tid!{GrantRoleContextExt<'a>}

impl<'input> GrantRoleContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GrantRoleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GrantRoleContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GrantRoleContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<GrantRoleContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_GRANT
/// Returns `None` if there is no child corresponding to token KW_GRANT
fn KW_GRANT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GRANT, 0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
fn principalSpecification(&self) -> Option<Rc<PrincipalSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLE
/// Returns `None` if there is no child corresponding to token KW_ROLE
fn KW_ROLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn withAdminOption(&self) -> Option<Rc<WithAdminOptionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GrantRoleContextAttrs<'input> for GrantRoleContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn grantRole(&mut self,)
	-> Result<Rc<GrantRoleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GrantRoleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 114, RULE_grantRole);
        let mut _localctx: Rc<GrantRoleContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1677);
			recog.base.match_token(KW_GRANT,&mut recog.err_handler)?;

			recog.base.set_state(1679);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(105,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1678);
					recog.base.match_token(KW_ROLE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule id_*/
			recog.base.set_state(1681);
			recog.id_()?;

			recog.base.set_state(1686);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1682);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(1683);
				recog.id_()?;

				}
				}
				recog.base.set_state(1688);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1689);
			recog.base.match_token(KW_TO,&mut recog.err_handler)?;

			/*InvokeRule principalSpecification*/
			recog.base.set_state(1690);
			recog.principalSpecification()?;

			recog.base.set_state(1692);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(107,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule withAdminOption*/
					recog.base.set_state(1691);
					recog.withAdminOption()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- revokeRole ----------------
pub type RevokeRoleContextAll<'input> = RevokeRoleContext<'input>;


pub type RevokeRoleContext<'input> = BaseParserRuleContext<'input,RevokeRoleContextExt<'input>>;

#[derive(Clone)]
pub struct RevokeRoleContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RevokeRoleContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RevokeRoleContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_revokeRole(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_revokeRole(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RevokeRoleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_revokeRole }
	//fn type_rule_index() -> usize where Self: Sized { RULE_revokeRole }
}
crate::tid!{RevokeRoleContextExt<'a>}

impl<'input> RevokeRoleContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RevokeRoleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RevokeRoleContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RevokeRoleContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RevokeRoleContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_REVOKE
/// Returns `None` if there is no child corresponding to token KW_REVOKE
fn KW_REVOKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REVOKE, 0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}
fn principalSpecification(&self) -> Option<Rc<PrincipalSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn adminOptionFor(&self) -> Option<Rc<AdminOptionForContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLE
/// Returns `None` if there is no child corresponding to token KW_ROLE
fn KW_ROLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> RevokeRoleContextAttrs<'input> for RevokeRoleContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn revokeRole(&mut self,)
	-> Result<Rc<RevokeRoleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RevokeRoleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 116, RULE_revokeRole);
        let mut _localctx: Rc<RevokeRoleContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1694);
			recog.base.match_token(KW_REVOKE,&mut recog.err_handler)?;

			recog.base.set_state(1696);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(108,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule adminOptionFor*/
					recog.base.set_state(1695);
					recog.adminOptionFor()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(1699);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(109,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1698);
					recog.base.match_token(KW_ROLE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule id_*/
			recog.base.set_state(1701);
			recog.id_()?;

			recog.base.set_state(1706);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1702);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(1703);
				recog.id_()?;

				}
				}
				recog.base.set_state(1708);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1709);
			recog.base.match_token(KW_FROM,&mut recog.err_handler)?;

			/*InvokeRule principalSpecification*/
			recog.base.set_state(1710);
			recog.principalSpecification()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- showRoleGrants ----------------
pub type ShowRoleGrantsContextAll<'input> = ShowRoleGrantsContext<'input>;


pub type ShowRoleGrantsContext<'input> = BaseParserRuleContext<'input,ShowRoleGrantsContextExt<'input>>;

#[derive(Clone)]
pub struct ShowRoleGrantsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ShowRoleGrantsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ShowRoleGrantsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_showRoleGrants(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_showRoleGrants(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ShowRoleGrantsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_showRoleGrants }
	//fn type_rule_index() -> usize where Self: Sized { RULE_showRoleGrants }
}
crate::tid!{ShowRoleGrantsContextExt<'a>}

impl<'input> ShowRoleGrantsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ShowRoleGrantsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ShowRoleGrantsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ShowRoleGrantsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ShowRoleGrantsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SHOW
/// Returns `None` if there is no child corresponding to token KW_SHOW
fn KW_SHOW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLE
/// Returns `None` if there is no child corresponding to token KW_ROLE
fn KW_ROLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_GRANT
/// Returns `None` if there is no child corresponding to token KW_GRANT
fn KW_GRANT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GRANT, 0)
}
fn principalName(&self) -> Option<Rc<PrincipalNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ShowRoleGrantsContextAttrs<'input> for ShowRoleGrantsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn showRoleGrants(&mut self,)
	-> Result<Rc<ShowRoleGrantsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ShowRoleGrantsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 118, RULE_showRoleGrants);
        let mut _localctx: Rc<ShowRoleGrantsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1712);
			recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

			recog.base.set_state(1713);
			recog.base.match_token(KW_ROLE,&mut recog.err_handler)?;

			recog.base.set_state(1714);
			recog.base.match_token(KW_GRANT,&mut recog.err_handler)?;

			/*InvokeRule principalName*/
			recog.base.set_state(1715);
			recog.principalName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- showRoles ----------------
pub type ShowRolesContextAll<'input> = ShowRolesContext<'input>;


pub type ShowRolesContext<'input> = BaseParserRuleContext<'input,ShowRolesContextExt<'input>>;

#[derive(Clone)]
pub struct ShowRolesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ShowRolesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ShowRolesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_showRoles(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_showRoles(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ShowRolesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_showRoles }
	//fn type_rule_index() -> usize where Self: Sized { RULE_showRoles }
}
crate::tid!{ShowRolesContextExt<'a>}

impl<'input> ShowRolesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ShowRolesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ShowRolesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ShowRolesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ShowRolesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SHOW
/// Returns `None` if there is no child corresponding to token KW_SHOW
fn KW_SHOW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLES
/// Returns `None` if there is no child corresponding to token KW_ROLES
fn KW_ROLES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLES, 0)
}

}

impl<'input> ShowRolesContextAttrs<'input> for ShowRolesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn showRoles(&mut self,)
	-> Result<Rc<ShowRolesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ShowRolesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 120, RULE_showRoles);
        let mut _localctx: Rc<ShowRolesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1717);
			recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

			recog.base.set_state(1718);
			recog.base.match_token(KW_ROLES,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- showCurrentRole ----------------
pub type ShowCurrentRoleContextAll<'input> = ShowCurrentRoleContext<'input>;


pub type ShowCurrentRoleContext<'input> = BaseParserRuleContext<'input,ShowCurrentRoleContextExt<'input>>;

#[derive(Clone)]
pub struct ShowCurrentRoleContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ShowCurrentRoleContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ShowCurrentRoleContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_showCurrentRole(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_showCurrentRole(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ShowCurrentRoleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_showCurrentRole }
	//fn type_rule_index() -> usize where Self: Sized { RULE_showCurrentRole }
}
crate::tid!{ShowCurrentRoleContextExt<'a>}

impl<'input> ShowCurrentRoleContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ShowCurrentRoleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ShowCurrentRoleContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ShowCurrentRoleContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ShowCurrentRoleContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SHOW
/// Returns `None` if there is no child corresponding to token KW_SHOW
fn KW_SHOW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CURRENT
/// Returns `None` if there is no child corresponding to token KW_CURRENT
fn KW_CURRENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CURRENT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLES
/// Returns `None` if there is no child corresponding to token KW_ROLES
fn KW_ROLES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLES, 0)
}

}

impl<'input> ShowCurrentRoleContextAttrs<'input> for ShowCurrentRoleContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn showCurrentRole(&mut self,)
	-> Result<Rc<ShowCurrentRoleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ShowCurrentRoleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 122, RULE_showCurrentRole);
        let mut _localctx: Rc<ShowCurrentRoleContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1720);
			recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

			recog.base.set_state(1721);
			recog.base.match_token(KW_CURRENT,&mut recog.err_handler)?;

			recog.base.set_state(1722);
			recog.base.match_token(KW_ROLES,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setRole ----------------
pub type SetRoleContextAll<'input> = SetRoleContext<'input>;


pub type SetRoleContext<'input> = BaseParserRuleContext<'input,SetRoleContextExt<'input>>;

#[derive(Clone)]
pub struct SetRoleContextExt<'input>{
	pub all: Option<TokenType<'input>>,
	pub none: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SetRoleContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SetRoleContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setRole(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_setRole(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SetRoleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setRole }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setRole }
}
crate::tid!{SetRoleContextExt<'a>}

impl<'input> SetRoleContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetRoleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetRoleContextExt{
				all: None, none: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SetRoleContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SetRoleContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLE
/// Returns `None` if there is no child corresponding to token KW_ROLE
fn KW_ROLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLE, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_ALL
/// Returns `None` if there is no child corresponding to token KW_ALL
fn KW_ALL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NONE
/// Returns `None` if there is no child corresponding to token KW_NONE
fn KW_NONE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NONE, 0)
}

}

impl<'input> SetRoleContextAttrs<'input> for SetRoleContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setRole(&mut self,)
	-> Result<Rc<SetRoleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetRoleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 124, RULE_setRole);
        let mut _localctx: Rc<SetRoleContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1724);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(1725);
			recog.base.match_token(KW_ROLE,&mut recog.err_handler)?;

			recog.base.set_state(1729);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ALL 
				=> {
					{
					recog.base.set_state(1726);
					let tmp = recog.base.match_token(KW_ALL,&mut recog.err_handler)?;
					 cast_mut::<_,SetRoleContext >(&mut _localctx).all = Some(tmp.clone());
					  

					}
				}

			 KW_NONE 
				=> {
					{
					recog.base.set_state(1727);
					let tmp = recog.base.match_token(KW_NONE,&mut recog.err_handler)?;
					 cast_mut::<_,SetRoleContext >(&mut _localctx).none = Some(tmp.clone());
					  

					}
				}

			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT | KW_BATCH |
			 KW_BEFORE | KW_BUCKET | KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CBO |
			 KW_CHANGE | KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS |
			 KW_COLLECTION | KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS |
			 KW_COMPUTE | KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_DATA |
			 KW_DATABASES | KW_DATETIME | KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES |
			 KW_DCPROPERTIES | KW_DEBUG | KW_DEFAULT | KW_DEFERRED | KW_DEFINED |
			 KW_DELIMITED | KW_DEPENDENCY | KW_DESC | KW_DETAIL | KW_DIRECTORIES |
			 KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE | KW_DISTRIBUTED | KW_DO |
			 KW_DUMP | KW_ELEM_TYPE | KW_ENABLE | KW_ENFORCED | KW_ESCAPED | KW_EVERY |
			 KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED | KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN |
			 KW_EXPORT | KW_EXPRESSION | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST |
			 KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_HOLD_DDLTIME | KW_HOUR |
			 KW_IDXPROPERTIES | KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER |
			 KW_INPUTFORMAT | KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY |
			 KW_KEYS | KW_KEY_TYPE | KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES |
			 KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED |
			 KW_MANAGEDLOCATION | KW_MANAGEMENT | KW_MAPJOIN | KW_MAPPING | KW_MATCHED |
			 KW_MATERIALIZED | KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK |
			 KW_NORELY | KW_NOSCAN | KW_NOVALIDATE | KW_NO_DROP | KW_NULLS | KW_OFFLINE |
			 KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT |
			 KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH |
			 KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION |
			 KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY |
			 KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD | KW_RELY |
			 KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL | KW_REPLACE |
			 KW_REPLICATION | KW_RESOURCE | KW_RESPECT | KW_RESTRICT | KW_REWRITE |
			 KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY | KW_SCHEMA |
			 KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER |
			 KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW | KW_SHOW_DATABASE |
			 KW_SKEWED | KW_SNAPSHOT | KW_SORT | KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS |
			 KW_STATUS | KW_STORED | KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY |
			 KW_SYSTEM_TIME | KW_SYSTEM_VERSION | KW_TABLES | KW_TBLPROPERTIES | KW_TEMPORARY |
			 KW_TERMINATED | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH | KW_TRANSACTION |
			 KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TYPE | KW_UNARCHIVE |
			 KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK | KW_UNMANAGED | KW_UNSET |
			 KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC | KW_UTCTIMESTAMP | KW_VALIDATE |
			 KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW | KW_VIEWS | KW_WAIT | KW_WEEK |
			 KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD | KW_WRITE | KW_YEAR | KW_ZONE |
			 Identifier 
				=> {
					{
					/*InvokeRule id_*/
					recog.base.set_state(1728);
					recog.id_()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- showGrants ----------------
pub type ShowGrantsContextAll<'input> = ShowGrantsContext<'input>;


pub type ShowGrantsContext<'input> = BaseParserRuleContext<'input,ShowGrantsContextExt<'input>>;

#[derive(Clone)]
pub struct ShowGrantsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ShowGrantsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ShowGrantsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_showGrants(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_showGrants(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ShowGrantsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_showGrants }
	//fn type_rule_index() -> usize where Self: Sized { RULE_showGrants }
}
crate::tid!{ShowGrantsContextExt<'a>}

impl<'input> ShowGrantsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ShowGrantsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ShowGrantsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ShowGrantsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ShowGrantsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SHOW
/// Returns `None` if there is no child corresponding to token KW_SHOW
fn KW_SHOW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_GRANT
/// Returns `None` if there is no child corresponding to token KW_GRANT
fn KW_GRANT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GRANT, 0)
}
fn principalName(&self) -> Option<Rc<PrincipalNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
fn privilegeIncludeColObject(&self) -> Option<Rc<PrivilegeIncludeColObjectContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ShowGrantsContextAttrs<'input> for ShowGrantsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn showGrants(&mut self,)
	-> Result<Rc<ShowGrantsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ShowGrantsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 126, RULE_showGrants);
        let mut _localctx: Rc<ShowGrantsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1731);
			recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

			recog.base.set_state(1732);
			recog.base.match_token(KW_GRANT,&mut recog.err_handler)?;

			recog.base.set_state(1734);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_GROUP || _la==KW_ROLE || _la==KW_USER {
				{
				/*InvokeRule principalName*/
				recog.base.set_state(1733);
				recog.principalName()?;

				}
			}

			recog.base.set_state(1738);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ON {
				{
				recog.base.set_state(1736);
				recog.base.match_token(KW_ON,&mut recog.err_handler)?;

				/*InvokeRule privilegeIncludeColObject*/
				recog.base.set_state(1737);
				recog.privilegeIncludeColObject()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- showRolePrincipals ----------------
pub type ShowRolePrincipalsContextAll<'input> = ShowRolePrincipalsContext<'input>;


pub type ShowRolePrincipalsContext<'input> = BaseParserRuleContext<'input,ShowRolePrincipalsContextExt<'input>>;

#[derive(Clone)]
pub struct ShowRolePrincipalsContextExt<'input>{
	pub roleName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ShowRolePrincipalsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ShowRolePrincipalsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_showRolePrincipals(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_showRolePrincipals(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ShowRolePrincipalsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_showRolePrincipals }
	//fn type_rule_index() -> usize where Self: Sized { RULE_showRolePrincipals }
}
crate::tid!{ShowRolePrincipalsContextExt<'a>}

impl<'input> ShowRolePrincipalsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ShowRolePrincipalsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ShowRolePrincipalsContextExt{
				roleName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ShowRolePrincipalsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ShowRolePrincipalsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SHOW
/// Returns `None` if there is no child corresponding to token KW_SHOW
fn KW_SHOW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PRINCIPALS
/// Returns `None` if there is no child corresponding to token KW_PRINCIPALS
fn KW_PRINCIPALS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PRINCIPALS, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ShowRolePrincipalsContextAttrs<'input> for ShowRolePrincipalsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn showRolePrincipals(&mut self,)
	-> Result<Rc<ShowRolePrincipalsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ShowRolePrincipalsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 128, RULE_showRolePrincipals);
        let mut _localctx: Rc<ShowRolePrincipalsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1740);
			recog.base.match_token(KW_SHOW,&mut recog.err_handler)?;

			recog.base.set_state(1741);
			recog.base.match_token(KW_PRINCIPALS,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(1742);
			let tmp = recog.id_()?;
			 cast_mut::<_,ShowRolePrincipalsContext >(&mut _localctx).roleName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- privilegeIncludeColObject ----------------
pub type PrivilegeIncludeColObjectContextAll<'input> = PrivilegeIncludeColObjectContext<'input>;


pub type PrivilegeIncludeColObjectContext<'input> = BaseParserRuleContext<'input,PrivilegeIncludeColObjectContextExt<'input>>;

#[derive(Clone)]
pub struct PrivilegeIncludeColObjectContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrivilegeIncludeColObjectContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrivilegeIncludeColObjectContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_privilegeIncludeColObject(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_privilegeIncludeColObject(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrivilegeIncludeColObjectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_privilegeIncludeColObject }
	//fn type_rule_index() -> usize where Self: Sized { RULE_privilegeIncludeColObject }
}
crate::tid!{PrivilegeIncludeColObjectContextExt<'a>}

impl<'input> PrivilegeIncludeColObjectContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrivilegeIncludeColObjectContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrivilegeIncludeColObjectContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrivilegeIncludeColObjectContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrivilegeIncludeColObjectContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ALL
/// Returns `None` if there is no child corresponding to token KW_ALL
fn KW_ALL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALL, 0)
}
fn privObjectCols(&self) -> Option<Rc<PrivObjectColsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrivilegeIncludeColObjectContextAttrs<'input> for PrivilegeIncludeColObjectContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn privilegeIncludeColObject(&mut self,)
	-> Result<Rc<PrivilegeIncludeColObjectContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrivilegeIncludeColObjectContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 130, RULE_privilegeIncludeColObject);
        let mut _localctx: Rc<PrivilegeIncludeColObjectContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1746);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ALL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1744);
					recog.base.match_token(KW_ALL,&mut recog.err_handler)?;

					}
				}

			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT | KW_BATCH |
			 KW_BEFORE | KW_BUCKET | KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CBO |
			 KW_CHANGE | KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS |
			 KW_COLLECTION | KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS |
			 KW_COMPUTE | KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_DATA |
			 KW_DATABASE | KW_DATABASES | KW_DATETIME | KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES |
			 KW_DCPROPERTIES | KW_DEBUG | KW_DEFAULT | KW_DEFERRED | KW_DEFINED |
			 KW_DELIMITED | KW_DEPENDENCY | KW_DESC | KW_DETAIL | KW_DIRECTORIES |
			 KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE | KW_DISTRIBUTED | KW_DO |
			 KW_DUMP | KW_ELEM_TYPE | KW_ENABLE | KW_ENFORCED | KW_ESCAPED | KW_EVERY |
			 KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED | KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN |
			 KW_EXPORT | KW_EXPRESSION | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST |
			 KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_HOLD_DDLTIME | KW_HOUR |
			 KW_IDXPROPERTIES | KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER |
			 KW_INPUTFORMAT | KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY |
			 KW_KEYS | KW_KEY_TYPE | KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES |
			 KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED |
			 KW_MANAGEDLOCATION | KW_MANAGEMENT | KW_MAPJOIN | KW_MAPPING | KW_MATCHED |
			 KW_MATERIALIZED | KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK |
			 KW_NORELY | KW_NOSCAN | KW_NOVALIDATE | KW_NO_DROP | KW_NULLS | KW_OFFLINE |
			 KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT |
			 KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH |
			 KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION |
			 KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY |
			 KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD | KW_RELY |
			 KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL | KW_REPLACE |
			 KW_REPLICATION | KW_RESOURCE | KW_RESPECT | KW_RESTRICT | KW_REWRITE |
			 KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY | KW_SCHEMA |
			 KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER |
			 KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW | KW_SHOW_DATABASE |
			 KW_SKEWED | KW_SNAPSHOT | KW_SORT | KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS |
			 KW_STATUS | KW_STORED | KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY |
			 KW_SYSTEM_TIME | KW_SYSTEM_VERSION | KW_TABLE | KW_TABLES | KW_TBLPROPERTIES |
			 KW_TEMPORARY | KW_TERMINATED | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH |
			 KW_TRANSACTION | KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TYPE |
			 KW_UNARCHIVE | KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK | KW_UNMANAGED |
			 KW_UNSET | KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC | KW_UTCTIMESTAMP |
			 KW_VALIDATE | KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW | KW_VIEWS |
			 KW_WAIT | KW_WEEK | KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD | KW_WRITE |
			 KW_YEAR | KW_ZONE | Identifier 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule privObjectCols*/
					recog.base.set_state(1745);
					recog.privObjectCols()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- privilegeObject ----------------
pub type PrivilegeObjectContextAll<'input> = PrivilegeObjectContext<'input>;


pub type PrivilegeObjectContext<'input> = BaseParserRuleContext<'input,PrivilegeObjectContextExt<'input>>;

#[derive(Clone)]
pub struct PrivilegeObjectContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrivilegeObjectContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrivilegeObjectContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_privilegeObject(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_privilegeObject(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrivilegeObjectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_privilegeObject }
	//fn type_rule_index() -> usize where Self: Sized { RULE_privilegeObject }
}
crate::tid!{PrivilegeObjectContextExt<'a>}

impl<'input> PrivilegeObjectContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrivilegeObjectContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrivilegeObjectContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrivilegeObjectContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrivilegeObjectContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
fn privObject(&self) -> Option<Rc<PrivObjectContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrivilegeObjectContextAttrs<'input> for PrivilegeObjectContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn privilegeObject(&mut self,)
	-> Result<Rc<PrivilegeObjectContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrivilegeObjectContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 132, RULE_privilegeObject);
        let mut _localctx: Rc<PrivilegeObjectContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1748);
			recog.base.match_token(KW_ON,&mut recog.err_handler)?;

			/*InvokeRule privObject*/
			recog.base.set_state(1749);
			recog.privObject()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- privObject ----------------
pub type PrivObjectContextAll<'input> = PrivObjectContext<'input>;


pub type PrivObjectContext<'input> = BaseParserRuleContext<'input,PrivObjectContextExt<'input>>;

#[derive(Clone)]
pub struct PrivObjectContextExt<'input>{
	pub path: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrivObjectContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrivObjectContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_privObject(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_privObject(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrivObjectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_privObject }
	//fn type_rule_index() -> usize where Self: Sized { RULE_privObject }
}
crate::tid!{PrivObjectContextExt<'a>}

impl<'input> PrivObjectContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrivObjectContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrivObjectContextExt{
				path: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrivObjectContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrivObjectContextExt<'input>>{

fn db_schema(&self) -> Option<Rc<Db_schemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_URI
/// Returns `None` if there is no child corresponding to token KW_URI
fn KW_URI(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_URI, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERVER
/// Returns `None` if there is no child corresponding to token KW_SERVER
fn KW_SERVER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERVER, 0)
}

}

impl<'input> PrivObjectContextAttrs<'input> for PrivObjectContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn privObject(&mut self,)
	-> Result<Rc<PrivObjectContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrivObjectContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 134, RULE_privObject);
        let mut _localctx: Rc<PrivObjectContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1765);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(117,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule db_schema*/
					recog.base.set_state(1751);
					recog.db_schema()?;

					/*InvokeRule id_*/
					recog.base.set_state(1752);
					recog.id_()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1755);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_TABLE {
						{
						recog.base.set_state(1754);
						recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule tableName*/
					recog.base.set_state(1757);
					recog.tableName()?;

					recog.base.set_state(1759);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1758);
						recog.partitionSpec()?;

						}
					}

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(1761);
					recog.base.match_token(KW_URI,&mut recog.err_handler)?;

					recog.base.set_state(1762);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,PrivObjectContext >(&mut _localctx).path = Some(tmp.clone());
					  

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(1763);
					recog.base.match_token(KW_SERVER,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(1764);
					recog.id_()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- privObjectCols ----------------
pub type PrivObjectColsContextAll<'input> = PrivObjectColsContext<'input>;


pub type PrivObjectColsContext<'input> = BaseParserRuleContext<'input,PrivObjectColsContextExt<'input>>;

#[derive(Clone)]
pub struct PrivObjectColsContextExt<'input>{
	pub cols: Option<Rc<ColumnNameListContextAll<'input>>>,
	pub path: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrivObjectColsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrivObjectColsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_privObjectCols(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_privObjectCols(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrivObjectColsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_privObjectCols }
	//fn type_rule_index() -> usize where Self: Sized { RULE_privObjectCols }
}
crate::tid!{PrivObjectColsContextExt<'a>}

impl<'input> PrivObjectColsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrivObjectColsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrivObjectColsContextExt{
				path: None, 
				cols: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrivObjectColsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrivObjectColsContextExt<'input>>{

fn db_schema(&self) -> Option<Rc<Db_schemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_URI
/// Returns `None` if there is no child corresponding to token KW_URI
fn KW_URI(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_URI, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERVER
/// Returns `None` if there is no child corresponding to token KW_SERVER
fn KW_SERVER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERVER, 0)
}

}

impl<'input> PrivObjectColsContextAttrs<'input> for PrivObjectColsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn privObjectCols(&mut self,)
	-> Result<Rc<PrivObjectColsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrivObjectColsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 136, RULE_privObjectCols);
        let mut _localctx: Rc<PrivObjectColsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1787);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(121,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule db_schema*/
					recog.base.set_state(1767);
					recog.db_schema()?;

					/*InvokeRule id_*/
					recog.base.set_state(1768);
					recog.id_()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1771);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_TABLE {
						{
						recog.base.set_state(1770);
						recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule tableName*/
					recog.base.set_state(1773);
					recog.tableName()?;

					recog.base.set_state(1778);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(119,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1774);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule columnNameList*/
							recog.base.set_state(1775);
							let tmp = recog.columnNameList()?;
							 cast_mut::<_,PrivObjectColsContext >(&mut _localctx).cols = Some(tmp.clone());
							  

							recog.base.set_state(1776);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1781);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1780);
						recog.partitionSpec()?;

						}
					}

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(1783);
					recog.base.match_token(KW_URI,&mut recog.err_handler)?;

					recog.base.set_state(1784);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,PrivObjectColsContext >(&mut _localctx).path = Some(tmp.clone());
					  

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(1785);
					recog.base.match_token(KW_SERVER,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(1786);
					recog.id_()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- privilegeList ----------------
pub type PrivilegeListContextAll<'input> = PrivilegeListContext<'input>;


pub type PrivilegeListContext<'input> = BaseParserRuleContext<'input,PrivilegeListContextExt<'input>>;

#[derive(Clone)]
pub struct PrivilegeListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrivilegeListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrivilegeListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_privilegeList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_privilegeList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrivilegeListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_privilegeList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_privilegeList }
}
crate::tid!{PrivilegeListContextExt<'a>}

impl<'input> PrivilegeListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrivilegeListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrivilegeListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrivilegeListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrivilegeListContextExt<'input>>{

fn privlegeDef_all(&self) ->  Vec<Rc<PrivlegeDefContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn privlegeDef(&self, i: usize) -> Option<Rc<PrivlegeDefContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PrivilegeListContextAttrs<'input> for PrivilegeListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn privilegeList(&mut self,)
	-> Result<Rc<PrivilegeListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrivilegeListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 138, RULE_privilegeList);
        let mut _localctx: Rc<PrivilegeListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule privlegeDef*/
			recog.base.set_state(1789);
			recog.privlegeDef()?;

			recog.base.set_state(1794);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1790);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule privlegeDef*/
				recog.base.set_state(1791);
				recog.privlegeDef()?;

				}
				}
				recog.base.set_state(1796);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- privlegeDef ----------------
pub type PrivlegeDefContextAll<'input> = PrivlegeDefContext<'input>;


pub type PrivlegeDefContext<'input> = BaseParserRuleContext<'input,PrivlegeDefContextExt<'input>>;

#[derive(Clone)]
pub struct PrivlegeDefContextExt<'input>{
	pub cols: Option<Rc<ColumnNameListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrivlegeDefContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrivlegeDefContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_privlegeDef(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_privlegeDef(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrivlegeDefContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_privlegeDef }
	//fn type_rule_index() -> usize where Self: Sized { RULE_privlegeDef }
}
crate::tid!{PrivlegeDefContextExt<'a>}

impl<'input> PrivlegeDefContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrivlegeDefContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrivlegeDefContextExt{
				cols: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrivlegeDefContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrivlegeDefContextExt<'input>>{

fn privilegeType(&self) -> Option<Rc<PrivilegeTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrivlegeDefContextAttrs<'input> for PrivlegeDefContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn privlegeDef(&mut self,)
	-> Result<Rc<PrivlegeDefContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrivlegeDefContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 140, RULE_privlegeDef);
        let mut _localctx: Rc<PrivlegeDefContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule privilegeType*/
			recog.base.set_state(1797);
			recog.privilegeType()?;

			recog.base.set_state(1802);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LPAREN {
				{
				recog.base.set_state(1798);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				/*InvokeRule columnNameList*/
				recog.base.set_state(1799);
				let tmp = recog.columnNameList()?;
				 cast_mut::<_,PrivlegeDefContext >(&mut _localctx).cols = Some(tmp.clone());
				  

				recog.base.set_state(1800);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- privilegeType ----------------
pub type PrivilegeTypeContextAll<'input> = PrivilegeTypeContext<'input>;


pub type PrivilegeTypeContext<'input> = BaseParserRuleContext<'input,PrivilegeTypeContextExt<'input>>;

#[derive(Clone)]
pub struct PrivilegeTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrivilegeTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrivilegeTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_privilegeType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_privilegeType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrivilegeTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_privilegeType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_privilegeType }
}
crate::tid!{PrivilegeTypeContextExt<'a>}

impl<'input> PrivilegeTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrivilegeTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrivilegeTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrivilegeTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrivilegeTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ALL
/// Returns `None` if there is no child corresponding to token KW_ALL
fn KW_ALL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ALTER
/// Returns `None` if there is no child corresponding to token KW_ALTER
fn KW_ALTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UPDATE
/// Returns `None` if there is no child corresponding to token KW_UPDATE
fn KW_UPDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCK
/// Returns `None` if there is no child corresponding to token KW_LOCK
fn KW_LOCK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SELECT
/// Returns `None` if there is no child corresponding to token KW_SELECT
fn KW_SELECT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SELECT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SHOW_DATABASE
/// Returns `None` if there is no child corresponding to token KW_SHOW_DATABASE
fn KW_SHOW_DATABASE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SHOW_DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INSERT
/// Returns `None` if there is no child corresponding to token KW_INSERT
fn KW_INSERT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DELETE
/// Returns `None` if there is no child corresponding to token KW_DELETE
fn KW_DELETE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DELETE, 0)
}

}

impl<'input> PrivilegeTypeContextAttrs<'input> for PrivilegeTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn privilegeType(&mut self,)
	-> Result<Rc<PrivilegeTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrivilegeTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 142, RULE_privilegeType);
        let mut _localctx: Rc<PrivilegeTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1804);
			_la = recog.base.input.la(1);
			if { !(_la==KW_ALL || _la==KW_ALTER || _la==KW_CREATE || _la==KW_DELETE || _la==KW_DROP || _la==KW_INSERT || _la==KW_LOCK || _la==KW_SELECT || _la==KW_SHOW_DATABASE || _la==KW_UPDATE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- principalSpecification ----------------
pub type PrincipalSpecificationContextAll<'input> = PrincipalSpecificationContext<'input>;


pub type PrincipalSpecificationContext<'input> = BaseParserRuleContext<'input,PrincipalSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct PrincipalSpecificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrincipalSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrincipalSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_principalSpecification(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_principalSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrincipalSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principalSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principalSpecification }
}
crate::tid!{PrincipalSpecificationContextExt<'a>}

impl<'input> PrincipalSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrincipalSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrincipalSpecificationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrincipalSpecificationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrincipalSpecificationContextExt<'input>>{

fn principalName_all(&self) ->  Vec<Rc<PrincipalNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn principalName(&self, i: usize) -> Option<Rc<PrincipalNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PrincipalSpecificationContextAttrs<'input> for PrincipalSpecificationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn principalSpecification(&mut self,)
	-> Result<Rc<PrincipalSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrincipalSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 144, RULE_principalSpecification);
        let mut _localctx: Rc<PrincipalSpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule principalName*/
			recog.base.set_state(1806);
			recog.principalName()?;

			recog.base.set_state(1811);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1807);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule principalName*/
				recog.base.set_state(1808);
				recog.principalName()?;

				}
				}
				recog.base.set_state(1813);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- principalName ----------------
pub type PrincipalNameContextAll<'input> = PrincipalNameContext<'input>;


pub type PrincipalNameContext<'input> = BaseParserRuleContext<'input,PrincipalNameContextExt<'input>>;

#[derive(Clone)]
pub struct PrincipalNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrincipalNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrincipalNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_principalName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_principalName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrincipalNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principalName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principalName }
}
crate::tid!{PrincipalNameContextExt<'a>}

impl<'input> PrincipalNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrincipalNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrincipalNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrincipalNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrincipalNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_USER
/// Returns `None` if there is no child corresponding to token KW_USER
fn KW_USER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USER, 0)
}
fn principalIdentifier(&self) -> Option<Rc<PrincipalIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_GROUP
/// Returns `None` if there is no child corresponding to token KW_GROUP
fn KW_GROUP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLE
/// Returns `None` if there is no child corresponding to token KW_ROLE
fn KW_ROLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLE, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrincipalNameContextAttrs<'input> for PrincipalNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn principalName(&mut self,)
	-> Result<Rc<PrincipalNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrincipalNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 146, RULE_principalName);
        let mut _localctx: Rc<PrincipalNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1820);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_USER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1814);
					recog.base.match_token(KW_USER,&mut recog.err_handler)?;

					/*InvokeRule principalIdentifier*/
					recog.base.set_state(1815);
					recog.principalIdentifier()?;

					}
				}

			 KW_GROUP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1816);
					recog.base.match_token(KW_GROUP,&mut recog.err_handler)?;

					/*InvokeRule principalIdentifier*/
					recog.base.set_state(1817);
					recog.principalIdentifier()?;

					}
				}

			 KW_ROLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(1818);
					recog.base.match_token(KW_ROLE,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(1819);
					recog.id_()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- withGrantOption ----------------
pub type WithGrantOptionContextAll<'input> = WithGrantOptionContext<'input>;


pub type WithGrantOptionContext<'input> = BaseParserRuleContext<'input,WithGrantOptionContextExt<'input>>;

#[derive(Clone)]
pub struct WithGrantOptionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for WithGrantOptionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for WithGrantOptionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_withGrantOption(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_withGrantOption(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for WithGrantOptionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_withGrantOption }
	//fn type_rule_index() -> usize where Self: Sized { RULE_withGrantOption }
}
crate::tid!{WithGrantOptionContextExt<'a>}

impl<'input> WithGrantOptionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WithGrantOptionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WithGrantOptionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WithGrantOptionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<WithGrantOptionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_GRANT
/// Returns `None` if there is no child corresponding to token KW_GRANT
fn KW_GRANT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GRANT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OPTION
/// Returns `None` if there is no child corresponding to token KW_OPTION
fn KW_OPTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OPTION, 0)
}

}

impl<'input> WithGrantOptionContextAttrs<'input> for WithGrantOptionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn withGrantOption(&mut self,)
	-> Result<Rc<WithGrantOptionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WithGrantOptionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 148, RULE_withGrantOption);
        let mut _localctx: Rc<WithGrantOptionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1822);
			recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

			recog.base.set_state(1823);
			recog.base.match_token(KW_GRANT,&mut recog.err_handler)?;

			recog.base.set_state(1824);
			recog.base.match_token(KW_OPTION,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- grantOptionFor ----------------
pub type GrantOptionForContextAll<'input> = GrantOptionForContext<'input>;


pub type GrantOptionForContext<'input> = BaseParserRuleContext<'input,GrantOptionForContextExt<'input>>;

#[derive(Clone)]
pub struct GrantOptionForContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for GrantOptionForContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for GrantOptionForContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_grantOptionFor(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_grantOptionFor(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for GrantOptionForContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_grantOptionFor }
	//fn type_rule_index() -> usize where Self: Sized { RULE_grantOptionFor }
}
crate::tid!{GrantOptionForContextExt<'a>}

impl<'input> GrantOptionForContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GrantOptionForContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GrantOptionForContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GrantOptionForContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<GrantOptionForContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_GRANT
/// Returns `None` if there is no child corresponding to token KW_GRANT
fn KW_GRANT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GRANT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OPTION
/// Returns `None` if there is no child corresponding to token KW_OPTION
fn KW_OPTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FOR
/// Returns `None` if there is no child corresponding to token KW_FOR
fn KW_FOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FOR, 0)
}

}

impl<'input> GrantOptionForContextAttrs<'input> for GrantOptionForContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn grantOptionFor(&mut self,)
	-> Result<Rc<GrantOptionForContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GrantOptionForContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 150, RULE_grantOptionFor);
        let mut _localctx: Rc<GrantOptionForContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1826);
			recog.base.match_token(KW_GRANT,&mut recog.err_handler)?;

			recog.base.set_state(1827);
			recog.base.match_token(KW_OPTION,&mut recog.err_handler)?;

			recog.base.set_state(1828);
			recog.base.match_token(KW_FOR,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- adminOptionFor ----------------
pub type AdminOptionForContextAll<'input> = AdminOptionForContext<'input>;


pub type AdminOptionForContext<'input> = BaseParserRuleContext<'input,AdminOptionForContextExt<'input>>;

#[derive(Clone)]
pub struct AdminOptionForContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AdminOptionForContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AdminOptionForContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_adminOptionFor(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_adminOptionFor(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AdminOptionForContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_adminOptionFor }
	//fn type_rule_index() -> usize where Self: Sized { RULE_adminOptionFor }
}
crate::tid!{AdminOptionForContextExt<'a>}

impl<'input> AdminOptionForContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AdminOptionForContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AdminOptionForContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AdminOptionForContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AdminOptionForContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ADMIN
/// Returns `None` if there is no child corresponding to token KW_ADMIN
fn KW_ADMIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ADMIN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OPTION
/// Returns `None` if there is no child corresponding to token KW_OPTION
fn KW_OPTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FOR
/// Returns `None` if there is no child corresponding to token KW_FOR
fn KW_FOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FOR, 0)
}

}

impl<'input> AdminOptionForContextAttrs<'input> for AdminOptionForContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn adminOptionFor(&mut self,)
	-> Result<Rc<AdminOptionForContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AdminOptionForContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 152, RULE_adminOptionFor);
        let mut _localctx: Rc<AdminOptionForContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1830);
			recog.base.match_token(KW_ADMIN,&mut recog.err_handler)?;

			recog.base.set_state(1831);
			recog.base.match_token(KW_OPTION,&mut recog.err_handler)?;

			recog.base.set_state(1832);
			recog.base.match_token(KW_FOR,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- withAdminOption ----------------
pub type WithAdminOptionContextAll<'input> = WithAdminOptionContext<'input>;


pub type WithAdminOptionContext<'input> = BaseParserRuleContext<'input,WithAdminOptionContextExt<'input>>;

#[derive(Clone)]
pub struct WithAdminOptionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for WithAdminOptionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for WithAdminOptionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_withAdminOption(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_withAdminOption(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for WithAdminOptionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_withAdminOption }
	//fn type_rule_index() -> usize where Self: Sized { RULE_withAdminOption }
}
crate::tid!{WithAdminOptionContextExt<'a>}

impl<'input> WithAdminOptionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WithAdminOptionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WithAdminOptionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WithAdminOptionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<WithAdminOptionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ADMIN
/// Returns `None` if there is no child corresponding to token KW_ADMIN
fn KW_ADMIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ADMIN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OPTION
/// Returns `None` if there is no child corresponding to token KW_OPTION
fn KW_OPTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OPTION, 0)
}

}

impl<'input> WithAdminOptionContextAttrs<'input> for WithAdminOptionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn withAdminOption(&mut self,)
	-> Result<Rc<WithAdminOptionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WithAdminOptionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 154, RULE_withAdminOption);
        let mut _localctx: Rc<WithAdminOptionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1834);
			recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

			recog.base.set_state(1835);
			recog.base.match_token(KW_ADMIN,&mut recog.err_handler)?;

			recog.base.set_state(1836);
			recog.base.match_token(KW_OPTION,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- metastoreCheck ----------------
pub type MetastoreCheckContextAll<'input> = MetastoreCheckContext<'input>;


pub type MetastoreCheckContext<'input> = BaseParserRuleContext<'input,MetastoreCheckContextExt<'input>>;

#[derive(Clone)]
pub struct MetastoreCheckContextExt<'input>{
	pub repair: Option<TokenType<'input>>,
	pub opt: Option<TokenType<'input>>,
	pub parts: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for MetastoreCheckContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for MetastoreCheckContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_metastoreCheck(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_metastoreCheck(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for MetastoreCheckContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_metastoreCheck }
	//fn type_rule_index() -> usize where Self: Sized { RULE_metastoreCheck }
}
crate::tid!{MetastoreCheckContextExt<'a>}

impl<'input> MetastoreCheckContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MetastoreCheckContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MetastoreCheckContextExt{
				repair: None, opt: None, parts: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MetastoreCheckContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<MetastoreCheckContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_MSCK
/// Returns `None` if there is no child corresponding to token KW_MSCK
fn KW_MSCK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MSCK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_REPAIR
/// Returns `None` if there is no child corresponding to token KW_REPAIR
fn KW_REPAIR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPAIR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PARTITIONS
/// Returns `None` if there is no child corresponding to token KW_PARTITIONS
fn KW_PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ADD
/// Returns `None` if there is no child corresponding to token KW_ADD
fn KW_ADD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SYNC
/// Returns `None` if there is no child corresponding to token KW_SYNC
fn KW_SYNC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SYNC, 0)
}
fn partitionSelectorSpec(&self) -> Option<Rc<PartitionSelectorSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MetastoreCheckContextAttrs<'input> for MetastoreCheckContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn metastoreCheck(&mut self,)
	-> Result<Rc<MetastoreCheckContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MetastoreCheckContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 156, RULE_metastoreCheck);
        let mut _localctx: Rc<MetastoreCheckContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1838);
			recog.base.match_token(KW_MSCK,&mut recog.err_handler)?;

			recog.base.set_state(1840);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_REPAIR {
				{
				recog.base.set_state(1839);
				let tmp = recog.base.match_token(KW_REPAIR,&mut recog.err_handler)?;
				 cast_mut::<_,MetastoreCheckContext >(&mut _localctx).repair = Some(tmp.clone());
				  

				}
			}

			{
			recog.base.set_state(1842);
			recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(1843);
			recog.tableName()?;

			recog.base.set_state(1849);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(128,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1844);
					 cast_mut::<_,MetastoreCheckContext >(&mut _localctx).opt = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==KW_ADD || _la==KW_DROP || _la==KW_SYNC) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,MetastoreCheckContext >(&mut _localctx).opt = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(1845);
					let tmp = recog.base.match_token(KW_PARTITIONS,&mut recog.err_handler)?;
					 cast_mut::<_,MetastoreCheckContext >(&mut _localctx).parts = Some(tmp.clone());
					  

					recog.base.set_state(1847);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(127,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule partitionSelectorSpec*/
							recog.base.set_state(1846);
							recog.partitionSelectorSpec()?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- resourceList ----------------
pub type ResourceListContextAll<'input> = ResourceListContext<'input>;


pub type ResourceListContext<'input> = BaseParserRuleContext<'input,ResourceListContextExt<'input>>;

#[derive(Clone)]
pub struct ResourceListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ResourceListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ResourceListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_resourceList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_resourceList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ResourceListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_resourceList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_resourceList }
}
crate::tid!{ResourceListContextExt<'a>}

impl<'input> ResourceListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ResourceListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ResourceListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ResourceListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ResourceListContextExt<'input>>{

fn resource_all(&self) ->  Vec<Rc<ResourceContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn resource(&self, i: usize) -> Option<Rc<ResourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ResourceListContextAttrs<'input> for ResourceListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn resourceList(&mut self,)
	-> Result<Rc<ResourceListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ResourceListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 158, RULE_resourceList);
        let mut _localctx: Rc<ResourceListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule resource*/
			recog.base.set_state(1851);
			recog.resource()?;

			recog.base.set_state(1856);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1852);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule resource*/
				recog.base.set_state(1853);
				recog.resource()?;

				}
				}
				recog.base.set_state(1858);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- resource ----------------
pub type ResourceContextAll<'input> = ResourceContext<'input>;


pub type ResourceContext<'input> = BaseParserRuleContext<'input,ResourceContextExt<'input>>;

#[derive(Clone)]
pub struct ResourceContextExt<'input>{
	pub resType: Option<Rc<ResourceTypeContextAll<'input>>>,
	pub resPath: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ResourceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ResourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_resource(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_resource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ResourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_resource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_resource }
}
crate::tid!{ResourceContextExt<'a>}

impl<'input> ResourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ResourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ResourceContextExt{
				resPath: None, 
				resType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ResourceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ResourceContextExt<'input>>{

fn resourceType(&self) -> Option<Rc<ResourceTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> ResourceContextAttrs<'input> for ResourceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn resource(&mut self,)
	-> Result<Rc<ResourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ResourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 160, RULE_resource);
        let mut _localctx: Rc<ResourceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule resourceType*/
			recog.base.set_state(1859);
			let tmp = recog.resourceType()?;
			 cast_mut::<_,ResourceContext >(&mut _localctx).resType = Some(tmp.clone());
			  

			recog.base.set_state(1860);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,ResourceContext >(&mut _localctx).resPath = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- resourceType ----------------
pub type ResourceTypeContextAll<'input> = ResourceTypeContext<'input>;


pub type ResourceTypeContext<'input> = BaseParserRuleContext<'input,ResourceTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ResourceTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ResourceTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ResourceTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_resourceType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_resourceType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ResourceTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_resourceType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_resourceType }
}
crate::tid!{ResourceTypeContextExt<'a>}

impl<'input> ResourceTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ResourceTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ResourceTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ResourceTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ResourceTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_JAR
/// Returns `None` if there is no child corresponding to token KW_JAR
fn KW_JAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_JAR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FILE
/// Returns `None` if there is no child corresponding to token KW_FILE
fn KW_FILE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FILE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ARCHIVE
/// Returns `None` if there is no child corresponding to token KW_ARCHIVE
fn KW_ARCHIVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ARCHIVE, 0)
}

}

impl<'input> ResourceTypeContextAttrs<'input> for ResourceTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn resourceType(&mut self,)
	-> Result<Rc<ResourceTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ResourceTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 162, RULE_resourceType);
        let mut _localctx: Rc<ResourceTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1862);
			_la = recog.base.input.la(1);
			if { !(_la==KW_ARCHIVE || _la==KW_FILE || _la==KW_JAR) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createFunctionStatement ----------------
pub type CreateFunctionStatementContextAll<'input> = CreateFunctionStatementContext<'input>;


pub type CreateFunctionStatementContext<'input> = BaseParserRuleContext<'input,CreateFunctionStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateFunctionStatementContextExt<'input>{
	pub temp: Option<TokenType<'input>>,
	pub rList: Option<Rc<ResourceListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateFunctionStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateFunctionStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createFunctionStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createFunctionStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateFunctionStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createFunctionStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createFunctionStatement }
}
crate::tid!{CreateFunctionStatementContextExt<'a>}

impl<'input> CreateFunctionStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateFunctionStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateFunctionStatementContextExt{
				temp: None, 
				rList: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateFunctionStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateFunctionStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FUNCTION
/// Returns `None` if there is no child corresponding to token KW_FUNCTION
fn KW_FUNCTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FUNCTION, 0)
}
fn functionIdentifier(&self) -> Option<Rc<FunctionIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_USING
/// Returns `None` if there is no child corresponding to token KW_USING
fn KW_USING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TEMPORARY
/// Returns `None` if there is no child corresponding to token KW_TEMPORARY
fn KW_TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TEMPORARY, 0)
}
fn resourceList(&self) -> Option<Rc<ResourceListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateFunctionStatementContextAttrs<'input> for CreateFunctionStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createFunctionStatement(&mut self,)
	-> Result<Rc<CreateFunctionStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateFunctionStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 164, RULE_createFunctionStatement);
        let mut _localctx: Rc<CreateFunctionStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1864);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(1866);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_TEMPORARY {
				{
				recog.base.set_state(1865);
				let tmp = recog.base.match_token(KW_TEMPORARY,&mut recog.err_handler)?;
				 cast_mut::<_,CreateFunctionStatementContext >(&mut _localctx).temp = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1868);
			recog.base.match_token(KW_FUNCTION,&mut recog.err_handler)?;

			/*InvokeRule functionIdentifier*/
			recog.base.set_state(1869);
			recog.functionIdentifier()?;

			recog.base.set_state(1870);
			recog.base.match_token(KW_AS,&mut recog.err_handler)?;

			recog.base.set_state(1871);
			recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

			recog.base.set_state(1874);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_USING {
				{
				recog.base.set_state(1872);
				recog.base.match_token(KW_USING,&mut recog.err_handler)?;

				/*InvokeRule resourceList*/
				recog.base.set_state(1873);
				let tmp = recog.resourceList()?;
				 cast_mut::<_,CreateFunctionStatementContext >(&mut _localctx).rList = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropFunctionStatement ----------------
pub type DropFunctionStatementContextAll<'input> = DropFunctionStatementContext<'input>;


pub type DropFunctionStatementContext<'input> = BaseParserRuleContext<'input,DropFunctionStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropFunctionStatementContextExt<'input>{
	pub temp: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropFunctionStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropFunctionStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropFunctionStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropFunctionStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropFunctionStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropFunctionStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropFunctionStatement }
}
crate::tid!{DropFunctionStatementContextExt<'a>}

impl<'input> DropFunctionStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropFunctionStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropFunctionStatementContextExt{
				temp: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DropFunctionStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropFunctionStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FUNCTION
/// Returns `None` if there is no child corresponding to token KW_FUNCTION
fn KW_FUNCTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FUNCTION, 0)
}
fn functionIdentifier(&self) -> Option<Rc<FunctionIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_TEMPORARY
/// Returns `None` if there is no child corresponding to token KW_TEMPORARY
fn KW_TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TEMPORARY, 0)
}

}

impl<'input> DropFunctionStatementContextAttrs<'input> for DropFunctionStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropFunctionStatement(&mut self,)
	-> Result<Rc<DropFunctionStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropFunctionStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 166, RULE_dropFunctionStatement);
        let mut _localctx: Rc<DropFunctionStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1876);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(1878);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_TEMPORARY {
				{
				recog.base.set_state(1877);
				let tmp = recog.base.match_token(KW_TEMPORARY,&mut recog.err_handler)?;
				 cast_mut::<_,DropFunctionStatementContext >(&mut _localctx).temp = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1880);
			recog.base.match_token(KW_FUNCTION,&mut recog.err_handler)?;

			recog.base.set_state(1882);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifExists*/
				recog.base.set_state(1881);
				recog.ifExists()?;

				}
			}

			/*InvokeRule functionIdentifier*/
			recog.base.set_state(1884);
			recog.functionIdentifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- reloadFunctionsStatement ----------------
pub type ReloadFunctionsStatementContextAll<'input> = ReloadFunctionsStatementContext<'input>;


pub type ReloadFunctionsStatementContext<'input> = BaseParserRuleContext<'input,ReloadFunctionsStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ReloadFunctionsStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ReloadFunctionsStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ReloadFunctionsStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_reloadFunctionsStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_reloadFunctionsStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ReloadFunctionsStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_reloadFunctionsStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_reloadFunctionsStatement }
}
crate::tid!{ReloadFunctionsStatementContextExt<'a>}

impl<'input> ReloadFunctionsStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReloadFunctionsStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReloadFunctionsStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ReloadFunctionsStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ReloadFunctionsStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_RELOAD
/// Returns `None` if there is no child corresponding to token KW_RELOAD
fn KW_RELOAD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RELOAD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FUNCTIONS
/// Returns `None` if there is no child corresponding to token KW_FUNCTIONS
fn KW_FUNCTIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FUNCTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FUNCTION
/// Returns `None` if there is no child corresponding to token KW_FUNCTION
fn KW_FUNCTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FUNCTION, 0)
}

}

impl<'input> ReloadFunctionsStatementContextAttrs<'input> for ReloadFunctionsStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn reloadFunctionsStatement(&mut self,)
	-> Result<Rc<ReloadFunctionsStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReloadFunctionsStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 168, RULE_reloadFunctionsStatement);
        let mut _localctx: Rc<ReloadFunctionsStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1886);
			recog.base.match_token(KW_RELOAD,&mut recog.err_handler)?;

			recog.base.set_state(1887);
			_la = recog.base.input.la(1);
			if { !(_la==KW_FUNCTION || _la==KW_FUNCTIONS) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createMacroStatement ----------------
pub type CreateMacroStatementContextAll<'input> = CreateMacroStatementContext<'input>;


pub type CreateMacroStatementContext<'input> = BaseParserRuleContext<'input,CreateMacroStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateMacroStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateMacroStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateMacroStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createMacroStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createMacroStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateMacroStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createMacroStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createMacroStatement }
}
crate::tid!{CreateMacroStatementContextExt<'a>}

impl<'input> CreateMacroStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateMacroStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateMacroStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateMacroStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateMacroStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TEMPORARY
/// Returns `None` if there is no child corresponding to token KW_TEMPORARY
fn KW_TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TEMPORARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MACRO
/// Returns `None` if there is no child corresponding to token KW_MACRO
fn KW_MACRO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MACRO, 0)
}
/// Retrieves first TerminalNode corresponding to token Identifier
/// Returns `None` if there is no child corresponding to token Identifier
fn Identifier(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Identifier, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnNameTypeList(&self) -> Option<Rc<ColumnNameTypeListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateMacroStatementContextAttrs<'input> for CreateMacroStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createMacroStatement(&mut self,)
	-> Result<Rc<CreateMacroStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateMacroStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 170, RULE_createMacroStatement);
        let mut _localctx: Rc<CreateMacroStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1889);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(1890);
			recog.base.match_token(KW_TEMPORARY,&mut recog.err_handler)?;

			recog.base.set_state(1891);
			recog.base.match_token(KW_MACRO,&mut recog.err_handler)?;

			recog.base.set_state(1892);
			recog.base.match_token(Identifier,&mut recog.err_handler)?;

			recog.base.set_state(1893);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(1895);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << KW_ABORT) | (1usize << KW_ACTIVATE) | (1usize << KW_ACTIVE) | (1usize << KW_ADD) | (1usize << KW_ADMIN) | (1usize << KW_AFTER) | (1usize << KW_ALLOC_FRACTION) | (1usize << KW_ANALYZE) | (1usize << KW_ARCHIVE) | (1usize << KW_ASC) | (1usize << KW_AST) | (1usize << KW_AT) | (1usize << KW_AUTOCOMMIT) | (1usize << KW_BATCH) | (1usize << KW_BEFORE) | (1usize << KW_BUCKET) | (1usize << KW_BUCKETS))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (KW_CACHE - 33)) | (1usize << (KW_CASCADE - 33)) | (1usize << (KW_CBO - 33)) | (1usize << (KW_CHANGE - 33)) | (1usize << (KW_CHECK - 33)) | (1usize << (KW_CLUSTER - 33)) | (1usize << (KW_CLUSTERED - 33)) | (1usize << (KW_CLUSTERSTATUS - 33)) | (1usize << (KW_COLLECTION - 33)) | (1usize << (KW_COLUMNS - 33)) | (1usize << (KW_COMMENT - 33)) | (1usize << (KW_COMPACT - 33)) | (1usize << (KW_COMPACTIONS - 33)) | (1usize << (KW_COMPUTE - 33)) | (1usize << (KW_CONCATENATE - 33)) | (1usize << (KW_CONTINUE - 33)) | (1usize << (KW_COST - 33)) | (1usize << (KW_CRON - 33)))) != 0) || ((((_la - 66)) & !0x3f) == 0 && ((1usize << (_la - 66)) & ((1usize << (KW_DATA - 66)) | (1usize << (KW_DATABASES - 66)) | (1usize << (KW_DATETIME - 66)) | (1usize << (KW_DAY - 66)) | (1usize << (KW_DAYOFWEEK - 66)) | (1usize << (KW_DBPROPERTIES - 66)) | (1usize << (KW_DCPROPERTIES - 66)) | (1usize << (KW_DEBUG - 66)) | (1usize << (KW_DEFAULT - 66)) | (1usize << (KW_DEFERRED - 66)) | (1usize << (KW_DEFINED - 66)) | (1usize << (KW_DELIMITED - 66)) | (1usize << (KW_DEPENDENCY - 66)) | (1usize << (KW_DESC - 66)) | (1usize << (KW_DETAIL - 66)) | (1usize << (KW_DIRECTORIES - 66)) | (1usize << (KW_DIRECTORY - 66)) | (1usize << (KW_DISABLE - 66)) | (1usize << (KW_DISTRIBUTE - 66)) | (1usize << (KW_DISTRIBUTED - 66)) | (1usize << (KW_DO - 66)))) != 0) || ((((_la - 98)) & !0x3f) == 0 && ((1usize << (_la - 98)) & ((1usize << (KW_DUMP - 98)) | (1usize << (KW_ELEM_TYPE - 98)) | (1usize << (KW_ENABLE - 98)) | (1usize << (KW_ENFORCED - 98)) | (1usize << (KW_ESCAPED - 98)) | (1usize << (KW_EVERY - 98)) | (1usize << (KW_EXCLUSIVE - 98)) | (1usize << (KW_EXECUTE - 98)) | (1usize << (KW_EXECUTED - 98)) | (1usize << (KW_EXPIRE_SNAPSHOTS - 98)) | (1usize << (KW_EXPLAIN - 98)) | (1usize << (KW_EXPORT - 98)) | (1usize << (KW_EXPRESSION - 98)) | (1usize << (KW_FIELDS - 98)) | (1usize << (KW_FILE - 98)) | (1usize << (KW_FILEFORMAT - 98)) | (1usize << (KW_FIRST - 98)))) != 0) || ((((_la - 131)) & !0x3f) == 0 && ((1usize << (_la - 131)) & ((1usize << (KW_FORMAT - 131)) | (1usize << (KW_FORMATTED - 131)) | (1usize << (KW_FUNCTIONS - 131)) | (1usize << (KW_HOLD_DDLTIME - 131)) | (1usize << (KW_HOUR - 131)) | (1usize << (KW_IDXPROPERTIES - 131)) | (1usize << (KW_IGNORE - 131)) | (1usize << (KW_INDEX - 131)) | (1usize << (KW_INDEXES - 131)) | (1usize << (KW_INPATH - 131)) | (1usize << (KW_INPUTDRIVER - 131)) | (1usize << (KW_INPUTFORMAT - 131)) | (1usize << (KW_ISOLATION - 131)) | (1usize << (KW_ITEMS - 131)) | (1usize << (KW_JAR - 131)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (KW_JOINCOST - 164)) | (1usize << (KW_KEY - 164)) | (1usize << (KW_KEYS - 164)) | (1usize << (KW_KEY_TYPE - 164)) | (1usize << (KW_KILL - 164)) | (1usize << (KW_LAST - 164)) | (1usize << (KW_LEVEL - 164)) | (1usize << (KW_LIMIT - 164)) | (1usize << (KW_LINES - 164)) | (1usize << (KW_LOAD - 164)) | (1usize << (KW_LOCATION - 164)) | (1usize << (KW_LOCK - 164)) | (1usize << (KW_LOCKS - 164)) | (1usize << (KW_LOGICAL - 164)) | (1usize << (KW_LONG - 164)) | (1usize << (KW_MANAGED - 164)) | (1usize << (KW_MANAGEDLOCATION - 164)) | (1usize << (KW_MANAGEMENT - 164)) | (1usize << (KW_MAPJOIN - 164)) | (1usize << (KW_MAPPING - 164)) | (1usize << (KW_MATCHED - 164)) | (1usize << (KW_MATERIALIZED - 164)) | (1usize << (KW_METADATA - 164)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (KW_MINUTE - 197)) | (1usize << (KW_MONTH - 197)) | (1usize << (KW_MOVE - 197)) | (1usize << (KW_MSCK - 197)) | (1usize << (KW_NORELY - 197)) | (1usize << (KW_NOSCAN - 197)) | (1usize << (KW_NOVALIDATE - 197)) | (1usize << (KW_NO_DROP - 197)) | (1usize << (KW_NULLS - 197)) | (1usize << (KW_OFFLINE - 197)) | (1usize << (KW_OFFSET - 197)) | (1usize << (KW_OPERATOR - 197)) | (1usize << (KW_OPTION - 197)) | (1usize << (KW_OUTPUTDRIVER - 197)) | (1usize << (KW_OUTPUTFORMAT - 197)) | (1usize << (KW_OVERWRITE - 197)) | (1usize << (KW_OWNER - 197)) | (1usize << (KW_PARTITIONED - 197)) | (1usize << (KW_PARTITIONS - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (KW_PATH - 229)) | (1usize << (KW_PLAN - 229)) | (1usize << (KW_PLANS - 229)) | (1usize << (KW_PLUS - 229)) | (1usize << (KW_POOL - 229)) | (1usize << (KW_PRINCIPALS - 229)) | (1usize << (KW_PROTECTION - 229)) | (1usize << (KW_PURGE - 229)) | (1usize << (KW_QUARTER - 229)) | (1usize << (KW_QUERY - 229)) | (1usize << (KW_QUERY_PARALLELISM - 229)) | (1usize << (KW_READ - 229)) | (1usize << (KW_READONLY - 229)) | (1usize << (KW_REBUILD - 229)) | (1usize << (KW_RECORDREADER - 229)) | (1usize << (KW_RECORDWRITER - 229)) | (1usize << (KW_RELOAD - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (KW_RELY - 261)) | (1usize << (KW_REMOTE - 261)) | (1usize << (KW_RENAME - 261)) | (1usize << (KW_REOPTIMIZATION - 261)) | (1usize << (KW_REPAIR - 261)) | (1usize << (KW_REPL - 261)) | (1usize << (KW_REPLACE - 261)) | (1usize << (KW_REPLICATION - 261)) | (1usize << (KW_RESOURCE - 261)) | (1usize << (KW_RESPECT - 261)) | (1usize << (KW_RESTRICT - 261)) | (1usize << (KW_REWRITE - 261)) | (1usize << (KW_ROLE - 261)) | (1usize << (KW_ROLES - 261)) | (1usize << (KW_SCHEDULED - 261)) | (1usize << (KW_SCHEDULING_POLICY - 261)) | (1usize << (KW_SCHEMA - 261)) | (1usize << (KW_SCHEMAS - 261)) | (1usize << (KW_SECOND - 261)) | (1usize << (KW_SEMI - 261)) | (1usize << (KW_SERDE - 261)) | (1usize << (KW_SERDEPROPERTIES - 261)) | (1usize << (KW_SERVER - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (KW_SETS - 293)) | (1usize << (KW_SET_CURRENT_SNAPSHOT - 293)) | (1usize << (KW_SHARED - 293)) | (1usize << (KW_SHOW - 293)) | (1usize << (KW_SHOW_DATABASE - 293)) | (1usize << (KW_SKEWED - 293)) | (1usize << (KW_SNAPSHOT - 293)) | (1usize << (KW_SORT - 293)) | (1usize << (KW_SORTED - 293)) | (1usize << (KW_SPEC - 293)) | (1usize << (KW_SSL - 293)) | (1usize << (KW_STATISTICS - 293)) | (1usize << (KW_STATUS - 293)) | (1usize << (KW_STORED - 293)) | (1usize << (KW_STREAMTABLE - 293)) | (1usize << (KW_STRING - 293)) | (1usize << (KW_STRUCT - 293)) | (1usize << (KW_SUMMARY - 293)) | (1usize << (KW_SYSTEM_TIME - 293)) | (1usize << (KW_SYSTEM_VERSION - 293)) | (1usize << (KW_TABLES - 293)) | (1usize << (KW_TBLPROPERTIES - 293)) | (1usize << (KW_TEMPORARY - 293)) | (1usize << (KW_TERMINATED - 293)))) != 0) || ((((_la - 327)) & !0x3f) == 0 && ((1usize << (_la - 327)) & ((1usize << (KW_TIMESTAMPTZ - 327)) | (1usize << (KW_TINYINT - 327)) | (1usize << (KW_TOUCH - 327)) | (1usize << (KW_TRANSACTION - 327)) | (1usize << (KW_TRANSACTIONAL - 327)) | (1usize << (KW_TRANSACTIONS - 327)) | (1usize << (KW_TRIM - 327)) | (1usize << (KW_TYPE - 327)) | (1usize << (KW_UNARCHIVE - 327)) | (1usize << (KW_UNDO - 327)) | (1usize << (KW_UNIONTYPE - 327)) | (1usize << (KW_UNKNOWN - 327)) | (1usize << (KW_UNLOCK - 327)) | (1usize << (KW_UNMANAGED - 327)) | (1usize << (KW_UNSET - 327)) | (1usize << (KW_UNSIGNED - 327)) | (1usize << (KW_URI - 327)) | (1usize << (KW_URL - 327)) | (1usize << (KW_USE - 327)))) != 0) || ((((_la - 359)) & !0x3f) == 0 && ((1usize << (_la - 359)) & ((1usize << (KW_UTC - 359)) | (1usize << (KW_UTCTIMESTAMP - 359)) | (1usize << (KW_VALIDATE - 359)) | (1usize << (KW_VALUE_TYPE - 359)) | (1usize << (KW_VECTORIZATION - 359)) | (1usize << (KW_VIEW - 359)) | (1usize << (KW_VIEWS - 359)) | (1usize << (KW_WAIT - 359)) | (1usize << (KW_WEEK - 359)) | (1usize << (KW_WHILE - 359)) | (1usize << (KW_WITHIN - 359)) | (1usize << (KW_WORK - 359)) | (1usize << (KW_WORKLOAD - 359)) | (1usize << (KW_WRITE - 359)) | (1usize << (KW_YEAR - 359)) | (1usize << (KW_ZONE - 359)))) != 0) || _la==Identifier {
				{
				/*InvokeRule columnNameTypeList*/
				recog.base.set_state(1894);
				recog.columnNameTypeList()?;

				}
			}

			recog.base.set_state(1897);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1898);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropMacroStatement ----------------
pub type DropMacroStatementContextAll<'input> = DropMacroStatementContext<'input>;


pub type DropMacroStatementContext<'input> = BaseParserRuleContext<'input,DropMacroStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropMacroStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropMacroStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropMacroStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropMacroStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropMacroStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropMacroStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropMacroStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropMacroStatement }
}
crate::tid!{DropMacroStatementContextExt<'a>}

impl<'input> DropMacroStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropMacroStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropMacroStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DropMacroStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropMacroStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TEMPORARY
/// Returns `None` if there is no child corresponding to token KW_TEMPORARY
fn KW_TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TEMPORARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MACRO
/// Returns `None` if there is no child corresponding to token KW_MACRO
fn KW_MACRO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MACRO, 0)
}
/// Retrieves first TerminalNode corresponding to token Identifier
/// Returns `None` if there is no child corresponding to token Identifier
fn Identifier(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Identifier, 0)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DropMacroStatementContextAttrs<'input> for DropMacroStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropMacroStatement(&mut self,)
	-> Result<Rc<DropMacroStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropMacroStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 172, RULE_dropMacroStatement);
        let mut _localctx: Rc<DropMacroStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1900);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(1901);
			recog.base.match_token(KW_TEMPORARY,&mut recog.err_handler)?;

			recog.base.set_state(1902);
			recog.base.match_token(KW_MACRO,&mut recog.err_handler)?;

			recog.base.set_state(1904);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifExists*/
				recog.base.set_state(1903);
				recog.ifExists()?;

				}
			}

			recog.base.set_state(1906);
			recog.base.match_token(Identifier,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createIndexStatement ----------------
pub type CreateIndexStatementContextAll<'input> = CreateIndexStatementContext<'input>;


pub type CreateIndexStatementContext<'input> = BaseParserRuleContext<'input,CreateIndexStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateIndexStatementContextExt<'input>{
	pub indextype: Option<TokenType<'input>>,
	pub locn: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateIndexStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateIndexStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createIndexStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createIndexStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateIndexStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createIndexStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createIndexStatement }
}
crate::tid!{CreateIndexStatementContextExt<'a>}

impl<'input> CreateIndexStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateIndexStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateIndexStatementContextExt{
				indextype: None, locn: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateIndexStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateIndexStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INDEX
/// Returns `None` if there is no child corresponding to token KW_INDEX
fn KW_INDEX(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INDEX, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_TABLE in current rule
fn KW_TABLE_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_TABLE, starting from 0.
/// Returns `None` if number of children corresponding to token KW_TABLE is less or equal than `i`.
fn KW_TABLE(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, i)
}
fn tableName_all(&self) ->  Vec<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn tableName(&self, i: usize) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn columnParenthesesList_all(&self) ->  Vec<Rc<ColumnParenthesesListContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnParenthesesList(&self, i: usize) -> Option<Rc<ColumnParenthesesListContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token StringLiteral in current rule
fn StringLiteral_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token StringLiteral, starting from 0.
/// Returns `None` if number of children corresponding to token StringLiteral is less or equal than `i`.
fn StringLiteral(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, i)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEFERRED
/// Returns `None` if there is no child corresponding to token KW_DEFERRED
fn KW_DEFERRED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEFERRED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REBUILD
/// Returns `None` if there is no child corresponding to token KW_REBUILD
fn KW_REBUILD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REBUILD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IDXPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_IDXPROPERTIES
fn KW_IDXPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IDXPROPERTIES, 0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_IN
/// Returns `None` if there is no child corresponding to token KW_IN
fn KW_IN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PARTITIONED
/// Returns `None` if there is no child corresponding to token KW_PARTITIONED
fn KW_PARTITIONED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITIONED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
fn tableFileFormat(&self) -> Option<Rc<TableFileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCATION
/// Returns `None` if there is no child corresponding to token KW_LOCATION
fn KW_LOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCATION, 0)
}
fn tablePropertiesPrefixed(&self) -> Option<Rc<TablePropertiesPrefixedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableComment(&self) -> Option<Rc<TableCommentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableRowFormat(&self) -> Option<Rc<TableRowFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateIndexStatementContextAttrs<'input> for CreateIndexStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createIndexStatement(&mut self,)
	-> Result<Rc<CreateIndexStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateIndexStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 174, RULE_createIndexStatement);
        let mut _localctx: Rc<CreateIndexStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1908);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(1909);
			recog.base.match_token(KW_INDEX,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(1910);
			recog.id_()?;

			recog.base.set_state(1911);
			recog.base.match_token(KW_ON,&mut recog.err_handler)?;

			recog.base.set_state(1912);
			recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(1913);
			recog.tableName()?;

			/*InvokeRule columnParenthesesList*/
			recog.base.set_state(1914);
			recog.columnParenthesesList()?;

			recog.base.set_state(1915);
			recog.base.match_token(KW_AS,&mut recog.err_handler)?;

			recog.base.set_state(1916);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,CreateIndexStatementContext >(&mut _localctx).indextype = Some(tmp.clone());
			  

			recog.base.set_state(1920);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(136,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1917);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					recog.base.set_state(1918);
					recog.base.match_token(KW_DEFERRED,&mut recog.err_handler)?;

					recog.base.set_state(1919);
					recog.base.match_token(KW_REBUILD,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			recog.base.set_state(1924);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IDXPROPERTIES {
				{
				recog.base.set_state(1922);
				recog.base.match_token(KW_IDXPROPERTIES,&mut recog.err_handler)?;

				/*InvokeRule tableProperties*/
				recog.base.set_state(1923);
				recog.tableProperties()?;

				}
			}

			recog.base.set_state(1929);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IN {
				{
				recog.base.set_state(1926);
				recog.base.match_token(KW_IN,&mut recog.err_handler)?;

				recog.base.set_state(1927);
				recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

				/*InvokeRule tableName*/
				recog.base.set_state(1928);
				recog.tableName()?;

				}
			}

			recog.base.set_state(1934);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PARTITIONED {
				{
				recog.base.set_state(1931);
				recog.base.match_token(KW_PARTITIONED,&mut recog.err_handler)?;

				recog.base.set_state(1932);
				recog.base.match_token(KW_BY,&mut recog.err_handler)?;

				/*InvokeRule columnParenthesesList*/
				recog.base.set_state(1933);
				recog.columnParenthesesList()?;

				}
			}

			recog.base.set_state(1940);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ROW || _la==KW_STORED {
				{
				recog.base.set_state(1937);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==KW_ROW {
					{
					/*InvokeRule tableRowFormat*/
					recog.base.set_state(1936);
					recog.tableRowFormat()?;

					}
				}

				/*InvokeRule tableFileFormat*/
				recog.base.set_state(1939);
				recog.tableFileFormat()?;

				}
			}

			recog.base.set_state(1944);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_LOCATION {
				{
				recog.base.set_state(1942);
				recog.base.match_token(KW_LOCATION,&mut recog.err_handler)?;

				recog.base.set_state(1943);
				let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
				 cast_mut::<_,CreateIndexStatementContext >(&mut _localctx).locn = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1947);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_TBLPROPERTIES {
				{
				/*InvokeRule tablePropertiesPrefixed*/
				recog.base.set_state(1946);
				recog.tablePropertiesPrefixed()?;

				}
			}

			recog.base.set_state(1950);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COMMENT {
				{
				/*InvokeRule tableComment*/
				recog.base.set_state(1949);
				recog.tableComment()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropIndexStatement ----------------
pub type DropIndexStatementContextAll<'input> = DropIndexStatementContext<'input>;


pub type DropIndexStatementContext<'input> = BaseParserRuleContext<'input,DropIndexStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropIndexStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropIndexStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropIndexStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropIndexStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropIndexStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropIndexStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropIndexStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropIndexStatement }
}
crate::tid!{DropIndexStatementContextExt<'a>}

impl<'input> DropIndexStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropIndexStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropIndexStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DropIndexStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropIndexStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INDEX
/// Returns `None` if there is no child corresponding to token KW_INDEX
fn KW_INDEX(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INDEX, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DropIndexStatementContextAttrs<'input> for DropIndexStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropIndexStatement(&mut self,)
	-> Result<Rc<DropIndexStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropIndexStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 176, RULE_dropIndexStatement);
        let mut _localctx: Rc<DropIndexStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1952);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(1953);
			recog.base.match_token(KW_INDEX,&mut recog.err_handler)?;

			recog.base.set_state(1955);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifExists*/
				recog.base.set_state(1954);
				recog.ifExists()?;

				}
			}

			/*InvokeRule id_*/
			recog.base.set_state(1957);
			recog.id_()?;

			recog.base.set_state(1958);
			recog.base.match_token(KW_ON,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(1959);
			recog.tableName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createViewStatement ----------------
pub type CreateViewStatementContextAll<'input> = CreateViewStatementContext<'input>;


pub type CreateViewStatementContext<'input> = BaseParserRuleContext<'input,CreateViewStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateViewStatementContextExt<'input>{
	pub name: Option<Rc<TableNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateViewStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateViewStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createViewStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createViewStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateViewStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createViewStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createViewStatement }
}
crate::tid!{CreateViewStatementContextExt<'a>}

impl<'input> CreateViewStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateViewStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateViewStatementContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateViewStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateViewStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VIEW
/// Returns `None` if there is no child corresponding to token KW_VIEW
fn KW_VIEW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VIEW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
fn selectStatementWithCTE(&self) -> Option<Rc<SelectStatementWithCTEContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orReplace(&self) -> Option<Rc<OrReplaceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifNotExists(&self) -> Option<Rc<IfNotExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnNameCommentList(&self) -> Option<Rc<ColumnNameCommentListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn tableComment(&self) -> Option<Rc<TableCommentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn viewPartition(&self) -> Option<Rc<ViewPartitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tablePropertiesPrefixed(&self) -> Option<Rc<TablePropertiesPrefixedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateViewStatementContextAttrs<'input> for CreateViewStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createViewStatement(&mut self,)
	-> Result<Rc<CreateViewStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateViewStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 178, RULE_createViewStatement);
        let mut _localctx: Rc<CreateViewStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1961);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(1963);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_OR {
				{
				/*InvokeRule orReplace*/
				recog.base.set_state(1962);
				recog.orReplace()?;

				}
			}

			recog.base.set_state(1965);
			recog.base.match_token(KW_VIEW,&mut recog.err_handler)?;

			recog.base.set_state(1967);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifNotExists*/
				recog.base.set_state(1966);
				recog.ifNotExists()?;

				}
			}

			/*InvokeRule tableName*/
			recog.base.set_state(1969);
			let tmp = recog.tableName()?;
			 cast_mut::<_,CreateViewStatementContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(1974);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LPAREN {
				{
				recog.base.set_state(1970);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				/*InvokeRule columnNameCommentList*/
				recog.base.set_state(1971);
				recog.columnNameCommentList()?;

				recog.base.set_state(1972);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(1977);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COMMENT {
				{
				/*InvokeRule tableComment*/
				recog.base.set_state(1976);
				recog.tableComment()?;

				}
			}

			recog.base.set_state(1980);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PARTITIONED {
				{
				/*InvokeRule viewPartition*/
				recog.base.set_state(1979);
				recog.viewPartition()?;

				}
			}

			recog.base.set_state(1983);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_TBLPROPERTIES {
				{
				/*InvokeRule tablePropertiesPrefixed*/
				recog.base.set_state(1982);
				recog.tablePropertiesPrefixed()?;

				}
			}

			recog.base.set_state(1985);
			recog.base.match_token(KW_AS,&mut recog.err_handler)?;

			/*InvokeRule selectStatementWithCTE*/
			recog.base.set_state(1986);
			recog.selectStatementWithCTE()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- viewPartition ----------------
pub type ViewPartitionContextAll<'input> = ViewPartitionContext<'input>;


pub type ViewPartitionContext<'input> = BaseParserRuleContext<'input,ViewPartitionContextExt<'input>>;

#[derive(Clone)]
pub struct ViewPartitionContextExt<'input>{
	pub spec: Option<Rc<PartitionTransformSpecContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ViewPartitionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ViewPartitionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_viewPartition(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_viewPartition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ViewPartitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_viewPartition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_viewPartition }
}
crate::tid!{ViewPartitionContextExt<'a>}

impl<'input> ViewPartitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ViewPartitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ViewPartitionContextExt{
				spec: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ViewPartitionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ViewPartitionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_PARTITIONED
/// Returns `None` if there is no child corresponding to token KW_PARTITIONED
fn KW_PARTITIONED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITIONED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_SPEC
/// Returns `None` if there is no child corresponding to token KW_SPEC
fn KW_SPEC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SPEC, 0)
}
fn partitionTransformSpec(&self) -> Option<Rc<PartitionTransformSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ViewPartitionContextAttrs<'input> for ViewPartitionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn viewPartition(&mut self,)
	-> Result<Rc<ViewPartitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ViewPartitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 180, RULE_viewPartition);
        let mut _localctx: Rc<ViewPartitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1988);
			recog.base.match_token(KW_PARTITIONED,&mut recog.err_handler)?;

			recog.base.set_state(1989);
			recog.base.match_token(KW_ON,&mut recog.err_handler)?;

			recog.base.set_state(1995);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 LPAREN 
				=> {
					{
					recog.base.set_state(1990);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule columnNameList*/
					recog.base.set_state(1991);
					recog.columnNameList()?;

					}
				}

			 KW_SPEC 
				=> {
					{
					recog.base.set_state(1992);
					recog.base.match_token(KW_SPEC,&mut recog.err_handler)?;

					recog.base.set_state(1993);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule partitionTransformSpec*/
					recog.base.set_state(1994);
					let tmp = recog.partitionTransformSpec()?;
					 cast_mut::<_,ViewPartitionContext >(&mut _localctx).spec = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(1997);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- viewOrganization ----------------
pub type ViewOrganizationContextAll<'input> = ViewOrganizationContext<'input>;


pub type ViewOrganizationContext<'input> = BaseParserRuleContext<'input,ViewOrganizationContextExt<'input>>;

#[derive(Clone)]
pub struct ViewOrganizationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ViewOrganizationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ViewOrganizationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_viewOrganization(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_viewOrganization(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ViewOrganizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_viewOrganization }
	//fn type_rule_index() -> usize where Self: Sized { RULE_viewOrganization }
}
crate::tid!{ViewOrganizationContextExt<'a>}

impl<'input> ViewOrganizationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ViewOrganizationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ViewOrganizationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ViewOrganizationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ViewOrganizationContextExt<'input>>{

fn viewClusterSpec(&self) -> Option<Rc<ViewClusterSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn viewComplexSpec(&self) -> Option<Rc<ViewComplexSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ViewOrganizationContextAttrs<'input> for ViewOrganizationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn viewOrganization(&mut self,)
	-> Result<Rc<ViewOrganizationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ViewOrganizationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 182, RULE_viewOrganization);
        let mut _localctx: Rc<ViewOrganizationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2001);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_CLUSTERED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule viewClusterSpec*/
					recog.base.set_state(1999);
					recog.viewClusterSpec()?;

					}
				}

			 KW_DISTRIBUTED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule viewComplexSpec*/
					recog.base.set_state(2000);
					recog.viewComplexSpec()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- viewClusterSpec ----------------
pub type ViewClusterSpecContextAll<'input> = ViewClusterSpecContext<'input>;


pub type ViewClusterSpecContext<'input> = BaseParserRuleContext<'input,ViewClusterSpecContextExt<'input>>;

#[derive(Clone)]
pub struct ViewClusterSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ViewClusterSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ViewClusterSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_viewClusterSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_viewClusterSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ViewClusterSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_viewClusterSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_viewClusterSpec }
}
crate::tid!{ViewClusterSpecContextExt<'a>}

impl<'input> ViewClusterSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ViewClusterSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ViewClusterSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ViewClusterSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ViewClusterSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CLUSTERED
/// Returns `None` if there is no child corresponding to token KW_CLUSTERED
fn KW_CLUSTERED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CLUSTERED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> ViewClusterSpecContextAttrs<'input> for ViewClusterSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn viewClusterSpec(&mut self,)
	-> Result<Rc<ViewClusterSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ViewClusterSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 184, RULE_viewClusterSpec);
        let mut _localctx: Rc<ViewClusterSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2003);
			recog.base.match_token(KW_CLUSTERED,&mut recog.err_handler)?;

			recog.base.set_state(2004);
			recog.base.match_token(KW_ON,&mut recog.err_handler)?;

			recog.base.set_state(2005);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnNameList*/
			recog.base.set_state(2006);
			recog.columnNameList()?;

			recog.base.set_state(2007);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- viewComplexSpec ----------------
pub type ViewComplexSpecContextAll<'input> = ViewComplexSpecContext<'input>;


pub type ViewComplexSpecContext<'input> = BaseParserRuleContext<'input,ViewComplexSpecContextExt<'input>>;

#[derive(Clone)]
pub struct ViewComplexSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ViewComplexSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ViewComplexSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_viewComplexSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_viewComplexSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ViewComplexSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_viewComplexSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_viewComplexSpec }
}
crate::tid!{ViewComplexSpecContextExt<'a>}

impl<'input> ViewComplexSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ViewComplexSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ViewComplexSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ViewComplexSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ViewComplexSpecContextExt<'input>>{

fn viewDistSpec(&self) -> Option<Rc<ViewDistSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn viewSortSpec(&self) -> Option<Rc<ViewSortSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ViewComplexSpecContextAttrs<'input> for ViewComplexSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn viewComplexSpec(&mut self,)
	-> Result<Rc<ViewComplexSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ViewComplexSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 186, RULE_viewComplexSpec);
        let mut _localctx: Rc<ViewComplexSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule viewDistSpec*/
			recog.base.set_state(2009);
			recog.viewDistSpec()?;

			/*InvokeRule viewSortSpec*/
			recog.base.set_state(2010);
			recog.viewSortSpec()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- viewDistSpec ----------------
pub type ViewDistSpecContextAll<'input> = ViewDistSpecContext<'input>;


pub type ViewDistSpecContext<'input> = BaseParserRuleContext<'input,ViewDistSpecContextExt<'input>>;

#[derive(Clone)]
pub struct ViewDistSpecContextExt<'input>{
	pub colList: Option<Rc<ColumnNameListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ViewDistSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ViewDistSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_viewDistSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_viewDistSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ViewDistSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_viewDistSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_viewDistSpec }
}
crate::tid!{ViewDistSpecContextExt<'a>}

impl<'input> ViewDistSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ViewDistSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ViewDistSpecContextExt{
				colList: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ViewDistSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ViewDistSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DISTRIBUTED
/// Returns `None` if there is no child corresponding to token KW_DISTRIBUTED
fn KW_DISTRIBUTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISTRIBUTED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ViewDistSpecContextAttrs<'input> for ViewDistSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn viewDistSpec(&mut self,)
	-> Result<Rc<ViewDistSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ViewDistSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 188, RULE_viewDistSpec);
        let mut _localctx: Rc<ViewDistSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2012);
			recog.base.match_token(KW_DISTRIBUTED,&mut recog.err_handler)?;

			recog.base.set_state(2013);
			recog.base.match_token(KW_ON,&mut recog.err_handler)?;

			recog.base.set_state(2014);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnNameList*/
			recog.base.set_state(2015);
			let tmp = recog.columnNameList()?;
			 cast_mut::<_,ViewDistSpecContext >(&mut _localctx).colList = Some(tmp.clone());
			  

			recog.base.set_state(2016);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- viewSortSpec ----------------
pub type ViewSortSpecContextAll<'input> = ViewSortSpecContext<'input>;


pub type ViewSortSpecContext<'input> = BaseParserRuleContext<'input,ViewSortSpecContextExt<'input>>;

#[derive(Clone)]
pub struct ViewSortSpecContextExt<'input>{
	pub colList: Option<Rc<ColumnNameListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ViewSortSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ViewSortSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_viewSortSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_viewSortSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ViewSortSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_viewSortSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_viewSortSpec }
}
crate::tid!{ViewSortSpecContextExt<'a>}

impl<'input> ViewSortSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ViewSortSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ViewSortSpecContextExt{
				colList: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ViewSortSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ViewSortSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SORTED
/// Returns `None` if there is no child corresponding to token KW_SORTED
fn KW_SORTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SORTED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ViewSortSpecContextAttrs<'input> for ViewSortSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn viewSortSpec(&mut self,)
	-> Result<Rc<ViewSortSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ViewSortSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 190, RULE_viewSortSpec);
        let mut _localctx: Rc<ViewSortSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2018);
			recog.base.match_token(KW_SORTED,&mut recog.err_handler)?;

			recog.base.set_state(2019);
			recog.base.match_token(KW_ON,&mut recog.err_handler)?;

			recog.base.set_state(2020);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnNameList*/
			recog.base.set_state(2021);
			let tmp = recog.columnNameList()?;
			 cast_mut::<_,ViewSortSpecContext >(&mut _localctx).colList = Some(tmp.clone());
			  

			recog.base.set_state(2022);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropViewStatement ----------------
pub type DropViewStatementContextAll<'input> = DropViewStatementContext<'input>;


pub type DropViewStatementContext<'input> = BaseParserRuleContext<'input,DropViewStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropViewStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropViewStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropViewStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropViewStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropViewStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropViewStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropViewStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropViewStatement }
}
crate::tid!{DropViewStatementContextExt<'a>}

impl<'input> DropViewStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropViewStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropViewStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DropViewStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropViewStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VIEW
/// Returns `None` if there is no child corresponding to token KW_VIEW
fn KW_VIEW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VIEW, 0)
}
fn viewName(&self) -> Option<Rc<ViewNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DropViewStatementContextAttrs<'input> for DropViewStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropViewStatement(&mut self,)
	-> Result<Rc<DropViewStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropViewStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 192, RULE_dropViewStatement);
        let mut _localctx: Rc<DropViewStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2024);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(2025);
			recog.base.match_token(KW_VIEW,&mut recog.err_handler)?;

			recog.base.set_state(2027);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifExists*/
				recog.base.set_state(2026);
				recog.ifExists()?;

				}
			}

			/*InvokeRule viewName*/
			recog.base.set_state(2029);
			recog.viewName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createMaterializedViewStatement ----------------
pub type CreateMaterializedViewStatementContextAll<'input> = CreateMaterializedViewStatementContext<'input>;


pub type CreateMaterializedViewStatementContext<'input> = BaseParserRuleContext<'input,CreateMaterializedViewStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateMaterializedViewStatementContextExt<'input>{
	pub name: Option<Rc<TableNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateMaterializedViewStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateMaterializedViewStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createMaterializedViewStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createMaterializedViewStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateMaterializedViewStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createMaterializedViewStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createMaterializedViewStatement }
}
crate::tid!{CreateMaterializedViewStatementContextExt<'a>}

impl<'input> CreateMaterializedViewStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateMaterializedViewStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateMaterializedViewStatementContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateMaterializedViewStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateMaterializedViewStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MATERIALIZED
/// Returns `None` if there is no child corresponding to token KW_MATERIALIZED
fn KW_MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VIEW
/// Returns `None` if there is no child corresponding to token KW_VIEW
fn KW_VIEW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VIEW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
fn selectStatementWithCTE(&self) -> Option<Rc<SelectStatementWithCTEContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifNotExists(&self) -> Option<Rc<IfNotExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn rewriteDisabled(&self) -> Option<Rc<RewriteDisabledContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableComment(&self) -> Option<Rc<TableCommentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn viewPartition(&self) -> Option<Rc<ViewPartitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn viewOrganization(&self) -> Option<Rc<ViewOrganizationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableRowFormat(&self) -> Option<Rc<TableRowFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableFileFormat(&self) -> Option<Rc<TableFileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableLocation(&self) -> Option<Rc<TableLocationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tablePropertiesPrefixed(&self) -> Option<Rc<TablePropertiesPrefixedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateMaterializedViewStatementContextAttrs<'input> for CreateMaterializedViewStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createMaterializedViewStatement(&mut self,)
	-> Result<Rc<CreateMaterializedViewStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateMaterializedViewStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 194, RULE_createMaterializedViewStatement);
        let mut _localctx: Rc<CreateMaterializedViewStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2031);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(2032);
			recog.base.match_token(KW_MATERIALIZED,&mut recog.err_handler)?;

			recog.base.set_state(2033);
			recog.base.match_token(KW_VIEW,&mut recog.err_handler)?;

			recog.base.set_state(2035);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifNotExists*/
				recog.base.set_state(2034);
				recog.ifNotExists()?;

				}
			}

			/*InvokeRule tableName*/
			recog.base.set_state(2037);
			let tmp = recog.tableName()?;
			 cast_mut::<_,CreateMaterializedViewStatementContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(2039);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_DISABLE {
				{
				/*InvokeRule rewriteDisabled*/
				recog.base.set_state(2038);
				recog.rewriteDisabled()?;

				}
			}

			recog.base.set_state(2042);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COMMENT {
				{
				/*InvokeRule tableComment*/
				recog.base.set_state(2041);
				recog.tableComment()?;

				}
			}

			recog.base.set_state(2045);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PARTITIONED {
				{
				/*InvokeRule viewPartition*/
				recog.base.set_state(2044);
				recog.viewPartition()?;

				}
			}

			recog.base.set_state(2048);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CLUSTERED || _la==KW_DISTRIBUTED {
				{
				/*InvokeRule viewOrganization*/
				recog.base.set_state(2047);
				recog.viewOrganization()?;

				}
			}

			recog.base.set_state(2051);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ROW {
				{
				/*InvokeRule tableRowFormat*/
				recog.base.set_state(2050);
				recog.tableRowFormat()?;

				}
			}

			recog.base.set_state(2054);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_STORED {
				{
				/*InvokeRule tableFileFormat*/
				recog.base.set_state(2053);
				recog.tableFileFormat()?;

				}
			}

			recog.base.set_state(2057);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_LOCATION {
				{
				/*InvokeRule tableLocation*/
				recog.base.set_state(2056);
				recog.tableLocation()?;

				}
			}

			recog.base.set_state(2060);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_TBLPROPERTIES {
				{
				/*InvokeRule tablePropertiesPrefixed*/
				recog.base.set_state(2059);
				recog.tablePropertiesPrefixed()?;

				}
			}

			recog.base.set_state(2062);
			recog.base.match_token(KW_AS,&mut recog.err_handler)?;

			/*InvokeRule selectStatementWithCTE*/
			recog.base.set_state(2063);
			recog.selectStatementWithCTE()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropMaterializedViewStatement ----------------
pub type DropMaterializedViewStatementContextAll<'input> = DropMaterializedViewStatementContext<'input>;


pub type DropMaterializedViewStatementContext<'input> = BaseParserRuleContext<'input,DropMaterializedViewStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropMaterializedViewStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropMaterializedViewStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropMaterializedViewStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropMaterializedViewStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropMaterializedViewStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropMaterializedViewStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropMaterializedViewStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropMaterializedViewStatement }
}
crate::tid!{DropMaterializedViewStatementContextExt<'a>}

impl<'input> DropMaterializedViewStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropMaterializedViewStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropMaterializedViewStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DropMaterializedViewStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropMaterializedViewStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MATERIALIZED
/// Returns `None` if there is no child corresponding to token KW_MATERIALIZED
fn KW_MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VIEW
/// Returns `None` if there is no child corresponding to token KW_VIEW
fn KW_VIEW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VIEW, 0)
}
fn viewName(&self) -> Option<Rc<ViewNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DropMaterializedViewStatementContextAttrs<'input> for DropMaterializedViewStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropMaterializedViewStatement(&mut self,)
	-> Result<Rc<DropMaterializedViewStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropMaterializedViewStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 196, RULE_dropMaterializedViewStatement);
        let mut _localctx: Rc<DropMaterializedViewStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2065);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(2066);
			recog.base.match_token(KW_MATERIALIZED,&mut recog.err_handler)?;

			recog.base.set_state(2067);
			recog.base.match_token(KW_VIEW,&mut recog.err_handler)?;

			recog.base.set_state(2069);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifExists*/
				recog.base.set_state(2068);
				recog.ifExists()?;

				}
			}

			/*InvokeRule viewName*/
			recog.base.set_state(2071);
			recog.viewName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createScheduledQueryStatement ----------------
pub type CreateScheduledQueryStatementContextAll<'input> = CreateScheduledQueryStatementContext<'input>;


pub type CreateScheduledQueryStatementContext<'input> = BaseParserRuleContext<'input,CreateScheduledQueryStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateScheduledQueryStatementContextExt<'input>{
	pub name: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateScheduledQueryStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateScheduledQueryStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createScheduledQueryStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createScheduledQueryStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateScheduledQueryStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createScheduledQueryStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createScheduledQueryStatement }
}
crate::tid!{CreateScheduledQueryStatementContextExt<'a>}

impl<'input> CreateScheduledQueryStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateScheduledQueryStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateScheduledQueryStatementContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateScheduledQueryStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateScheduledQueryStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SCHEDULED
/// Returns `None` if there is no child corresponding to token KW_SCHEDULED
fn KW_SCHEDULED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SCHEDULED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_QUERY
/// Returns `None` if there is no child corresponding to token KW_QUERY
fn KW_QUERY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUERY, 0)
}
fn scheduleSpec(&self) -> Option<Rc<ScheduleSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn definedAsSpec(&self) -> Option<Rc<DefinedAsSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn executedAsSpec(&self) -> Option<Rc<ExecutedAsSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn enableSpecification(&self) -> Option<Rc<EnableSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateScheduledQueryStatementContextAttrs<'input> for CreateScheduledQueryStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createScheduledQueryStatement(&mut self,)
	-> Result<Rc<CreateScheduledQueryStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateScheduledQueryStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 198, RULE_createScheduledQueryStatement);
        let mut _localctx: Rc<CreateScheduledQueryStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2073);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(2074);
			recog.base.match_token(KW_SCHEDULED,&mut recog.err_handler)?;

			recog.base.set_state(2075);
			recog.base.match_token(KW_QUERY,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(2076);
			let tmp = recog.id_()?;
			 cast_mut::<_,CreateScheduledQueryStatementContext >(&mut _localctx).name = Some(tmp.clone());
			  

			/*InvokeRule scheduleSpec*/
			recog.base.set_state(2077);
			recog.scheduleSpec()?;

			recog.base.set_state(2079);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_EXECUTED {
				{
				/*InvokeRule executedAsSpec*/
				recog.base.set_state(2078);
				recog.executedAsSpec()?;

				}
			}

			recog.base.set_state(2082);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_DISABLE || _la==KW_ENABLE {
				{
				/*InvokeRule enableSpecification*/
				recog.base.set_state(2081);
				recog.enableSpecification()?;

				}
			}

			/*InvokeRule definedAsSpec*/
			recog.base.set_state(2084);
			recog.definedAsSpec()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropScheduledQueryStatement ----------------
pub type DropScheduledQueryStatementContextAll<'input> = DropScheduledQueryStatementContext<'input>;


pub type DropScheduledQueryStatementContext<'input> = BaseParserRuleContext<'input,DropScheduledQueryStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropScheduledQueryStatementContextExt<'input>{
	pub name: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropScheduledQueryStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropScheduledQueryStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropScheduledQueryStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropScheduledQueryStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropScheduledQueryStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropScheduledQueryStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropScheduledQueryStatement }
}
crate::tid!{DropScheduledQueryStatementContextExt<'a>}

impl<'input> DropScheduledQueryStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropScheduledQueryStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropScheduledQueryStatementContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DropScheduledQueryStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropScheduledQueryStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SCHEDULED
/// Returns `None` if there is no child corresponding to token KW_SCHEDULED
fn KW_SCHEDULED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SCHEDULED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_QUERY
/// Returns `None` if there is no child corresponding to token KW_QUERY
fn KW_QUERY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUERY, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DropScheduledQueryStatementContextAttrs<'input> for DropScheduledQueryStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropScheduledQueryStatement(&mut self,)
	-> Result<Rc<DropScheduledQueryStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropScheduledQueryStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 200, RULE_dropScheduledQueryStatement);
        let mut _localctx: Rc<DropScheduledQueryStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2086);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(2087);
			recog.base.match_token(KW_SCHEDULED,&mut recog.err_handler)?;

			recog.base.set_state(2088);
			recog.base.match_token(KW_QUERY,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(2089);
			let tmp = recog.id_()?;
			 cast_mut::<_,DropScheduledQueryStatementContext >(&mut _localctx).name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterScheduledQueryStatement ----------------
pub type AlterScheduledQueryStatementContextAll<'input> = AlterScheduledQueryStatementContext<'input>;


pub type AlterScheduledQueryStatementContext<'input> = BaseParserRuleContext<'input,AlterScheduledQueryStatementContextExt<'input>>;

#[derive(Clone)]
pub struct AlterScheduledQueryStatementContextExt<'input>{
	pub name: Option<Rc<Id_ContextAll<'input>>>,
	pub r#mod: Option<Rc<AlterScheduledQueryChangeContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterScheduledQueryStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterScheduledQueryStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterScheduledQueryStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterScheduledQueryStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterScheduledQueryStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterScheduledQueryStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterScheduledQueryStatement }
}
crate::tid!{AlterScheduledQueryStatementContextExt<'a>}

impl<'input> AlterScheduledQueryStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterScheduledQueryStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterScheduledQueryStatementContextExt{
				name: None, r#mod: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterScheduledQueryStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterScheduledQueryStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ALTER
/// Returns `None` if there is no child corresponding to token KW_ALTER
fn KW_ALTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SCHEDULED
/// Returns `None` if there is no child corresponding to token KW_SCHEDULED
fn KW_SCHEDULED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SCHEDULED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_QUERY
/// Returns `None` if there is no child corresponding to token KW_QUERY
fn KW_QUERY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUERY, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterScheduledQueryChange(&self) -> Option<Rc<AlterScheduledQueryChangeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterScheduledQueryStatementContextAttrs<'input> for AlterScheduledQueryStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterScheduledQueryStatement(&mut self,)
	-> Result<Rc<AlterScheduledQueryStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterScheduledQueryStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 202, RULE_alterScheduledQueryStatement);
        let mut _localctx: Rc<AlterScheduledQueryStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2091);
			recog.base.match_token(KW_ALTER,&mut recog.err_handler)?;

			recog.base.set_state(2092);
			recog.base.match_token(KW_SCHEDULED,&mut recog.err_handler)?;

			recog.base.set_state(2093);
			recog.base.match_token(KW_QUERY,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(2094);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterScheduledQueryStatementContext >(&mut _localctx).name = Some(tmp.clone());
			  

			/*InvokeRule alterScheduledQueryChange*/
			recog.base.set_state(2095);
			let tmp = recog.alterScheduledQueryChange()?;
			 cast_mut::<_,AlterScheduledQueryStatementContext >(&mut _localctx).r#mod = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterScheduledQueryChange ----------------
pub type AlterScheduledQueryChangeContextAll<'input> = AlterScheduledQueryChangeContext<'input>;


pub type AlterScheduledQueryChangeContext<'input> = BaseParserRuleContext<'input,AlterScheduledQueryChangeContextExt<'input>>;

#[derive(Clone)]
pub struct AlterScheduledQueryChangeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterScheduledQueryChangeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterScheduledQueryChangeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterScheduledQueryChange(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterScheduledQueryChange(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterScheduledQueryChangeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterScheduledQueryChange }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterScheduledQueryChange }
}
crate::tid!{AlterScheduledQueryChangeContextExt<'a>}

impl<'input> AlterScheduledQueryChangeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterScheduledQueryChangeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterScheduledQueryChangeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterScheduledQueryChangeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterScheduledQueryChangeContextExt<'input>>{

fn scheduleSpec(&self) -> Option<Rc<ScheduleSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn executedAsSpec(&self) -> Option<Rc<ExecutedAsSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn enableSpecification(&self) -> Option<Rc<EnableSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn definedAsSpec(&self) -> Option<Rc<DefinedAsSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXECUTE
/// Returns `None` if there is no child corresponding to token KW_EXECUTE
fn KW_EXECUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXECUTE, 0)
}

}

impl<'input> AlterScheduledQueryChangeContextAttrs<'input> for AlterScheduledQueryChangeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterScheduledQueryChange(&mut self,)
	-> Result<Rc<AlterScheduledQueryChangeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterScheduledQueryChangeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 204, RULE_alterScheduledQueryChange);
        let mut _localctx: Rc<AlterScheduledQueryChangeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2102);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_CRON | KW_EVERY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule scheduleSpec*/
					recog.base.set_state(2097);
					recog.scheduleSpec()?;

					}
				}

			 KW_EXECUTED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule executedAsSpec*/
					recog.base.set_state(2098);
					recog.executedAsSpec()?;

					}
				}

			 KW_DISABLE | KW_ENABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule enableSpecification*/
					recog.base.set_state(2099);
					recog.enableSpecification()?;

					}
				}

			 KW_AS | KW_DEFINED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule definedAsSpec*/
					recog.base.set_state(2100);
					recog.definedAsSpec()?;

					}
				}

			 KW_EXECUTE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(2101);
					recog.base.match_token(KW_EXECUTE,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scheduleSpec ----------------
pub type ScheduleSpecContextAll<'input> = ScheduleSpecContext<'input>;


pub type ScheduleSpecContext<'input> = BaseParserRuleContext<'input,ScheduleSpecContextExt<'input>>;

#[derive(Clone)]
pub struct ScheduleSpecContextExt<'input>{
	pub cronString: Option<TokenType<'input>>,
	pub value: Option<TokenType<'input>>,
	pub qualifier: Option<Rc<IntervalQualifiersContextAll<'input>>>,
	pub offsetTs: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ScheduleSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ScheduleSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scheduleSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_scheduleSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ScheduleSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scheduleSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scheduleSpec }
}
crate::tid!{ScheduleSpecContextExt<'a>}

impl<'input> ScheduleSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScheduleSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScheduleSpecContextExt{
				cronString: None, value: None, offsetTs: None, 
				qualifier: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScheduleSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ScheduleSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CRON
/// Returns `None` if there is no child corresponding to token KW_CRON
fn KW_CRON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CRON, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EVERY
/// Returns `None` if there is no child corresponding to token KW_EVERY
fn KW_EVERY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EVERY, 0)
}
fn intervalQualifiers(&self) -> Option<Rc<IntervalQualifiersContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AT
/// Returns `None` if there is no child corresponding to token KW_AT
fn KW_AT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OFFSET
/// Returns `None` if there is no child corresponding to token KW_OFFSET
fn KW_OFFSET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OFFSET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}

}

impl<'input> ScheduleSpecContextAttrs<'input> for ScheduleSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scheduleSpec(&mut self,)
	-> Result<Rc<ScheduleSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScheduleSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 206, RULE_scheduleSpec);
        let mut _localctx: Rc<ScheduleSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2119);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_CRON 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2104);
					recog.base.match_token(KW_CRON,&mut recog.err_handler)?;

					recog.base.set_state(2105);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,ScheduleSpecContext >(&mut _localctx).cronString = Some(tmp.clone());
					  

					}
				}

			 KW_EVERY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2106);
					recog.base.match_token(KW_EVERY,&mut recog.err_handler)?;

					recog.base.set_state(2108);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==Number {
						{
						recog.base.set_state(2107);
						let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
						 cast_mut::<_,ScheduleSpecContext >(&mut _localctx).value = Some(tmp.clone());
						  

						}
					}

					/*InvokeRule intervalQualifiers*/
					recog.base.set_state(2110);
					let tmp = recog.intervalQualifiers()?;
					 cast_mut::<_,ScheduleSpecContext >(&mut _localctx).qualifier = Some(tmp.clone());
					  

					recog.base.set_state(2117);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_AT || _la==KW_OFFSET {
						{
						recog.base.set_state(2114);
						recog.err_handler.sync(&mut recog.base)?;
						match recog.base.input.la(1) {
						 KW_AT 
							=> {
								{
								recog.base.set_state(2111);
								recog.base.match_token(KW_AT,&mut recog.err_handler)?;

								}
							}

						 KW_OFFSET 
							=> {
								{
								recog.base.set_state(2112);
								recog.base.match_token(KW_OFFSET,&mut recog.err_handler)?;

								recog.base.set_state(2113);
								recog.base.match_token(KW_BY,&mut recog.err_handler)?;

								}
							}

							_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
						}
						recog.base.set_state(2116);
						let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
						 cast_mut::<_,ScheduleSpecContext >(&mut _localctx).offsetTs = Some(tmp.clone());
						  

						}
					}

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- executedAsSpec ----------------
pub type ExecutedAsSpecContextAll<'input> = ExecutedAsSpecContext<'input>;


pub type ExecutedAsSpecContext<'input> = BaseParserRuleContext<'input,ExecutedAsSpecContextExt<'input>>;

#[derive(Clone)]
pub struct ExecutedAsSpecContextExt<'input>{
	pub executedAs: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExecutedAsSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExecutedAsSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_executedAsSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_executedAsSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExecutedAsSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_executedAsSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_executedAsSpec }
}
crate::tid!{ExecutedAsSpecContextExt<'a>}

impl<'input> ExecutedAsSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExecutedAsSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExecutedAsSpecContextExt{
				executedAs: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExecutedAsSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExecutedAsSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_EXECUTED
/// Returns `None` if there is no child corresponding to token KW_EXECUTED
fn KW_EXECUTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXECUTED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> ExecutedAsSpecContextAttrs<'input> for ExecutedAsSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn executedAsSpec(&mut self,)
	-> Result<Rc<ExecutedAsSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExecutedAsSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 208, RULE_executedAsSpec);
        let mut _localctx: Rc<ExecutedAsSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2121);
			recog.base.match_token(KW_EXECUTED,&mut recog.err_handler)?;

			recog.base.set_state(2122);
			recog.base.match_token(KW_AS,&mut recog.err_handler)?;

			recog.base.set_state(2123);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,ExecutedAsSpecContext >(&mut _localctx).executedAs = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- definedAsSpec ----------------
pub type DefinedAsSpecContextAll<'input> = DefinedAsSpecContext<'input>;


pub type DefinedAsSpecContext<'input> = BaseParserRuleContext<'input,DefinedAsSpecContextExt<'input>>;

#[derive(Clone)]
pub struct DefinedAsSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DefinedAsSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DefinedAsSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_definedAsSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_definedAsSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DefinedAsSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_definedAsSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_definedAsSpec }
}
crate::tid!{DefinedAsSpecContextExt<'a>}

impl<'input> DefinedAsSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DefinedAsSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DefinedAsSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DefinedAsSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DefinedAsSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
fn statement(&self) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEFINED
/// Returns `None` if there is no child corresponding to token KW_DEFINED
fn KW_DEFINED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEFINED, 0)
}

}

impl<'input> DefinedAsSpecContextAttrs<'input> for DefinedAsSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn definedAsSpec(&mut self,)
	-> Result<Rc<DefinedAsSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DefinedAsSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 210, RULE_definedAsSpec);
        let mut _localctx: Rc<DefinedAsSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2126);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_DEFINED {
				{
				recog.base.set_state(2125);
				recog.base.match_token(KW_DEFINED,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(2128);
			recog.base.match_token(KW_AS,&mut recog.err_handler)?;

			/*InvokeRule statement*/
			recog.base.set_state(2129);
			recog.statement()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- showFunctionIdentifier ----------------
pub type ShowFunctionIdentifierContextAll<'input> = ShowFunctionIdentifierContext<'input>;


pub type ShowFunctionIdentifierContext<'input> = BaseParserRuleContext<'input,ShowFunctionIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct ShowFunctionIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ShowFunctionIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ShowFunctionIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_showFunctionIdentifier(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_showFunctionIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ShowFunctionIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_showFunctionIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_showFunctionIdentifier }
}
crate::tid!{ShowFunctionIdentifierContextExt<'a>}

impl<'input> ShowFunctionIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ShowFunctionIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ShowFunctionIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ShowFunctionIdentifierContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ShowFunctionIdentifierContextExt<'input>>{

fn functionIdentifier(&self) -> Option<Rc<FunctionIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> ShowFunctionIdentifierContextAttrs<'input> for ShowFunctionIdentifierContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn showFunctionIdentifier(&mut self,)
	-> Result<Rc<ShowFunctionIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ShowFunctionIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 212, RULE_showFunctionIdentifier);
        let mut _localctx: Rc<ShowFunctionIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2133);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT | KW_BATCH |
			 KW_BEFORE | KW_BUCKET | KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CBO |
			 KW_CHANGE | KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS |
			 KW_COLLECTION | KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS |
			 KW_COMPUTE | KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_DATA |
			 KW_DATABASES | KW_DATETIME | KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES |
			 KW_DCPROPERTIES | KW_DEBUG | KW_DEFAULT | KW_DEFERRED | KW_DEFINED |
			 KW_DELIMITED | KW_DEPENDENCY | KW_DESC | KW_DETAIL | KW_DIRECTORIES |
			 KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE | KW_DISTRIBUTED | KW_DO |
			 KW_DUMP | KW_ELEM_TYPE | KW_ENABLE | KW_ENFORCED | KW_ESCAPED | KW_EVERY |
			 KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED | KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN |
			 KW_EXPORT | KW_EXPRESSION | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST |
			 KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_HOLD_DDLTIME | KW_HOUR |
			 KW_IDXPROPERTIES | KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER |
			 KW_INPUTFORMAT | KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY |
			 KW_KEYS | KW_KEY_TYPE | KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES |
			 KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED |
			 KW_MANAGEDLOCATION | KW_MANAGEMENT | KW_MAPJOIN | KW_MAPPING | KW_MATCHED |
			 KW_MATERIALIZED | KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK |
			 KW_NORELY | KW_NOSCAN | KW_NOVALIDATE | KW_NO_DROP | KW_NULLS | KW_OFFLINE |
			 KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT |
			 KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH |
			 KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION |
			 KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY |
			 KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD | KW_RELY |
			 KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL | KW_REPLACE |
			 KW_REPLICATION | KW_RESOURCE | KW_RESPECT | KW_RESTRICT | KW_REWRITE |
			 KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY | KW_SCHEMA |
			 KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER |
			 KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW | KW_SHOW_DATABASE |
			 KW_SKEWED | KW_SNAPSHOT | KW_SORT | KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS |
			 KW_STATUS | KW_STORED | KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY |
			 KW_SYSTEM_TIME | KW_SYSTEM_VERSION | KW_TABLES | KW_TBLPROPERTIES | KW_TEMPORARY |
			 KW_TERMINATED | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH | KW_TRANSACTION |
			 KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TYPE | KW_UNARCHIVE |
			 KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK | KW_UNMANAGED | KW_UNSET |
			 KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC | KW_UTCTIMESTAMP | KW_VALIDATE |
			 KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW | KW_VIEWS | KW_WAIT | KW_WEEK |
			 KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD | KW_WRITE | KW_YEAR | KW_ZONE |
			 Identifier 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule functionIdentifier*/
					recog.base.set_state(2131);
					recog.functionIdentifier()?;

					}
				}

			 StringLiteral 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2132);
					recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- showStmtIdentifier ----------------
pub type ShowStmtIdentifierContextAll<'input> = ShowStmtIdentifierContext<'input>;


pub type ShowStmtIdentifierContext<'input> = BaseParserRuleContext<'input,ShowStmtIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct ShowStmtIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ShowStmtIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ShowStmtIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_showStmtIdentifier(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_showStmtIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ShowStmtIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_showStmtIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_showStmtIdentifier }
}
crate::tid!{ShowStmtIdentifierContextExt<'a>}

impl<'input> ShowStmtIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ShowStmtIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ShowStmtIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ShowStmtIdentifierContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ShowStmtIdentifierContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> ShowStmtIdentifierContextAttrs<'input> for ShowStmtIdentifierContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn showStmtIdentifier(&mut self,)
	-> Result<Rc<ShowStmtIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ShowStmtIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 214, RULE_showStmtIdentifier);
        let mut _localctx: Rc<ShowStmtIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2137);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT | KW_BATCH |
			 KW_BEFORE | KW_BUCKET | KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CBO |
			 KW_CHANGE | KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS |
			 KW_COLLECTION | KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS |
			 KW_COMPUTE | KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_DATA |
			 KW_DATABASES | KW_DATETIME | KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES |
			 KW_DCPROPERTIES | KW_DEBUG | KW_DEFAULT | KW_DEFERRED | KW_DEFINED |
			 KW_DELIMITED | KW_DEPENDENCY | KW_DESC | KW_DETAIL | KW_DIRECTORIES |
			 KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE | KW_DISTRIBUTED | KW_DO |
			 KW_DUMP | KW_ELEM_TYPE | KW_ENABLE | KW_ENFORCED | KW_ESCAPED | KW_EVERY |
			 KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED | KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN |
			 KW_EXPORT | KW_EXPRESSION | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST |
			 KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_HOLD_DDLTIME | KW_HOUR |
			 KW_IDXPROPERTIES | KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER |
			 KW_INPUTFORMAT | KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY |
			 KW_KEYS | KW_KEY_TYPE | KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES |
			 KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED |
			 KW_MANAGEDLOCATION | KW_MANAGEMENT | KW_MAPJOIN | KW_MAPPING | KW_MATCHED |
			 KW_MATERIALIZED | KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK |
			 KW_NORELY | KW_NOSCAN | KW_NOVALIDATE | KW_NO_DROP | KW_NULLS | KW_OFFLINE |
			 KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT |
			 KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH |
			 KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION |
			 KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY |
			 KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD | KW_RELY |
			 KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL | KW_REPLACE |
			 KW_REPLICATION | KW_RESOURCE | KW_RESPECT | KW_RESTRICT | KW_REWRITE |
			 KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY | KW_SCHEMA |
			 KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER |
			 KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW | KW_SHOW_DATABASE |
			 KW_SKEWED | KW_SNAPSHOT | KW_SORT | KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS |
			 KW_STATUS | KW_STORED | KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY |
			 KW_SYSTEM_TIME | KW_SYSTEM_VERSION | KW_TABLES | KW_TBLPROPERTIES | KW_TEMPORARY |
			 KW_TERMINATED | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH | KW_TRANSACTION |
			 KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TYPE | KW_UNARCHIVE |
			 KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK | KW_UNMANAGED | KW_UNSET |
			 KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC | KW_UTCTIMESTAMP | KW_VALIDATE |
			 KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW | KW_VIEWS | KW_WAIT | KW_WEEK |
			 KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD | KW_WRITE | KW_YEAR | KW_ZONE |
			 Identifier 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule id_*/
					recog.base.set_state(2135);
					recog.id_()?;

					}
				}

			 StringLiteral 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2136);
					recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableComment ----------------
pub type TableCommentContextAll<'input> = TableCommentContext<'input>;


pub type TableCommentContext<'input> = BaseParserRuleContext<'input,TableCommentContextExt<'input>>;

#[derive(Clone)]
pub struct TableCommentContextExt<'input>{
	pub comment: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableCommentContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableCommentContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableComment(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableComment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableCommentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableComment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableComment }
}
crate::tid!{TableCommentContextExt<'a>}

impl<'input> TableCommentContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableCommentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableCommentContextExt{
				comment: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableCommentContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableCommentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_COMMENT
/// Returns `None` if there is no child corresponding to token KW_COMMENT
fn KW_COMMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> TableCommentContextAttrs<'input> for TableCommentContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableComment(&mut self,)
	-> Result<Rc<TableCommentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableCommentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 216, RULE_tableComment);
        let mut _localctx: Rc<TableCommentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2139);
			recog.base.match_token(KW_COMMENT,&mut recog.err_handler)?;

			recog.base.set_state(2140);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,TableCommentContext >(&mut _localctx).comment = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createTablePartitionSpec ----------------
pub type CreateTablePartitionSpecContextAll<'input> = CreateTablePartitionSpecContext<'input>;


pub type CreateTablePartitionSpecContext<'input> = BaseParserRuleContext<'input,CreateTablePartitionSpecContextExt<'input>>;

#[derive(Clone)]
pub struct CreateTablePartitionSpecContextExt<'input>{
	pub opt1: Option<Rc<CreateTablePartitionColumnTypeSpecContextAll<'input>>>,
	pub opt2: Option<Rc<CreateTablePartitionColumnSpecContextAll<'input>>>,
	pub spec: Option<Rc<PartitionTransformSpecContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateTablePartitionSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateTablePartitionSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createTablePartitionSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createTablePartitionSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateTablePartitionSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createTablePartitionSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createTablePartitionSpec }
}
crate::tid!{CreateTablePartitionSpecContextExt<'a>}

impl<'input> CreateTablePartitionSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateTablePartitionSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateTablePartitionSpecContextExt{
				opt1: None, opt2: None, spec: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateTablePartitionSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateTablePartitionSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_PARTITIONED
/// Returns `None` if there is no child corresponding to token KW_PARTITIONED
fn KW_PARTITIONED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITIONED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SPEC
/// Returns `None` if there is no child corresponding to token KW_SPEC
fn KW_SPEC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SPEC, 0)
}
fn partitionTransformSpec(&self) -> Option<Rc<PartitionTransformSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createTablePartitionColumnTypeSpec(&self) -> Option<Rc<CreateTablePartitionColumnTypeSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createTablePartitionColumnSpec(&self) -> Option<Rc<CreateTablePartitionColumnSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateTablePartitionSpecContextAttrs<'input> for CreateTablePartitionSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createTablePartitionSpec(&mut self,)
	-> Result<Rc<CreateTablePartitionSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateTablePartitionSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 218, RULE_createTablePartitionSpec);
        let mut _localctx: Rc<CreateTablePartitionSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2142);
			recog.base.match_token(KW_PARTITIONED,&mut recog.err_handler)?;

			recog.base.set_state(2143);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			recog.base.set_state(2152);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 LPAREN 
				=> {
					{
					recog.base.set_state(2144);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2147);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(175,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule createTablePartitionColumnTypeSpec*/
							recog.base.set_state(2145);
							let tmp = recog.createTablePartitionColumnTypeSpec()?;
							 cast_mut::<_,CreateTablePartitionSpecContext >(&mut _localctx).opt1 = Some(tmp.clone());
							  

							}
						}
					,
						2 =>{
							{
							/*InvokeRule createTablePartitionColumnSpec*/
							recog.base.set_state(2146);
							let tmp = recog.createTablePartitionColumnSpec()?;
							 cast_mut::<_,CreateTablePartitionSpecContext >(&mut _localctx).opt2 = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					}
				}

			 KW_SPEC 
				=> {
					{
					recog.base.set_state(2149);
					recog.base.match_token(KW_SPEC,&mut recog.err_handler)?;

					recog.base.set_state(2150);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule partitionTransformSpec*/
					recog.base.set_state(2151);
					let tmp = recog.partitionTransformSpec()?;
					 cast_mut::<_,CreateTablePartitionSpecContext >(&mut _localctx).spec = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(2154);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createTablePartitionColumnTypeSpec ----------------
pub type CreateTablePartitionColumnTypeSpecContextAll<'input> = CreateTablePartitionColumnTypeSpecContext<'input>;


pub type CreateTablePartitionColumnTypeSpecContext<'input> = BaseParserRuleContext<'input,CreateTablePartitionColumnTypeSpecContextExt<'input>>;

#[derive(Clone)]
pub struct CreateTablePartitionColumnTypeSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateTablePartitionColumnTypeSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateTablePartitionColumnTypeSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createTablePartitionColumnTypeSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createTablePartitionColumnTypeSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateTablePartitionColumnTypeSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createTablePartitionColumnTypeSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createTablePartitionColumnTypeSpec }
}
crate::tid!{CreateTablePartitionColumnTypeSpecContextExt<'a>}

impl<'input> CreateTablePartitionColumnTypeSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateTablePartitionColumnTypeSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateTablePartitionColumnTypeSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateTablePartitionColumnTypeSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateTablePartitionColumnTypeSpecContextExt<'input>>{

fn columnNameTypeConstraint_all(&self) ->  Vec<Rc<ColumnNameTypeConstraintContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnNameTypeConstraint(&self, i: usize) -> Option<Rc<ColumnNameTypeConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> CreateTablePartitionColumnTypeSpecContextAttrs<'input> for CreateTablePartitionColumnTypeSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createTablePartitionColumnTypeSpec(&mut self,)
	-> Result<Rc<CreateTablePartitionColumnTypeSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateTablePartitionColumnTypeSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 220, RULE_createTablePartitionColumnTypeSpec);
        let mut _localctx: Rc<CreateTablePartitionColumnTypeSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnNameTypeConstraint*/
			recog.base.set_state(2156);
			recog.columnNameTypeConstraint()?;

			recog.base.set_state(2161);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2157);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnNameTypeConstraint*/
				recog.base.set_state(2158);
				recog.columnNameTypeConstraint()?;

				}
				}
				recog.base.set_state(2163);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createTablePartitionColumnSpec ----------------
pub type CreateTablePartitionColumnSpecContextAll<'input> = CreateTablePartitionColumnSpecContext<'input>;


pub type CreateTablePartitionColumnSpecContext<'input> = BaseParserRuleContext<'input,CreateTablePartitionColumnSpecContextExt<'input>>;

#[derive(Clone)]
pub struct CreateTablePartitionColumnSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateTablePartitionColumnSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateTablePartitionColumnSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createTablePartitionColumnSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createTablePartitionColumnSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateTablePartitionColumnSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createTablePartitionColumnSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createTablePartitionColumnSpec }
}
crate::tid!{CreateTablePartitionColumnSpecContextExt<'a>}

impl<'input> CreateTablePartitionColumnSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateTablePartitionColumnSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateTablePartitionColumnSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateTablePartitionColumnSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateTablePartitionColumnSpecContextExt<'input>>{

fn columnName_all(&self) ->  Vec<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnName(&self, i: usize) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> CreateTablePartitionColumnSpecContextAttrs<'input> for CreateTablePartitionColumnSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createTablePartitionColumnSpec(&mut self,)
	-> Result<Rc<CreateTablePartitionColumnSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateTablePartitionColumnSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 222, RULE_createTablePartitionColumnSpec);
        let mut _localctx: Rc<CreateTablePartitionColumnSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnName*/
			recog.base.set_state(2164);
			recog.columnName()?;

			recog.base.set_state(2169);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2165);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnName*/
				recog.base.set_state(2166);
				recog.columnName()?;

				}
				}
				recog.base.set_state(2171);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionTransformSpec ----------------
pub type PartitionTransformSpecContextAll<'input> = PartitionTransformSpecContext<'input>;


pub type PartitionTransformSpecContext<'input> = BaseParserRuleContext<'input,PartitionTransformSpecContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionTransformSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitionTransformSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitionTransformSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionTransformSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitionTransformSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitionTransformSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionTransformSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionTransformSpec }
}
crate::tid!{PartitionTransformSpecContextExt<'a>}

impl<'input> PartitionTransformSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionTransformSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionTransformSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionTransformSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitionTransformSpecContextExt<'input>>{

fn columnNameTransformConstraint_all(&self) ->  Vec<Rc<ColumnNameTransformConstraintContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnNameTransformConstraint(&self, i: usize) -> Option<Rc<ColumnNameTransformConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PartitionTransformSpecContextAttrs<'input> for PartitionTransformSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionTransformSpec(&mut self,)
	-> Result<Rc<PartitionTransformSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionTransformSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 224, RULE_partitionTransformSpec);
        let mut _localctx: Rc<PartitionTransformSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnNameTransformConstraint*/
			recog.base.set_state(2172);
			recog.columnNameTransformConstraint()?;

			recog.base.set_state(2177);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2173);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnNameTransformConstraint*/
				recog.base.set_state(2174);
				recog.columnNameTransformConstraint()?;

				}
				}
				recog.base.set_state(2179);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameTransformConstraint ----------------
pub type ColumnNameTransformConstraintContextAll<'input> = ColumnNameTransformConstraintContext<'input>;


pub type ColumnNameTransformConstraintContext<'input> = BaseParserRuleContext<'input,ColumnNameTransformConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameTransformConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameTransformConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameTransformConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameTransformConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameTransformConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameTransformConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameTransformConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameTransformConstraint }
}
crate::tid!{ColumnNameTransformConstraintContextExt<'a>}

impl<'input> ColumnNameTransformConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameTransformConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameTransformConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameTransformConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameTransformConstraintContextExt<'input>>{

fn partitionTransformType(&self) -> Option<Rc<PartitionTransformTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnNameTransformConstraintContextAttrs<'input> for ColumnNameTransformConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameTransformConstraint(&mut self,)
	-> Result<Rc<ColumnNameTransformConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameTransformConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 226, RULE_columnNameTransformConstraint);
        let mut _localctx: Rc<ColumnNameTransformConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule partitionTransformType*/
			recog.base.set_state(2180);
			recog.partitionTransformType()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionTransformType ----------------
pub type PartitionTransformTypeContextAll<'input> = PartitionTransformTypeContext<'input>;


pub type PartitionTransformTypeContext<'input> = BaseParserRuleContext<'input,PartitionTransformTypeContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionTransformTypeContextExt<'input>{
	pub value: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitionTransformTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitionTransformTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionTransformType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitionTransformType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitionTransformTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionTransformType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionTransformType }
}
crate::tid!{PartitionTransformTypeContextExt<'a>}

impl<'input> PartitionTransformTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionTransformTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionTransformTypeContextExt{
				value: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionTransformTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitionTransformTypeContextExt<'input>>{

fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_YEAR
/// Returns `None` if there is no child corresponding to token KW_YEAR
fn KW_YEAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MONTH
/// Returns `None` if there is no child corresponding to token KW_MONTH
fn KW_MONTH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DAY
/// Returns `None` if there is no child corresponding to token KW_DAY
fn KW_DAY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_HOUR
/// Returns `None` if there is no child corresponding to token KW_HOUR
fn KW_HOUR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRUNCATE
/// Returns `None` if there is no child corresponding to token KW_TRUNCATE
fn KW_TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRUNCATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BUCKET
/// Returns `None` if there is no child corresponding to token KW_BUCKET
fn KW_BUCKET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BUCKET, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}

}

impl<'input> PartitionTransformTypeContextAttrs<'input> for PartitionTransformTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionTransformType(&mut self,)
	-> Result<Rc<PartitionTransformTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionTransformTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 228, RULE_partitionTransformType);
        let mut _localctx: Rc<PartitionTransformTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2195);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(180,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule columnName*/
					recog.base.set_state(2182);
					recog.columnName()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2183);
					_la = recog.base.input.la(1);
					if { !(_la==KW_DAY || _la==KW_HOUR || _la==KW_MONTH || _la==KW_YEAR) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2184);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule columnName*/
					recog.base.set_state(2185);
					recog.columnName()?;

					recog.base.set_state(2186);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(2188);
					_la = recog.base.input.la(1);
					if { !(_la==KW_BUCKET || _la==KW_TRUNCATE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2189);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2190);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,PartitionTransformTypeContext >(&mut _localctx).value = Some(tmp.clone());
					  

					recog.base.set_state(2191);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule columnName*/
					recog.base.set_state(2192);
					recog.columnName()?;

					recog.base.set_state(2193);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableBuckets ----------------
pub type TableBucketsContextAll<'input> = TableBucketsContext<'input>;


pub type TableBucketsContext<'input> = BaseParserRuleContext<'input,TableBucketsContextExt<'input>>;

#[derive(Clone)]
pub struct TableBucketsContextExt<'input>{
	pub bucketCols: Option<Rc<ColumnNameListContextAll<'input>>>,
	pub sortCols: Option<Rc<ColumnNameOrderListContextAll<'input>>>,
	pub num: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableBucketsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableBucketsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableBuckets(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableBuckets(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableBucketsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableBuckets }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableBuckets }
}
crate::tid!{TableBucketsContextExt<'a>}

impl<'input> TableBucketsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableBucketsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableBucketsContextExt{
				num: None, 
				bucketCols: None, sortCols: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableBucketsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableBucketsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CLUSTERED
/// Returns `None` if there is no child corresponding to token KW_CLUSTERED
fn KW_CLUSTERED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CLUSTERED, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_BY in current rule
fn KW_BY_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_BY, starting from 0.
/// Returns `None` if number of children corresponding to token KW_BY is less or equal than `i`.
fn KW_BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
/// Retrieves first TerminalNode corresponding to token KW_INTO
/// Returns `None` if there is no child corresponding to token KW_INTO
fn KW_INTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INTO, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BUCKETS
/// Returns `None` if there is no child corresponding to token KW_BUCKETS
fn KW_BUCKETS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BUCKETS, 0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SORTED
/// Returns `None` if there is no child corresponding to token KW_SORTED
fn KW_SORTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SORTED, 0)
}
fn columnNameOrderList(&self) -> Option<Rc<ColumnNameOrderListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableBucketsContextAttrs<'input> for TableBucketsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableBuckets(&mut self,)
	-> Result<Rc<TableBucketsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableBucketsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 230, RULE_tableBuckets);
        let mut _localctx: Rc<TableBucketsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2197);
			recog.base.match_token(KW_CLUSTERED,&mut recog.err_handler)?;

			recog.base.set_state(2198);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			recog.base.set_state(2199);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnNameList*/
			recog.base.set_state(2200);
			let tmp = recog.columnNameList()?;
			 cast_mut::<_,TableBucketsContext >(&mut _localctx).bucketCols = Some(tmp.clone());
			  

			recog.base.set_state(2201);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2208);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_SORTED {
				{
				recog.base.set_state(2202);
				recog.base.match_token(KW_SORTED,&mut recog.err_handler)?;

				recog.base.set_state(2203);
				recog.base.match_token(KW_BY,&mut recog.err_handler)?;

				recog.base.set_state(2204);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				/*InvokeRule columnNameOrderList*/
				recog.base.set_state(2205);
				let tmp = recog.columnNameOrderList()?;
				 cast_mut::<_,TableBucketsContext >(&mut _localctx).sortCols = Some(tmp.clone());
				  

				recog.base.set_state(2206);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(2210);
			recog.base.match_token(KW_INTO,&mut recog.err_handler)?;

			recog.base.set_state(2211);
			let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
			 cast_mut::<_,TableBucketsContext >(&mut _localctx).num = Some(tmp.clone());
			  

			recog.base.set_state(2212);
			recog.base.match_token(KW_BUCKETS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableImplBuckets ----------------
pub type TableImplBucketsContextAll<'input> = TableImplBucketsContext<'input>;


pub type TableImplBucketsContext<'input> = BaseParserRuleContext<'input,TableImplBucketsContextExt<'input>>;

#[derive(Clone)]
pub struct TableImplBucketsContextExt<'input>{
	pub num: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableImplBucketsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableImplBucketsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableImplBuckets(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableImplBuckets(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableImplBucketsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableImplBuckets }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableImplBuckets }
}
crate::tid!{TableImplBucketsContextExt<'a>}

impl<'input> TableImplBucketsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableImplBucketsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableImplBucketsContextExt{
				num: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableImplBucketsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableImplBucketsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CLUSTERED
/// Returns `None` if there is no child corresponding to token KW_CLUSTERED
fn KW_CLUSTERED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CLUSTERED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INTO
/// Returns `None` if there is no child corresponding to token KW_INTO
fn KW_INTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INTO, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BUCKETS
/// Returns `None` if there is no child corresponding to token KW_BUCKETS
fn KW_BUCKETS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BUCKETS, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}

}

impl<'input> TableImplBucketsContextAttrs<'input> for TableImplBucketsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableImplBuckets(&mut self,)
	-> Result<Rc<TableImplBucketsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableImplBucketsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 232, RULE_tableImplBuckets);
        let mut _localctx: Rc<TableImplBucketsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2214);
			recog.base.match_token(KW_CLUSTERED,&mut recog.err_handler)?;

			recog.base.set_state(2215);
			recog.base.match_token(KW_INTO,&mut recog.err_handler)?;

			recog.base.set_state(2216);
			let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
			 cast_mut::<_,TableImplBucketsContext >(&mut _localctx).num = Some(tmp.clone());
			  

			recog.base.set_state(2217);
			recog.base.match_token(KW_BUCKETS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableSkewed ----------------
pub type TableSkewedContextAll<'input> = TableSkewedContext<'input>;


pub type TableSkewedContext<'input> = BaseParserRuleContext<'input,TableSkewedContextExt<'input>>;

#[derive(Clone)]
pub struct TableSkewedContextExt<'input>{
	pub skewedCols: Option<Rc<ColumnNameListContextAll<'input>>>,
	pub skewedValues: Option<Rc<SkewedValueElementContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableSkewedContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableSkewedContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableSkewed(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableSkewed(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableSkewedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableSkewed }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableSkewed }
}
crate::tid!{TableSkewedContextExt<'a>}

impl<'input> TableSkewedContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableSkewedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableSkewedContextExt{
				skewedCols: None, skewedValues: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableSkewedContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableSkewedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SKEWED
/// Returns `None` if there is no child corresponding to token KW_SKEWED
fn KW_SKEWED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SKEWED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn skewedValueElement(&self) -> Option<Rc<SkewedValueElementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn storedAsDirs(&self) -> Option<Rc<StoredAsDirsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableSkewedContextAttrs<'input> for TableSkewedContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableSkewed(&mut self,)
	-> Result<Rc<TableSkewedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableSkewedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 234, RULE_tableSkewed);
        let mut _localctx: Rc<TableSkewedContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2219);
			recog.base.match_token(KW_SKEWED,&mut recog.err_handler)?;

			recog.base.set_state(2220);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			recog.base.set_state(2221);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnNameList*/
			recog.base.set_state(2222);
			let tmp = recog.columnNameList()?;
			 cast_mut::<_,TableSkewedContext >(&mut _localctx).skewedCols = Some(tmp.clone());
			  

			recog.base.set_state(2223);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2224);
			recog.base.match_token(KW_ON,&mut recog.err_handler)?;

			recog.base.set_state(2225);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule skewedValueElement*/
			recog.base.set_state(2226);
			let tmp = recog.skewedValueElement()?;
			 cast_mut::<_,TableSkewedContext >(&mut _localctx).skewedValues = Some(tmp.clone());
			  

			recog.base.set_state(2227);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2229);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(182,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule storedAsDirs*/
					recog.base.set_state(2228);
					recog.storedAsDirs()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowFormat ----------------
pub type RowFormatContextAll<'input> = RowFormatContext<'input>;


pub type RowFormatContext<'input> = BaseParserRuleContext<'input,RowFormatContextExt<'input>>;

#[derive(Clone)]
pub struct RowFormatContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RowFormatContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RowFormatContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowFormat(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rowFormat(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RowFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowFormat }
}
crate::tid!{RowFormatContextExt<'a>}

impl<'input> RowFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowFormatContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowFormatContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RowFormatContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RowFormatContextExt<'input>>{

fn rowFormatSerde(&self) -> Option<Rc<RowFormatSerdeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn rowFormatDelimited(&self) -> Option<Rc<RowFormatDelimitedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RowFormatContextAttrs<'input> for RowFormatContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowFormat(&mut self,)
	-> Result<Rc<RowFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 236, RULE_rowFormat);
        let mut _localctx: Rc<RowFormatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2233);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(183,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule rowFormatSerde*/
					recog.base.set_state(2231);
					recog.rowFormatSerde()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule rowFormatDelimited*/
					recog.base.set_state(2232);
					recog.rowFormatDelimited()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- recordReader ----------------
pub type RecordReaderContextAll<'input> = RecordReaderContext<'input>;


pub type RecordReaderContext<'input> = BaseParserRuleContext<'input,RecordReaderContextExt<'input>>;

#[derive(Clone)]
pub struct RecordReaderContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RecordReaderContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RecordReaderContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_recordReader(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_recordReader(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RecordReaderContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_recordReader }
	//fn type_rule_index() -> usize where Self: Sized { RULE_recordReader }
}
crate::tid!{RecordReaderContextExt<'a>}

impl<'input> RecordReaderContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RecordReaderContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RecordReaderContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RecordReaderContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RecordReaderContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_RECORDREADER
/// Returns `None` if there is no child corresponding to token KW_RECORDREADER
fn KW_RECORDREADER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RECORDREADER, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> RecordReaderContextAttrs<'input> for RecordReaderContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn recordReader(&mut self,)
	-> Result<Rc<RecordReaderContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RecordReaderContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 238, RULE_recordReader);
        let mut _localctx: Rc<RecordReaderContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2235);
			recog.base.match_token(KW_RECORDREADER,&mut recog.err_handler)?;

			recog.base.set_state(2236);
			recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- recordWriter ----------------
pub type RecordWriterContextAll<'input> = RecordWriterContext<'input>;


pub type RecordWriterContext<'input> = BaseParserRuleContext<'input,RecordWriterContextExt<'input>>;

#[derive(Clone)]
pub struct RecordWriterContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RecordWriterContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RecordWriterContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_recordWriter(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_recordWriter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RecordWriterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_recordWriter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_recordWriter }
}
crate::tid!{RecordWriterContextExt<'a>}

impl<'input> RecordWriterContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RecordWriterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RecordWriterContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RecordWriterContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RecordWriterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_RECORDWRITER
/// Returns `None` if there is no child corresponding to token KW_RECORDWRITER
fn KW_RECORDWRITER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RECORDWRITER, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> RecordWriterContextAttrs<'input> for RecordWriterContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn recordWriter(&mut self,)
	-> Result<Rc<RecordWriterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RecordWriterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 240, RULE_recordWriter);
        let mut _localctx: Rc<RecordWriterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2238);
			recog.base.match_token(KW_RECORDWRITER,&mut recog.err_handler)?;

			recog.base.set_state(2239);
			recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowFormatSerde ----------------
pub type RowFormatSerdeContextAll<'input> = RowFormatSerdeContext<'input>;


pub type RowFormatSerdeContext<'input> = BaseParserRuleContext<'input,RowFormatSerdeContextExt<'input>>;

#[derive(Clone)]
pub struct RowFormatSerdeContextExt<'input>{
	pub name: Option<TokenType<'input>>,
	pub serdeprops: Option<Rc<TablePropertiesContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RowFormatSerdeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RowFormatSerdeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowFormatSerde(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rowFormatSerde(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RowFormatSerdeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowFormatSerde }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowFormatSerde }
}
crate::tid!{RowFormatSerdeContextExt<'a>}

impl<'input> RowFormatSerdeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowFormatSerdeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowFormatSerdeContextExt{
				name: None, 
				serdeprops: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RowFormatSerdeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RowFormatSerdeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ROW
/// Returns `None` if there is no child corresponding to token KW_ROW
fn KW_ROW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FORMAT
/// Returns `None` if there is no child corresponding to token KW_FORMAT
fn KW_FORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERDE
/// Returns `None` if there is no child corresponding to token KW_SERDE
fn KW_SERDE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERDE, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_SERDEPROPERTIES
fn KW_SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERDEPROPERTIES, 0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RowFormatSerdeContextAttrs<'input> for RowFormatSerdeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowFormatSerde(&mut self,)
	-> Result<Rc<RowFormatSerdeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowFormatSerdeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 242, RULE_rowFormatSerde);
        let mut _localctx: Rc<RowFormatSerdeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2241);
			recog.base.match_token(KW_ROW,&mut recog.err_handler)?;

			recog.base.set_state(2242);
			recog.base.match_token(KW_FORMAT,&mut recog.err_handler)?;

			recog.base.set_state(2243);
			recog.base.match_token(KW_SERDE,&mut recog.err_handler)?;

			recog.base.set_state(2244);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,RowFormatSerdeContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(2248);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(184,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2245);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					recog.base.set_state(2246);
					recog.base.match_token(KW_SERDEPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule tableProperties*/
					recog.base.set_state(2247);
					let tmp = recog.tableProperties()?;
					 cast_mut::<_,RowFormatSerdeContext >(&mut _localctx).serdeprops = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowFormatDelimited ----------------
pub type RowFormatDelimitedContextAll<'input> = RowFormatDelimitedContext<'input>;


pub type RowFormatDelimitedContext<'input> = BaseParserRuleContext<'input,RowFormatDelimitedContextExt<'input>>;

#[derive(Clone)]
pub struct RowFormatDelimitedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RowFormatDelimitedContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RowFormatDelimitedContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowFormatDelimited(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rowFormatDelimited(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RowFormatDelimitedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowFormatDelimited }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowFormatDelimited }
}
crate::tid!{RowFormatDelimitedContextExt<'a>}

impl<'input> RowFormatDelimitedContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowFormatDelimitedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowFormatDelimitedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RowFormatDelimitedContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RowFormatDelimitedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ROW
/// Returns `None` if there is no child corresponding to token KW_ROW
fn KW_ROW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FORMAT
/// Returns `None` if there is no child corresponding to token KW_FORMAT
fn KW_FORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DELIMITED
/// Returns `None` if there is no child corresponding to token KW_DELIMITED
fn KW_DELIMITED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DELIMITED, 0)
}
fn tableRowFormatFieldIdentifier(&self) -> Option<Rc<TableRowFormatFieldIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableRowFormatCollItemsIdentifier(&self) -> Option<Rc<TableRowFormatCollItemsIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableRowFormatMapKeysIdentifier(&self) -> Option<Rc<TableRowFormatMapKeysIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableRowFormatLinesIdentifier(&self) -> Option<Rc<TableRowFormatLinesIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableRowNullFormat(&self) -> Option<Rc<TableRowNullFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RowFormatDelimitedContextAttrs<'input> for RowFormatDelimitedContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowFormatDelimited(&mut self,)
	-> Result<Rc<RowFormatDelimitedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowFormatDelimitedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 244, RULE_rowFormatDelimited);
        let mut _localctx: Rc<RowFormatDelimitedContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2250);
			recog.base.match_token(KW_ROW,&mut recog.err_handler)?;

			recog.base.set_state(2251);
			recog.base.match_token(KW_FORMAT,&mut recog.err_handler)?;

			recog.base.set_state(2252);
			recog.base.match_token(KW_DELIMITED,&mut recog.err_handler)?;

			recog.base.set_state(2254);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_FIELDS {
				{
				/*InvokeRule tableRowFormatFieldIdentifier*/
				recog.base.set_state(2253);
				recog.tableRowFormatFieldIdentifier()?;

				}
			}

			recog.base.set_state(2257);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COLLECTION {
				{
				/*InvokeRule tableRowFormatCollItemsIdentifier*/
				recog.base.set_state(2256);
				recog.tableRowFormatCollItemsIdentifier()?;

				}
			}

			recog.base.set_state(2260);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(187,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule tableRowFormatMapKeysIdentifier*/
					recog.base.set_state(2259);
					recog.tableRowFormatMapKeysIdentifier()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(2263);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_LINES {
				{
				/*InvokeRule tableRowFormatLinesIdentifier*/
				recog.base.set_state(2262);
				recog.tableRowFormatLinesIdentifier()?;

				}
			}

			recog.base.set_state(2266);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_NULL {
				{
				/*InvokeRule tableRowNullFormat*/
				recog.base.set_state(2265);
				recog.tableRowNullFormat()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableRowFormat ----------------
pub type TableRowFormatContextAll<'input> = TableRowFormatContext<'input>;


pub type TableRowFormatContext<'input> = BaseParserRuleContext<'input,TableRowFormatContextExt<'input>>;

#[derive(Clone)]
pub struct TableRowFormatContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableRowFormatContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableRowFormatContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableRowFormat(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableRowFormat(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableRowFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableRowFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableRowFormat }
}
crate::tid!{TableRowFormatContextExt<'a>}

impl<'input> TableRowFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableRowFormatContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableRowFormatContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableRowFormatContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableRowFormatContextExt<'input>>{

fn rowFormatDelimited(&self) -> Option<Rc<RowFormatDelimitedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn rowFormatSerde(&self) -> Option<Rc<RowFormatSerdeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableRowFormatContextAttrs<'input> for TableRowFormatContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableRowFormat(&mut self,)
	-> Result<Rc<TableRowFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableRowFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 246, RULE_tableRowFormat);
        let mut _localctx: Rc<TableRowFormatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2270);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(190,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule rowFormatDelimited*/
					recog.base.set_state(2268);
					recog.rowFormatDelimited()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule rowFormatSerde*/
					recog.base.set_state(2269);
					recog.rowFormatSerde()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tablePropertiesPrefixed ----------------
pub type TablePropertiesPrefixedContextAll<'input> = TablePropertiesPrefixedContext<'input>;


pub type TablePropertiesPrefixedContext<'input> = BaseParserRuleContext<'input,TablePropertiesPrefixedContextExt<'input>>;

#[derive(Clone)]
pub struct TablePropertiesPrefixedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TablePropertiesPrefixedContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TablePropertiesPrefixedContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tablePropertiesPrefixed(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tablePropertiesPrefixed(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TablePropertiesPrefixedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tablePropertiesPrefixed }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tablePropertiesPrefixed }
}
crate::tid!{TablePropertiesPrefixedContextExt<'a>}

impl<'input> TablePropertiesPrefixedContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TablePropertiesPrefixedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TablePropertiesPrefixedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TablePropertiesPrefixedContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TablePropertiesPrefixedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TBLPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_TBLPROPERTIES
fn KW_TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TBLPROPERTIES, 0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TablePropertiesPrefixedContextAttrs<'input> for TablePropertiesPrefixedContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tablePropertiesPrefixed(&mut self,)
	-> Result<Rc<TablePropertiesPrefixedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TablePropertiesPrefixedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 248, RULE_tablePropertiesPrefixed);
        let mut _localctx: Rc<TablePropertiesPrefixedContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2272);
			recog.base.match_token(KW_TBLPROPERTIES,&mut recog.err_handler)?;

			/*InvokeRule tableProperties*/
			recog.base.set_state(2273);
			recog.tableProperties()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableProperties ----------------
pub type TablePropertiesContextAll<'input> = TablePropertiesContext<'input>;


pub type TablePropertiesContext<'input> = BaseParserRuleContext<'input,TablePropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct TablePropertiesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TablePropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TablePropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableProperties(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableProperties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TablePropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableProperties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableProperties }
}
crate::tid!{TablePropertiesContextExt<'a>}

impl<'input> TablePropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TablePropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TablePropertiesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TablePropertiesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TablePropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn tablePropertiesList(&self) -> Option<Rc<TablePropertiesListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> TablePropertiesContextAttrs<'input> for TablePropertiesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableProperties(&mut self,)
	-> Result<Rc<TablePropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TablePropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 250, RULE_tableProperties);
        let mut _localctx: Rc<TablePropertiesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2275);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule tablePropertiesList*/
			recog.base.set_state(2276);
			recog.tablePropertiesList()?;

			recog.base.set_state(2277);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tablePropertiesList ----------------
pub type TablePropertiesListContextAll<'input> = TablePropertiesListContext<'input>;


pub type TablePropertiesListContext<'input> = BaseParserRuleContext<'input,TablePropertiesListContextExt<'input>>;

#[derive(Clone)]
pub struct TablePropertiesListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TablePropertiesListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TablePropertiesListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tablePropertiesList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tablePropertiesList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TablePropertiesListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tablePropertiesList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tablePropertiesList }
}
crate::tid!{TablePropertiesListContextExt<'a>}

impl<'input> TablePropertiesListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TablePropertiesListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TablePropertiesListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TablePropertiesListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TablePropertiesListContextExt<'input>>{

fn keyValueProperty_all(&self) ->  Vec<Rc<KeyValuePropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn keyValueProperty(&self, i: usize) -> Option<Rc<KeyValuePropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn keyProperty_all(&self) ->  Vec<Rc<KeyPropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn keyProperty(&self, i: usize) -> Option<Rc<KeyPropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> TablePropertiesListContextAttrs<'input> for TablePropertiesListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tablePropertiesList(&mut self,)
	-> Result<Rc<TablePropertiesListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TablePropertiesListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 252, RULE_tablePropertiesList);
        let mut _localctx: Rc<TablePropertiesListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2295);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(193,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule keyValueProperty*/
					recog.base.set_state(2279);
					recog.keyValueProperty()?;

					recog.base.set_state(2284);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2280);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule keyValueProperty*/
						recog.base.set_state(2281);
						recog.keyValueProperty()?;

						}
						}
						recog.base.set_state(2286);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule keyProperty*/
					recog.base.set_state(2287);
					recog.keyProperty()?;

					recog.base.set_state(2292);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2288);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule keyProperty*/
						recog.base.set_state(2289);
						recog.keyProperty()?;

						}
						}
						recog.base.set_state(2294);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- keyValueProperty ----------------
pub type KeyValuePropertyContextAll<'input> = KeyValuePropertyContext<'input>;


pub type KeyValuePropertyContext<'input> = BaseParserRuleContext<'input,KeyValuePropertyContextExt<'input>>;

#[derive(Clone)]
pub struct KeyValuePropertyContextExt<'input>{
	pub key: Option<TokenType<'input>>,
	pub value: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for KeyValuePropertyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for KeyValuePropertyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_keyValueProperty(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_keyValueProperty(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for KeyValuePropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_keyValueProperty }
	//fn type_rule_index() -> usize where Self: Sized { RULE_keyValueProperty }
}
crate::tid!{KeyValuePropertyContextExt<'a>}

impl<'input> KeyValuePropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<KeyValuePropertyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,KeyValuePropertyContextExt{
				key: None, value: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait KeyValuePropertyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<KeyValuePropertyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token StringLiteral in current rule
fn StringLiteral_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token StringLiteral, starting from 0.
/// Returns `None` if number of children corresponding to token StringLiteral is less or equal than `i`.
fn StringLiteral(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, i)
}

}

impl<'input> KeyValuePropertyContextAttrs<'input> for KeyValuePropertyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn keyValueProperty(&mut self,)
	-> Result<Rc<KeyValuePropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = KeyValuePropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 254, RULE_keyValueProperty);
        let mut _localctx: Rc<KeyValuePropertyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2297);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,KeyValuePropertyContext >(&mut _localctx).key = Some(tmp.clone());
			  

			recog.base.set_state(2298);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(2299);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,KeyValuePropertyContext >(&mut _localctx).value = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- keyProperty ----------------
pub type KeyPropertyContextAll<'input> = KeyPropertyContext<'input>;


pub type KeyPropertyContext<'input> = BaseParserRuleContext<'input,KeyPropertyContextExt<'input>>;

#[derive(Clone)]
pub struct KeyPropertyContextExt<'input>{
	pub key: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for KeyPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for KeyPropertyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_keyProperty(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_keyProperty(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for KeyPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_keyProperty }
	//fn type_rule_index() -> usize where Self: Sized { RULE_keyProperty }
}
crate::tid!{KeyPropertyContextExt<'a>}

impl<'input> KeyPropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<KeyPropertyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,KeyPropertyContextExt{
				key: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait KeyPropertyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<KeyPropertyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> KeyPropertyContextAttrs<'input> for KeyPropertyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn keyProperty(&mut self,)
	-> Result<Rc<KeyPropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = KeyPropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 256, RULE_keyProperty);
        let mut _localctx: Rc<KeyPropertyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2301);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,KeyPropertyContext >(&mut _localctx).key = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableRowFormatFieldIdentifier ----------------
pub type TableRowFormatFieldIdentifierContextAll<'input> = TableRowFormatFieldIdentifierContext<'input>;


pub type TableRowFormatFieldIdentifierContext<'input> = BaseParserRuleContext<'input,TableRowFormatFieldIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct TableRowFormatFieldIdentifierContextExt<'input>{
	pub fldIdnt: Option<TokenType<'input>>,
	pub fldEscape: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableRowFormatFieldIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableRowFormatFieldIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableRowFormatFieldIdentifier(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableRowFormatFieldIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableRowFormatFieldIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableRowFormatFieldIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableRowFormatFieldIdentifier }
}
crate::tid!{TableRowFormatFieldIdentifierContextExt<'a>}

impl<'input> TableRowFormatFieldIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableRowFormatFieldIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableRowFormatFieldIdentifierContextExt{
				fldIdnt: None, fldEscape: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableRowFormatFieldIdentifierContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableRowFormatFieldIdentifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_FIELDS
/// Returns `None` if there is no child corresponding to token KW_FIELDS
fn KW_FIELDS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FIELDS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TERMINATED
/// Returns `None` if there is no child corresponding to token KW_TERMINATED
fn KW_TERMINATED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TERMINATED, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_BY in current rule
fn KW_BY_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_BY, starting from 0.
/// Returns `None` if number of children corresponding to token KW_BY is less or equal than `i`.
fn KW_BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token StringLiteral in current rule
fn StringLiteral_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token StringLiteral, starting from 0.
/// Returns `None` if number of children corresponding to token StringLiteral is less or equal than `i`.
fn StringLiteral(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, i)
}
/// Retrieves first TerminalNode corresponding to token KW_ESCAPED
/// Returns `None` if there is no child corresponding to token KW_ESCAPED
fn KW_ESCAPED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ESCAPED, 0)
}

}

impl<'input> TableRowFormatFieldIdentifierContextAttrs<'input> for TableRowFormatFieldIdentifierContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableRowFormatFieldIdentifier(&mut self,)
	-> Result<Rc<TableRowFormatFieldIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableRowFormatFieldIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 258, RULE_tableRowFormatFieldIdentifier);
        let mut _localctx: Rc<TableRowFormatFieldIdentifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2303);
			recog.base.match_token(KW_FIELDS,&mut recog.err_handler)?;

			recog.base.set_state(2304);
			recog.base.match_token(KW_TERMINATED,&mut recog.err_handler)?;

			recog.base.set_state(2305);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			recog.base.set_state(2306);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,TableRowFormatFieldIdentifierContext >(&mut _localctx).fldIdnt = Some(tmp.clone());
			  

			recog.base.set_state(2310);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ESCAPED {
				{
				recog.base.set_state(2307);
				recog.base.match_token(KW_ESCAPED,&mut recog.err_handler)?;

				recog.base.set_state(2308);
				recog.base.match_token(KW_BY,&mut recog.err_handler)?;

				recog.base.set_state(2309);
				let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
				 cast_mut::<_,TableRowFormatFieldIdentifierContext >(&mut _localctx).fldEscape = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableRowFormatCollItemsIdentifier ----------------
pub type TableRowFormatCollItemsIdentifierContextAll<'input> = TableRowFormatCollItemsIdentifierContext<'input>;


pub type TableRowFormatCollItemsIdentifierContext<'input> = BaseParserRuleContext<'input,TableRowFormatCollItemsIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct TableRowFormatCollItemsIdentifierContextExt<'input>{
	pub collIdnt: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableRowFormatCollItemsIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableRowFormatCollItemsIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableRowFormatCollItemsIdentifier(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableRowFormatCollItemsIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableRowFormatCollItemsIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableRowFormatCollItemsIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableRowFormatCollItemsIdentifier }
}
crate::tid!{TableRowFormatCollItemsIdentifierContextExt<'a>}

impl<'input> TableRowFormatCollItemsIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableRowFormatCollItemsIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableRowFormatCollItemsIdentifierContextExt{
				collIdnt: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableRowFormatCollItemsIdentifierContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableRowFormatCollItemsIdentifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_COLLECTION
/// Returns `None` if there is no child corresponding to token KW_COLLECTION
fn KW_COLLECTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLLECTION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ITEMS
/// Returns `None` if there is no child corresponding to token KW_ITEMS
fn KW_ITEMS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ITEMS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TERMINATED
/// Returns `None` if there is no child corresponding to token KW_TERMINATED
fn KW_TERMINATED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TERMINATED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> TableRowFormatCollItemsIdentifierContextAttrs<'input> for TableRowFormatCollItemsIdentifierContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableRowFormatCollItemsIdentifier(&mut self,)
	-> Result<Rc<TableRowFormatCollItemsIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableRowFormatCollItemsIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 260, RULE_tableRowFormatCollItemsIdentifier);
        let mut _localctx: Rc<TableRowFormatCollItemsIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2312);
			recog.base.match_token(KW_COLLECTION,&mut recog.err_handler)?;

			recog.base.set_state(2313);
			recog.base.match_token(KW_ITEMS,&mut recog.err_handler)?;

			recog.base.set_state(2314);
			recog.base.match_token(KW_TERMINATED,&mut recog.err_handler)?;

			recog.base.set_state(2315);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			recog.base.set_state(2316);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,TableRowFormatCollItemsIdentifierContext >(&mut _localctx).collIdnt = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableRowFormatMapKeysIdentifier ----------------
pub type TableRowFormatMapKeysIdentifierContextAll<'input> = TableRowFormatMapKeysIdentifierContext<'input>;


pub type TableRowFormatMapKeysIdentifierContext<'input> = BaseParserRuleContext<'input,TableRowFormatMapKeysIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct TableRowFormatMapKeysIdentifierContextExt<'input>{
	pub mapKeysIdnt: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableRowFormatMapKeysIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableRowFormatMapKeysIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableRowFormatMapKeysIdentifier(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableRowFormatMapKeysIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableRowFormatMapKeysIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableRowFormatMapKeysIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableRowFormatMapKeysIdentifier }
}
crate::tid!{TableRowFormatMapKeysIdentifierContextExt<'a>}

impl<'input> TableRowFormatMapKeysIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableRowFormatMapKeysIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableRowFormatMapKeysIdentifierContextExt{
				mapKeysIdnt: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableRowFormatMapKeysIdentifierContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableRowFormatMapKeysIdentifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_MAP
/// Returns `None` if there is no child corresponding to token KW_MAP
fn KW_MAP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_KEYS
/// Returns `None` if there is no child corresponding to token KW_KEYS
fn KW_KEYS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KEYS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TERMINATED
/// Returns `None` if there is no child corresponding to token KW_TERMINATED
fn KW_TERMINATED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TERMINATED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> TableRowFormatMapKeysIdentifierContextAttrs<'input> for TableRowFormatMapKeysIdentifierContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableRowFormatMapKeysIdentifier(&mut self,)
	-> Result<Rc<TableRowFormatMapKeysIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableRowFormatMapKeysIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 262, RULE_tableRowFormatMapKeysIdentifier);
        let mut _localctx: Rc<TableRowFormatMapKeysIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2318);
			recog.base.match_token(KW_MAP,&mut recog.err_handler)?;

			recog.base.set_state(2319);
			recog.base.match_token(KW_KEYS,&mut recog.err_handler)?;

			recog.base.set_state(2320);
			recog.base.match_token(KW_TERMINATED,&mut recog.err_handler)?;

			recog.base.set_state(2321);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			recog.base.set_state(2322);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,TableRowFormatMapKeysIdentifierContext >(&mut _localctx).mapKeysIdnt = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableRowFormatLinesIdentifier ----------------
pub type TableRowFormatLinesIdentifierContextAll<'input> = TableRowFormatLinesIdentifierContext<'input>;


pub type TableRowFormatLinesIdentifierContext<'input> = BaseParserRuleContext<'input,TableRowFormatLinesIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct TableRowFormatLinesIdentifierContextExt<'input>{
	pub linesIdnt: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableRowFormatLinesIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableRowFormatLinesIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableRowFormatLinesIdentifier(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableRowFormatLinesIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableRowFormatLinesIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableRowFormatLinesIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableRowFormatLinesIdentifier }
}
crate::tid!{TableRowFormatLinesIdentifierContextExt<'a>}

impl<'input> TableRowFormatLinesIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableRowFormatLinesIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableRowFormatLinesIdentifierContextExt{
				linesIdnt: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableRowFormatLinesIdentifierContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableRowFormatLinesIdentifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LINES
/// Returns `None` if there is no child corresponding to token KW_LINES
fn KW_LINES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LINES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TERMINATED
/// Returns `None` if there is no child corresponding to token KW_TERMINATED
fn KW_TERMINATED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TERMINATED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> TableRowFormatLinesIdentifierContextAttrs<'input> for TableRowFormatLinesIdentifierContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableRowFormatLinesIdentifier(&mut self,)
	-> Result<Rc<TableRowFormatLinesIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableRowFormatLinesIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 264, RULE_tableRowFormatLinesIdentifier);
        let mut _localctx: Rc<TableRowFormatLinesIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2324);
			recog.base.match_token(KW_LINES,&mut recog.err_handler)?;

			recog.base.set_state(2325);
			recog.base.match_token(KW_TERMINATED,&mut recog.err_handler)?;

			recog.base.set_state(2326);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			recog.base.set_state(2327);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,TableRowFormatLinesIdentifierContext >(&mut _localctx).linesIdnt = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableRowNullFormat ----------------
pub type TableRowNullFormatContextAll<'input> = TableRowNullFormatContext<'input>;


pub type TableRowNullFormatContext<'input> = BaseParserRuleContext<'input,TableRowNullFormatContextExt<'input>>;

#[derive(Clone)]
pub struct TableRowNullFormatContextExt<'input>{
	pub nullIdnt: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableRowNullFormatContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableRowNullFormatContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableRowNullFormat(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableRowNullFormat(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableRowNullFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableRowNullFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableRowNullFormat }
}
crate::tid!{TableRowNullFormatContextExt<'a>}

impl<'input> TableRowNullFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableRowNullFormatContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableRowNullFormatContextExt{
				nullIdnt: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableRowNullFormatContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableRowNullFormatContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_NULL
/// Returns `None` if there is no child corresponding to token KW_NULL
fn KW_NULL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEFINED
/// Returns `None` if there is no child corresponding to token KW_DEFINED
fn KW_DEFINED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEFINED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> TableRowNullFormatContextAttrs<'input> for TableRowNullFormatContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableRowNullFormat(&mut self,)
	-> Result<Rc<TableRowNullFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableRowNullFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 266, RULE_tableRowNullFormat);
        let mut _localctx: Rc<TableRowNullFormatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2329);
			recog.base.match_token(KW_NULL,&mut recog.err_handler)?;

			recog.base.set_state(2330);
			recog.base.match_token(KW_DEFINED,&mut recog.err_handler)?;

			recog.base.set_state(2331);
			recog.base.match_token(KW_AS,&mut recog.err_handler)?;

			recog.base.set_state(2332);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,TableRowNullFormatContext >(&mut _localctx).nullIdnt = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableFileFormat ----------------
pub type TableFileFormatContextAll<'input> = TableFileFormatContext<'input>;


pub type TableFileFormatContext<'input> = BaseParserRuleContext<'input,TableFileFormatContextExt<'input>>;

#[derive(Clone)]
pub struct TableFileFormatContextExt<'input>{
	pub inFmt: Option<TokenType<'input>>,
	pub outFmt: Option<TokenType<'input>>,
	pub inDriver: Option<TokenType<'input>>,
	pub outDriver: Option<TokenType<'input>>,
	pub storageHandler: Option<TokenType<'input>>,
	pub serdeprops: Option<Rc<TablePropertiesContextAll<'input>>>,
	pub fileformat: Option<Rc<Id_ContextAll<'input>>>,
	pub genericSpec: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableFileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableFileFormatContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableFileFormat(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableFileFormat(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableFileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableFileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableFileFormat }
}
crate::tid!{TableFileFormatContextExt<'a>}

impl<'input> TableFileFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableFileFormatContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableFileFormatContextExt{
				inFmt: None, outFmt: None, inDriver: None, outDriver: None, storageHandler: None, 
				serdeprops: None, fileformat: None, genericSpec: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableFileFormatContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableFileFormatContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token KW_STORED in current rule
fn KW_STORED_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_STORED, starting from 0.
/// Returns `None` if number of children corresponding to token KW_STORED is less or equal than `i`.
fn KW_STORED(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STORED, i)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INPUTFORMAT
/// Returns `None` if there is no child corresponding to token KW_INPUTFORMAT
fn KW_INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OUTPUTFORMAT
/// Returns `None` if there is no child corresponding to token KW_OUTPUTFORMAT
fn KW_OUTPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OUTPUTFORMAT, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token StringLiteral in current rule
fn StringLiteral_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token StringLiteral, starting from 0.
/// Returns `None` if number of children corresponding to token StringLiteral is less or equal than `i`.
fn StringLiteral(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, i)
}
/// Retrieves first TerminalNode corresponding to token KW_INPUTDRIVER
/// Returns `None` if there is no child corresponding to token KW_INPUTDRIVER
fn KW_INPUTDRIVER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INPUTDRIVER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OUTPUTDRIVER
/// Returns `None` if there is no child corresponding to token KW_OUTPUTDRIVER
fn KW_OUTPUTDRIVER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OUTPUTDRIVER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_SERDEPROPERTIES
fn KW_SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERDEPROPERTIES, 0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> TableFileFormatContextAttrs<'input> for TableFileFormatContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableFileFormat(&mut self,)
	-> Result<Rc<TableFileFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableFileFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 268, RULE_tableFileFormat);
        let mut _localctx: Rc<TableFileFormatContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2375);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(200,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2334);
					recog.base.match_token(KW_STORED,&mut recog.err_handler)?;

					recog.base.set_state(2335);
					recog.base.match_token(KW_AS,&mut recog.err_handler)?;

					recog.base.set_state(2336);
					recog.base.match_token(KW_INPUTFORMAT,&mut recog.err_handler)?;

					recog.base.set_state(2337);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,TableFileFormatContext >(&mut _localctx).inFmt = Some(tmp.clone());
					  

					recog.base.set_state(2338);
					recog.base.match_token(KW_OUTPUTFORMAT,&mut recog.err_handler)?;

					recog.base.set_state(2339);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,TableFileFormatContext >(&mut _localctx).outFmt = Some(tmp.clone());
					  

					recog.base.set_state(2344);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_INPUTDRIVER {
						{
						recog.base.set_state(2340);
						recog.base.match_token(KW_INPUTDRIVER,&mut recog.err_handler)?;

						recog.base.set_state(2341);
						let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
						 cast_mut::<_,TableFileFormatContext >(&mut _localctx).inDriver = Some(tmp.clone());
						  

						recog.base.set_state(2342);
						recog.base.match_token(KW_OUTPUTDRIVER,&mut recog.err_handler)?;

						recog.base.set_state(2343);
						let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
						 cast_mut::<_,TableFileFormatContext >(&mut _localctx).outDriver = Some(tmp.clone());
						  

						}
					}

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2346);
					recog.base.match_token(KW_STORED,&mut recog.err_handler)?;

					recog.base.set_state(2347);
					recog.base.match_token(KW_BY,&mut recog.err_handler)?;

					recog.base.set_state(2348);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,TableFileFormatContext >(&mut _localctx).storageHandler = Some(tmp.clone());
					  

					recog.base.set_state(2352);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(196,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2349);
							recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

							recog.base.set_state(2350);
							recog.base.match_token(KW_SERDEPROPERTIES,&mut recog.err_handler)?;

							/*InvokeRule tableProperties*/
							recog.base.set_state(2351);
							let tmp = recog.tableProperties()?;
							 cast_mut::<_,TableFileFormatContext >(&mut _localctx).serdeprops = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					recog.base.set_state(2357);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_STORED {
						{
						recog.base.set_state(2354);
						recog.base.match_token(KW_STORED,&mut recog.err_handler)?;

						recog.base.set_state(2355);
						recog.base.match_token(KW_AS,&mut recog.err_handler)?;

						/*InvokeRule id_*/
						recog.base.set_state(2356);
						let tmp = recog.id_()?;
						 cast_mut::<_,TableFileFormatContext >(&mut _localctx).fileformat = Some(tmp.clone());
						  

						}
					}

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(2359);
					recog.base.match_token(KW_STORED,&mut recog.err_handler)?;

					recog.base.set_state(2360);
					recog.base.match_token(KW_BY,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(2361);
					let tmp = recog.id_()?;
					 cast_mut::<_,TableFileFormatContext >(&mut _localctx).genericSpec = Some(tmp.clone());
					  

					recog.base.set_state(2365);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(198,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2362);
							recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

							recog.base.set_state(2363);
							recog.base.match_token(KW_SERDEPROPERTIES,&mut recog.err_handler)?;

							/*InvokeRule tableProperties*/
							recog.base.set_state(2364);
							let tmp = recog.tableProperties()?;
							 cast_mut::<_,TableFileFormatContext >(&mut _localctx).serdeprops = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					recog.base.set_state(2370);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_STORED {
						{
						recog.base.set_state(2367);
						recog.base.match_token(KW_STORED,&mut recog.err_handler)?;

						recog.base.set_state(2368);
						recog.base.match_token(KW_AS,&mut recog.err_handler)?;

						/*InvokeRule id_*/
						recog.base.set_state(2369);
						let tmp = recog.id_()?;
						 cast_mut::<_,TableFileFormatContext >(&mut _localctx).fileformat = Some(tmp.clone());
						  

						}
					}

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(2372);
					recog.base.match_token(KW_STORED,&mut recog.err_handler)?;

					recog.base.set_state(2373);
					recog.base.match_token(KW_AS,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(2374);
					let tmp = recog.id_()?;
					 cast_mut::<_,TableFileFormatContext >(&mut _localctx).genericSpec = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableLocation ----------------
pub type TableLocationContextAll<'input> = TableLocationContext<'input>;


pub type TableLocationContext<'input> = BaseParserRuleContext<'input,TableLocationContextExt<'input>>;

#[derive(Clone)]
pub struct TableLocationContextExt<'input>{
	pub locn: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableLocationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableLocationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableLocation(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableLocation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableLocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableLocation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableLocation }
}
crate::tid!{TableLocationContextExt<'a>}

impl<'input> TableLocationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableLocationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableLocationContextExt{
				locn: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableLocationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableLocationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LOCATION
/// Returns `None` if there is no child corresponding to token KW_LOCATION
fn KW_LOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> TableLocationContextAttrs<'input> for TableLocationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableLocation(&mut self,)
	-> Result<Rc<TableLocationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableLocationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 270, RULE_tableLocation);
        let mut _localctx: Rc<TableLocationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2377);
			recog.base.match_token(KW_LOCATION,&mut recog.err_handler)?;

			recog.base.set_state(2378);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,TableLocationContext >(&mut _localctx).locn = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameTypeList ----------------
pub type ColumnNameTypeListContextAll<'input> = ColumnNameTypeListContext<'input>;


pub type ColumnNameTypeListContext<'input> = BaseParserRuleContext<'input,ColumnNameTypeListContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameTypeListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameTypeListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameTypeListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameTypeList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameTypeList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameTypeListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameTypeList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameTypeList }
}
crate::tid!{ColumnNameTypeListContextExt<'a>}

impl<'input> ColumnNameTypeListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameTypeListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameTypeListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameTypeListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameTypeListContextExt<'input>>{

fn columnNameType_all(&self) ->  Vec<Rc<ColumnNameTypeContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnNameType(&self, i: usize) -> Option<Rc<ColumnNameTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnNameTypeListContextAttrs<'input> for ColumnNameTypeListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameTypeList(&mut self,)
	-> Result<Rc<ColumnNameTypeListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameTypeListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 272, RULE_columnNameTypeList);
        let mut _localctx: Rc<ColumnNameTypeListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnNameType*/
			recog.base.set_state(2380);
			recog.columnNameType()?;

			recog.base.set_state(2385);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2381);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnNameType*/
				recog.base.set_state(2382);
				recog.columnNameType()?;

				}
				}
				recog.base.set_state(2387);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameTypeOrConstraintList ----------------
pub type ColumnNameTypeOrConstraintListContextAll<'input> = ColumnNameTypeOrConstraintListContext<'input>;


pub type ColumnNameTypeOrConstraintListContext<'input> = BaseParserRuleContext<'input,ColumnNameTypeOrConstraintListContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameTypeOrConstraintListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameTypeOrConstraintListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameTypeOrConstraintListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameTypeOrConstraintList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameTypeOrConstraintList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameTypeOrConstraintListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameTypeOrConstraintList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameTypeOrConstraintList }
}
crate::tid!{ColumnNameTypeOrConstraintListContextExt<'a>}

impl<'input> ColumnNameTypeOrConstraintListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameTypeOrConstraintListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameTypeOrConstraintListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameTypeOrConstraintListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameTypeOrConstraintListContextExt<'input>>{

fn columnNameTypeOrConstraint_all(&self) ->  Vec<Rc<ColumnNameTypeOrConstraintContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnNameTypeOrConstraint(&self, i: usize) -> Option<Rc<ColumnNameTypeOrConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnNameTypeOrConstraintListContextAttrs<'input> for ColumnNameTypeOrConstraintListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameTypeOrConstraintList(&mut self,)
	-> Result<Rc<ColumnNameTypeOrConstraintListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameTypeOrConstraintListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 274, RULE_columnNameTypeOrConstraintList);
        let mut _localctx: Rc<ColumnNameTypeOrConstraintListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnNameTypeOrConstraint*/
			recog.base.set_state(2388);
			recog.columnNameTypeOrConstraint()?;

			recog.base.set_state(2393);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2389);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnNameTypeOrConstraint*/
				recog.base.set_state(2390);
				recog.columnNameTypeOrConstraint()?;

				}
				}
				recog.base.set_state(2395);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameColonTypeList ----------------
pub type ColumnNameColonTypeListContextAll<'input> = ColumnNameColonTypeListContext<'input>;


pub type ColumnNameColonTypeListContext<'input> = BaseParserRuleContext<'input,ColumnNameColonTypeListContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameColonTypeListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameColonTypeListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameColonTypeListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameColonTypeList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameColonTypeList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameColonTypeListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameColonTypeList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameColonTypeList }
}
crate::tid!{ColumnNameColonTypeListContextExt<'a>}

impl<'input> ColumnNameColonTypeListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameColonTypeListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameColonTypeListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameColonTypeListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameColonTypeListContextExt<'input>>{

fn columnNameColonType_all(&self) ->  Vec<Rc<ColumnNameColonTypeContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnNameColonType(&self, i: usize) -> Option<Rc<ColumnNameColonTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnNameColonTypeListContextAttrs<'input> for ColumnNameColonTypeListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameColonTypeList(&mut self,)
	-> Result<Rc<ColumnNameColonTypeListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameColonTypeListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 276, RULE_columnNameColonTypeList);
        let mut _localctx: Rc<ColumnNameColonTypeListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnNameColonType*/
			recog.base.set_state(2396);
			recog.columnNameColonType()?;

			recog.base.set_state(2401);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2397);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnNameColonType*/
				recog.base.set_state(2398);
				recog.columnNameColonType()?;

				}
				}
				recog.base.set_state(2403);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameList ----------------
pub type ColumnNameListContextAll<'input> = ColumnNameListContext<'input>;


pub type ColumnNameListContext<'input> = BaseParserRuleContext<'input,ColumnNameListContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameList }
}
crate::tid!{ColumnNameListContextExt<'a>}

impl<'input> ColumnNameListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameListContextExt<'input>>{

fn columnName_all(&self) ->  Vec<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnName(&self, i: usize) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnNameListContextAttrs<'input> for ColumnNameListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameList(&mut self,)
	-> Result<Rc<ColumnNameListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 278, RULE_columnNameList);
        let mut _localctx: Rc<ColumnNameListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnName*/
			recog.base.set_state(2404);
			recog.columnName()?;

			recog.base.set_state(2409);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2405);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnName*/
				recog.base.set_state(2406);
				recog.columnName()?;

				}
				}
				recog.base.set_state(2411);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnName ----------------
pub type ColumnNameContextAll<'input> = ColumnNameContext<'input>;


pub type ColumnNameContext<'input> = BaseParserRuleContext<'input,ColumnNameContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnName }
}
crate::tid!{ColumnNameContextExt<'a>}

impl<'input> ColumnNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnNameContextAttrs<'input> for ColumnNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnName(&mut self,)
	-> Result<Rc<ColumnNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 280, RULE_columnName);
        let mut _localctx: Rc<ColumnNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(2412);
			recog.id_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- extColumnName ----------------
pub type ExtColumnNameContextAll<'input> = ExtColumnNameContext<'input>;


pub type ExtColumnNameContext<'input> = BaseParserRuleContext<'input,ExtColumnNameContextExt<'input>>;

#[derive(Clone)]
pub struct ExtColumnNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExtColumnNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExtColumnNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_extColumnName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_extColumnName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExtColumnNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_extColumnName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_extColumnName }
}
crate::tid!{ExtColumnNameContextExt<'a>}

impl<'input> ExtColumnNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExtColumnNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExtColumnNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExtColumnNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExtColumnNameContextExt<'input>>{

fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_ELEM_TYPE in current rule
fn KW_ELEM_TYPE_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_ELEM_TYPE, starting from 0.
/// Returns `None` if number of children corresponding to token KW_ELEM_TYPE is less or equal than `i`.
fn KW_ELEM_TYPE(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ELEM_TYPE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_KEY_TYPE in current rule
fn KW_KEY_TYPE_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_KEY_TYPE, starting from 0.
/// Returns `None` if number of children corresponding to token KW_KEY_TYPE is less or equal than `i`.
fn KW_KEY_TYPE(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KEY_TYPE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_VALUE_TYPE in current rule
fn KW_VALUE_TYPE_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_VALUE_TYPE, starting from 0.
/// Returns `None` if number of children corresponding to token KW_VALUE_TYPE is less or equal than `i`.
fn KW_VALUE_TYPE(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VALUE_TYPE, i)
}

}

impl<'input> ExtColumnNameContextAttrs<'input> for ExtColumnNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn extColumnName(&mut self,)
	-> Result<Rc<ExtColumnNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExtColumnNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 282, RULE_extColumnName);
        let mut _localctx: Rc<ExtColumnNameContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(2414);
			recog.id_()?;

			recog.base.set_state(2424);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==DOT {
				{
				{
				recog.base.set_state(2415);
				recog.base.match_token(DOT,&mut recog.err_handler)?;

				recog.base.set_state(2420);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(205,&mut recog.base)? {
					1 =>{
						{
						recog.base.set_state(2416);
						recog.base.match_token(KW_ELEM_TYPE,&mut recog.err_handler)?;

						}
					}
				,
					2 =>{
						{
						recog.base.set_state(2417);
						recog.base.match_token(KW_KEY_TYPE,&mut recog.err_handler)?;

						}
					}
				,
					3 =>{
						{
						recog.base.set_state(2418);
						recog.base.match_token(KW_VALUE_TYPE,&mut recog.err_handler)?;

						}
					}
				,
					4 =>{
						{
						/*InvokeRule id_*/
						recog.base.set_state(2419);
						recog.id_()?;

						}
					}

					_ => {}
				}
				}
				}
				recog.base.set_state(2426);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameOrderList ----------------
pub type ColumnNameOrderListContextAll<'input> = ColumnNameOrderListContext<'input>;


pub type ColumnNameOrderListContext<'input> = BaseParserRuleContext<'input,ColumnNameOrderListContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameOrderListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameOrderListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameOrderListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameOrderList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameOrderList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameOrderListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameOrderList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameOrderList }
}
crate::tid!{ColumnNameOrderListContextExt<'a>}

impl<'input> ColumnNameOrderListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameOrderListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameOrderListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameOrderListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameOrderListContextExt<'input>>{

fn columnNameOrder_all(&self) ->  Vec<Rc<ColumnNameOrderContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnNameOrder(&self, i: usize) -> Option<Rc<ColumnNameOrderContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnNameOrderListContextAttrs<'input> for ColumnNameOrderListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameOrderList(&mut self,)
	-> Result<Rc<ColumnNameOrderListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameOrderListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 284, RULE_columnNameOrderList);
        let mut _localctx: Rc<ColumnNameOrderListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnNameOrder*/
			recog.base.set_state(2427);
			recog.columnNameOrder()?;

			recog.base.set_state(2432);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2428);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnNameOrder*/
				recog.base.set_state(2429);
				recog.columnNameOrder()?;

				}
				}
				recog.base.set_state(2434);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnParenthesesList ----------------
pub type ColumnParenthesesListContextAll<'input> = ColumnParenthesesListContext<'input>;


pub type ColumnParenthesesListContext<'input> = BaseParserRuleContext<'input,ColumnParenthesesListContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnParenthesesListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnParenthesesListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnParenthesesListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnParenthesesList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnParenthesesList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnParenthesesListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnParenthesesList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnParenthesesList }
}
crate::tid!{ColumnParenthesesListContextExt<'a>}

impl<'input> ColumnParenthesesListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnParenthesesListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnParenthesesListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnParenthesesListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnParenthesesListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> ColumnParenthesesListContextAttrs<'input> for ColumnParenthesesListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnParenthesesList(&mut self,)
	-> Result<Rc<ColumnParenthesesListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnParenthesesListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 286, RULE_columnParenthesesList);
        let mut _localctx: Rc<ColumnParenthesesListContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2435);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnNameList*/
			recog.base.set_state(2436);
			recog.columnNameList()?;

			recog.base.set_state(2437);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- enableValidateSpecification ----------------
pub type EnableValidateSpecificationContextAll<'input> = EnableValidateSpecificationContext<'input>;


pub type EnableValidateSpecificationContext<'input> = BaseParserRuleContext<'input,EnableValidateSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct EnableValidateSpecificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for EnableValidateSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for EnableValidateSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_enableValidateSpecification(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_enableValidateSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for EnableValidateSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_enableValidateSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_enableValidateSpecification }
}
crate::tid!{EnableValidateSpecificationContextExt<'a>}

impl<'input> EnableValidateSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EnableValidateSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EnableValidateSpecificationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait EnableValidateSpecificationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<EnableValidateSpecificationContextExt<'input>>{

fn enableSpecification(&self) -> Option<Rc<EnableSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn validateSpecification(&self) -> Option<Rc<ValidateSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn enforcedSpecification(&self) -> Option<Rc<EnforcedSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EnableValidateSpecificationContextAttrs<'input> for EnableValidateSpecificationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn enableValidateSpecification(&mut self,)
	-> Result<Rc<EnableValidateSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EnableValidateSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 288, RULE_enableValidateSpecification);
        let mut _localctx: Rc<EnableValidateSpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2444);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_DISABLE | KW_ENABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule enableSpecification*/
					recog.base.set_state(2439);
					recog.enableSpecification()?;

					recog.base.set_state(2441);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_NOVALIDATE || _la==KW_VALIDATE {
						{
						/*InvokeRule validateSpecification*/
						recog.base.set_state(2440);
						recog.validateSpecification()?;

						}
					}

					}
				}

			 KW_ENFORCED | KW_NOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule enforcedSpecification*/
					recog.base.set_state(2443);
					recog.enforcedSpecification()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- enableSpecification ----------------
pub type EnableSpecificationContextAll<'input> = EnableSpecificationContext<'input>;


pub type EnableSpecificationContext<'input> = BaseParserRuleContext<'input,EnableSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct EnableSpecificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for EnableSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for EnableSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_enableSpecification(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_enableSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for EnableSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_enableSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_enableSpecification }
}
crate::tid!{EnableSpecificationContextExt<'a>}

impl<'input> EnableSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EnableSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EnableSpecificationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait EnableSpecificationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<EnableSpecificationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ENABLE
/// Returns `None` if there is no child corresponding to token KW_ENABLE
fn KW_ENABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ENABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DISABLE
/// Returns `None` if there is no child corresponding to token KW_DISABLE
fn KW_DISABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISABLE, 0)
}

}

impl<'input> EnableSpecificationContextAttrs<'input> for EnableSpecificationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn enableSpecification(&mut self,)
	-> Result<Rc<EnableSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EnableSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 290, RULE_enableSpecification);
        let mut _localctx: Rc<EnableSpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2446);
			_la = recog.base.input.la(1);
			if { !(_la==KW_DISABLE || _la==KW_ENABLE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- validateSpecification ----------------
pub type ValidateSpecificationContextAll<'input> = ValidateSpecificationContext<'input>;


pub type ValidateSpecificationContext<'input> = BaseParserRuleContext<'input,ValidateSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct ValidateSpecificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ValidateSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ValidateSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_validateSpecification(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_validateSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ValidateSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_validateSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_validateSpecification }
}
crate::tid!{ValidateSpecificationContextExt<'a>}

impl<'input> ValidateSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ValidateSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ValidateSpecificationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ValidateSpecificationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ValidateSpecificationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_VALIDATE
/// Returns `None` if there is no child corresponding to token KW_VALIDATE
fn KW_VALIDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VALIDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOVALIDATE
/// Returns `None` if there is no child corresponding to token KW_NOVALIDATE
fn KW_NOVALIDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOVALIDATE, 0)
}

}

impl<'input> ValidateSpecificationContextAttrs<'input> for ValidateSpecificationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn validateSpecification(&mut self,)
	-> Result<Rc<ValidateSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ValidateSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 292, RULE_validateSpecification);
        let mut _localctx: Rc<ValidateSpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2448);
			_la = recog.base.input.la(1);
			if { !(_la==KW_NOVALIDATE || _la==KW_VALIDATE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- enforcedSpecification ----------------
pub type EnforcedSpecificationContextAll<'input> = EnforcedSpecificationContext<'input>;


pub type EnforcedSpecificationContext<'input> = BaseParserRuleContext<'input,EnforcedSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct EnforcedSpecificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for EnforcedSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for EnforcedSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_enforcedSpecification(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_enforcedSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for EnforcedSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_enforcedSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_enforcedSpecification }
}
crate::tid!{EnforcedSpecificationContextExt<'a>}

impl<'input> EnforcedSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EnforcedSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EnforcedSpecificationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait EnforcedSpecificationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<EnforcedSpecificationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ENFORCED
/// Returns `None` if there is no child corresponding to token KW_ENFORCED
fn KW_ENFORCED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ENFORCED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOT
/// Returns `None` if there is no child corresponding to token KW_NOT
fn KW_NOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOT, 0)
}

}

impl<'input> EnforcedSpecificationContextAttrs<'input> for EnforcedSpecificationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn enforcedSpecification(&mut self,)
	-> Result<Rc<EnforcedSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EnforcedSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 294, RULE_enforcedSpecification);
        let mut _localctx: Rc<EnforcedSpecificationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2453);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ENFORCED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2450);
					recog.base.match_token(KW_ENFORCED,&mut recog.err_handler)?;

					}
				}

			 KW_NOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2451);
					recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

					recog.base.set_state(2452);
					recog.base.match_token(KW_ENFORCED,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relySpecification ----------------
pub type RelySpecificationContextAll<'input> = RelySpecificationContext<'input>;


pub type RelySpecificationContext<'input> = BaseParserRuleContext<'input,RelySpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct RelySpecificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RelySpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RelySpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_relySpecification(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_relySpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RelySpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relySpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relySpecification }
}
crate::tid!{RelySpecificationContextExt<'a>}

impl<'input> RelySpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelySpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelySpecificationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RelySpecificationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RelySpecificationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_RELY
/// Returns `None` if there is no child corresponding to token KW_RELY
fn KW_RELY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RELY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NORELY
/// Returns `None` if there is no child corresponding to token KW_NORELY
fn KW_NORELY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NORELY, 0)
}

}

impl<'input> RelySpecificationContextAttrs<'input> for RelySpecificationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relySpecification(&mut self,)
	-> Result<Rc<RelySpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelySpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 296, RULE_relySpecification);
        let mut _localctx: Rc<RelySpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2455);
			_la = recog.base.input.la(1);
			if { !(_la==KW_NORELY || _la==KW_RELY) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createConstraint ----------------
pub type CreateConstraintContextAll<'input> = CreateConstraintContext<'input>;


pub type CreateConstraintContext<'input> = BaseParserRuleContext<'input,CreateConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct CreateConstraintContextExt<'input>{
	pub constraintName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createConstraint }
}
crate::tid!{CreateConstraintContextExt<'a>}

impl<'input> CreateConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateConstraintContextExt{
				constraintName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateConstraintContextExt<'input>>{

fn tableLevelConstraint(&self) -> Option<Rc<TableLevelConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_CONSTRAINT
/// Returns `None` if there is no child corresponding to token KW_CONSTRAINT
fn KW_CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONSTRAINT, 0)
}
fn constraintOptsCreate(&self) -> Option<Rc<ConstraintOptsCreateContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateConstraintContextAttrs<'input> for CreateConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createConstraint(&mut self,)
	-> Result<Rc<CreateConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 298, RULE_createConstraint);
        let mut _localctx: Rc<CreateConstraintContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2459);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CONSTRAINT {
				{
				recog.base.set_state(2457);
				recog.base.match_token(KW_CONSTRAINT,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(2458);
				let tmp = recog.id_()?;
				 cast_mut::<_,CreateConstraintContext >(&mut _localctx).constraintName = Some(tmp.clone());
				  

				}
			}

			/*InvokeRule tableLevelConstraint*/
			recog.base.set_state(2461);
			recog.tableLevelConstraint()?;

			recog.base.set_state(2463);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 91)) & !0x3f) == 0 && ((1usize << (_la - 91)) & ((1usize << (KW_DISABLE - 91)) | (1usize << (KW_ENABLE - 91)) | (1usize << (KW_ENFORCED - 91)))) != 0) || _la==KW_NOT {
				{
				/*InvokeRule constraintOptsCreate*/
				recog.base.set_state(2462);
				recog.constraintOptsCreate()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterConstraintWithName ----------------
pub type AlterConstraintWithNameContextAll<'input> = AlterConstraintWithNameContext<'input>;


pub type AlterConstraintWithNameContext<'input> = BaseParserRuleContext<'input,AlterConstraintWithNameContextExt<'input>>;

#[derive(Clone)]
pub struct AlterConstraintWithNameContextExt<'input>{
	pub constraintName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterConstraintWithNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterConstraintWithNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterConstraintWithName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterConstraintWithName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterConstraintWithNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterConstraintWithName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterConstraintWithName }
}
crate::tid!{AlterConstraintWithNameContextExt<'a>}

impl<'input> AlterConstraintWithNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterConstraintWithNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterConstraintWithNameContextExt{
				constraintName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterConstraintWithNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterConstraintWithNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CONSTRAINT
/// Returns `None` if there is no child corresponding to token KW_CONSTRAINT
fn KW_CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONSTRAINT, 0)
}
fn tableLevelConstraint(&self) -> Option<Rc<TableLevelConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn constraintOptsAlter(&self) -> Option<Rc<ConstraintOptsAlterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterConstraintWithNameContextAttrs<'input> for AlterConstraintWithNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterConstraintWithName(&mut self,)
	-> Result<Rc<AlterConstraintWithNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterConstraintWithNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 300, RULE_alterConstraintWithName);
        let mut _localctx: Rc<AlterConstraintWithNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2465);
			recog.base.match_token(KW_CONSTRAINT,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(2466);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterConstraintWithNameContext >(&mut _localctx).constraintName = Some(tmp.clone());
			  

			/*InvokeRule tableLevelConstraint*/
			recog.base.set_state(2467);
			recog.tableLevelConstraint()?;

			recog.base.set_state(2469);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(213,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule constraintOptsAlter*/
					recog.base.set_state(2468);
					recog.constraintOptsAlter()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableLevelConstraint ----------------
pub type TableLevelConstraintContextAll<'input> = TableLevelConstraintContext<'input>;


pub type TableLevelConstraintContext<'input> = BaseParserRuleContext<'input,TableLevelConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct TableLevelConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableLevelConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableLevelConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableLevelConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableLevelConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableLevelConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableLevelConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableLevelConstraint }
}
crate::tid!{TableLevelConstraintContextExt<'a>}

impl<'input> TableLevelConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableLevelConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableLevelConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableLevelConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableLevelConstraintContextExt<'input>>{

fn pkUkConstraint(&self) -> Option<Rc<PkUkConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn checkConstraint(&self) -> Option<Rc<CheckConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableLevelConstraintContextAttrs<'input> for TableLevelConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableLevelConstraint(&mut self,)
	-> Result<Rc<TableLevelConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableLevelConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 302, RULE_tableLevelConstraint);
        let mut _localctx: Rc<TableLevelConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2473);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_PRIMARY | KW_UNIQUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule pkUkConstraint*/
					recog.base.set_state(2471);
					recog.pkUkConstraint()?;

					}
				}

			 KW_CHECK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule checkConstraint*/
					recog.base.set_state(2472);
					recog.checkConstraint()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pkUkConstraint ----------------
pub type PkUkConstraintContextAll<'input> = PkUkConstraintContext<'input>;


pub type PkUkConstraintContext<'input> = BaseParserRuleContext<'input,PkUkConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct PkUkConstraintContextExt<'input>{
	pub pkCols: Option<Rc<ColumnParenthesesListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PkUkConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PkUkConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pkUkConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_pkUkConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PkUkConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pkUkConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pkUkConstraint }
}
crate::tid!{PkUkConstraintContextExt<'a>}

impl<'input> PkUkConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PkUkConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PkUkConstraintContextExt{
				pkCols: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PkUkConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PkUkConstraintContextExt<'input>>{

fn tableConstraintType(&self) -> Option<Rc<TableConstraintTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnParenthesesList(&self) -> Option<Rc<ColumnParenthesesListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PkUkConstraintContextAttrs<'input> for PkUkConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pkUkConstraint(&mut self,)
	-> Result<Rc<PkUkConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PkUkConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 304, RULE_pkUkConstraint);
        let mut _localctx: Rc<PkUkConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableConstraintType*/
			recog.base.set_state(2475);
			recog.tableConstraintType()?;

			/*InvokeRule columnParenthesesList*/
			recog.base.set_state(2476);
			let tmp = recog.columnParenthesesList()?;
			 cast_mut::<_,PkUkConstraintContext >(&mut _localctx).pkCols = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- checkConstraint ----------------
pub type CheckConstraintContextAll<'input> = CheckConstraintContext<'input>;


pub type CheckConstraintContext<'input> = BaseParserRuleContext<'input,CheckConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct CheckConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CheckConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CheckConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_checkConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_checkConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CheckConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_checkConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_checkConstraint }
}
crate::tid!{CheckConstraintContextExt<'a>}

impl<'input> CheckConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CheckConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CheckConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CheckConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CheckConstraintContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CHECK
/// Returns `None` if there is no child corresponding to token KW_CHECK
fn KW_CHECK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CHECK, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> CheckConstraintContextAttrs<'input> for CheckConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn checkConstraint(&mut self,)
	-> Result<Rc<CheckConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CheckConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 306, RULE_checkConstraint);
        let mut _localctx: Rc<CheckConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2478);
			recog.base.match_token(KW_CHECK,&mut recog.err_handler)?;

			recog.base.set_state(2479);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2480);
			recog.expression()?;

			recog.base.set_state(2481);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createForeignKey ----------------
pub type CreateForeignKeyContextAll<'input> = CreateForeignKeyContext<'input>;


pub type CreateForeignKeyContext<'input> = BaseParserRuleContext<'input,CreateForeignKeyContextExt<'input>>;

#[derive(Clone)]
pub struct CreateForeignKeyContextExt<'input>{
	pub constraintName: Option<Rc<Id_ContextAll<'input>>>,
	pub fkCols: Option<Rc<ColumnParenthesesListContextAll<'input>>>,
	pub tabName: Option<Rc<TableNameContextAll<'input>>>,
	pub parCols: Option<Rc<ColumnParenthesesListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateForeignKeyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateForeignKeyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createForeignKey(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createForeignKey(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateForeignKeyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createForeignKey }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createForeignKey }
}
crate::tid!{CreateForeignKeyContextExt<'a>}

impl<'input> CreateForeignKeyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateForeignKeyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateForeignKeyContextExt{
				constraintName: None, fkCols: None, tabName: None, parCols: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateForeignKeyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateForeignKeyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_FOREIGN
/// Returns `None` if there is no child corresponding to token KW_FOREIGN
fn KW_FOREIGN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FOREIGN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_KEY
/// Returns `None` if there is no child corresponding to token KW_KEY
fn KW_KEY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KEY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REFERENCES
/// Returns `None` if there is no child corresponding to token KW_REFERENCES
fn KW_REFERENCES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REFERENCES, 0)
}
fn columnParenthesesList_all(&self) ->  Vec<Rc<ColumnParenthesesListContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnParenthesesList(&self, i: usize) -> Option<Rc<ColumnParenthesesListContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_CONSTRAINT
/// Returns `None` if there is no child corresponding to token KW_CONSTRAINT
fn KW_CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONSTRAINT, 0)
}
fn constraintOptsCreate(&self) -> Option<Rc<ConstraintOptsCreateContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateForeignKeyContextAttrs<'input> for CreateForeignKeyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createForeignKey(&mut self,)
	-> Result<Rc<CreateForeignKeyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateForeignKeyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 308, RULE_createForeignKey);
        let mut _localctx: Rc<CreateForeignKeyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2485);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CONSTRAINT {
				{
				recog.base.set_state(2483);
				recog.base.match_token(KW_CONSTRAINT,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(2484);
				let tmp = recog.id_()?;
				 cast_mut::<_,CreateForeignKeyContext >(&mut _localctx).constraintName = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2487);
			recog.base.match_token(KW_FOREIGN,&mut recog.err_handler)?;

			recog.base.set_state(2488);
			recog.base.match_token(KW_KEY,&mut recog.err_handler)?;

			/*InvokeRule columnParenthesesList*/
			recog.base.set_state(2489);
			let tmp = recog.columnParenthesesList()?;
			 cast_mut::<_,CreateForeignKeyContext >(&mut _localctx).fkCols = Some(tmp.clone());
			  

			recog.base.set_state(2490);
			recog.base.match_token(KW_REFERENCES,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(2491);
			let tmp = recog.tableName()?;
			 cast_mut::<_,CreateForeignKeyContext >(&mut _localctx).tabName = Some(tmp.clone());
			  

			/*InvokeRule columnParenthesesList*/
			recog.base.set_state(2492);
			let tmp = recog.columnParenthesesList()?;
			 cast_mut::<_,CreateForeignKeyContext >(&mut _localctx).parCols = Some(tmp.clone());
			  

			recog.base.set_state(2494);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 91)) & !0x3f) == 0 && ((1usize << (_la - 91)) & ((1usize << (KW_DISABLE - 91)) | (1usize << (KW_ENABLE - 91)) | (1usize << (KW_ENFORCED - 91)))) != 0) || _la==KW_NOT {
				{
				/*InvokeRule constraintOptsCreate*/
				recog.base.set_state(2493);
				recog.constraintOptsCreate()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterForeignKeyWithName ----------------
pub type AlterForeignKeyWithNameContextAll<'input> = AlterForeignKeyWithNameContext<'input>;


pub type AlterForeignKeyWithNameContext<'input> = BaseParserRuleContext<'input,AlterForeignKeyWithNameContextExt<'input>>;

#[derive(Clone)]
pub struct AlterForeignKeyWithNameContextExt<'input>{
	pub constraintName: Option<Rc<Id_ContextAll<'input>>>,
	pub fkCols: Option<Rc<ColumnParenthesesListContextAll<'input>>>,
	pub tabName: Option<Rc<TableNameContextAll<'input>>>,
	pub parCols: Option<Rc<ColumnParenthesesListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterForeignKeyWithNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterForeignKeyWithNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterForeignKeyWithName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterForeignKeyWithName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterForeignKeyWithNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterForeignKeyWithName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterForeignKeyWithName }
}
crate::tid!{AlterForeignKeyWithNameContextExt<'a>}

impl<'input> AlterForeignKeyWithNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterForeignKeyWithNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterForeignKeyWithNameContextExt{
				constraintName: None, fkCols: None, tabName: None, parCols: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterForeignKeyWithNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterForeignKeyWithNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CONSTRAINT
/// Returns `None` if there is no child corresponding to token KW_CONSTRAINT
fn KW_CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONSTRAINT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FOREIGN
/// Returns `None` if there is no child corresponding to token KW_FOREIGN
fn KW_FOREIGN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FOREIGN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_KEY
/// Returns `None` if there is no child corresponding to token KW_KEY
fn KW_KEY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KEY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REFERENCES
/// Returns `None` if there is no child corresponding to token KW_REFERENCES
fn KW_REFERENCES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REFERENCES, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnParenthesesList_all(&self) ->  Vec<Rc<ColumnParenthesesListContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnParenthesesList(&self, i: usize) -> Option<Rc<ColumnParenthesesListContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn constraintOptsAlter(&self) -> Option<Rc<ConstraintOptsAlterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterForeignKeyWithNameContextAttrs<'input> for AlterForeignKeyWithNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterForeignKeyWithName(&mut self,)
	-> Result<Rc<AlterForeignKeyWithNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterForeignKeyWithNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 310, RULE_alterForeignKeyWithName);
        let mut _localctx: Rc<AlterForeignKeyWithNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2496);
			recog.base.match_token(KW_CONSTRAINT,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(2497);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterForeignKeyWithNameContext >(&mut _localctx).constraintName = Some(tmp.clone());
			  

			recog.base.set_state(2498);
			recog.base.match_token(KW_FOREIGN,&mut recog.err_handler)?;

			recog.base.set_state(2499);
			recog.base.match_token(KW_KEY,&mut recog.err_handler)?;

			/*InvokeRule columnParenthesesList*/
			recog.base.set_state(2500);
			let tmp = recog.columnParenthesesList()?;
			 cast_mut::<_,AlterForeignKeyWithNameContext >(&mut _localctx).fkCols = Some(tmp.clone());
			  

			recog.base.set_state(2501);
			recog.base.match_token(KW_REFERENCES,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(2502);
			let tmp = recog.tableName()?;
			 cast_mut::<_,AlterForeignKeyWithNameContext >(&mut _localctx).tabName = Some(tmp.clone());
			  

			/*InvokeRule columnParenthesesList*/
			recog.base.set_state(2503);
			let tmp = recog.columnParenthesesList()?;
			 cast_mut::<_,AlterForeignKeyWithNameContext >(&mut _localctx).parCols = Some(tmp.clone());
			  

			recog.base.set_state(2505);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(217,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule constraintOptsAlter*/
					recog.base.set_state(2504);
					recog.constraintOptsAlter()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- skewedValueElement ----------------
pub type SkewedValueElementContextAll<'input> = SkewedValueElementContext<'input>;


pub type SkewedValueElementContext<'input> = BaseParserRuleContext<'input,SkewedValueElementContextExt<'input>>;

#[derive(Clone)]
pub struct SkewedValueElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SkewedValueElementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SkewedValueElementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_skewedValueElement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_skewedValueElement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SkewedValueElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_skewedValueElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_skewedValueElement }
}
crate::tid!{SkewedValueElementContextExt<'a>}

impl<'input> SkewedValueElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SkewedValueElementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SkewedValueElementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SkewedValueElementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SkewedValueElementContextExt<'input>>{

fn skewedColumnValues(&self) -> Option<Rc<SkewedColumnValuesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn skewedColumnValuePairList(&self) -> Option<Rc<SkewedColumnValuePairListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SkewedValueElementContextAttrs<'input> for SkewedValueElementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn skewedValueElement(&mut self,)
	-> Result<Rc<SkewedValueElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SkewedValueElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 312, RULE_skewedValueElement);
        let mut _localctx: Rc<SkewedValueElementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2509);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_CURRENT_DATE | KW_CURRENT_TIMESTAMP | KW_DATE | KW_FALSE | KW_NULL |
			 KW_TIMESTAMP | KW_TIMESTAMPLOCALTZ | KW_TRUE | QUESTION | StringLiteral |
			 IntegralLiteral | NumberLiteral | Number | CharSetName 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule skewedColumnValues*/
					recog.base.set_state(2507);
					recog.skewedColumnValues()?;

					}
				}

			 LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule skewedColumnValuePairList*/
					recog.base.set_state(2508);
					recog.skewedColumnValuePairList()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- skewedColumnValuePairList ----------------
pub type SkewedColumnValuePairListContextAll<'input> = SkewedColumnValuePairListContext<'input>;


pub type SkewedColumnValuePairListContext<'input> = BaseParserRuleContext<'input,SkewedColumnValuePairListContextExt<'input>>;

#[derive(Clone)]
pub struct SkewedColumnValuePairListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SkewedColumnValuePairListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SkewedColumnValuePairListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_skewedColumnValuePairList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_skewedColumnValuePairList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SkewedColumnValuePairListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_skewedColumnValuePairList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_skewedColumnValuePairList }
}
crate::tid!{SkewedColumnValuePairListContextExt<'a>}

impl<'input> SkewedColumnValuePairListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SkewedColumnValuePairListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SkewedColumnValuePairListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SkewedColumnValuePairListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SkewedColumnValuePairListContextExt<'input>>{

fn skewedColumnValuePair_all(&self) ->  Vec<Rc<SkewedColumnValuePairContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn skewedColumnValuePair(&self, i: usize) -> Option<Rc<SkewedColumnValuePairContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> SkewedColumnValuePairListContextAttrs<'input> for SkewedColumnValuePairListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn skewedColumnValuePairList(&mut self,)
	-> Result<Rc<SkewedColumnValuePairListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SkewedColumnValuePairListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 314, RULE_skewedColumnValuePairList);
        let mut _localctx: Rc<SkewedColumnValuePairListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule skewedColumnValuePair*/
			recog.base.set_state(2511);
			recog.skewedColumnValuePair()?;

			recog.base.set_state(2516);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2512);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule skewedColumnValuePair*/
				recog.base.set_state(2513);
				recog.skewedColumnValuePair()?;

				}
				}
				recog.base.set_state(2518);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- skewedColumnValuePair ----------------
pub type SkewedColumnValuePairContextAll<'input> = SkewedColumnValuePairContext<'input>;


pub type SkewedColumnValuePairContext<'input> = BaseParserRuleContext<'input,SkewedColumnValuePairContextExt<'input>>;

#[derive(Clone)]
pub struct SkewedColumnValuePairContextExt<'input>{
	pub colValues: Option<Rc<SkewedColumnValuesContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SkewedColumnValuePairContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SkewedColumnValuePairContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_skewedColumnValuePair(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_skewedColumnValuePair(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SkewedColumnValuePairContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_skewedColumnValuePair }
	//fn type_rule_index() -> usize where Self: Sized { RULE_skewedColumnValuePair }
}
crate::tid!{SkewedColumnValuePairContextExt<'a>}

impl<'input> SkewedColumnValuePairContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SkewedColumnValuePairContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SkewedColumnValuePairContextExt{
				colValues: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SkewedColumnValuePairContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SkewedColumnValuePairContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn skewedColumnValues(&self) -> Option<Rc<SkewedColumnValuesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SkewedColumnValuePairContextAttrs<'input> for SkewedColumnValuePairContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn skewedColumnValuePair(&mut self,)
	-> Result<Rc<SkewedColumnValuePairContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SkewedColumnValuePairContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 316, RULE_skewedColumnValuePair);
        let mut _localctx: Rc<SkewedColumnValuePairContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2519);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule skewedColumnValues*/
			recog.base.set_state(2520);
			let tmp = recog.skewedColumnValues()?;
			 cast_mut::<_,SkewedColumnValuePairContext >(&mut _localctx).colValues = Some(tmp.clone());
			  

			recog.base.set_state(2521);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- skewedColumnValues ----------------
pub type SkewedColumnValuesContextAll<'input> = SkewedColumnValuesContext<'input>;


pub type SkewedColumnValuesContext<'input> = BaseParserRuleContext<'input,SkewedColumnValuesContextExt<'input>>;

#[derive(Clone)]
pub struct SkewedColumnValuesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SkewedColumnValuesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SkewedColumnValuesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_skewedColumnValues(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_skewedColumnValues(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SkewedColumnValuesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_skewedColumnValues }
	//fn type_rule_index() -> usize where Self: Sized { RULE_skewedColumnValues }
}
crate::tid!{SkewedColumnValuesContextExt<'a>}

impl<'input> SkewedColumnValuesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SkewedColumnValuesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SkewedColumnValuesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SkewedColumnValuesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SkewedColumnValuesContextExt<'input>>{

fn skewedColumnValue_all(&self) ->  Vec<Rc<SkewedColumnValueContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn skewedColumnValue(&self, i: usize) -> Option<Rc<SkewedColumnValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> SkewedColumnValuesContextAttrs<'input> for SkewedColumnValuesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn skewedColumnValues(&mut self,)
	-> Result<Rc<SkewedColumnValuesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SkewedColumnValuesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 318, RULE_skewedColumnValues);
        let mut _localctx: Rc<SkewedColumnValuesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule skewedColumnValue*/
			recog.base.set_state(2523);
			recog.skewedColumnValue()?;

			recog.base.set_state(2528);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2524);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule skewedColumnValue*/
				recog.base.set_state(2525);
				recog.skewedColumnValue()?;

				}
				}
				recog.base.set_state(2530);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- skewedColumnValue ----------------
pub type SkewedColumnValueContextAll<'input> = SkewedColumnValueContext<'input>;


pub type SkewedColumnValueContext<'input> = BaseParserRuleContext<'input,SkewedColumnValueContextExt<'input>>;

#[derive(Clone)]
pub struct SkewedColumnValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SkewedColumnValueContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SkewedColumnValueContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_skewedColumnValue(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_skewedColumnValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SkewedColumnValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_skewedColumnValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_skewedColumnValue }
}
crate::tid!{SkewedColumnValueContextExt<'a>}

impl<'input> SkewedColumnValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SkewedColumnValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SkewedColumnValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SkewedColumnValueContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SkewedColumnValueContextExt<'input>>{

fn constant(&self) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SkewedColumnValueContextAttrs<'input> for SkewedColumnValueContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn skewedColumnValue(&mut self,)
	-> Result<Rc<SkewedColumnValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SkewedColumnValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 320, RULE_skewedColumnValue);
        let mut _localctx: Rc<SkewedColumnValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule constant*/
			recog.base.set_state(2531);
			recog.constant()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- skewedValueLocationElement ----------------
pub type SkewedValueLocationElementContextAll<'input> = SkewedValueLocationElementContext<'input>;


pub type SkewedValueLocationElementContext<'input> = BaseParserRuleContext<'input,SkewedValueLocationElementContextExt<'input>>;

#[derive(Clone)]
pub struct SkewedValueLocationElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SkewedValueLocationElementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SkewedValueLocationElementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_skewedValueLocationElement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_skewedValueLocationElement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SkewedValueLocationElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_skewedValueLocationElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_skewedValueLocationElement }
}
crate::tid!{SkewedValueLocationElementContextExt<'a>}

impl<'input> SkewedValueLocationElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SkewedValueLocationElementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SkewedValueLocationElementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SkewedValueLocationElementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SkewedValueLocationElementContextExt<'input>>{

fn skewedColumnValue(&self) -> Option<Rc<SkewedColumnValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn skewedColumnValuePair(&self) -> Option<Rc<SkewedColumnValuePairContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SkewedValueLocationElementContextAttrs<'input> for SkewedValueLocationElementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn skewedValueLocationElement(&mut self,)
	-> Result<Rc<SkewedValueLocationElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SkewedValueLocationElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 322, RULE_skewedValueLocationElement);
        let mut _localctx: Rc<SkewedValueLocationElementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2535);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_CURRENT_DATE | KW_CURRENT_TIMESTAMP | KW_DATE | KW_FALSE | KW_NULL |
			 KW_TIMESTAMP | KW_TIMESTAMPLOCALTZ | KW_TRUE | QUESTION | StringLiteral |
			 IntegralLiteral | NumberLiteral | Number | CharSetName 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule skewedColumnValue*/
					recog.base.set_state(2533);
					recog.skewedColumnValue()?;

					}
				}

			 LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule skewedColumnValuePair*/
					recog.base.set_state(2534);
					recog.skewedColumnValuePair()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- orderSpecification ----------------
pub type OrderSpecificationContextAll<'input> = OrderSpecificationContext<'input>;


pub type OrderSpecificationContext<'input> = BaseParserRuleContext<'input,OrderSpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct OrderSpecificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for OrderSpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for OrderSpecificationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_orderSpecification(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_orderSpecification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for OrderSpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_orderSpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_orderSpecification }
}
crate::tid!{OrderSpecificationContextExt<'a>}

impl<'input> OrderSpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OrderSpecificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OrderSpecificationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait OrderSpecificationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<OrderSpecificationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ASC
/// Returns `None` if there is no child corresponding to token KW_ASC
fn KW_ASC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DESC
/// Returns `None` if there is no child corresponding to token KW_DESC
fn KW_DESC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DESC, 0)
}

}

impl<'input> OrderSpecificationContextAttrs<'input> for OrderSpecificationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn orderSpecification(&mut self,)
	-> Result<Rc<OrderSpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OrderSpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 324, RULE_orderSpecification);
        let mut _localctx: Rc<OrderSpecificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2537);
			_la = recog.base.input.la(1);
			if { !(_la==KW_ASC || _la==KW_DESC) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nullOrdering ----------------
pub type NullOrderingContextAll<'input> = NullOrderingContext<'input>;


pub type NullOrderingContext<'input> = BaseParserRuleContext<'input,NullOrderingContextExt<'input>>;

#[derive(Clone)]
pub struct NullOrderingContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for NullOrderingContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for NullOrderingContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nullOrdering(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_nullOrdering(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for NullOrderingContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nullOrdering }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nullOrdering }
}
crate::tid!{NullOrderingContextExt<'a>}

impl<'input> NullOrderingContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NullOrderingContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NullOrderingContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NullOrderingContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<NullOrderingContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_NULLS
/// Returns `None` if there is no child corresponding to token KW_NULLS
fn KW_NULLS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FIRST
/// Returns `None` if there is no child corresponding to token KW_FIRST
fn KW_FIRST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LAST
/// Returns `None` if there is no child corresponding to token KW_LAST
fn KW_LAST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LAST, 0)
}

}

impl<'input> NullOrderingContextAttrs<'input> for NullOrderingContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nullOrdering(&mut self,)
	-> Result<Rc<NullOrderingContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NullOrderingContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 326, RULE_nullOrdering);
        let mut _localctx: Rc<NullOrderingContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2539);
			recog.base.match_token(KW_NULLS,&mut recog.err_handler)?;

			recog.base.set_state(2540);
			_la = recog.base.input.la(1);
			if { !(_la==KW_FIRST || _la==KW_LAST) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameOrder ----------------
pub type ColumnNameOrderContextAll<'input> = ColumnNameOrderContext<'input>;


pub type ColumnNameOrderContext<'input> = BaseParserRuleContext<'input,ColumnNameOrderContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameOrderContextExt<'input>{
	pub orderSpec: Option<Rc<OrderSpecificationContextAll<'input>>>,
	pub nullSpec: Option<Rc<NullOrderingContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameOrderContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameOrderContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameOrder(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameOrder(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameOrderContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameOrder }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameOrder }
}
crate::tid!{ColumnNameOrderContextExt<'a>}

impl<'input> ColumnNameOrderContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameOrderContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameOrderContextExt{
				orderSpec: None, nullSpec: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameOrderContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameOrderContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orderSpecification(&self) -> Option<Rc<OrderSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn nullOrdering(&self) -> Option<Rc<NullOrderingContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnNameOrderContextAttrs<'input> for ColumnNameOrderContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameOrder(&mut self,)
	-> Result<Rc<ColumnNameOrderContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameOrderContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 328, RULE_columnNameOrder);
        let mut _localctx: Rc<ColumnNameOrderContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(2542);
			recog.id_()?;

			recog.base.set_state(2544);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ASC || _la==KW_DESC {
				{
				/*InvokeRule orderSpecification*/
				recog.base.set_state(2543);
				let tmp = recog.orderSpecification()?;
				 cast_mut::<_,ColumnNameOrderContext >(&mut _localctx).orderSpec = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2547);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_NULLS {
				{
				/*InvokeRule nullOrdering*/
				recog.base.set_state(2546);
				let tmp = recog.nullOrdering()?;
				 cast_mut::<_,ColumnNameOrderContext >(&mut _localctx).nullSpec = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameCommentList ----------------
pub type ColumnNameCommentListContextAll<'input> = ColumnNameCommentListContext<'input>;


pub type ColumnNameCommentListContext<'input> = BaseParserRuleContext<'input,ColumnNameCommentListContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameCommentListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameCommentListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameCommentListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameCommentList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameCommentList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameCommentListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameCommentList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameCommentList }
}
crate::tid!{ColumnNameCommentListContextExt<'a>}

impl<'input> ColumnNameCommentListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameCommentListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameCommentListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameCommentListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameCommentListContextExt<'input>>{

fn columnNameComment_all(&self) ->  Vec<Rc<ColumnNameCommentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnNameComment(&self, i: usize) -> Option<Rc<ColumnNameCommentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnNameCommentListContextAttrs<'input> for ColumnNameCommentListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameCommentList(&mut self,)
	-> Result<Rc<ColumnNameCommentListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameCommentListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 330, RULE_columnNameCommentList);
        let mut _localctx: Rc<ColumnNameCommentListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnNameComment*/
			recog.base.set_state(2549);
			recog.columnNameComment()?;

			recog.base.set_state(2554);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2550);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnNameComment*/
				recog.base.set_state(2551);
				recog.columnNameComment()?;

				}
				}
				recog.base.set_state(2556);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameComment ----------------
pub type ColumnNameCommentContextAll<'input> = ColumnNameCommentContext<'input>;


pub type ColumnNameCommentContext<'input> = BaseParserRuleContext<'input,ColumnNameCommentContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameCommentContextExt<'input>{
	pub colName: Option<Rc<Id_ContextAll<'input>>>,
	pub comment: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameCommentContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameCommentContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameComment(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameComment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameCommentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameComment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameComment }
}
crate::tid!{ColumnNameCommentContextExt<'a>}

impl<'input> ColumnNameCommentContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameCommentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameCommentContextExt{
				comment: None, 
				colName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameCommentContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameCommentContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMMENT
/// Returns `None` if there is no child corresponding to token KW_COMMENT
fn KW_COMMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> ColumnNameCommentContextAttrs<'input> for ColumnNameCommentContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameComment(&mut self,)
	-> Result<Rc<ColumnNameCommentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameCommentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 332, RULE_columnNameComment);
        let mut _localctx: Rc<ColumnNameCommentContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(2557);
			let tmp = recog.id_()?;
			 cast_mut::<_,ColumnNameCommentContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			recog.base.set_state(2560);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COMMENT {
				{
				recog.base.set_state(2558);
				recog.base.match_token(KW_COMMENT,&mut recog.err_handler)?;

				recog.base.set_state(2559);
				let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
				 cast_mut::<_,ColumnNameCommentContext >(&mut _localctx).comment = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- orderSpecificationRewrite ----------------
pub type OrderSpecificationRewriteContextAll<'input> = OrderSpecificationRewriteContext<'input>;


pub type OrderSpecificationRewriteContext<'input> = BaseParserRuleContext<'input,OrderSpecificationRewriteContextExt<'input>>;

#[derive(Clone)]
pub struct OrderSpecificationRewriteContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for OrderSpecificationRewriteContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for OrderSpecificationRewriteContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_orderSpecificationRewrite(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_orderSpecificationRewrite(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for OrderSpecificationRewriteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_orderSpecificationRewrite }
	//fn type_rule_index() -> usize where Self: Sized { RULE_orderSpecificationRewrite }
}
crate::tid!{OrderSpecificationRewriteContextExt<'a>}

impl<'input> OrderSpecificationRewriteContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OrderSpecificationRewriteContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OrderSpecificationRewriteContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait OrderSpecificationRewriteContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<OrderSpecificationRewriteContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ASC
/// Returns `None` if there is no child corresponding to token KW_ASC
fn KW_ASC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DESC
/// Returns `None` if there is no child corresponding to token KW_DESC
fn KW_DESC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DESC, 0)
}

}

impl<'input> OrderSpecificationRewriteContextAttrs<'input> for OrderSpecificationRewriteContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn orderSpecificationRewrite(&mut self,)
	-> Result<Rc<OrderSpecificationRewriteContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OrderSpecificationRewriteContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 334, RULE_orderSpecificationRewrite);
        let mut _localctx: Rc<OrderSpecificationRewriteContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2562);
			_la = recog.base.input.la(1);
			if { !(_la==KW_ASC || _la==KW_DESC) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnRefOrder ----------------
pub type ColumnRefOrderContextAll<'input> = ColumnRefOrderContext<'input>;


pub type ColumnRefOrderContext<'input> = BaseParserRuleContext<'input,ColumnRefOrderContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnRefOrderContextExt<'input>{
	pub orderSpec: Option<Rc<OrderSpecificationRewriteContextAll<'input>>>,
	pub nullSpec: Option<Rc<NullOrderingContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnRefOrderContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnRefOrderContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnRefOrder(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnRefOrder(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnRefOrderContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnRefOrder }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnRefOrder }
}
crate::tid!{ColumnRefOrderContextExt<'a>}

impl<'input> ColumnRefOrderContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnRefOrderContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnRefOrderContextExt{
				orderSpec: None, nullSpec: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnRefOrderContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnRefOrderContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orderSpecificationRewrite(&self) -> Option<Rc<OrderSpecificationRewriteContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn nullOrdering(&self) -> Option<Rc<NullOrderingContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnRefOrderContextAttrs<'input> for ColumnRefOrderContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnRefOrder(&mut self,)
	-> Result<Rc<ColumnRefOrderContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnRefOrderContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 336, RULE_columnRefOrder);
        let mut _localctx: Rc<ColumnRefOrderContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(2564);
			recog.expression()?;

			recog.base.set_state(2566);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(226,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule orderSpecificationRewrite*/
					recog.base.set_state(2565);
					let tmp = recog.orderSpecificationRewrite()?;
					 cast_mut::<_,ColumnRefOrderContext >(&mut _localctx).orderSpec = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			recog.base.set_state(2569);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_NULLS {
				{
				/*InvokeRule nullOrdering*/
				recog.base.set_state(2568);
				let tmp = recog.nullOrdering()?;
				 cast_mut::<_,ColumnRefOrderContext >(&mut _localctx).nullSpec = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameType ----------------
pub type ColumnNameTypeContextAll<'input> = ColumnNameTypeContext<'input>;


pub type ColumnNameTypeContext<'input> = BaseParserRuleContext<'input,ColumnNameTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameTypeContextExt<'input>{
	pub colName: Option<Rc<Id_ContextAll<'input>>>,
	pub comment: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameType }
}
crate::tid!{ColumnNameTypeContextExt<'a>}

impl<'input> ColumnNameTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameTypeContextExt{
				comment: None, 
				colName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameTypeContextExt<'input>>{

fn colType(&self) -> Option<Rc<ColTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMMENT
/// Returns `None` if there is no child corresponding to token KW_COMMENT
fn KW_COMMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> ColumnNameTypeContextAttrs<'input> for ColumnNameTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameType(&mut self,)
	-> Result<Rc<ColumnNameTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 338, RULE_columnNameType);
        let mut _localctx: Rc<ColumnNameTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(2571);
			let tmp = recog.id_()?;
			 cast_mut::<_,ColumnNameTypeContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			/*InvokeRule colType*/
			recog.base.set_state(2572);
			recog.colType()?;

			recog.base.set_state(2575);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COMMENT {
				{
				recog.base.set_state(2573);
				recog.base.match_token(KW_COMMENT,&mut recog.err_handler)?;

				recog.base.set_state(2574);
				let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
				 cast_mut::<_,ColumnNameTypeContext >(&mut _localctx).comment = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameTypeOrConstraint ----------------
pub type ColumnNameTypeOrConstraintContextAll<'input> = ColumnNameTypeOrConstraintContext<'input>;


pub type ColumnNameTypeOrConstraintContext<'input> = BaseParserRuleContext<'input,ColumnNameTypeOrConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameTypeOrConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameTypeOrConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameTypeOrConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameTypeOrConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameTypeOrConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameTypeOrConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameTypeOrConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameTypeOrConstraint }
}
crate::tid!{ColumnNameTypeOrConstraintContextExt<'a>}

impl<'input> ColumnNameTypeOrConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameTypeOrConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameTypeOrConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameTypeOrConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameTypeOrConstraintContextExt<'input>>{

fn tableConstraint(&self) -> Option<Rc<TableConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnNameTypeConstraint(&self) -> Option<Rc<ColumnNameTypeConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnNameTypeOrConstraintContextAttrs<'input> for ColumnNameTypeOrConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameTypeOrConstraint(&mut self,)
	-> Result<Rc<ColumnNameTypeOrConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameTypeOrConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 340, RULE_columnNameTypeOrConstraint);
        let mut _localctx: Rc<ColumnNameTypeOrConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2579);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(229,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule tableConstraint*/
					recog.base.set_state(2577);
					recog.tableConstraint()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule columnNameTypeConstraint*/
					recog.base.set_state(2578);
					recog.columnNameTypeConstraint()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableConstraint ----------------
pub type TableConstraintContextAll<'input> = TableConstraintContext<'input>;


pub type TableConstraintContext<'input> = BaseParserRuleContext<'input,TableConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct TableConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableConstraint }
}
crate::tid!{TableConstraintContextExt<'a>}

impl<'input> TableConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableConstraintContextExt<'input>>{

fn createForeignKey(&self) -> Option<Rc<CreateForeignKeyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createConstraint(&self) -> Option<Rc<CreateConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableConstraintContextAttrs<'input> for TableConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableConstraint(&mut self,)
	-> Result<Rc<TableConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 342, RULE_tableConstraint);
        let mut _localctx: Rc<TableConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2583);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(230,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule createForeignKey*/
					recog.base.set_state(2581);
					recog.createForeignKey()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule createConstraint*/
					recog.base.set_state(2582);
					recog.createConstraint()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameTypeConstraint ----------------
pub type ColumnNameTypeConstraintContextAll<'input> = ColumnNameTypeConstraintContext<'input>;


pub type ColumnNameTypeConstraintContext<'input> = BaseParserRuleContext<'input,ColumnNameTypeConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameTypeConstraintContextExt<'input>{
	pub colName: Option<Rc<Id_ContextAll<'input>>>,
	pub comment: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameTypeConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameTypeConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameTypeConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameTypeConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameTypeConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameTypeConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameTypeConstraint }
}
crate::tid!{ColumnNameTypeConstraintContextExt<'a>}

impl<'input> ColumnNameTypeConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameTypeConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameTypeConstraintContextExt{
				comment: None, 
				colName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameTypeConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameTypeConstraintContextExt<'input>>{

fn colType(&self) -> Option<Rc<ColTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnConstraint(&self) -> Option<Rc<ColumnConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMMENT
/// Returns `None` if there is no child corresponding to token KW_COMMENT
fn KW_COMMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> ColumnNameTypeConstraintContextAttrs<'input> for ColumnNameTypeConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameTypeConstraint(&mut self,)
	-> Result<Rc<ColumnNameTypeConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameTypeConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 344, RULE_columnNameTypeConstraint);
        let mut _localctx: Rc<ColumnNameTypeConstraintContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(2585);
			let tmp = recog.id_()?;
			 cast_mut::<_,ColumnNameTypeConstraintContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			/*InvokeRule colType*/
			recog.base.set_state(2586);
			recog.colType()?;

			recog.base.set_state(2588);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CHECK || _la==KW_CONSTRAINT || _la==KW_DEFAULT || _la==KW_NOT || _la==KW_PRIMARY || _la==KW_REFERENCES || _la==KW_UNIQUE {
				{
				/*InvokeRule columnConstraint*/
				recog.base.set_state(2587);
				recog.columnConstraint()?;

				}
			}

			recog.base.set_state(2592);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COMMENT {
				{
				recog.base.set_state(2590);
				recog.base.match_token(KW_COMMENT,&mut recog.err_handler)?;

				recog.base.set_state(2591);
				let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
				 cast_mut::<_,ColumnNameTypeConstraintContext >(&mut _localctx).comment = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnConstraint ----------------
pub type ColumnConstraintContextAll<'input> = ColumnConstraintContext<'input>;


pub type ColumnConstraintContext<'input> = BaseParserRuleContext<'input,ColumnConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnConstraint }
}
crate::tid!{ColumnConstraintContextExt<'a>}

impl<'input> ColumnConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnConstraintContextExt<'input>>{

fn foreignKeyConstraint(&self) -> Option<Rc<ForeignKeyConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn colConstraint(&self) -> Option<Rc<ColConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnConstraintContextAttrs<'input> for ColumnConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnConstraint(&mut self,)
	-> Result<Rc<ColumnConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 346, RULE_columnConstraint);
        let mut _localctx: Rc<ColumnConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2596);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(233,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule foreignKeyConstraint*/
					recog.base.set_state(2594);
					recog.foreignKeyConstraint()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule colConstraint*/
					recog.base.set_state(2595);
					recog.colConstraint()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- foreignKeyConstraint ----------------
pub type ForeignKeyConstraintContextAll<'input> = ForeignKeyConstraintContext<'input>;


pub type ForeignKeyConstraintContext<'input> = BaseParserRuleContext<'input,ForeignKeyConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct ForeignKeyConstraintContextExt<'input>{
	pub constraintName: Option<Rc<Id_ContextAll<'input>>>,
	pub tabName: Option<Rc<TableNameContextAll<'input>>>,
	pub colName: Option<Rc<ColumnNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ForeignKeyConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ForeignKeyConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_foreignKeyConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_foreignKeyConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ForeignKeyConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_foreignKeyConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_foreignKeyConstraint }
}
crate::tid!{ForeignKeyConstraintContextExt<'a>}

impl<'input> ForeignKeyConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ForeignKeyConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ForeignKeyConstraintContextExt{
				constraintName: None, tabName: None, colName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ForeignKeyConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ForeignKeyConstraintContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_REFERENCES
/// Returns `None` if there is no child corresponding to token KW_REFERENCES
fn KW_REFERENCES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REFERENCES, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_CONSTRAINT
/// Returns `None` if there is no child corresponding to token KW_CONSTRAINT
fn KW_CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONSTRAINT, 0)
}
fn constraintOptsCreate(&self) -> Option<Rc<ConstraintOptsCreateContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ForeignKeyConstraintContextAttrs<'input> for ForeignKeyConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn foreignKeyConstraint(&mut self,)
	-> Result<Rc<ForeignKeyConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ForeignKeyConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 348, RULE_foreignKeyConstraint);
        let mut _localctx: Rc<ForeignKeyConstraintContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2600);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CONSTRAINT {
				{
				recog.base.set_state(2598);
				recog.base.match_token(KW_CONSTRAINT,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(2599);
				let tmp = recog.id_()?;
				 cast_mut::<_,ForeignKeyConstraintContext >(&mut _localctx).constraintName = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2602);
			recog.base.match_token(KW_REFERENCES,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(2603);
			let tmp = recog.tableName()?;
			 cast_mut::<_,ForeignKeyConstraintContext >(&mut _localctx).tabName = Some(tmp.clone());
			  

			recog.base.set_state(2604);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnName*/
			recog.base.set_state(2605);
			let tmp = recog.columnName()?;
			 cast_mut::<_,ForeignKeyConstraintContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			recog.base.set_state(2606);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2608);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 91)) & !0x3f) == 0 && ((1usize << (_la - 91)) & ((1usize << (KW_DISABLE - 91)) | (1usize << (KW_ENABLE - 91)) | (1usize << (KW_ENFORCED - 91)))) != 0) || _la==KW_NOT {
				{
				/*InvokeRule constraintOptsCreate*/
				recog.base.set_state(2607);
				recog.constraintOptsCreate()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colConstraint ----------------
pub type ColConstraintContextAll<'input> = ColConstraintContext<'input>;


pub type ColConstraintContext<'input> = BaseParserRuleContext<'input,ColConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct ColConstraintContextExt<'input>{
	pub constraintName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_colConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colConstraint }
}
crate::tid!{ColConstraintContextExt<'a>}

impl<'input> ColConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColConstraintContextExt{
				constraintName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColConstraintContextExt<'input>>{

fn columnConstraintType(&self) -> Option<Rc<ColumnConstraintTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_CONSTRAINT
/// Returns `None` if there is no child corresponding to token KW_CONSTRAINT
fn KW_CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONSTRAINT, 0)
}
fn constraintOptsCreate(&self) -> Option<Rc<ConstraintOptsCreateContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColConstraintContextAttrs<'input> for ColConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colConstraint(&mut self,)
	-> Result<Rc<ColConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 350, RULE_colConstraint);
        let mut _localctx: Rc<ColConstraintContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2612);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CONSTRAINT {
				{
				recog.base.set_state(2610);
				recog.base.match_token(KW_CONSTRAINT,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(2611);
				let tmp = recog.id_()?;
				 cast_mut::<_,ColConstraintContext >(&mut _localctx).constraintName = Some(tmp.clone());
				  

				}
			}

			/*InvokeRule columnConstraintType*/
			recog.base.set_state(2614);
			recog.columnConstraintType()?;

			recog.base.set_state(2616);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 91)) & !0x3f) == 0 && ((1usize << (_la - 91)) & ((1usize << (KW_DISABLE - 91)) | (1usize << (KW_ENABLE - 91)) | (1usize << (KW_ENFORCED - 91)))) != 0) || _la==KW_NOT {
				{
				/*InvokeRule constraintOptsCreate*/
				recog.base.set_state(2615);
				recog.constraintOptsCreate()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterColumnConstraint ----------------
pub type AlterColumnConstraintContextAll<'input> = AlterColumnConstraintContext<'input>;


pub type AlterColumnConstraintContext<'input> = BaseParserRuleContext<'input,AlterColumnConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct AlterColumnConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterColumnConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterColumnConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterColumnConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterColumnConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterColumnConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterColumnConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterColumnConstraint }
}
crate::tid!{AlterColumnConstraintContextExt<'a>}

impl<'input> AlterColumnConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterColumnConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterColumnConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterColumnConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterColumnConstraintContextExt<'input>>{

fn alterForeignKeyConstraint(&self) -> Option<Rc<AlterForeignKeyConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterColConstraint(&self) -> Option<Rc<AlterColConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterColumnConstraintContextAttrs<'input> for AlterColumnConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterColumnConstraint(&mut self,)
	-> Result<Rc<AlterColumnConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterColumnConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 352, RULE_alterColumnConstraint);
        let mut _localctx: Rc<AlterColumnConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2620);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(238,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule alterForeignKeyConstraint*/
					recog.base.set_state(2618);
					recog.alterForeignKeyConstraint()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule alterColConstraint*/
					recog.base.set_state(2619);
					recog.alterColConstraint()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterForeignKeyConstraint ----------------
pub type AlterForeignKeyConstraintContextAll<'input> = AlterForeignKeyConstraintContext<'input>;


pub type AlterForeignKeyConstraintContext<'input> = BaseParserRuleContext<'input,AlterForeignKeyConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct AlterForeignKeyConstraintContextExt<'input>{
	pub constraintName: Option<Rc<Id_ContextAll<'input>>>,
	pub tabName: Option<Rc<TableNameContextAll<'input>>>,
	pub colName: Option<Rc<ColumnNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterForeignKeyConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterForeignKeyConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterForeignKeyConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterForeignKeyConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterForeignKeyConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterForeignKeyConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterForeignKeyConstraint }
}
crate::tid!{AlterForeignKeyConstraintContextExt<'a>}

impl<'input> AlterForeignKeyConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterForeignKeyConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterForeignKeyConstraintContextExt{
				constraintName: None, tabName: None, colName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterForeignKeyConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterForeignKeyConstraintContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_REFERENCES
/// Returns `None` if there is no child corresponding to token KW_REFERENCES
fn KW_REFERENCES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REFERENCES, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnName(&self) -> Option<Rc<ColumnNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_CONSTRAINT
/// Returns `None` if there is no child corresponding to token KW_CONSTRAINT
fn KW_CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONSTRAINT, 0)
}
fn constraintOptsAlter(&self) -> Option<Rc<ConstraintOptsAlterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterForeignKeyConstraintContextAttrs<'input> for AlterForeignKeyConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterForeignKeyConstraint(&mut self,)
	-> Result<Rc<AlterForeignKeyConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterForeignKeyConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 354, RULE_alterForeignKeyConstraint);
        let mut _localctx: Rc<AlterForeignKeyConstraintContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2624);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CONSTRAINT {
				{
				recog.base.set_state(2622);
				recog.base.match_token(KW_CONSTRAINT,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(2623);
				let tmp = recog.id_()?;
				 cast_mut::<_,AlterForeignKeyConstraintContext >(&mut _localctx).constraintName = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2626);
			recog.base.match_token(KW_REFERENCES,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(2627);
			let tmp = recog.tableName()?;
			 cast_mut::<_,AlterForeignKeyConstraintContext >(&mut _localctx).tabName = Some(tmp.clone());
			  

			recog.base.set_state(2628);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnName*/
			recog.base.set_state(2629);
			let tmp = recog.columnName()?;
			 cast_mut::<_,AlterForeignKeyConstraintContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			recog.base.set_state(2630);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2632);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(240,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule constraintOptsAlter*/
					recog.base.set_state(2631);
					recog.constraintOptsAlter()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterColConstraint ----------------
pub type AlterColConstraintContextAll<'input> = AlterColConstraintContext<'input>;


pub type AlterColConstraintContext<'input> = BaseParserRuleContext<'input,AlterColConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct AlterColConstraintContextExt<'input>{
	pub constraintName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterColConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterColConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterColConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterColConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterColConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterColConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterColConstraint }
}
crate::tid!{AlterColConstraintContextExt<'a>}

impl<'input> AlterColConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterColConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterColConstraintContextExt{
				constraintName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterColConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterColConstraintContextExt<'input>>{

fn columnConstraintType(&self) -> Option<Rc<ColumnConstraintTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_CONSTRAINT
/// Returns `None` if there is no child corresponding to token KW_CONSTRAINT
fn KW_CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONSTRAINT, 0)
}
fn constraintOptsAlter(&self) -> Option<Rc<ConstraintOptsAlterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterColConstraintContextAttrs<'input> for AlterColConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterColConstraint(&mut self,)
	-> Result<Rc<AlterColConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterColConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 356, RULE_alterColConstraint);
        let mut _localctx: Rc<AlterColConstraintContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2636);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CONSTRAINT {
				{
				recog.base.set_state(2634);
				recog.base.match_token(KW_CONSTRAINT,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(2635);
				let tmp = recog.id_()?;
				 cast_mut::<_,AlterColConstraintContext >(&mut _localctx).constraintName = Some(tmp.clone());
				  

				}
			}

			/*InvokeRule columnConstraintType*/
			recog.base.set_state(2638);
			recog.columnConstraintType()?;

			recog.base.set_state(2640);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(242,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule constraintOptsAlter*/
					recog.base.set_state(2639);
					recog.constraintOptsAlter()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnConstraintType ----------------
pub type ColumnConstraintTypeContextAll<'input> = ColumnConstraintTypeContext<'input>;


pub type ColumnConstraintTypeContext<'input> = BaseParserRuleContext<'input,ColumnConstraintTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnConstraintTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnConstraintTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnConstraintTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnConstraintType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnConstraintType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnConstraintTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnConstraintType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnConstraintType }
}
crate::tid!{ColumnConstraintTypeContextExt<'a>}

impl<'input> ColumnConstraintTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnConstraintTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnConstraintTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnConstraintTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnConstraintTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_NOT
/// Returns `None` if there is no child corresponding to token KW_NOT
fn KW_NOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NULL
/// Returns `None` if there is no child corresponding to token KW_NULL
fn KW_NULL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEFAULT
/// Returns `None` if there is no child corresponding to token KW_DEFAULT
fn KW_DEFAULT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEFAULT, 0)
}
fn defaultVal(&self) -> Option<Rc<DefaultValContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn checkConstraint(&self) -> Option<Rc<CheckConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableConstraintType(&self) -> Option<Rc<TableConstraintTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnConstraintTypeContextAttrs<'input> for ColumnConstraintTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnConstraintType(&mut self,)
	-> Result<Rc<ColumnConstraintTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnConstraintTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 358, RULE_columnConstraintType);
        let mut _localctx: Rc<ColumnConstraintTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2648);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_NOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2642);
					recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

					recog.base.set_state(2643);
					recog.base.match_token(KW_NULL,&mut recog.err_handler)?;

					}
				}

			 KW_DEFAULT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2644);
					recog.base.match_token(KW_DEFAULT,&mut recog.err_handler)?;

					/*InvokeRule defaultVal*/
					recog.base.set_state(2645);
					recog.defaultVal()?;

					}
				}

			 KW_CHECK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule checkConstraint*/
					recog.base.set_state(2646);
					recog.checkConstraint()?;

					}
				}

			 KW_PRIMARY | KW_UNIQUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule tableConstraintType*/
					recog.base.set_state(2647);
					recog.tableConstraintType()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- defaultVal ----------------
pub type DefaultValContextAll<'input> = DefaultValContext<'input>;


pub type DefaultValContext<'input> = BaseParserRuleContext<'input,DefaultValContextExt<'input>>;

#[derive(Clone)]
pub struct DefaultValContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DefaultValContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DefaultValContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_defaultVal(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_defaultVal(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DefaultValContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_defaultVal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_defaultVal }
}
crate::tid!{DefaultValContextExt<'a>}

impl<'input> DefaultValContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DefaultValContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DefaultValContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DefaultValContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DefaultValContextExt<'input>>{

fn constant(&self) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn function_(&self) -> Option<Rc<Function_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn castExpression(&self) -> Option<Rc<CastExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DefaultValContextAttrs<'input> for DefaultValContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn defaultVal(&mut self,)
	-> Result<Rc<DefaultValContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DefaultValContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 360, RULE_defaultVal);
        let mut _localctx: Rc<DefaultValContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2653);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(244,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule constant*/
					recog.base.set_state(2650);
					recog.constant()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule function_*/
					recog.base.set_state(2651);
					recog.function_()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule castExpression*/
					recog.base.set_state(2652);
					recog.castExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableConstraintType ----------------
pub type TableConstraintTypeContextAll<'input> = TableConstraintTypeContext<'input>;


pub type TableConstraintTypeContext<'input> = BaseParserRuleContext<'input,TableConstraintTypeContextExt<'input>>;

#[derive(Clone)]
pub struct TableConstraintTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableConstraintTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableConstraintTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableConstraintType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableConstraintType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableConstraintTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableConstraintType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableConstraintType }
}
crate::tid!{TableConstraintTypeContextExt<'a>}

impl<'input> TableConstraintTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableConstraintTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableConstraintTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableConstraintTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableConstraintTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_PRIMARY
/// Returns `None` if there is no child corresponding to token KW_PRIMARY
fn KW_PRIMARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PRIMARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_KEY
/// Returns `None` if there is no child corresponding to token KW_KEY
fn KW_KEY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KEY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNIQUE
/// Returns `None` if there is no child corresponding to token KW_UNIQUE
fn KW_UNIQUE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNIQUE, 0)
}

}

impl<'input> TableConstraintTypeContextAttrs<'input> for TableConstraintTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableConstraintType(&mut self,)
	-> Result<Rc<TableConstraintTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableConstraintTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 362, RULE_tableConstraintType);
        let mut _localctx: Rc<TableConstraintTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2658);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_PRIMARY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2655);
					recog.base.match_token(KW_PRIMARY,&mut recog.err_handler)?;

					recog.base.set_state(2656);
					recog.base.match_token(KW_KEY,&mut recog.err_handler)?;

					}
				}

			 KW_UNIQUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2657);
					recog.base.match_token(KW_UNIQUE,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- constraintOptsCreate ----------------
pub type ConstraintOptsCreateContextAll<'input> = ConstraintOptsCreateContext<'input>;


pub type ConstraintOptsCreateContext<'input> = BaseParserRuleContext<'input,ConstraintOptsCreateContextExt<'input>>;

#[derive(Clone)]
pub struct ConstraintOptsCreateContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ConstraintOptsCreateContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ConstraintOptsCreateContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_constraintOptsCreate(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_constraintOptsCreate(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ConstraintOptsCreateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constraintOptsCreate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constraintOptsCreate }
}
crate::tid!{ConstraintOptsCreateContextExt<'a>}

impl<'input> ConstraintOptsCreateContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConstraintOptsCreateContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConstraintOptsCreateContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ConstraintOptsCreateContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ConstraintOptsCreateContextExt<'input>>{

fn enableValidateSpecification(&self) -> Option<Rc<EnableValidateSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relySpecification(&self) -> Option<Rc<RelySpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ConstraintOptsCreateContextAttrs<'input> for ConstraintOptsCreateContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn constraintOptsCreate(&mut self,)
	-> Result<Rc<ConstraintOptsCreateContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConstraintOptsCreateContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 364, RULE_constraintOptsCreate);
        let mut _localctx: Rc<ConstraintOptsCreateContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule enableValidateSpecification*/
			recog.base.set_state(2660);
			recog.enableValidateSpecification()?;

			recog.base.set_state(2662);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_NORELY || _la==KW_RELY {
				{
				/*InvokeRule relySpecification*/
				recog.base.set_state(2661);
				recog.relySpecification()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- constraintOptsAlter ----------------
pub type ConstraintOptsAlterContextAll<'input> = ConstraintOptsAlterContext<'input>;


pub type ConstraintOptsAlterContext<'input> = BaseParserRuleContext<'input,ConstraintOptsAlterContextExt<'input>>;

#[derive(Clone)]
pub struct ConstraintOptsAlterContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ConstraintOptsAlterContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ConstraintOptsAlterContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_constraintOptsAlter(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_constraintOptsAlter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ConstraintOptsAlterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constraintOptsAlter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constraintOptsAlter }
}
crate::tid!{ConstraintOptsAlterContextExt<'a>}

impl<'input> ConstraintOptsAlterContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConstraintOptsAlterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConstraintOptsAlterContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ConstraintOptsAlterContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ConstraintOptsAlterContextExt<'input>>{

fn enableValidateSpecification(&self) -> Option<Rc<EnableValidateSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relySpecification(&self) -> Option<Rc<RelySpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ConstraintOptsAlterContextAttrs<'input> for ConstraintOptsAlterContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn constraintOptsAlter(&mut self,)
	-> Result<Rc<ConstraintOptsAlterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConstraintOptsAlterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 366, RULE_constraintOptsAlter);
        let mut _localctx: Rc<ConstraintOptsAlterContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule enableValidateSpecification*/
			recog.base.set_state(2664);
			recog.enableValidateSpecification()?;

			recog.base.set_state(2666);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_NORELY || _la==KW_RELY {
				{
				/*InvokeRule relySpecification*/
				recog.base.set_state(2665);
				recog.relySpecification()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnNameColonType ----------------
pub type ColumnNameColonTypeContextAll<'input> = ColumnNameColonTypeContext<'input>;


pub type ColumnNameColonTypeContext<'input> = BaseParserRuleContext<'input,ColumnNameColonTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnNameColonTypeContextExt<'input>{
	pub colName: Option<Rc<Id_ContextAll<'input>>>,
	pub comment: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnNameColonTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnNameColonTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnNameColonType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnNameColonType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnNameColonTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnNameColonType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnNameColonType }
}
crate::tid!{ColumnNameColonTypeContextExt<'a>}

impl<'input> ColumnNameColonTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnNameColonTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnNameColonTypeContextExt{
				comment: None, 
				colName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnNameColonTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnNameColonTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn colType(&self) -> Option<Rc<ColTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMMENT
/// Returns `None` if there is no child corresponding to token KW_COMMENT
fn KW_COMMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> ColumnNameColonTypeContextAttrs<'input> for ColumnNameColonTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnNameColonType(&mut self,)
	-> Result<Rc<ColumnNameColonTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnNameColonTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 368, RULE_columnNameColonType);
        let mut _localctx: Rc<ColumnNameColonTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(2668);
			let tmp = recog.id_()?;
			 cast_mut::<_,ColumnNameColonTypeContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			recog.base.set_state(2669);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			/*InvokeRule colType*/
			recog.base.set_state(2670);
			recog.colType()?;

			recog.base.set_state(2673);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COMMENT {
				{
				recog.base.set_state(2671);
				recog.base.match_token(KW_COMMENT,&mut recog.err_handler)?;

				recog.base.set_state(2672);
				let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
				 cast_mut::<_,ColumnNameColonTypeContext >(&mut _localctx).comment = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colType ----------------
pub type ColTypeContextAll<'input> = ColTypeContext<'input>;


pub type ColTypeContext<'input> = BaseParserRuleContext<'input,ColTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ColTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_colType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colType }
}
crate::tid!{ColTypeContextExt<'a>}

impl<'input> ColTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColTypeContextExt<'input>>{

fn r#type(&self) -> Option<Rc<TypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColTypeContextAttrs<'input> for ColTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colType(&mut self,)
	-> Result<Rc<ColTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 370, RULE_colType);
        let mut _localctx: Rc<ColTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule type*/
			recog.base.set_state(2675);
			recog.r#type()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colTypeList ----------------
pub type ColTypeListContextAll<'input> = ColTypeListContext<'input>;


pub type ColTypeListContext<'input> = BaseParserRuleContext<'input,ColTypeListContextExt<'input>>;

#[derive(Clone)]
pub struct ColTypeListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColTypeListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColTypeListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colTypeList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_colTypeList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColTypeListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colTypeList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colTypeList }
}
crate::tid!{ColTypeListContextExt<'a>}

impl<'input> ColTypeListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColTypeListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColTypeListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColTypeListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColTypeListContextExt<'input>>{

fn colType_all(&self) ->  Vec<Rc<ColTypeContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn colType(&self, i: usize) -> Option<Rc<ColTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColTypeListContextAttrs<'input> for ColTypeListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colTypeList(&mut self,)
	-> Result<Rc<ColTypeListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColTypeListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 372, RULE_colTypeList);
        let mut _localctx: Rc<ColTypeListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule colType*/
			recog.base.set_state(2677);
			recog.colType()?;

			recog.base.set_state(2682);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2678);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule colType*/
				recog.base.set_state(2679);
				recog.colType()?;

				}
				}
				recog.base.set_state(2684);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- type ----------------
pub type TypeContextAll<'input> = TypeContext<'input>;


pub type TypeContext<'input> = BaseParserRuleContext<'input,TypeContextExt<'input>>;

#[derive(Clone)]
pub struct TypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_type(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_type(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_type }
	//fn type_rule_index() -> usize where Self: Sized { RULE_type }
}
crate::tid!{TypeContextExt<'a>}

impl<'input> TypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TypeContextExt<'input>>{

fn primitiveType(&self) -> Option<Rc<PrimitiveTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn listType(&self) -> Option<Rc<ListTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn structType(&self) -> Option<Rc<StructTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn mapType(&self) -> Option<Rc<MapTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unionType(&self) -> Option<Rc<UnionTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TypeContextAttrs<'input> for TypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn r#type(&mut self,)
	-> Result<Rc<TypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 374, RULE_type);
        let mut _localctx: Rc<TypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2690);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_BIGINT | KW_BINARY | KW_BOOLEAN | KW_CHAR | KW_DATE | KW_DATETIME |
			 KW_DECIMAL | KW_DOUBLE | KW_FLOAT | KW_INT | KW_REAL | KW_SMALLINT |
			 KW_STRING | KW_TIMESTAMP | KW_TIMESTAMPLOCALTZ | KW_TINYINT | KW_VARCHAR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule primitiveType*/
					recog.base.set_state(2685);
					recog.primitiveType()?;

					}
				}

			 KW_ARRAY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule listType*/
					recog.base.set_state(2686);
					recog.listType()?;

					}
				}

			 KW_STRUCT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule structType*/
					recog.base.set_state(2687);
					recog.structType()?;

					}
				}

			 KW_MAP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule mapType*/
					recog.base.set_state(2688);
					recog.mapType()?;

					}
				}

			 KW_UNIONTYPE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule unionType*/
					recog.base.set_state(2689);
					recog.unionType()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- primitiveType ----------------
pub type PrimitiveTypeContextAll<'input> = PrimitiveTypeContext<'input>;


pub type PrimitiveTypeContext<'input> = BaseParserRuleContext<'input,PrimitiveTypeContextExt<'input>>;

#[derive(Clone)]
pub struct PrimitiveTypeContextExt<'input>{
	pub prec: Option<TokenType<'input>>,
	pub scale: Option<TokenType<'input>>,
	pub length: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrimitiveTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrimitiveTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_primitiveType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_primitiveType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrimitiveTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primitiveType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primitiveType }
}
crate::tid!{PrimitiveTypeContextExt<'a>}

impl<'input> PrimitiveTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrimitiveTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrimitiveTypeContextExt{
				prec: None, scale: None, length: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrimitiveTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrimitiveTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TINYINT
/// Returns `None` if there is no child corresponding to token KW_TINYINT
fn KW_TINYINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TINYINT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SMALLINT
/// Returns `None` if there is no child corresponding to token KW_SMALLINT
fn KW_SMALLINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SMALLINT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INT
/// Returns `None` if there is no child corresponding to token KW_INT
fn KW_INT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BIGINT
/// Returns `None` if there is no child corresponding to token KW_BIGINT
fn KW_BIGINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BIGINT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BOOLEAN
/// Returns `None` if there is no child corresponding to token KW_BOOLEAN
fn KW_BOOLEAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BOOLEAN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FLOAT
/// Returns `None` if there is no child corresponding to token KW_FLOAT
fn KW_FLOAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FLOAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REAL
/// Returns `None` if there is no child corresponding to token KW_REAL
fn KW_REAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DOUBLE
/// Returns `None` if there is no child corresponding to token KW_DOUBLE
fn KW_DOUBLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PRECISION
/// Returns `None` if there is no child corresponding to token KW_PRECISION
fn KW_PRECISION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PRECISION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATE
/// Returns `None` if there is no child corresponding to token KW_DATE
fn KW_DATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATETIME
/// Returns `None` if there is no child corresponding to token KW_DATETIME
fn KW_DATETIME(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATETIME, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TIMESTAMP
/// Returns `None` if there is no child corresponding to token KW_TIMESTAMP
fn KW_TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TIMESTAMPLOCALTZ
/// Returns `None` if there is no child corresponding to token KW_TIMESTAMPLOCALTZ
fn KW_TIMESTAMPLOCALTZ(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TIMESTAMPLOCALTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCAL
/// Returns `None` if there is no child corresponding to token KW_LOCAL
fn KW_LOCAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TIME
/// Returns `None` if there is no child corresponding to token KW_TIME
fn KW_TIME(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ZONE
/// Returns `None` if there is no child corresponding to token KW_ZONE
fn KW_ZONE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ZONE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STRING
/// Returns `None` if there is no child corresponding to token KW_STRING
fn KW_STRING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STRING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BINARY
/// Returns `None` if there is no child corresponding to token KW_BINARY
fn KW_BINARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BINARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DECIMAL
/// Returns `None` if there is no child corresponding to token KW_DECIMAL
fn KW_DECIMAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DECIMAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token Number in current rule
fn Number_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token Number, starting from 0.
/// Returns `None` if number of children corresponding to token Number is less or equal than `i`.
fn Number(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, i)
}
/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VARCHAR
/// Returns `None` if there is no child corresponding to token KW_VARCHAR
fn KW_VARCHAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VARCHAR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CHAR
/// Returns `None` if there is no child corresponding to token KW_CHAR
fn KW_CHAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CHAR, 0)
}

}

impl<'input> PrimitiveTypeContextAttrs<'input> for PrimitiveTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn primitiveType(&mut self,)
	-> Result<Rc<PrimitiveTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrimitiveTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 376, RULE_primitiveType);
        let mut _localctx: Rc<PrimitiveTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2728);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(254,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2692);
					recog.base.match_token(KW_TINYINT,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2693);
					recog.base.match_token(KW_SMALLINT,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(2694);
					recog.base.match_token(KW_INT,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(2695);
					recog.base.match_token(KW_BIGINT,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(2696);
					recog.base.match_token(KW_BOOLEAN,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(2697);
					recog.base.match_token(KW_FLOAT,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(2698);
					recog.base.match_token(KW_REAL,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(2699);
					recog.base.match_token(KW_DOUBLE,&mut recog.err_handler)?;

					recog.base.set_state(2701);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_PRECISION {
						{
						recog.base.set_state(2700);
						recog.base.match_token(KW_PRECISION,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					recog.base.set_state(2703);
					recog.base.match_token(KW_DATE,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					recog.base.set_state(2704);
					recog.base.match_token(KW_DATETIME,&mut recog.err_handler)?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					recog.base.set_state(2705);
					recog.base.match_token(KW_TIMESTAMP,&mut recog.err_handler)?;

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					recog.base.set_state(2706);
					recog.base.match_token(KW_TIMESTAMPLOCALTZ,&mut recog.err_handler)?;

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					recog.base.set_state(2707);
					recog.base.match_token(KW_TIMESTAMP,&mut recog.err_handler)?;

					recog.base.set_state(2708);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					recog.base.set_state(2709);
					recog.base.match_token(KW_LOCAL,&mut recog.err_handler)?;

					recog.base.set_state(2710);
					recog.base.match_token(KW_TIME,&mut recog.err_handler)?;

					recog.base.set_state(2711);
					recog.base.match_token(KW_ZONE,&mut recog.err_handler)?;

					}
				}
			,
				14 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					recog.base.set_state(2712);
					recog.base.match_token(KW_STRING,&mut recog.err_handler)?;

					}
				}
			,
				15 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					recog.base.set_state(2713);
					recog.base.match_token(KW_BINARY,&mut recog.err_handler)?;

					}
				}
			,
				16 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 16);
					recog.base.enter_outer_alt(None, 16);
					{
					recog.base.set_state(2714);
					recog.base.match_token(KW_DECIMAL,&mut recog.err_handler)?;

					recog.base.set_state(2722);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(253,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2715);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							recog.base.set_state(2716);
							let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
							 cast_mut::<_,PrimitiveTypeContext >(&mut _localctx).prec = Some(tmp.clone());
							  

							recog.base.set_state(2719);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(2717);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								recog.base.set_state(2718);
								let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
								 cast_mut::<_,PrimitiveTypeContext >(&mut _localctx).scale = Some(tmp.clone());
								  

								}
							}

							recog.base.set_state(2721);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				17 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 17);
					recog.base.enter_outer_alt(None, 17);
					{
					recog.base.set_state(2724);
					_la = recog.base.input.la(1);
					if { !(_la==KW_CHAR || _la==KW_VARCHAR) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2725);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(2726);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,PrimitiveTypeContext >(&mut _localctx).length = Some(tmp.clone());
					  

					recog.base.set_state(2727);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- listType ----------------
pub type ListTypeContextAll<'input> = ListTypeContext<'input>;


pub type ListTypeContext<'input> = BaseParserRuleContext<'input,ListTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ListTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ListTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ListTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_listType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_listType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ListTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_listType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_listType }
}
crate::tid!{ListTypeContextExt<'a>}

impl<'input> ListTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ListTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ListTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ListTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ListTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ARRAY
/// Returns `None` if there is no child corresponding to token KW_ARRAY
fn KW_ARRAY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN
/// Returns `None` if there is no child corresponding to token LESSTHAN
fn LESSTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN, 0)
}
fn r#type(&self) -> Option<Rc<TypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHAN
/// Returns `None` if there is no child corresponding to token GREATERTHAN
fn GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHAN, 0)
}

}

impl<'input> ListTypeContextAttrs<'input> for ListTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn listType(&mut self,)
	-> Result<Rc<ListTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ListTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 378, RULE_listType);
        let mut _localctx: Rc<ListTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2730);
			recog.base.match_token(KW_ARRAY,&mut recog.err_handler)?;

			recog.base.set_state(2731);
			recog.base.match_token(LESSTHAN,&mut recog.err_handler)?;

			/*InvokeRule type*/
			recog.base.set_state(2732);
			recog.r#type()?;

			recog.base.set_state(2733);
			recog.base.match_token(GREATERTHAN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- structType ----------------
pub type StructTypeContextAll<'input> = StructTypeContext<'input>;


pub type StructTypeContext<'input> = BaseParserRuleContext<'input,StructTypeContextExt<'input>>;

#[derive(Clone)]
pub struct StructTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for StructTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for StructTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_structType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_structType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for StructTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_structType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_structType }
}
crate::tid!{StructTypeContextExt<'a>}

impl<'input> StructTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StructTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StructTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StructTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<StructTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_STRUCT
/// Returns `None` if there is no child corresponding to token KW_STRUCT
fn KW_STRUCT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN
/// Returns `None` if there is no child corresponding to token LESSTHAN
fn LESSTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN, 0)
}
fn columnNameColonTypeList(&self) -> Option<Rc<ColumnNameColonTypeListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHAN
/// Returns `None` if there is no child corresponding to token GREATERTHAN
fn GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHAN, 0)
}

}

impl<'input> StructTypeContextAttrs<'input> for StructTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn structType(&mut self,)
	-> Result<Rc<StructTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StructTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 380, RULE_structType);
        let mut _localctx: Rc<StructTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2735);
			recog.base.match_token(KW_STRUCT,&mut recog.err_handler)?;

			recog.base.set_state(2736);
			recog.base.match_token(LESSTHAN,&mut recog.err_handler)?;

			/*InvokeRule columnNameColonTypeList*/
			recog.base.set_state(2737);
			recog.columnNameColonTypeList()?;

			recog.base.set_state(2738);
			recog.base.match_token(GREATERTHAN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mapType ----------------
pub type MapTypeContextAll<'input> = MapTypeContext<'input>;


pub type MapTypeContext<'input> = BaseParserRuleContext<'input,MapTypeContextExt<'input>>;

#[derive(Clone)]
pub struct MapTypeContextExt<'input>{
	pub left: Option<Rc<PrimitiveTypeContextAll<'input>>>,
	pub right: Option<Rc<TypeContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for MapTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for MapTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_mapType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_mapType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for MapTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mapType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mapType }
}
crate::tid!{MapTypeContextExt<'a>}

impl<'input> MapTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MapTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MapTypeContextExt{
				left: None, right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MapTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<MapTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_MAP
/// Returns `None` if there is no child corresponding to token KW_MAP
fn KW_MAP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN
/// Returns `None` if there is no child corresponding to token LESSTHAN
fn LESSTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHAN
/// Returns `None` if there is no child corresponding to token GREATERTHAN
fn GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHAN, 0)
}
fn primitiveType(&self) -> Option<Rc<PrimitiveTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn r#type(&self) -> Option<Rc<TypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MapTypeContextAttrs<'input> for MapTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mapType(&mut self,)
	-> Result<Rc<MapTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MapTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 382, RULE_mapType);
        let mut _localctx: Rc<MapTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2740);
			recog.base.match_token(KW_MAP,&mut recog.err_handler)?;

			recog.base.set_state(2741);
			recog.base.match_token(LESSTHAN,&mut recog.err_handler)?;

			/*InvokeRule primitiveType*/
			recog.base.set_state(2742);
			let tmp = recog.primitiveType()?;
			 cast_mut::<_,MapTypeContext >(&mut _localctx).left = Some(tmp.clone());
			  

			recog.base.set_state(2743);
			recog.base.match_token(COMMA,&mut recog.err_handler)?;

			/*InvokeRule type*/
			recog.base.set_state(2744);
			let tmp = recog.r#type()?;
			 cast_mut::<_,MapTypeContext >(&mut _localctx).right = Some(tmp.clone());
			  

			recog.base.set_state(2745);
			recog.base.match_token(GREATERTHAN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unionType ----------------
pub type UnionTypeContextAll<'input> = UnionTypeContext<'input>;


pub type UnionTypeContext<'input> = BaseParserRuleContext<'input,UnionTypeContextExt<'input>>;

#[derive(Clone)]
pub struct UnionTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for UnionTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for UnionTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unionType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_unionType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for UnionTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unionType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unionType }
}
crate::tid!{UnionTypeContextExt<'a>}

impl<'input> UnionTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnionTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnionTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnionTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<UnionTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UNIONTYPE
/// Returns `None` if there is no child corresponding to token KW_UNIONTYPE
fn KW_UNIONTYPE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNIONTYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN
/// Returns `None` if there is no child corresponding to token LESSTHAN
fn LESSTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN, 0)
}
fn colTypeList(&self) -> Option<Rc<ColTypeListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHAN
/// Returns `None` if there is no child corresponding to token GREATERTHAN
fn GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHAN, 0)
}

}

impl<'input> UnionTypeContextAttrs<'input> for UnionTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unionType(&mut self,)
	-> Result<Rc<UnionTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnionTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 384, RULE_unionType);
        let mut _localctx: Rc<UnionTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2747);
			recog.base.match_token(KW_UNIONTYPE,&mut recog.err_handler)?;

			recog.base.set_state(2748);
			recog.base.match_token(LESSTHAN,&mut recog.err_handler)?;

			/*InvokeRule colTypeList*/
			recog.base.set_state(2749);
			recog.colTypeList()?;

			recog.base.set_state(2750);
			recog.base.match_token(GREATERTHAN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setOperator ----------------
pub type SetOperatorContextAll<'input> = SetOperatorContext<'input>;


pub type SetOperatorContext<'input> = BaseParserRuleContext<'input,SetOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SetOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SetOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SetOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_setOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SetOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setOperator }
}
crate::tid!{SetOperatorContextExt<'a>}

impl<'input> SetOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SetOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UNION
/// Returns `None` if there is no child corresponding to token KW_UNION
fn KW_UNION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INTERSECT
/// Returns `None` if there is no child corresponding to token KW_INTERSECT
fn KW_INTERSECT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INTERSECT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXCEPT
/// Returns `None` if there is no child corresponding to token KW_EXCEPT
fn KW_EXCEPT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXCEPT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MINUS
/// Returns `None` if there is no child corresponding to token KW_MINUS
fn KW_MINUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MINUS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ALL
/// Returns `None` if there is no child corresponding to token KW_ALL
fn KW_ALL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DISTINCT
/// Returns `None` if there is no child corresponding to token KW_DISTINCT
fn KW_DISTINCT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISTINCT, 0)
}

}

impl<'input> SetOperatorContextAttrs<'input> for SetOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setOperator(&mut self,)
	-> Result<Rc<SetOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 386, RULE_setOperator);
        let mut _localctx: Rc<SetOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2752);
			_la = recog.base.input.la(1);
			if { !(_la==KW_EXCEPT || _la==KW_INTERSECT || _la==KW_MINUS || _la==KW_UNION) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2754);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ALL || _la==KW_DISTINCT {
				{
				recog.base.set_state(2753);
				_la = recog.base.input.la(1);
				if { !(_la==KW_ALL || _la==KW_DISTINCT) } {
					recog.err_handler.recover_inline(&mut recog.base)?;

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryStatementExpression ----------------
pub type QueryStatementExpressionContextAll<'input> = QueryStatementExpressionContext<'input>;


pub type QueryStatementExpressionContext<'input> = BaseParserRuleContext<'input,QueryStatementExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct QueryStatementExpressionContextExt<'input>{
	pub w: Option<Rc<WithClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for QueryStatementExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for QueryStatementExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryStatementExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_queryStatementExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for QueryStatementExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryStatementExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryStatementExpression }
}
crate::tid!{QueryStatementExpressionContextExt<'a>}

impl<'input> QueryStatementExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryStatementExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryStatementExpressionContextExt{
				w: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryStatementExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<QueryStatementExpressionContextExt<'input>>{

fn queryStatementExpressionBody(&self) -> Option<Rc<QueryStatementExpressionBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn withClause(&self) -> Option<Rc<WithClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryStatementExpressionContextAttrs<'input> for QueryStatementExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryStatementExpression(&mut self,)
	-> Result<Rc<QueryStatementExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryStatementExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 388, RULE_queryStatementExpression);
        let mut _localctx: Rc<QueryStatementExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2757);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_WITH {
				{
				/*InvokeRule withClause*/
				recog.base.set_state(2756);
				let tmp = recog.withClause()?;
				 cast_mut::<_,QueryStatementExpressionContext >(&mut _localctx).w = Some(tmp.clone());
				  

				}
			}

			/*InvokeRule queryStatementExpressionBody*/
			recog.base.set_state(2759);
			recog.queryStatementExpressionBody()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryStatementExpressionBody ----------------
pub type QueryStatementExpressionBodyContextAll<'input> = QueryStatementExpressionBodyContext<'input>;


pub type QueryStatementExpressionBodyContext<'input> = BaseParserRuleContext<'input,QueryStatementExpressionBodyContextExt<'input>>;

#[derive(Clone)]
pub struct QueryStatementExpressionBodyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for QueryStatementExpressionBodyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for QueryStatementExpressionBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryStatementExpressionBody(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_queryStatementExpressionBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for QueryStatementExpressionBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryStatementExpressionBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryStatementExpressionBody }
}
crate::tid!{QueryStatementExpressionBodyContextExt<'a>}

impl<'input> QueryStatementExpressionBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryStatementExpressionBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryStatementExpressionBodyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryStatementExpressionBodyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<QueryStatementExpressionBodyContextExt<'input>>{

fn fromStatement(&self) -> Option<Rc<FromStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn regularBody(&self) -> Option<Rc<RegularBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryStatementExpressionBodyContextAttrs<'input> for QueryStatementExpressionBodyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryStatementExpressionBody(&mut self,)
	-> Result<Rc<QueryStatementExpressionBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryStatementExpressionBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 390, RULE_queryStatementExpressionBody);
        let mut _localctx: Rc<QueryStatementExpressionBodyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2763);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_FROM 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule fromStatement*/
					recog.base.set_state(2761);
					recog.fromStatement()?;

					}
				}

			 KW_INSERT | KW_MAP | KW_REDUCE | KW_SELECT | KW_VALUES | LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule regularBody*/
					recog.base.set_state(2762);
					recog.regularBody()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- withClause ----------------
pub type WithClauseContextAll<'input> = WithClauseContext<'input>;


pub type WithClauseContext<'input> = BaseParserRuleContext<'input,WithClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WithClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for WithClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for WithClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_withClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_withClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for WithClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_withClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_withClause }
}
crate::tid!{WithClauseContextExt<'a>}

impl<'input> WithClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WithClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WithClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WithClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<WithClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
fn cteStatement_all(&self) ->  Vec<Rc<CteStatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn cteStatement(&self, i: usize) -> Option<Rc<CteStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> WithClauseContextAttrs<'input> for WithClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn withClause(&mut self,)
	-> Result<Rc<WithClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WithClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 392, RULE_withClause);
        let mut _localctx: Rc<WithClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2765);
			recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

			/*InvokeRule cteStatement*/
			recog.base.set_state(2766);
			recog.cteStatement()?;

			recog.base.set_state(2771);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2767);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule cteStatement*/
				recog.base.set_state(2768);
				recog.cteStatement()?;

				}
				}
				recog.base.set_state(2773);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- cteStatement ----------------
pub type CteStatementContextAll<'input> = CteStatementContext<'input>;


pub type CteStatementContext<'input> = BaseParserRuleContext<'input,CteStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CteStatementContextExt<'input>{
	pub colAliases: Option<Rc<ColumnNameListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CteStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CteStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_cteStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_cteStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CteStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_cteStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_cteStatement }
}
crate::tid!{CteStatementContextExt<'a>}

impl<'input> CteStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CteStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CteStatementContextExt{
				colAliases: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CteStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CteStatementContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
fn queryStatementExpression(&self) -> Option<Rc<QueryStatementExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CteStatementContextAttrs<'input> for CteStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn cteStatement(&mut self,)
	-> Result<Rc<CteStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CteStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 394, RULE_cteStatement);
        let mut _localctx: Rc<CteStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(2774);
			recog.id_()?;

			recog.base.set_state(2779);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LPAREN {
				{
				recog.base.set_state(2775);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				/*InvokeRule columnNameList*/
				recog.base.set_state(2776);
				let tmp = recog.columnNameList()?;
				 cast_mut::<_,CteStatementContext >(&mut _localctx).colAliases = Some(tmp.clone());
				  

				recog.base.set_state(2777);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(2781);
			recog.base.match_token(KW_AS,&mut recog.err_handler)?;

			recog.base.set_state(2782);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule queryStatementExpression*/
			recog.base.set_state(2783);
			recog.queryStatementExpression()?;

			recog.base.set_state(2784);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fromStatement ----------------
pub type FromStatementContextAll<'input> = FromStatementContext<'input>;


pub type FromStatementContext<'input> = BaseParserRuleContext<'input,FromStatementContextExt<'input>>;

#[derive(Clone)]
pub struct FromStatementContextExt<'input>{
	pub u: Option<Rc<SetOperatorContextAll<'input>>>,
	pub r: Option<Rc<SingleFromStatementContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for FromStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for FromStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fromStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_fromStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for FromStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fromStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fromStatement }
}
crate::tid!{FromStatementContextExt<'a>}

impl<'input> FromStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FromStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FromStatementContextExt{
				u: None, r: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FromStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<FromStatementContextExt<'input>>{

fn singleFromStatement_all(&self) ->  Vec<Rc<SingleFromStatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn singleFromStatement(&self, i: usize) -> Option<Rc<SingleFromStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn setOperator_all(&self) ->  Vec<Rc<SetOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn setOperator(&self, i: usize) -> Option<Rc<SetOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> FromStatementContextAttrs<'input> for FromStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fromStatement(&mut self,)
	-> Result<Rc<FromStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FromStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 396, RULE_fromStatement);
        let mut _localctx: Rc<FromStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule singleFromStatement*/
			recog.base.set_state(2786);
			recog.singleFromStatement()?;

			recog.base.set_state(2792);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==KW_EXCEPT || _la==KW_INTERSECT || _la==KW_MINUS || _la==KW_UNION {
				{
				{
				/*InvokeRule setOperator*/
				recog.base.set_state(2787);
				let tmp = recog.setOperator()?;
				 cast_mut::<_,FromStatementContext >(&mut _localctx).u = Some(tmp.clone());
				  

				/*InvokeRule singleFromStatement*/
				recog.base.set_state(2788);
				let tmp = recog.singleFromStatement()?;
				 cast_mut::<_,FromStatementContext >(&mut _localctx).r = Some(tmp.clone());
				  

				}
				}
				recog.base.set_state(2794);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleFromStatement ----------------
pub type SingleFromStatementContextAll<'input> = SingleFromStatementContext<'input>;


pub type SingleFromStatementContext<'input> = BaseParserRuleContext<'input,SingleFromStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SingleFromStatementContextExt<'input>{
	pub body: Option<Rc<BodyContextAll<'input>>>,
	pub b:Vec<Rc<BodyContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SingleFromStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SingleFromStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleFromStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_singleFromStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SingleFromStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleFromStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleFromStatement }
}
crate::tid!{SingleFromStatementContextExt<'a>}

impl<'input> SingleFromStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleFromStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleFromStatementContextExt{
				body: None, 
				b: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleFromStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SingleFromStatementContextExt<'input>>{

fn fromClause(&self) -> Option<Rc<FromClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn body_all(&self) ->  Vec<Rc<BodyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn body(&self, i: usize) -> Option<Rc<BodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SingleFromStatementContextAttrs<'input> for SingleFromStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleFromStatement(&mut self,)
	-> Result<Rc<SingleFromStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleFromStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 398, RULE_singleFromStatement);
        let mut _localctx: Rc<SingleFromStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule fromClause*/
			recog.base.set_state(2795);
			recog.fromClause()?;

			recog.base.set_state(2797); 
			recog.err_handler.sync(&mut recog.base)?;
			_alt = 1;
			loop {
				match _alt {
				    x if x == 1=>
					{
					{
					/*InvokeRule body*/
					recog.base.set_state(2796);
					let tmp = recog.body()?;
					 cast_mut::<_,SingleFromStatementContext >(&mut _localctx).body = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,SingleFromStatementContext >(&mut _localctx).body.clone().unwrap()
					 ;
					 cast_mut::<_,SingleFromStatementContext >(&mut _localctx).b.push(temp);
					  
					}
					}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				recog.base.set_state(2799); 
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(261,&mut recog.base)?;
				if _alt==2 || _alt==INVALID_ALT { break }
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- regularBody ----------------
pub type RegularBodyContextAll<'input> = RegularBodyContext<'input>;


pub type RegularBodyContext<'input> = BaseParserRuleContext<'input,RegularBodyContextExt<'input>>;

#[derive(Clone)]
pub struct RegularBodyContextExt<'input>{
	pub i: Option<Rc<InsertClauseContextAll<'input>>>,
	pub s: Option<Rc<SelectStatementContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RegularBodyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RegularBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_regularBody(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_regularBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RegularBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_regularBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_regularBody }
}
crate::tid!{RegularBodyContextExt<'a>}

impl<'input> RegularBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RegularBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RegularBodyContextExt{
				i: None, s: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RegularBodyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RegularBodyContextExt<'input>>{

fn insertClause(&self) -> Option<Rc<InsertClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn selectStatement(&self) -> Option<Rc<SelectStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RegularBodyContextAttrs<'input> for RegularBodyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn regularBody(&mut self,)
	-> Result<Rc<RegularBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RegularBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 400, RULE_regularBody);
        let mut _localctx: Rc<RegularBodyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2805);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_INSERT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule insertClause*/
					recog.base.set_state(2801);
					let tmp = recog.insertClause()?;
					 cast_mut::<_,RegularBodyContext >(&mut _localctx).i = Some(tmp.clone());
					  

					/*InvokeRule selectStatement*/
					recog.base.set_state(2802);
					let tmp = recog.selectStatement()?;
					 cast_mut::<_,RegularBodyContext >(&mut _localctx).s = Some(tmp.clone());
					  

					}
				}

			 KW_MAP | KW_REDUCE | KW_SELECT | KW_VALUES | LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule selectStatement*/
					recog.base.set_state(2804);
					recog.selectStatement()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- atomSelectStatement ----------------
pub type AtomSelectStatementContextAll<'input> = AtomSelectStatementContext<'input>;


pub type AtomSelectStatementContext<'input> = BaseParserRuleContext<'input,AtomSelectStatementContextExt<'input>>;

#[derive(Clone)]
pub struct AtomSelectStatementContextExt<'input>{
	pub s: Option<Rc<SelectClauseContextAll<'input>>>,
	pub f: Option<Rc<FromClauseContextAll<'input>>>,
	pub w: Option<Rc<WhereClauseContextAll<'input>>>,
	pub g: Option<Rc<GroupByClauseContextAll<'input>>>,
	pub h: Option<Rc<HavingClauseContextAll<'input>>>,
	pub win: Option<Rc<Window_clauseContextAll<'input>>>,
	pub q: Option<Rc<QualifyClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AtomSelectStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AtomSelectStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_atomSelectStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_atomSelectStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AtomSelectStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_atomSelectStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_atomSelectStatement }
}
crate::tid!{AtomSelectStatementContextExt<'a>}

impl<'input> AtomSelectStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AtomSelectStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AtomSelectStatementContextExt{
				s: None, f: None, w: None, g: None, h: None, win: None, q: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AtomSelectStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AtomSelectStatementContextExt<'input>>{

fn selectClause(&self) -> Option<Rc<SelectClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn fromClause(&self) -> Option<Rc<FromClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn groupByClause(&self) -> Option<Rc<GroupByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn havingClause(&self) -> Option<Rc<HavingClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn window_clause(&self) -> Option<Rc<Window_clauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn qualifyClause(&self) -> Option<Rc<QualifyClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn selectStatement(&self) -> Option<Rc<SelectStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn valuesSource(&self) -> Option<Rc<ValuesSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AtomSelectStatementContextAttrs<'input> for AtomSelectStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn atomSelectStatement(&mut self,)
	-> Result<Rc<AtomSelectStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AtomSelectStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 402, RULE_atomSelectStatement);
        let mut _localctx: Rc<AtomSelectStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2831);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_MAP | KW_REDUCE | KW_SELECT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule selectClause*/
					recog.base.set_state(2807);
					let tmp = recog.selectClause()?;
					 cast_mut::<_,AtomSelectStatementContext >(&mut _localctx).s = Some(tmp.clone());
					  

					recog.base.set_state(2809);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(263,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule fromClause*/
							recog.base.set_state(2808);
							let tmp = recog.fromClause()?;
							 cast_mut::<_,AtomSelectStatementContext >(&mut _localctx).f = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					recog.base.set_state(2812);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_WHERE {
						{
						/*InvokeRule whereClause*/
						recog.base.set_state(2811);
						let tmp = recog.whereClause()?;
						 cast_mut::<_,AtomSelectStatementContext >(&mut _localctx).w = Some(tmp.clone());
						  

						}
					}

					recog.base.set_state(2815);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_GROUP {
						{
						/*InvokeRule groupByClause*/
						recog.base.set_state(2814);
						let tmp = recog.groupByClause()?;
						 cast_mut::<_,AtomSelectStatementContext >(&mut _localctx).g = Some(tmp.clone());
						  

						}
					}

					recog.base.set_state(2818);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_HAVING {
						{
						/*InvokeRule havingClause*/
						recog.base.set_state(2817);
						let tmp = recog.havingClause()?;
						 cast_mut::<_,AtomSelectStatementContext >(&mut _localctx).h = Some(tmp.clone());
						  

						}
					}

					recog.base.set_state(2821);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_WINDOW {
						{
						/*InvokeRule window_clause*/
						recog.base.set_state(2820);
						let tmp = recog.window_clause()?;
						 cast_mut::<_,AtomSelectStatementContext >(&mut _localctx).win = Some(tmp.clone());
						  

						}
					}

					recog.base.set_state(2824);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_QUALIFY {
						{
						/*InvokeRule qualifyClause*/
						recog.base.set_state(2823);
						let tmp = recog.qualifyClause()?;
						 cast_mut::<_,AtomSelectStatementContext >(&mut _localctx).q = Some(tmp.clone());
						  

						}
					}

					}
				}

			 LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2826);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule selectStatement*/
					recog.base.set_state(2827);
					recog.selectStatement()?;

					recog.base.set_state(2828);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

			 KW_VALUES 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule valuesSource*/
					recog.base.set_state(2830);
					recog.valuesSource()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectStatement ----------------
pub type SelectStatementContextAll<'input> = SelectStatementContext<'input>;


pub type SelectStatementContext<'input> = BaseParserRuleContext<'input,SelectStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SelectStatementContextExt<'input>{
	pub a: Option<Rc<AtomSelectStatementContextAll<'input>>>,
	pub set: Option<Rc<SetOpSelectStatementContextAll<'input>>>,
	pub o: Option<Rc<OrderByClauseContextAll<'input>>>,
	pub c: Option<Rc<ClusterByClauseContextAll<'input>>>,
	pub d: Option<Rc<DistributeByClauseContextAll<'input>>>,
	pub sort: Option<Rc<SortByClauseContextAll<'input>>>,
	pub l: Option<Rc<LimitClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SelectStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SelectStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_selectStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SelectStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectStatement }
}
crate::tid!{SelectStatementContextExt<'a>}

impl<'input> SelectStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectStatementContextExt{
				a: None, set: None, o: None, c: None, d: None, sort: None, l: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SelectStatementContextExt<'input>>{

fn atomSelectStatement(&self) -> Option<Rc<AtomSelectStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setOpSelectStatement(&self) -> Option<Rc<SetOpSelectStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orderByClause(&self) -> Option<Rc<OrderByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn clusterByClause(&self) -> Option<Rc<ClusterByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn distributeByClause(&self) -> Option<Rc<DistributeByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sortByClause(&self) -> Option<Rc<SortByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn limitClause(&self) -> Option<Rc<LimitClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SelectStatementContextAttrs<'input> for SelectStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectStatement(&mut self,)
	-> Result<Rc<SelectStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 404, RULE_selectStatement);
        let mut _localctx: Rc<SelectStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule atomSelectStatement*/
			recog.base.set_state(2833);
			let tmp = recog.atomSelectStatement()?;
			 cast_mut::<_,SelectStatementContext >(&mut _localctx).a = Some(tmp.clone());
			  

			recog.base.set_state(2835);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_EXCEPT || _la==KW_INTERSECT || _la==KW_MINUS || _la==KW_UNION {
				{
				/*InvokeRule setOpSelectStatement*/
				recog.base.set_state(2834);
				let tmp = recog.setOpSelectStatement()?;
				 cast_mut::<_,SelectStatementContext >(&mut _localctx).set = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2838);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ORDER {
				{
				/*InvokeRule orderByClause*/
				recog.base.set_state(2837);
				let tmp = recog.orderByClause()?;
				 cast_mut::<_,SelectStatementContext >(&mut _localctx).o = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2841);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CLUSTER {
				{
				/*InvokeRule clusterByClause*/
				recog.base.set_state(2840);
				let tmp = recog.clusterByClause()?;
				 cast_mut::<_,SelectStatementContext >(&mut _localctx).c = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2844);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_DISTRIBUTE {
				{
				/*InvokeRule distributeByClause*/
				recog.base.set_state(2843);
				let tmp = recog.distributeByClause()?;
				 cast_mut::<_,SelectStatementContext >(&mut _localctx).d = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2847);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_SORT {
				{
				/*InvokeRule sortByClause*/
				recog.base.set_state(2846);
				let tmp = recog.sortByClause()?;
				 cast_mut::<_,SelectStatementContext >(&mut _localctx).sort = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2850);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_LIMIT {
				{
				/*InvokeRule limitClause*/
				recog.base.set_state(2849);
				let tmp = recog.limitClause()?;
				 cast_mut::<_,SelectStatementContext >(&mut _localctx).l = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setOpSelectStatement ----------------
pub type SetOpSelectStatementContextAll<'input> = SetOpSelectStatementContext<'input>;


pub type SetOpSelectStatementContext<'input> = BaseParserRuleContext<'input,SetOpSelectStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SetOpSelectStatementContextExt<'input>{
	pub u: Option<Rc<SetOperatorContextAll<'input>>>,
	pub b: Option<Rc<AtomSelectStatementContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SetOpSelectStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SetOpSelectStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setOpSelectStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_setOpSelectStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SetOpSelectStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setOpSelectStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setOpSelectStatement }
}
crate::tid!{SetOpSelectStatementContextExt<'a>}

impl<'input> SetOpSelectStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetOpSelectStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetOpSelectStatementContextExt{
				u: None, b: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SetOpSelectStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SetOpSelectStatementContextExt<'input>>{

fn setOperator_all(&self) ->  Vec<Rc<SetOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn setOperator(&self, i: usize) -> Option<Rc<SetOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn atomSelectStatement_all(&self) ->  Vec<Rc<AtomSelectStatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn atomSelectStatement(&self, i: usize) -> Option<Rc<AtomSelectStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SetOpSelectStatementContextAttrs<'input> for SetOpSelectStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setOpSelectStatement(&mut self,)
	-> Result<Rc<SetOpSelectStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetOpSelectStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 406, RULE_setOpSelectStatement);
        let mut _localctx: Rc<SetOpSelectStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2855); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				/*InvokeRule setOperator*/
				recog.base.set_state(2852);
				let tmp = recog.setOperator()?;
				 cast_mut::<_,SetOpSelectStatementContext >(&mut _localctx).u = Some(tmp.clone());
				  

				/*InvokeRule atomSelectStatement*/
				recog.base.set_state(2853);
				let tmp = recog.atomSelectStatement()?;
				 cast_mut::<_,SetOpSelectStatementContext >(&mut _localctx).b = Some(tmp.clone());
				  

				}
				}
				recog.base.set_state(2857); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==KW_EXCEPT || _la==KW_INTERSECT || _la==KW_MINUS || _la==KW_UNION) {break}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectStatementWithCTE ----------------
pub type SelectStatementWithCTEContextAll<'input> = SelectStatementWithCTEContext<'input>;


pub type SelectStatementWithCTEContext<'input> = BaseParserRuleContext<'input,SelectStatementWithCTEContextExt<'input>>;

#[derive(Clone)]
pub struct SelectStatementWithCTEContextExt<'input>{
	pub w: Option<Rc<WithClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SelectStatementWithCTEContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SelectStatementWithCTEContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectStatementWithCTE(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_selectStatementWithCTE(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SelectStatementWithCTEContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectStatementWithCTE }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectStatementWithCTE }
}
crate::tid!{SelectStatementWithCTEContextExt<'a>}

impl<'input> SelectStatementWithCTEContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectStatementWithCTEContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectStatementWithCTEContextExt{
				w: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectStatementWithCTEContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SelectStatementWithCTEContextExt<'input>>{

fn selectStatement(&self) -> Option<Rc<SelectStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn withClause(&self) -> Option<Rc<WithClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SelectStatementWithCTEContextAttrs<'input> for SelectStatementWithCTEContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectStatementWithCTE(&mut self,)
	-> Result<Rc<SelectStatementWithCTEContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectStatementWithCTEContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 408, RULE_selectStatementWithCTE);
        let mut _localctx: Rc<SelectStatementWithCTEContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2860);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_WITH {
				{
				/*InvokeRule withClause*/
				recog.base.set_state(2859);
				let tmp = recog.withClause()?;
				 cast_mut::<_,SelectStatementWithCTEContext >(&mut _localctx).w = Some(tmp.clone());
				  

				}
			}

			/*InvokeRule selectStatement*/
			recog.base.set_state(2862);
			recog.selectStatement()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- body ----------------
pub type BodyContextAll<'input> = BodyContext<'input>;


pub type BodyContext<'input> = BaseParserRuleContext<'input,BodyContextExt<'input>>;

#[derive(Clone)]
pub struct BodyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for BodyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for BodyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_body(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_body(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for BodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_body }
	//fn type_rule_index() -> usize where Self: Sized { RULE_body }
}
crate::tid!{BodyContextExt<'a>}

impl<'input> BodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BodyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BodyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<BodyContextExt<'input>>{

fn insertClause(&self) -> Option<Rc<InsertClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn selectClause(&self) -> Option<Rc<SelectClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn lateralView(&self) -> Option<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn groupByClause(&self) -> Option<Rc<GroupByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn havingClause(&self) -> Option<Rc<HavingClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn window_clause(&self) -> Option<Rc<Window_clauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn qualifyClause(&self) -> Option<Rc<QualifyClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orderByClause(&self) -> Option<Rc<OrderByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn clusterByClause(&self) -> Option<Rc<ClusterByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn distributeByClause(&self) -> Option<Rc<DistributeByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sortByClause(&self) -> Option<Rc<SortByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn limitClause(&self) -> Option<Rc<LimitClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> BodyContextAttrs<'input> for BodyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn body(&mut self,)
	-> Result<Rc<BodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 410, RULE_body);
        let mut _localctx: Rc<BodyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2933);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_INSERT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule insertClause*/
					recog.base.set_state(2864);
					recog.insertClause()?;

					/*InvokeRule selectClause*/
					recog.base.set_state(2865);
					recog.selectClause()?;

					recog.base.set_state(2867);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_LATERAL || _la==COMMA {
						{
						/*InvokeRule lateralView*/
						recog.base.set_state(2866);
						recog.lateralView()?;

						}
					}

					recog.base.set_state(2870);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_WHERE {
						{
						/*InvokeRule whereClause*/
						recog.base.set_state(2869);
						recog.whereClause()?;

						}
					}

					recog.base.set_state(2873);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_GROUP {
						{
						/*InvokeRule groupByClause*/
						recog.base.set_state(2872);
						recog.groupByClause()?;

						}
					}

					recog.base.set_state(2876);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_HAVING {
						{
						/*InvokeRule havingClause*/
						recog.base.set_state(2875);
						recog.havingClause()?;

						}
					}

					recog.base.set_state(2879);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_WINDOW {
						{
						/*InvokeRule window_clause*/
						recog.base.set_state(2878);
						recog.window_clause()?;

						}
					}

					recog.base.set_state(2882);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_QUALIFY {
						{
						/*InvokeRule qualifyClause*/
						recog.base.set_state(2881);
						recog.qualifyClause()?;

						}
					}

					recog.base.set_state(2885);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_ORDER {
						{
						/*InvokeRule orderByClause*/
						recog.base.set_state(2884);
						recog.orderByClause()?;

						}
					}

					recog.base.set_state(2888);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_CLUSTER {
						{
						/*InvokeRule clusterByClause*/
						recog.base.set_state(2887);
						recog.clusterByClause()?;

						}
					}

					recog.base.set_state(2891);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_DISTRIBUTE {
						{
						/*InvokeRule distributeByClause*/
						recog.base.set_state(2890);
						recog.distributeByClause()?;

						}
					}

					recog.base.set_state(2894);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_SORT {
						{
						/*InvokeRule sortByClause*/
						recog.base.set_state(2893);
						recog.sortByClause()?;

						}
					}

					recog.base.set_state(2897);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_LIMIT {
						{
						/*InvokeRule limitClause*/
						recog.base.set_state(2896);
						recog.limitClause()?;

						}
					}

					}
				}

			 KW_MAP | KW_REDUCE | KW_SELECT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule selectClause*/
					recog.base.set_state(2899);
					recog.selectClause()?;

					recog.base.set_state(2901);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_LATERAL || _la==COMMA {
						{
						/*InvokeRule lateralView*/
						recog.base.set_state(2900);
						recog.lateralView()?;

						}
					}

					recog.base.set_state(2904);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_WHERE {
						{
						/*InvokeRule whereClause*/
						recog.base.set_state(2903);
						recog.whereClause()?;

						}
					}

					recog.base.set_state(2907);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_GROUP {
						{
						/*InvokeRule groupByClause*/
						recog.base.set_state(2906);
						recog.groupByClause()?;

						}
					}

					recog.base.set_state(2910);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_HAVING {
						{
						/*InvokeRule havingClause*/
						recog.base.set_state(2909);
						recog.havingClause()?;

						}
					}

					recog.base.set_state(2913);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_WINDOW {
						{
						/*InvokeRule window_clause*/
						recog.base.set_state(2912);
						recog.window_clause()?;

						}
					}

					recog.base.set_state(2916);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_QUALIFY {
						{
						/*InvokeRule qualifyClause*/
						recog.base.set_state(2915);
						recog.qualifyClause()?;

						}
					}

					recog.base.set_state(2919);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_ORDER {
						{
						/*InvokeRule orderByClause*/
						recog.base.set_state(2918);
						recog.orderByClause()?;

						}
					}

					recog.base.set_state(2922);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_CLUSTER {
						{
						/*InvokeRule clusterByClause*/
						recog.base.set_state(2921);
						recog.clusterByClause()?;

						}
					}

					recog.base.set_state(2925);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_DISTRIBUTE {
						{
						/*InvokeRule distributeByClause*/
						recog.base.set_state(2924);
						recog.distributeByClause()?;

						}
					}

					recog.base.set_state(2928);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_SORT {
						{
						/*InvokeRule sortByClause*/
						recog.base.set_state(2927);
						recog.sortByClause()?;

						}
					}

					recog.base.set_state(2931);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_LIMIT {
						{
						/*InvokeRule limitClause*/
						recog.base.set_state(2930);
						recog.limitClause()?;

						}
					}

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- insertClause ----------------
pub type InsertClauseContextAll<'input> = InsertClauseContext<'input>;


pub type InsertClauseContext<'input> = BaseParserRuleContext<'input,InsertClauseContextExt<'input>>;

#[derive(Clone)]
pub struct InsertClauseContextExt<'input>{
	pub targetCols: Option<Rc<ColumnNameListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for InsertClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for InsertClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_insertClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_insertClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for InsertClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertClause }
}
crate::tid!{InsertClauseContextExt<'a>}

impl<'input> InsertClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<InsertClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,InsertClauseContextExt{
				targetCols: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait InsertClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<InsertClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_INSERT
/// Returns `None` if there is no child corresponding to token KW_INSERT
fn KW_INSERT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OVERWRITE
/// Returns `None` if there is no child corresponding to token KW_OVERWRITE
fn KW_OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OVERWRITE, 0)
}
fn destination(&self) -> Option<Rc<DestinationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_INTO
/// Returns `None` if there is no child corresponding to token KW_INTO
fn KW_INTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INTO, 0)
}
fn tableOrPartition(&self) -> Option<Rc<TableOrPartitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifNotExists(&self) -> Option<Rc<IfNotExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn columnNameList(&self) -> Option<Rc<ColumnNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> InsertClauseContextAttrs<'input> for InsertClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn insertClause(&mut self,)
	-> Result<Rc<InsertClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = InsertClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 412, RULE_insertClause);
        let mut _localctx: Rc<InsertClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2935);
			recog.base.match_token(KW_INSERT,&mut recog.err_handler)?;

			recog.base.set_state(2952);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_OVERWRITE 
				=> {
					{
					recog.base.set_state(2936);
					recog.base.match_token(KW_OVERWRITE,&mut recog.err_handler)?;

					/*InvokeRule destination*/
					recog.base.set_state(2937);
					recog.destination()?;

					recog.base.set_state(2939);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_IF {
						{
						/*InvokeRule ifNotExists*/
						recog.base.set_state(2938);
						recog.ifNotExists()?;

						}
					}

					}
				}

			 KW_INTO 
				=> {
					{
					recog.base.set_state(2941);
					recog.base.match_token(KW_INTO,&mut recog.err_handler)?;

					recog.base.set_state(2943);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_TABLE {
						{
						recog.base.set_state(2942);
						recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule tableOrPartition*/
					recog.base.set_state(2945);
					recog.tableOrPartition()?;

					recog.base.set_state(2950);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(303,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2946);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule columnNameList*/
							recog.base.set_state(2947);
							let tmp = recog.columnNameList()?;
							 cast_mut::<_,InsertClauseContext >(&mut _localctx).targetCols = Some(tmp.clone());
							  

							recog.base.set_state(2948);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- destination ----------------
pub type DestinationContextAll<'input> = DestinationContext<'input>;


pub type DestinationContext<'input> = BaseParserRuleContext<'input,DestinationContextExt<'input>>;

#[derive(Clone)]
pub struct DestinationContextExt<'input>{
	pub local: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DestinationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DestinationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_destination(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_destination(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DestinationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_destination }
	//fn type_rule_index() -> usize where Self: Sized { RULE_destination }
}
crate::tid!{DestinationContextExt<'a>}

impl<'input> DestinationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DestinationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DestinationContextExt{
				local: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DestinationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DestinationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DIRECTORY
/// Returns `None` if there is no child corresponding to token KW_DIRECTORY
fn KW_DIRECTORY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DIRECTORY, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn tableRowFormat(&self) -> Option<Rc<TableRowFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableFileFormat(&self) -> Option<Rc<TableFileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCAL
/// Returns `None` if there is no child corresponding to token KW_LOCAL
fn KW_LOCAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableOrPartition(&self) -> Option<Rc<TableOrPartitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DestinationContextAttrs<'input> for DestinationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn destination(&mut self,)
	-> Result<Rc<DestinationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DestinationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 414, RULE_destination);
        let mut _localctx: Rc<DestinationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2967);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_DIRECTORY | KW_LOCAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2955);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_LOCAL {
						{
						recog.base.set_state(2954);
						let tmp = recog.base.match_token(KW_LOCAL,&mut recog.err_handler)?;
						 cast_mut::<_,DestinationContext >(&mut _localctx).local = Some(tmp.clone());
						  

						}
					}

					recog.base.set_state(2957);
					recog.base.match_token(KW_DIRECTORY,&mut recog.err_handler)?;

					recog.base.set_state(2958);
					recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

					recog.base.set_state(2960);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_ROW {
						{
						/*InvokeRule tableRowFormat*/
						recog.base.set_state(2959);
						recog.tableRowFormat()?;

						}
					}

					recog.base.set_state(2963);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_STORED {
						{
						/*InvokeRule tableFileFormat*/
						recog.base.set_state(2962);
						recog.tableFileFormat()?;

						}
					}

					}
				}

			 KW_TABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2965);
					recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

					/*InvokeRule tableOrPartition*/
					recog.base.set_state(2966);
					recog.tableOrPartition()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- limitClause ----------------
pub type LimitClauseContextAll<'input> = LimitClauseContext<'input>;


pub type LimitClauseContext<'input> = BaseParserRuleContext<'input,LimitClauseContextExt<'input>>;

#[derive(Clone)]
pub struct LimitClauseContextExt<'input>{
	pub offset: Option<TokenType<'input>>,
	pub num: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for LimitClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for LimitClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_limitClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_limitClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for LimitClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_limitClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_limitClause }
}
crate::tid!{LimitClauseContextExt<'a>}

impl<'input> LimitClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LimitClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LimitClauseContextExt{
				offset: None, num: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LimitClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<LimitClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LIMIT
/// Returns `None` if there is no child corresponding to token KW_LIMIT
fn KW_LIMIT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OFFSET
/// Returns `None` if there is no child corresponding to token KW_OFFSET
fn KW_OFFSET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OFFSET, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token Number in current rule
fn Number_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token Number, starting from 0.
/// Returns `None` if number of children corresponding to token Number is less or equal than `i`.
fn Number(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, i)
}
/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}

}

impl<'input> LimitClauseContextAttrs<'input> for LimitClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn limitClause(&mut self,)
	-> Result<Rc<LimitClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LimitClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 416, RULE_limitClause);
        let mut _localctx: Rc<LimitClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2969);
			recog.base.match_token(KW_LIMIT,&mut recog.err_handler)?;

			recog.base.set_state(2978);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(310,&mut recog.base)? {
				1 =>{
					{
					recog.base.set_state(2972);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(309,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2970);
							let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
							 cast_mut::<_,LimitClauseContext >(&mut _localctx).offset = Some(tmp.clone());
							  

							recog.base.set_state(2971);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2974);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,LimitClauseContext >(&mut _localctx).num = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					{
					recog.base.set_state(2975);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,LimitClauseContext >(&mut _localctx).num = Some(tmp.clone());
					  

					recog.base.set_state(2976);
					recog.base.match_token(KW_OFFSET,&mut recog.err_handler)?;

					recog.base.set_state(2977);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,LimitClauseContext >(&mut _localctx).offset = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- deleteStatement ----------------
pub type DeleteStatementContextAll<'input> = DeleteStatementContext<'input>;


pub type DeleteStatementContext<'input> = BaseParserRuleContext<'input,DeleteStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DeleteStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DeleteStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DeleteStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_deleteStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_deleteStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DeleteStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_deleteStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_deleteStatement }
}
crate::tid!{DeleteStatementContextExt<'a>}

impl<'input> DeleteStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeleteStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeleteStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DeleteStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DeleteStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DELETE
/// Returns `None` if there is no child corresponding to token KW_DELETE
fn KW_DELETE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DeleteStatementContextAttrs<'input> for DeleteStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn deleteStatement(&mut self,)
	-> Result<Rc<DeleteStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeleteStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 418, RULE_deleteStatement);
        let mut _localctx: Rc<DeleteStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2980);
			recog.base.match_token(KW_DELETE,&mut recog.err_handler)?;

			recog.base.set_state(2981);
			recog.base.match_token(KW_FROM,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(2982);
			recog.tableName()?;

			recog.base.set_state(2984);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_WHERE {
				{
				/*InvokeRule whereClause*/
				recog.base.set_state(2983);
				recog.whereClause()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnAssignmentClause ----------------
pub type ColumnAssignmentClauseContextAll<'input> = ColumnAssignmentClauseContext<'input>;


pub type ColumnAssignmentClauseContext<'input> = BaseParserRuleContext<'input,ColumnAssignmentClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnAssignmentClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnAssignmentClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnAssignmentClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnAssignmentClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnAssignmentClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnAssignmentClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnAssignmentClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnAssignmentClause }
}
crate::tid!{ColumnAssignmentClauseContextExt<'a>}

impl<'input> ColumnAssignmentClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnAssignmentClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnAssignmentClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnAssignmentClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnAssignmentClauseContextExt<'input>>{

fn tableOrColumn(&self) -> Option<Rc<TableOrColumnContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn precedencePlusExpressionOrDefault(&self) -> Option<Rc<PrecedencePlusExpressionOrDefaultContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnAssignmentClauseContextAttrs<'input> for ColumnAssignmentClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnAssignmentClause(&mut self,)
	-> Result<Rc<ColumnAssignmentClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnAssignmentClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 420, RULE_columnAssignmentClause);
        let mut _localctx: Rc<ColumnAssignmentClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableOrColumn*/
			recog.base.set_state(2986);
			recog.tableOrColumn()?;

			recog.base.set_state(2987);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule precedencePlusExpressionOrDefault*/
			recog.base.set_state(2988);
			recog.precedencePlusExpressionOrDefault()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedencePlusExpressionOrDefault ----------------
pub type PrecedencePlusExpressionOrDefaultContextAll<'input> = PrecedencePlusExpressionOrDefaultContext<'input>;


pub type PrecedencePlusExpressionOrDefaultContext<'input> = BaseParserRuleContext<'input,PrecedencePlusExpressionOrDefaultContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedencePlusExpressionOrDefaultContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedencePlusExpressionOrDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedencePlusExpressionOrDefaultContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedencePlusExpressionOrDefault(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedencePlusExpressionOrDefault(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedencePlusExpressionOrDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedencePlusExpressionOrDefault }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedencePlusExpressionOrDefault }
}
crate::tid!{PrecedencePlusExpressionOrDefaultContextExt<'a>}

impl<'input> PrecedencePlusExpressionOrDefaultContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedencePlusExpressionOrDefaultContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedencePlusExpressionOrDefaultContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedencePlusExpressionOrDefaultContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedencePlusExpressionOrDefaultContextExt<'input>>{

fn defaultValue(&self) -> Option<Rc<DefaultValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn precedencePlusExpression(&self) -> Option<Rc<PrecedencePlusExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrecedencePlusExpressionOrDefaultContextAttrs<'input> for PrecedencePlusExpressionOrDefaultContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedencePlusExpressionOrDefault(&mut self,)
	-> Result<Rc<PrecedencePlusExpressionOrDefaultContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedencePlusExpressionOrDefaultContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 422, RULE_precedencePlusExpressionOrDefault);
        let mut _localctx: Rc<PrecedencePlusExpressionOrDefaultContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2992);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(312,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule defaultValue*/
					recog.base.set_state(2990);
					recog.defaultValue()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule precedencePlusExpression*/
					recog.base.set_state(2991);
					recog.precedencePlusExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setColumnsClause ----------------
pub type SetColumnsClauseContextAll<'input> = SetColumnsClauseContext<'input>;


pub type SetColumnsClauseContext<'input> = BaseParserRuleContext<'input,SetColumnsClauseContextExt<'input>>;

#[derive(Clone)]
pub struct SetColumnsClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SetColumnsClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SetColumnsClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setColumnsClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_setColumnsClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SetColumnsClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setColumnsClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setColumnsClause }
}
crate::tid!{SetColumnsClauseContextExt<'a>}

impl<'input> SetColumnsClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetColumnsClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetColumnsClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetColumnsClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SetColumnsClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
fn columnAssignmentClause_all(&self) ->  Vec<Rc<ColumnAssignmentClauseContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnAssignmentClause(&self, i: usize) -> Option<Rc<ColumnAssignmentClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> SetColumnsClauseContextAttrs<'input> for SetColumnsClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setColumnsClause(&mut self,)
	-> Result<Rc<SetColumnsClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetColumnsClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 424, RULE_setColumnsClause);
        let mut _localctx: Rc<SetColumnsClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2994);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			/*InvokeRule columnAssignmentClause*/
			recog.base.set_state(2995);
			recog.columnAssignmentClause()?;

			recog.base.set_state(3000);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2996);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnAssignmentClause*/
				recog.base.set_state(2997);
				recog.columnAssignmentClause()?;

				}
				}
				recog.base.set_state(3002);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- updateStatement ----------------
pub type UpdateStatementContextAll<'input> = UpdateStatementContext<'input>;


pub type UpdateStatementContext<'input> = BaseParserRuleContext<'input,UpdateStatementContextExt<'input>>;

#[derive(Clone)]
pub struct UpdateStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for UpdateStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for UpdateStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_updateStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_updateStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for UpdateStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_updateStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_updateStatement }
}
crate::tid!{UpdateStatementContextExt<'a>}

impl<'input> UpdateStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UpdateStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UpdateStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UpdateStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<UpdateStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UPDATE
/// Returns `None` if there is no child corresponding to token KW_UPDATE
fn KW_UPDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UPDATE, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setColumnsClause(&self) -> Option<Rc<SetColumnsClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UpdateStatementContextAttrs<'input> for UpdateStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn updateStatement(&mut self,)
	-> Result<Rc<UpdateStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UpdateStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 426, RULE_updateStatement);
        let mut _localctx: Rc<UpdateStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3003);
			recog.base.match_token(KW_UPDATE,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(3004);
			recog.tableName()?;

			/*InvokeRule setColumnsClause*/
			recog.base.set_state(3005);
			recog.setColumnsClause()?;

			recog.base.set_state(3007);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_WHERE {
				{
				/*InvokeRule whereClause*/
				recog.base.set_state(3006);
				recog.whereClause()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sqlTransactionStatement ----------------
pub type SqlTransactionStatementContextAll<'input> = SqlTransactionStatementContext<'input>;


pub type SqlTransactionStatementContext<'input> = BaseParserRuleContext<'input,SqlTransactionStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SqlTransactionStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SqlTransactionStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SqlTransactionStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sqlTransactionStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_sqlTransactionStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SqlTransactionStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sqlTransactionStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sqlTransactionStatement }
}
crate::tid!{SqlTransactionStatementContextExt<'a>}

impl<'input> SqlTransactionStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SqlTransactionStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SqlTransactionStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SqlTransactionStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SqlTransactionStatementContextExt<'input>>{

fn startTransactionStatement(&self) -> Option<Rc<StartTransactionStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn commitStatement(&self) -> Option<Rc<CommitStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn rollbackStatement(&self) -> Option<Rc<RollbackStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setAutoCommitStatement(&self) -> Option<Rc<SetAutoCommitStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SqlTransactionStatementContextAttrs<'input> for SqlTransactionStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sqlTransactionStatement(&mut self,)
	-> Result<Rc<SqlTransactionStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SqlTransactionStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 428, RULE_sqlTransactionStatement);
        let mut _localctx: Rc<SqlTransactionStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3013);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_START 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule startTransactionStatement*/
					recog.base.set_state(3009);
					recog.startTransactionStatement()?;

					}
				}

			 KW_COMMIT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule commitStatement*/
					recog.base.set_state(3010);
					recog.commitStatement()?;

					}
				}

			 KW_ROLLBACK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule rollbackStatement*/
					recog.base.set_state(3011);
					recog.rollbackStatement()?;

					}
				}

			 KW_SET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule setAutoCommitStatement*/
					recog.base.set_state(3012);
					recog.setAutoCommitStatement()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- startTransactionStatement ----------------
pub type StartTransactionStatementContextAll<'input> = StartTransactionStatementContext<'input>;


pub type StartTransactionStatementContext<'input> = BaseParserRuleContext<'input,StartTransactionStatementContextExt<'input>>;

#[derive(Clone)]
pub struct StartTransactionStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for StartTransactionStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for StartTransactionStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_startTransactionStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_startTransactionStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for StartTransactionStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_startTransactionStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_startTransactionStatement }
}
crate::tid!{StartTransactionStatementContextExt<'a>}

impl<'input> StartTransactionStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StartTransactionStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StartTransactionStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StartTransactionStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<StartTransactionStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_START
/// Returns `None` if there is no child corresponding to token KW_START
fn KW_START(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_START, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRANSACTION
/// Returns `None` if there is no child corresponding to token KW_TRANSACTION
fn KW_TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRANSACTION, 0)
}
fn transactionMode_all(&self) ->  Vec<Rc<TransactionModeContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn transactionMode(&self, i: usize) -> Option<Rc<TransactionModeContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> StartTransactionStatementContextAttrs<'input> for StartTransactionStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn startTransactionStatement(&mut self,)
	-> Result<Rc<StartTransactionStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StartTransactionStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 430, RULE_startTransactionStatement);
        let mut _localctx: Rc<StartTransactionStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3015);
			recog.base.match_token(KW_START,&mut recog.err_handler)?;

			recog.base.set_state(3016);
			recog.base.match_token(KW_TRANSACTION,&mut recog.err_handler)?;

			recog.base.set_state(3025);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ISOLATION || _la==KW_READ {
				{
				/*InvokeRule transactionMode*/
				recog.base.set_state(3017);
				recog.transactionMode()?;

				recog.base.set_state(3022);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(3018);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule transactionMode*/
					recog.base.set_state(3019);
					recog.transactionMode()?;

					}
					}
					recog.base.set_state(3024);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- transactionMode ----------------
pub type TransactionModeContextAll<'input> = TransactionModeContext<'input>;


pub type TransactionModeContext<'input> = BaseParserRuleContext<'input,TransactionModeContextExt<'input>>;

#[derive(Clone)]
pub struct TransactionModeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TransactionModeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TransactionModeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_transactionMode(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_transactionMode(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TransactionModeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transactionMode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transactionMode }
}
crate::tid!{TransactionModeContextExt<'a>}

impl<'input> TransactionModeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TransactionModeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TransactionModeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TransactionModeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TransactionModeContextExt<'input>>{

fn isolationLevel(&self) -> Option<Rc<IsolationLevelContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn transactionAccessMode(&self) -> Option<Rc<TransactionAccessModeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TransactionModeContextAttrs<'input> for TransactionModeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn transactionMode(&mut self,)
	-> Result<Rc<TransactionModeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TransactionModeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 432, RULE_transactionMode);
        let mut _localctx: Rc<TransactionModeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3029);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ISOLATION 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule isolationLevel*/
					recog.base.set_state(3027);
					recog.isolationLevel()?;

					}
				}

			 KW_READ 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule transactionAccessMode*/
					recog.base.set_state(3028);
					recog.transactionAccessMode()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- transactionAccessMode ----------------
pub type TransactionAccessModeContextAll<'input> = TransactionAccessModeContext<'input>;


pub type TransactionAccessModeContext<'input> = BaseParserRuleContext<'input,TransactionAccessModeContextExt<'input>>;

#[derive(Clone)]
pub struct TransactionAccessModeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TransactionAccessModeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TransactionAccessModeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_transactionAccessMode(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_transactionAccessMode(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TransactionAccessModeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transactionAccessMode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transactionAccessMode }
}
crate::tid!{TransactionAccessModeContextExt<'a>}

impl<'input> TransactionAccessModeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TransactionAccessModeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TransactionAccessModeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TransactionAccessModeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TransactionAccessModeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_READ
/// Returns `None` if there is no child corresponding to token KW_READ
fn KW_READ(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_READ, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ONLY
/// Returns `None` if there is no child corresponding to token KW_ONLY
fn KW_ONLY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ONLY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WRITE
/// Returns `None` if there is no child corresponding to token KW_WRITE
fn KW_WRITE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WRITE, 0)
}

}

impl<'input> TransactionAccessModeContextAttrs<'input> for TransactionAccessModeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn transactionAccessMode(&mut self,)
	-> Result<Rc<TransactionAccessModeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TransactionAccessModeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 434, RULE_transactionAccessMode);
        let mut _localctx: Rc<TransactionAccessModeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3031);
			recog.base.match_token(KW_READ,&mut recog.err_handler)?;

			recog.base.set_state(3032);
			_la = recog.base.input.la(1);
			if { !(_la==KW_ONLY || _la==KW_WRITE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- isolationLevel ----------------
pub type IsolationLevelContextAll<'input> = IsolationLevelContext<'input>;


pub type IsolationLevelContext<'input> = BaseParserRuleContext<'input,IsolationLevelContextExt<'input>>;

#[derive(Clone)]
pub struct IsolationLevelContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for IsolationLevelContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for IsolationLevelContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_isolationLevel(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_isolationLevel(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for IsolationLevelContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_isolationLevel }
	//fn type_rule_index() -> usize where Self: Sized { RULE_isolationLevel }
}
crate::tid!{IsolationLevelContextExt<'a>}

impl<'input> IsolationLevelContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IsolationLevelContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IsolationLevelContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IsolationLevelContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<IsolationLevelContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ISOLATION
/// Returns `None` if there is no child corresponding to token KW_ISOLATION
fn KW_ISOLATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ISOLATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LEVEL
/// Returns `None` if there is no child corresponding to token KW_LEVEL
fn KW_LEVEL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LEVEL, 0)
}
fn levelOfIsolation(&self) -> Option<Rc<LevelOfIsolationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IsolationLevelContextAttrs<'input> for IsolationLevelContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn isolationLevel(&mut self,)
	-> Result<Rc<IsolationLevelContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IsolationLevelContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 436, RULE_isolationLevel);
        let mut _localctx: Rc<IsolationLevelContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3034);
			recog.base.match_token(KW_ISOLATION,&mut recog.err_handler)?;

			recog.base.set_state(3035);
			recog.base.match_token(KW_LEVEL,&mut recog.err_handler)?;

			/*InvokeRule levelOfIsolation*/
			recog.base.set_state(3036);
			recog.levelOfIsolation()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- levelOfIsolation ----------------
pub type LevelOfIsolationContextAll<'input> = LevelOfIsolationContext<'input>;


pub type LevelOfIsolationContext<'input> = BaseParserRuleContext<'input,LevelOfIsolationContextExt<'input>>;

#[derive(Clone)]
pub struct LevelOfIsolationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for LevelOfIsolationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for LevelOfIsolationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_levelOfIsolation(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_levelOfIsolation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for LevelOfIsolationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_levelOfIsolation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_levelOfIsolation }
}
crate::tid!{LevelOfIsolationContextExt<'a>}

impl<'input> LevelOfIsolationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LevelOfIsolationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LevelOfIsolationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LevelOfIsolationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<LevelOfIsolationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SNAPSHOT
/// Returns `None` if there is no child corresponding to token KW_SNAPSHOT
fn KW_SNAPSHOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SNAPSHOT, 0)
}

}

impl<'input> LevelOfIsolationContextAttrs<'input> for LevelOfIsolationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn levelOfIsolation(&mut self,)
	-> Result<Rc<LevelOfIsolationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LevelOfIsolationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 438, RULE_levelOfIsolation);
        let mut _localctx: Rc<LevelOfIsolationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3038);
			recog.base.match_token(KW_SNAPSHOT,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- commitStatement ----------------
pub type CommitStatementContextAll<'input> = CommitStatementContext<'input>;


pub type CommitStatementContext<'input> = BaseParserRuleContext<'input,CommitStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CommitStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CommitStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CommitStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_commitStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_commitStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CommitStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_commitStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_commitStatement }
}
crate::tid!{CommitStatementContextExt<'a>}

impl<'input> CommitStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CommitStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CommitStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CommitStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CommitStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_COMMIT
/// Returns `None` if there is no child corresponding to token KW_COMMIT
fn KW_COMMIT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WORK
/// Returns `None` if there is no child corresponding to token KW_WORK
fn KW_WORK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WORK, 0)
}

}

impl<'input> CommitStatementContextAttrs<'input> for CommitStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn commitStatement(&mut self,)
	-> Result<Rc<CommitStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CommitStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 440, RULE_commitStatement);
        let mut _localctx: Rc<CommitStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3040);
			recog.base.match_token(KW_COMMIT,&mut recog.err_handler)?;

			recog.base.set_state(3042);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_WORK {
				{
				recog.base.set_state(3041);
				recog.base.match_token(KW_WORK,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rollbackStatement ----------------
pub type RollbackStatementContextAll<'input> = RollbackStatementContext<'input>;


pub type RollbackStatementContext<'input> = BaseParserRuleContext<'input,RollbackStatementContextExt<'input>>;

#[derive(Clone)]
pub struct RollbackStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RollbackStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RollbackStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rollbackStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rollbackStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RollbackStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rollbackStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rollbackStatement }
}
crate::tid!{RollbackStatementContextExt<'a>}

impl<'input> RollbackStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RollbackStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RollbackStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RollbackStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RollbackStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ROLLBACK
/// Returns `None` if there is no child corresponding to token KW_ROLLBACK
fn KW_ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLLBACK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WORK
/// Returns `None` if there is no child corresponding to token KW_WORK
fn KW_WORK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WORK, 0)
}

}

impl<'input> RollbackStatementContextAttrs<'input> for RollbackStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rollbackStatement(&mut self,)
	-> Result<Rc<RollbackStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RollbackStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 442, RULE_rollbackStatement);
        let mut _localctx: Rc<RollbackStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3044);
			recog.base.match_token(KW_ROLLBACK,&mut recog.err_handler)?;

			recog.base.set_state(3046);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_WORK {
				{
				recog.base.set_state(3045);
				recog.base.match_token(KW_WORK,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setAutoCommitStatement ----------------
pub type SetAutoCommitStatementContextAll<'input> = SetAutoCommitStatementContext<'input>;


pub type SetAutoCommitStatementContext<'input> = BaseParserRuleContext<'input,SetAutoCommitStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SetAutoCommitStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SetAutoCommitStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SetAutoCommitStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setAutoCommitStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_setAutoCommitStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SetAutoCommitStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setAutoCommitStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setAutoCommitStatement }
}
crate::tid!{SetAutoCommitStatementContextExt<'a>}

impl<'input> SetAutoCommitStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetAutoCommitStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetAutoCommitStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetAutoCommitStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SetAutoCommitStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AUTOCOMMIT
/// Returns `None` if there is no child corresponding to token KW_AUTOCOMMIT
fn KW_AUTOCOMMIT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AUTOCOMMIT, 0)
}
fn booleanValueTok(&self) -> Option<Rc<BooleanValueTokContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SetAutoCommitStatementContextAttrs<'input> for SetAutoCommitStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setAutoCommitStatement(&mut self,)
	-> Result<Rc<SetAutoCommitStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetAutoCommitStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 444, RULE_setAutoCommitStatement);
        let mut _localctx: Rc<SetAutoCommitStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3048);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3049);
			recog.base.match_token(KW_AUTOCOMMIT,&mut recog.err_handler)?;

			/*InvokeRule booleanValueTok*/
			recog.base.set_state(3050);
			recog.booleanValueTok()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- abortTransactionStatement ----------------
pub type AbortTransactionStatementContextAll<'input> = AbortTransactionStatementContext<'input>;


pub type AbortTransactionStatementContext<'input> = BaseParserRuleContext<'input,AbortTransactionStatementContextExt<'input>>;

#[derive(Clone)]
pub struct AbortTransactionStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AbortTransactionStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AbortTransactionStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_abortTransactionStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_abortTransactionStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AbortTransactionStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_abortTransactionStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_abortTransactionStatement }
}
crate::tid!{AbortTransactionStatementContextExt<'a>}

impl<'input> AbortTransactionStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AbortTransactionStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AbortTransactionStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AbortTransactionStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AbortTransactionStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ABORT
/// Returns `None` if there is no child corresponding to token KW_ABORT
fn KW_ABORT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ABORT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRANSACTIONS
/// Returns `None` if there is no child corresponding to token KW_TRANSACTIONS
fn KW_TRANSACTIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRANSACTIONS, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token Number in current rule
fn Number_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token Number, starting from 0.
/// Returns `None` if number of children corresponding to token Number is less or equal than `i`.
fn Number(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, i)
}

}

impl<'input> AbortTransactionStatementContextAttrs<'input> for AbortTransactionStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn abortTransactionStatement(&mut self,)
	-> Result<Rc<AbortTransactionStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AbortTransactionStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 446, RULE_abortTransactionStatement);
        let mut _localctx: Rc<AbortTransactionStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3052);
			recog.base.match_token(KW_ABORT,&mut recog.err_handler)?;

			recog.base.set_state(3053);
			recog.base.match_token(KW_TRANSACTIONS,&mut recog.err_handler)?;

			recog.base.set_state(3055); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				recog.base.set_state(3054);
				recog.base.match_token(Number,&mut recog.err_handler)?;

				}
				}
				recog.base.set_state(3057); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==Number) {break}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- abortCompactionStatement ----------------
pub type AbortCompactionStatementContextAll<'input> = AbortCompactionStatementContext<'input>;


pub type AbortCompactionStatementContext<'input> = BaseParserRuleContext<'input,AbortCompactionStatementContextExt<'input>>;

#[derive(Clone)]
pub struct AbortCompactionStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AbortCompactionStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AbortCompactionStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_abortCompactionStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_abortCompactionStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AbortCompactionStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_abortCompactionStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_abortCompactionStatement }
}
crate::tid!{AbortCompactionStatementContextExt<'a>}

impl<'input> AbortCompactionStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AbortCompactionStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AbortCompactionStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AbortCompactionStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AbortCompactionStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ABORT
/// Returns `None` if there is no child corresponding to token KW_ABORT
fn KW_ABORT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ABORT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMPACTIONS
/// Returns `None` if there is no child corresponding to token KW_COMPACTIONS
fn KW_COMPACTIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMPACTIONS, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token Number in current rule
fn Number_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token Number, starting from 0.
/// Returns `None` if number of children corresponding to token Number is less or equal than `i`.
fn Number(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, i)
}

}

impl<'input> AbortCompactionStatementContextAttrs<'input> for AbortCompactionStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn abortCompactionStatement(&mut self,)
	-> Result<Rc<AbortCompactionStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AbortCompactionStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 448, RULE_abortCompactionStatement);
        let mut _localctx: Rc<AbortCompactionStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3059);
			recog.base.match_token(KW_ABORT,&mut recog.err_handler)?;

			recog.base.set_state(3060);
			recog.base.match_token(KW_COMPACTIONS,&mut recog.err_handler)?;

			recog.base.set_state(3062); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				recog.base.set_state(3061);
				recog.base.match_token(Number,&mut recog.err_handler)?;

				}
				}
				recog.base.set_state(3064); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==Number) {break}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mergeStatement ----------------
pub type MergeStatementContextAll<'input> = MergeStatementContext<'input>;


pub type MergeStatementContext<'input> = BaseParserRuleContext<'input,MergeStatementContextExt<'input>>;

#[derive(Clone)]
pub struct MergeStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for MergeStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for MergeStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_mergeStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_mergeStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for MergeStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mergeStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mergeStatement }
}
crate::tid!{MergeStatementContextExt<'a>}

impl<'input> MergeStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MergeStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MergeStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MergeStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<MergeStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_MERGE
/// Returns `None` if there is no child corresponding to token KW_MERGE
fn KW_MERGE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MERGE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INTO
/// Returns `None` if there is no child corresponding to token KW_INTO
fn KW_INTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INTO, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_USING
/// Returns `None` if there is no child corresponding to token KW_USING
fn KW_USING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USING, 0)
}
fn joinSourcePart(&self) -> Option<Rc<JoinSourcePartContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whenClauses(&self) -> Option<Rc<WhenClausesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token QUERY_HINT
/// Returns `None` if there is no child corresponding to token QUERY_HINT
fn QUERY_HINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(QUERY_HINT, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}

}

impl<'input> MergeStatementContextAttrs<'input> for MergeStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mergeStatement(&mut self,)
	-> Result<Rc<MergeStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MergeStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 450, RULE_mergeStatement);
        let mut _localctx: Rc<MergeStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3066);
			recog.base.match_token(KW_MERGE,&mut recog.err_handler)?;

			recog.base.set_state(3068);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==QUERY_HINT {
				{
				recog.base.set_state(3067);
				recog.base.match_token(QUERY_HINT,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(3070);
			recog.base.match_token(KW_INTO,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(3071);
			recog.tableName()?;

			recog.base.set_state(3076);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << KW_ABORT) | (1usize << KW_ACTIVATE) | (1usize << KW_ACTIVE) | (1usize << KW_ADD) | (1usize << KW_ADMIN) | (1usize << KW_AFTER) | (1usize << KW_ALLOC_FRACTION) | (1usize << KW_ANALYZE) | (1usize << KW_ARCHIVE) | (1usize << KW_AS) | (1usize << KW_ASC) | (1usize << KW_AST) | (1usize << KW_AT) | (1usize << KW_AUTOCOMMIT) | (1usize << KW_BATCH) | (1usize << KW_BEFORE) | (1usize << KW_BUCKET) | (1usize << KW_BUCKETS))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (KW_CACHE - 33)) | (1usize << (KW_CASCADE - 33)) | (1usize << (KW_CBO - 33)) | (1usize << (KW_CHANGE - 33)) | (1usize << (KW_CHECK - 33)) | (1usize << (KW_CLUSTER - 33)) | (1usize << (KW_CLUSTERED - 33)) | (1usize << (KW_CLUSTERSTATUS - 33)) | (1usize << (KW_COLLECTION - 33)) | (1usize << (KW_COLUMNS - 33)) | (1usize << (KW_COMMENT - 33)) | (1usize << (KW_COMPACT - 33)) | (1usize << (KW_COMPACTIONS - 33)) | (1usize << (KW_COMPUTE - 33)) | (1usize << (KW_CONCATENATE - 33)) | (1usize << (KW_CONTINUE - 33)) | (1usize << (KW_COST - 33)) | (1usize << (KW_CRON - 33)))) != 0) || ((((_la - 66)) & !0x3f) == 0 && ((1usize << (_la - 66)) & ((1usize << (KW_DATA - 66)) | (1usize << (KW_DATABASES - 66)) | (1usize << (KW_DATETIME - 66)) | (1usize << (KW_DAY - 66)) | (1usize << (KW_DAYOFWEEK - 66)) | (1usize << (KW_DBPROPERTIES - 66)) | (1usize << (KW_DCPROPERTIES - 66)) | (1usize << (KW_DEBUG - 66)) | (1usize << (KW_DEFAULT - 66)) | (1usize << (KW_DEFERRED - 66)) | (1usize << (KW_DEFINED - 66)) | (1usize << (KW_DELIMITED - 66)) | (1usize << (KW_DEPENDENCY - 66)) | (1usize << (KW_DESC - 66)) | (1usize << (KW_DETAIL - 66)) | (1usize << (KW_DIRECTORIES - 66)) | (1usize << (KW_DIRECTORY - 66)) | (1usize << (KW_DISABLE - 66)) | (1usize << (KW_DISTRIBUTE - 66)) | (1usize << (KW_DISTRIBUTED - 66)) | (1usize << (KW_DO - 66)))) != 0) || ((((_la - 98)) & !0x3f) == 0 && ((1usize << (_la - 98)) & ((1usize << (KW_DUMP - 98)) | (1usize << (KW_ELEM_TYPE - 98)) | (1usize << (KW_ENABLE - 98)) | (1usize << (KW_ENFORCED - 98)) | (1usize << (KW_ESCAPED - 98)) | (1usize << (KW_EVERY - 98)) | (1usize << (KW_EXCLUSIVE - 98)) | (1usize << (KW_EXECUTE - 98)) | (1usize << (KW_EXECUTED - 98)) | (1usize << (KW_EXPIRE_SNAPSHOTS - 98)) | (1usize << (KW_EXPLAIN - 98)) | (1usize << (KW_EXPORT - 98)) | (1usize << (KW_EXPRESSION - 98)) | (1usize << (KW_FIELDS - 98)) | (1usize << (KW_FILE - 98)) | (1usize << (KW_FILEFORMAT - 98)) | (1usize << (KW_FIRST - 98)))) != 0) || ((((_la - 131)) & !0x3f) == 0 && ((1usize << (_la - 131)) & ((1usize << (KW_FORMAT - 131)) | (1usize << (KW_FORMATTED - 131)) | (1usize << (KW_FUNCTIONS - 131)) | (1usize << (KW_HOLD_DDLTIME - 131)) | (1usize << (KW_HOUR - 131)) | (1usize << (KW_IDXPROPERTIES - 131)) | (1usize << (KW_IGNORE - 131)) | (1usize << (KW_INDEX - 131)) | (1usize << (KW_INDEXES - 131)) | (1usize << (KW_INPATH - 131)) | (1usize << (KW_INPUTDRIVER - 131)) | (1usize << (KW_INPUTFORMAT - 131)) | (1usize << (KW_ISOLATION - 131)) | (1usize << (KW_ITEMS - 131)) | (1usize << (KW_JAR - 131)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (KW_JOINCOST - 164)) | (1usize << (KW_KEY - 164)) | (1usize << (KW_KEYS - 164)) | (1usize << (KW_KEY_TYPE - 164)) | (1usize << (KW_KILL - 164)) | (1usize << (KW_LAST - 164)) | (1usize << (KW_LEVEL - 164)) | (1usize << (KW_LIMIT - 164)) | (1usize << (KW_LINES - 164)) | (1usize << (KW_LOAD - 164)) | (1usize << (KW_LOCATION - 164)) | (1usize << (KW_LOCK - 164)) | (1usize << (KW_LOCKS - 164)) | (1usize << (KW_LOGICAL - 164)) | (1usize << (KW_LONG - 164)) | (1usize << (KW_MANAGED - 164)) | (1usize << (KW_MANAGEDLOCATION - 164)) | (1usize << (KW_MANAGEMENT - 164)) | (1usize << (KW_MAPJOIN - 164)) | (1usize << (KW_MAPPING - 164)) | (1usize << (KW_MATCHED - 164)) | (1usize << (KW_MATERIALIZED - 164)) | (1usize << (KW_METADATA - 164)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (KW_MINUTE - 197)) | (1usize << (KW_MONTH - 197)) | (1usize << (KW_MOVE - 197)) | (1usize << (KW_MSCK - 197)) | (1usize << (KW_NORELY - 197)) | (1usize << (KW_NOSCAN - 197)) | (1usize << (KW_NOVALIDATE - 197)) | (1usize << (KW_NO_DROP - 197)) | (1usize << (KW_NULLS - 197)) | (1usize << (KW_OFFLINE - 197)) | (1usize << (KW_OFFSET - 197)) | (1usize << (KW_OPERATOR - 197)) | (1usize << (KW_OPTION - 197)) | (1usize << (KW_OUTPUTDRIVER - 197)) | (1usize << (KW_OUTPUTFORMAT - 197)) | (1usize << (KW_OVERWRITE - 197)) | (1usize << (KW_OWNER - 197)) | (1usize << (KW_PARTITIONED - 197)) | (1usize << (KW_PARTITIONS - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (KW_PATH - 229)) | (1usize << (KW_PLAN - 229)) | (1usize << (KW_PLANS - 229)) | (1usize << (KW_PLUS - 229)) | (1usize << (KW_POOL - 229)) | (1usize << (KW_PRINCIPALS - 229)) | (1usize << (KW_PROTECTION - 229)) | (1usize << (KW_PURGE - 229)) | (1usize << (KW_QUARTER - 229)) | (1usize << (KW_QUERY - 229)) | (1usize << (KW_QUERY_PARALLELISM - 229)) | (1usize << (KW_READ - 229)) | (1usize << (KW_READONLY - 229)) | (1usize << (KW_REBUILD - 229)) | (1usize << (KW_RECORDREADER - 229)) | (1usize << (KW_RECORDWRITER - 229)) | (1usize << (KW_RELOAD - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (KW_RELY - 261)) | (1usize << (KW_REMOTE - 261)) | (1usize << (KW_RENAME - 261)) | (1usize << (KW_REOPTIMIZATION - 261)) | (1usize << (KW_REPAIR - 261)) | (1usize << (KW_REPL - 261)) | (1usize << (KW_REPLACE - 261)) | (1usize << (KW_REPLICATION - 261)) | (1usize << (KW_RESOURCE - 261)) | (1usize << (KW_RESPECT - 261)) | (1usize << (KW_RESTRICT - 261)) | (1usize << (KW_REWRITE - 261)) | (1usize << (KW_ROLE - 261)) | (1usize << (KW_ROLES - 261)) | (1usize << (KW_SCHEDULED - 261)) | (1usize << (KW_SCHEDULING_POLICY - 261)) | (1usize << (KW_SCHEMA - 261)) | (1usize << (KW_SCHEMAS - 261)) | (1usize << (KW_SECOND - 261)) | (1usize << (KW_SEMI - 261)) | (1usize << (KW_SERDE - 261)) | (1usize << (KW_SERDEPROPERTIES - 261)) | (1usize << (KW_SERVER - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (KW_SETS - 293)) | (1usize << (KW_SET_CURRENT_SNAPSHOT - 293)) | (1usize << (KW_SHARED - 293)) | (1usize << (KW_SHOW - 293)) | (1usize << (KW_SHOW_DATABASE - 293)) | (1usize << (KW_SKEWED - 293)) | (1usize << (KW_SNAPSHOT - 293)) | (1usize << (KW_SORT - 293)) | (1usize << (KW_SORTED - 293)) | (1usize << (KW_SPEC - 293)) | (1usize << (KW_SSL - 293)) | (1usize << (KW_STATISTICS - 293)) | (1usize << (KW_STATUS - 293)) | (1usize << (KW_STORED - 293)) | (1usize << (KW_STREAMTABLE - 293)) | (1usize << (KW_STRING - 293)) | (1usize << (KW_STRUCT - 293)) | (1usize << (KW_SUMMARY - 293)) | (1usize << (KW_SYSTEM_TIME - 293)) | (1usize << (KW_SYSTEM_VERSION - 293)) | (1usize << (KW_TABLES - 293)) | (1usize << (KW_TBLPROPERTIES - 293)) | (1usize << (KW_TEMPORARY - 293)) | (1usize << (KW_TERMINATED - 293)))) != 0) || ((((_la - 327)) & !0x3f) == 0 && ((1usize << (_la - 327)) & ((1usize << (KW_TIMESTAMPTZ - 327)) | (1usize << (KW_TINYINT - 327)) | (1usize << (KW_TOUCH - 327)) | (1usize << (KW_TRANSACTION - 327)) | (1usize << (KW_TRANSACTIONAL - 327)) | (1usize << (KW_TRANSACTIONS - 327)) | (1usize << (KW_TRIM - 327)) | (1usize << (KW_TYPE - 327)) | (1usize << (KW_UNARCHIVE - 327)) | (1usize << (KW_UNDO - 327)) | (1usize << (KW_UNIONTYPE - 327)) | (1usize << (KW_UNKNOWN - 327)) | (1usize << (KW_UNLOCK - 327)) | (1usize << (KW_UNMANAGED - 327)) | (1usize << (KW_UNSET - 327)) | (1usize << (KW_UNSIGNED - 327)) | (1usize << (KW_URI - 327)) | (1usize << (KW_URL - 327)) | (1usize << (KW_USE - 327)))) != 0) || ((((_la - 359)) & !0x3f) == 0 && ((1usize << (_la - 359)) & ((1usize << (KW_UTC - 359)) | (1usize << (KW_UTCTIMESTAMP - 359)) | (1usize << (KW_VALIDATE - 359)) | (1usize << (KW_VALUE_TYPE - 359)) | (1usize << (KW_VECTORIZATION - 359)) | (1usize << (KW_VIEW - 359)) | (1usize << (KW_VIEWS - 359)) | (1usize << (KW_WAIT - 359)) | (1usize << (KW_WEEK - 359)) | (1usize << (KW_WHILE - 359)) | (1usize << (KW_WITHIN - 359)) | (1usize << (KW_WORK - 359)) | (1usize << (KW_WORKLOAD - 359)) | (1usize << (KW_WRITE - 359)) | (1usize << (KW_YEAR - 359)) | (1usize << (KW_ZONE - 359)))) != 0) || _la==Identifier {
				{
				recog.base.set_state(3073);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==KW_AS {
					{
					recog.base.set_state(3072);
					recog.base.match_token(KW_AS,&mut recog.err_handler)?;

					}
				}

				/*InvokeRule id_*/
				recog.base.set_state(3075);
				recog.id_()?;

				}
			}

			recog.base.set_state(3078);
			recog.base.match_token(KW_USING,&mut recog.err_handler)?;

			/*InvokeRule joinSourcePart*/
			recog.base.set_state(3079);
			recog.joinSourcePart()?;

			recog.base.set_state(3080);
			recog.base.match_token(KW_ON,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(3081);
			recog.expression()?;

			/*InvokeRule whenClauses*/
			recog.base.set_state(3082);
			recog.whenClauses()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whenClauses ----------------
pub type WhenClausesContextAll<'input> = WhenClausesContext<'input>;


pub type WhenClausesContext<'input> = BaseParserRuleContext<'input,WhenClausesContextExt<'input>>;

#[derive(Clone)]
pub struct WhenClausesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for WhenClausesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for WhenClausesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whenClauses(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_whenClauses(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for WhenClausesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whenClauses }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whenClauses }
}
crate::tid!{WhenClausesContextExt<'a>}

impl<'input> WhenClausesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhenClausesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhenClausesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WhenClausesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<WhenClausesContextExt<'input>>{

fn whenMatchedAndClause_all(&self) ->  Vec<Rc<WhenMatchedAndClauseContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn whenMatchedAndClause(&self, i: usize) -> Option<Rc<WhenMatchedAndClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn whenMatchedThenClause_all(&self) ->  Vec<Rc<WhenMatchedThenClauseContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn whenMatchedThenClause(&self, i: usize) -> Option<Rc<WhenMatchedThenClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn whenNotMatchedClause(&self) -> Option<Rc<WhenNotMatchedClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WhenClausesContextAttrs<'input> for WhenClausesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whenClauses(&mut self,)
	-> Result<Rc<WhenClausesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhenClausesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 452, RULE_whenClauses);
        let mut _localctx: Rc<WhenClausesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3088);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(327,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					recog.base.set_state(3086);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(326,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule whenMatchedAndClause*/
							recog.base.set_state(3084);
							recog.whenMatchedAndClause()?;

							}
						}
					,
						2 =>{
							{
							/*InvokeRule whenMatchedThenClause*/
							recog.base.set_state(3085);
							recog.whenMatchedThenClause()?;

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(3090);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(327,&mut recog.base)?;
			}
			recog.base.set_state(3092);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_WHEN {
				{
				/*InvokeRule whenNotMatchedClause*/
				recog.base.set_state(3091);
				recog.whenNotMatchedClause()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whenNotMatchedClause ----------------
pub type WhenNotMatchedClauseContextAll<'input> = WhenNotMatchedClauseContext<'input>;


pub type WhenNotMatchedClauseContext<'input> = BaseParserRuleContext<'input,WhenNotMatchedClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WhenNotMatchedClauseContextExt<'input>{
	pub targetCols: Option<Rc<ColumnParenthesesListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for WhenNotMatchedClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for WhenNotMatchedClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whenNotMatchedClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_whenNotMatchedClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for WhenNotMatchedClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whenNotMatchedClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whenNotMatchedClause }
}
crate::tid!{WhenNotMatchedClauseContextExt<'a>}

impl<'input> WhenNotMatchedClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhenNotMatchedClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhenNotMatchedClauseContextExt{
				targetCols: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WhenNotMatchedClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<WhenNotMatchedClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_WHEN
/// Returns `None` if there is no child corresponding to token KW_WHEN
fn KW_WHEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOT
/// Returns `None` if there is no child corresponding to token KW_NOT
fn KW_NOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MATCHED
/// Returns `None` if there is no child corresponding to token KW_MATCHED
fn KW_MATCHED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_THEN
/// Returns `None` if there is no child corresponding to token KW_THEN
fn KW_THEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_THEN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INSERT
/// Returns `None` if there is no child corresponding to token KW_INSERT
fn KW_INSERT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VALUES
/// Returns `None` if there is no child corresponding to token KW_VALUES
fn KW_VALUES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VALUES, 0)
}
fn valueRowConstructor(&self) -> Option<Rc<ValueRowConstructorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AND
/// Returns `None` if there is no child corresponding to token KW_AND
fn KW_AND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AND, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnParenthesesList(&self) -> Option<Rc<ColumnParenthesesListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WhenNotMatchedClauseContextAttrs<'input> for WhenNotMatchedClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whenNotMatchedClause(&mut self,)
	-> Result<Rc<WhenNotMatchedClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhenNotMatchedClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 454, RULE_whenNotMatchedClause);
        let mut _localctx: Rc<WhenNotMatchedClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3094);
			recog.base.match_token(KW_WHEN,&mut recog.err_handler)?;

			recog.base.set_state(3095);
			recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

			recog.base.set_state(3096);
			recog.base.match_token(KW_MATCHED,&mut recog.err_handler)?;

			recog.base.set_state(3099);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_AND {
				{
				recog.base.set_state(3097);
				recog.base.match_token(KW_AND,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(3098);
				recog.expression()?;

				}
			}

			recog.base.set_state(3101);
			recog.base.match_token(KW_THEN,&mut recog.err_handler)?;

			recog.base.set_state(3102);
			recog.base.match_token(KW_INSERT,&mut recog.err_handler)?;

			recog.base.set_state(3104);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LPAREN {
				{
				/*InvokeRule columnParenthesesList*/
				recog.base.set_state(3103);
				let tmp = recog.columnParenthesesList()?;
				 cast_mut::<_,WhenNotMatchedClauseContext >(&mut _localctx).targetCols = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(3106);
			recog.base.match_token(KW_VALUES,&mut recog.err_handler)?;

			/*InvokeRule valueRowConstructor*/
			recog.base.set_state(3107);
			recog.valueRowConstructor()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whenMatchedAndClause ----------------
pub type WhenMatchedAndClauseContextAll<'input> = WhenMatchedAndClauseContext<'input>;


pub type WhenMatchedAndClauseContext<'input> = BaseParserRuleContext<'input,WhenMatchedAndClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WhenMatchedAndClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for WhenMatchedAndClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for WhenMatchedAndClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whenMatchedAndClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_whenMatchedAndClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for WhenMatchedAndClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whenMatchedAndClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whenMatchedAndClause }
}
crate::tid!{WhenMatchedAndClauseContextExt<'a>}

impl<'input> WhenMatchedAndClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhenMatchedAndClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhenMatchedAndClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WhenMatchedAndClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<WhenMatchedAndClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_WHEN
/// Returns `None` if there is no child corresponding to token KW_WHEN
fn KW_WHEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MATCHED
/// Returns `None` if there is no child corresponding to token KW_MATCHED
fn KW_MATCHED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AND
/// Returns `None` if there is no child corresponding to token KW_AND
fn KW_AND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AND, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_THEN
/// Returns `None` if there is no child corresponding to token KW_THEN
fn KW_THEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_THEN, 0)
}
fn updateOrDelete(&self) -> Option<Rc<UpdateOrDeleteContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WhenMatchedAndClauseContextAttrs<'input> for WhenMatchedAndClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whenMatchedAndClause(&mut self,)
	-> Result<Rc<WhenMatchedAndClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhenMatchedAndClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 456, RULE_whenMatchedAndClause);
        let mut _localctx: Rc<WhenMatchedAndClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3109);
			recog.base.match_token(KW_WHEN,&mut recog.err_handler)?;

			recog.base.set_state(3110);
			recog.base.match_token(KW_MATCHED,&mut recog.err_handler)?;

			recog.base.set_state(3111);
			recog.base.match_token(KW_AND,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(3112);
			recog.expression()?;

			recog.base.set_state(3113);
			recog.base.match_token(KW_THEN,&mut recog.err_handler)?;

			/*InvokeRule updateOrDelete*/
			recog.base.set_state(3114);
			recog.updateOrDelete()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whenMatchedThenClause ----------------
pub type WhenMatchedThenClauseContextAll<'input> = WhenMatchedThenClauseContext<'input>;


pub type WhenMatchedThenClauseContext<'input> = BaseParserRuleContext<'input,WhenMatchedThenClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WhenMatchedThenClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for WhenMatchedThenClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for WhenMatchedThenClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whenMatchedThenClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_whenMatchedThenClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for WhenMatchedThenClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whenMatchedThenClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whenMatchedThenClause }
}
crate::tid!{WhenMatchedThenClauseContextExt<'a>}

impl<'input> WhenMatchedThenClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhenMatchedThenClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhenMatchedThenClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WhenMatchedThenClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<WhenMatchedThenClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_WHEN
/// Returns `None` if there is no child corresponding to token KW_WHEN
fn KW_WHEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MATCHED
/// Returns `None` if there is no child corresponding to token KW_MATCHED
fn KW_MATCHED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_THEN
/// Returns `None` if there is no child corresponding to token KW_THEN
fn KW_THEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_THEN, 0)
}
fn updateOrDelete(&self) -> Option<Rc<UpdateOrDeleteContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WhenMatchedThenClauseContextAttrs<'input> for WhenMatchedThenClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whenMatchedThenClause(&mut self,)
	-> Result<Rc<WhenMatchedThenClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhenMatchedThenClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 458, RULE_whenMatchedThenClause);
        let mut _localctx: Rc<WhenMatchedThenClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3116);
			recog.base.match_token(KW_WHEN,&mut recog.err_handler)?;

			recog.base.set_state(3117);
			recog.base.match_token(KW_MATCHED,&mut recog.err_handler)?;

			recog.base.set_state(3118);
			recog.base.match_token(KW_THEN,&mut recog.err_handler)?;

			/*InvokeRule updateOrDelete*/
			recog.base.set_state(3119);
			recog.updateOrDelete()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- updateOrDelete ----------------
pub type UpdateOrDeleteContextAll<'input> = UpdateOrDeleteContext<'input>;


pub type UpdateOrDeleteContext<'input> = BaseParserRuleContext<'input,UpdateOrDeleteContextExt<'input>>;

#[derive(Clone)]
pub struct UpdateOrDeleteContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for UpdateOrDeleteContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for UpdateOrDeleteContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_updateOrDelete(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_updateOrDelete(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for UpdateOrDeleteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_updateOrDelete }
	//fn type_rule_index() -> usize where Self: Sized { RULE_updateOrDelete }
}
crate::tid!{UpdateOrDeleteContextExt<'a>}

impl<'input> UpdateOrDeleteContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UpdateOrDeleteContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UpdateOrDeleteContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UpdateOrDeleteContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<UpdateOrDeleteContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UPDATE
/// Returns `None` if there is no child corresponding to token KW_UPDATE
fn KW_UPDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UPDATE, 0)
}
fn setColumnsClause(&self) -> Option<Rc<SetColumnsClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_DELETE
/// Returns `None` if there is no child corresponding to token KW_DELETE
fn KW_DELETE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DELETE, 0)
}

}

impl<'input> UpdateOrDeleteContextAttrs<'input> for UpdateOrDeleteContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn updateOrDelete(&mut self,)
	-> Result<Rc<UpdateOrDeleteContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UpdateOrDeleteContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 460, RULE_updateOrDelete);
        let mut _localctx: Rc<UpdateOrDeleteContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3124);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_UPDATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3121);
					recog.base.match_token(KW_UPDATE,&mut recog.err_handler)?;

					/*InvokeRule setColumnsClause*/
					recog.base.set_state(3122);
					recog.setColumnsClause()?;

					}
				}

			 KW_DELETE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3123);
					recog.base.match_token(KW_DELETE,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- killQueryStatement ----------------
pub type KillQueryStatementContextAll<'input> = KillQueryStatementContext<'input>;


pub type KillQueryStatementContext<'input> = BaseParserRuleContext<'input,KillQueryStatementContextExt<'input>>;

#[derive(Clone)]
pub struct KillQueryStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for KillQueryStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for KillQueryStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_killQueryStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_killQueryStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for KillQueryStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_killQueryStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_killQueryStatement }
}
crate::tid!{KillQueryStatementContextExt<'a>}

impl<'input> KillQueryStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<KillQueryStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,KillQueryStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait KillQueryStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<KillQueryStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_KILL
/// Returns `None` if there is no child corresponding to token KW_KILL
fn KW_KILL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KILL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_QUERY
/// Returns `None` if there is no child corresponding to token KW_QUERY
fn KW_QUERY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUERY, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token StringLiteral in current rule
fn StringLiteral_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token StringLiteral, starting from 0.
/// Returns `None` if number of children corresponding to token StringLiteral is less or equal than `i`.
fn StringLiteral(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, i)
}

}

impl<'input> KillQueryStatementContextAttrs<'input> for KillQueryStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn killQueryStatement(&mut self,)
	-> Result<Rc<KillQueryStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = KillQueryStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 462, RULE_killQueryStatement);
        let mut _localctx: Rc<KillQueryStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3126);
			recog.base.match_token(KW_KILL,&mut recog.err_handler)?;

			recog.base.set_state(3127);
			recog.base.match_token(KW_QUERY,&mut recog.err_handler)?;

			recog.base.set_state(3129); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				recog.base.set_state(3128);
				recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

				}
				}
				recog.base.set_state(3131); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==StringLiteral) {break}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- compactionId ----------------
pub type CompactionIdContextAll<'input> = CompactionIdContext<'input>;


pub type CompactionIdContext<'input> = BaseParserRuleContext<'input,CompactionIdContextExt<'input>>;

#[derive(Clone)]
pub struct CompactionIdContextExt<'input>{
	pub compactId: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CompactionIdContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CompactionIdContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_compactionId(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_compactionId(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CompactionIdContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_compactionId }
	//fn type_rule_index() -> usize where Self: Sized { RULE_compactionId }
}
crate::tid!{CompactionIdContextExt<'a>}

impl<'input> CompactionIdContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CompactionIdContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CompactionIdContextExt{
				compactId: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CompactionIdContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CompactionIdContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_COMPACT_ID
/// Returns `None` if there is no child corresponding to token KW_COMPACT_ID
fn KW_COMPACT_ID(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMPACT_ID, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}

}

impl<'input> CompactionIdContextAttrs<'input> for CompactionIdContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn compactionId(&mut self,)
	-> Result<Rc<CompactionIdContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CompactionIdContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 464, RULE_compactionId);
        let mut _localctx: Rc<CompactionIdContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3133);
			recog.base.match_token(KW_COMPACT_ID,&mut recog.err_handler)?;

			recog.base.set_state(3134);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(3135);
			let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
			 cast_mut::<_,CompactionIdContext >(&mut _localctx).compactId = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- compactionPool ----------------
pub type CompactionPoolContextAll<'input> = CompactionPoolContext<'input>;


pub type CompactionPoolContext<'input> = BaseParserRuleContext<'input,CompactionPoolContextExt<'input>>;

#[derive(Clone)]
pub struct CompactionPoolContextExt<'input>{
	pub poolName: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CompactionPoolContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CompactionPoolContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_compactionPool(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_compactionPool(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CompactionPoolContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_compactionPool }
	//fn type_rule_index() -> usize where Self: Sized { RULE_compactionPool }
}
crate::tid!{CompactionPoolContextExt<'a>}

impl<'input> CompactionPoolContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CompactionPoolContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CompactionPoolContextExt{
				poolName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CompactionPoolContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CompactionPoolContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_POOL
/// Returns `None` if there is no child corresponding to token KW_POOL
fn KW_POOL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_POOL, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> CompactionPoolContextAttrs<'input> for CompactionPoolContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn compactionPool(&mut self,)
	-> Result<Rc<CompactionPoolContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CompactionPoolContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 466, RULE_compactionPool);
        let mut _localctx: Rc<CompactionPoolContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3137);
			recog.base.match_token(KW_POOL,&mut recog.err_handler)?;

			recog.base.set_state(3138);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,CompactionPoolContext >(&mut _localctx).poolName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- compactionType ----------------
pub type CompactionTypeContextAll<'input> = CompactionTypeContext<'input>;


pub type CompactionTypeContext<'input> = BaseParserRuleContext<'input,CompactionTypeContextExt<'input>>;

#[derive(Clone)]
pub struct CompactionTypeContextExt<'input>{
	pub compactType: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CompactionTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CompactionTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_compactionType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_compactionType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CompactionTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_compactionType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_compactionType }
}
crate::tid!{CompactionTypeContextExt<'a>}

impl<'input> CompactionTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CompactionTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CompactionTypeContextExt{
				compactType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CompactionTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CompactionTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TYPE
/// Returns `None` if there is no child corresponding to token KW_TYPE
fn KW_TYPE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> CompactionTypeContextAttrs<'input> for CompactionTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn compactionType(&mut self,)
	-> Result<Rc<CompactionTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CompactionTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 468, RULE_compactionType);
        let mut _localctx: Rc<CompactionTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3140);
			recog.base.match_token(KW_TYPE,&mut recog.err_handler)?;

			recog.base.set_state(3141);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,CompactionTypeContext >(&mut _localctx).compactType = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- compactionStatus ----------------
pub type CompactionStatusContextAll<'input> = CompactionStatusContext<'input>;


pub type CompactionStatusContext<'input> = BaseParserRuleContext<'input,CompactionStatusContextExt<'input>>;

#[derive(Clone)]
pub struct CompactionStatusContextExt<'input>{
	pub status: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CompactionStatusContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CompactionStatusContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_compactionStatus(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_compactionStatus(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CompactionStatusContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_compactionStatus }
	//fn type_rule_index() -> usize where Self: Sized { RULE_compactionStatus }
}
crate::tid!{CompactionStatusContextExt<'a>}

impl<'input> CompactionStatusContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CompactionStatusContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CompactionStatusContextExt{
				status: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CompactionStatusContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CompactionStatusContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_STATUS
/// Returns `None` if there is no child corresponding to token KW_STATUS
fn KW_STATUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STATUS, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> CompactionStatusContextAttrs<'input> for CompactionStatusContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn compactionStatus(&mut self,)
	-> Result<Rc<CompactionStatusContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CompactionStatusContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 470, RULE_compactionStatus);
        let mut _localctx: Rc<CompactionStatusContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3143);
			recog.base.match_token(KW_STATUS,&mut recog.err_handler)?;

			recog.base.set_state(3144);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,CompactionStatusContext >(&mut _localctx).status = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatement ----------------
pub type AlterStatementContextAll<'input> = AlterStatementContext<'input>;


pub type AlterStatementContext<'input> = BaseParserRuleContext<'input,AlterStatementContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementContextExt<'input>{
	pub tableNameTree: Option<Rc<TableNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatement }
}
crate::tid!{AlterStatementContextExt<'a>}

impl<'input> AlterStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementContextExt{
				tableNameTree: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ALTER
/// Returns `None` if there is no child corresponding to token KW_ALTER
fn KW_ALTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterTableStatementSuffix(&self) -> Option<Rc<AlterTableStatementSuffixContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_VIEW
/// Returns `None` if there is no child corresponding to token KW_VIEW
fn KW_VIEW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VIEW, 0)
}
fn alterViewStatementSuffix(&self) -> Option<Rc<AlterViewStatementSuffixContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_MATERIALIZED
/// Returns `None` if there is no child corresponding to token KW_MATERIALIZED
fn KW_MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MATERIALIZED, 0)
}
fn alterMaterializedViewStatementSuffix(&self) -> Option<Rc<AlterMaterializedViewStatementSuffixContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn db_schema(&self) -> Option<Rc<Db_schemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterDatabaseStatementSuffix(&self) -> Option<Rc<AlterDatabaseStatementSuffixContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATACONNECTOR
/// Returns `None` if there is no child corresponding to token KW_DATACONNECTOR
fn KW_DATACONNECTOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATACONNECTOR, 0)
}
fn alterDataConnectorStatementSuffix(&self) -> Option<Rc<AlterDataConnectorStatementSuffixContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_INDEX
/// Returns `None` if there is no child corresponding to token KW_INDEX
fn KW_INDEX(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INDEX, 0)
}
fn alterIndexStatementSuffix(&self) -> Option<Rc<AlterIndexStatementSuffixContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}

}

impl<'input> AlterStatementContextAttrs<'input> for AlterStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatement(&mut self,)
	-> Result<Rc<AlterStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 472, RULE_alterStatement);
        let mut _localctx: Rc<AlterStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3146);
			recog.base.match_token(KW_ALTER,&mut recog.err_handler)?;

			recog.base.set_state(3170);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_TABLE 
				=> {
					{
					recog.base.set_state(3147);
					recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

					/*InvokeRule tableName*/
					recog.base.set_state(3148);
					recog.tableName()?;

					/*InvokeRule alterTableStatementSuffix*/
					recog.base.set_state(3149);
					recog.alterTableStatementSuffix()?;

					}
				}

			 KW_VIEW 
				=> {
					{
					recog.base.set_state(3151);
					recog.base.match_token(KW_VIEW,&mut recog.err_handler)?;

					/*InvokeRule tableName*/
					recog.base.set_state(3152);
					recog.tableName()?;

					recog.base.set_state(3154);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_AS {
						{
						recog.base.set_state(3153);
						recog.base.match_token(KW_AS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule alterViewStatementSuffix*/
					recog.base.set_state(3156);
					recog.alterViewStatementSuffix()?;

					}
				}

			 KW_MATERIALIZED 
				=> {
					{
					recog.base.set_state(3158);
					recog.base.match_token(KW_MATERIALIZED,&mut recog.err_handler)?;

					recog.base.set_state(3159);
					recog.base.match_token(KW_VIEW,&mut recog.err_handler)?;

					/*InvokeRule tableName*/
					recog.base.set_state(3160);
					let tmp = recog.tableName()?;
					 cast_mut::<_,AlterStatementContext >(&mut _localctx).tableNameTree = Some(tmp.clone());
					  

					/*InvokeRule alterMaterializedViewStatementSuffix*/
					recog.base.set_state(3161);
					recog.alterMaterializedViewStatementSuffix()?;

					}
				}

			 KW_DATABASE | KW_SCHEMA 
				=> {
					{
					/*InvokeRule db_schema*/
					recog.base.set_state(3163);
					recog.db_schema()?;

					/*InvokeRule alterDatabaseStatementSuffix*/
					recog.base.set_state(3164);
					recog.alterDatabaseStatementSuffix()?;

					}
				}

			 KW_DATACONNECTOR 
				=> {
					{
					recog.base.set_state(3166);
					recog.base.match_token(KW_DATACONNECTOR,&mut recog.err_handler)?;

					/*InvokeRule alterDataConnectorStatementSuffix*/
					recog.base.set_state(3167);
					recog.alterDataConnectorStatementSuffix()?;

					}
				}

			 KW_INDEX 
				=> {
					{
					recog.base.set_state(3168);
					recog.base.match_token(KW_INDEX,&mut recog.err_handler)?;

					/*InvokeRule alterIndexStatementSuffix*/
					recog.base.set_state(3169);
					recog.alterIndexStatementSuffix()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterTableStatementSuffix ----------------
pub type AlterTableStatementSuffixContextAll<'input> = AlterTableStatementSuffixContext<'input>;


pub type AlterTableStatementSuffixContext<'input> = BaseParserRuleContext<'input,AlterTableStatementSuffixContextExt<'input>>;

#[derive(Clone)]
pub struct AlterTableStatementSuffixContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterTableStatementSuffixContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterTableStatementSuffixContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterTableStatementSuffix(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterTableStatementSuffix(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterTableStatementSuffixContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterTableStatementSuffix }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterTableStatementSuffix }
}
crate::tid!{AlterTableStatementSuffixContextExt<'a>}

impl<'input> AlterTableStatementSuffixContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterTableStatementSuffixContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterTableStatementSuffixContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterTableStatementSuffixContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterTableStatementSuffixContextExt<'input>>{

fn alterStatementSuffixRename(&self) -> Option<Rc<AlterStatementSuffixRenameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixDropPartitions(&self) -> Option<Rc<AlterStatementSuffixDropPartitionsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixAddPartitions(&self) -> Option<Rc<AlterStatementSuffixAddPartitionsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixTouch(&self) -> Option<Rc<AlterStatementSuffixTouchContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixArchive(&self) -> Option<Rc<AlterStatementSuffixArchiveContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixUnArchive(&self) -> Option<Rc<AlterStatementSuffixUnArchiveContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixProperties(&self) -> Option<Rc<AlterStatementSuffixPropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixSkewedby(&self) -> Option<Rc<AlterStatementSuffixSkewedbyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixExchangePartition(&self) -> Option<Rc<AlterStatementSuffixExchangePartitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementPartitionKeyType(&self) -> Option<Rc<AlterStatementPartitionKeyTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixDropConstraint(&self) -> Option<Rc<AlterStatementSuffixDropConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixAddConstraint(&self) -> Option<Rc<AlterStatementSuffixAddConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterTblPartitionStatementSuffix(&self) -> Option<Rc<AlterTblPartitionStatementSuffixContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixSetOwner(&self) -> Option<Rc<AlterStatementSuffixSetOwnerContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixSetPartSpec(&self) -> Option<Rc<AlterStatementSuffixSetPartSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixExecute(&self) -> Option<Rc<AlterStatementSuffixExecuteContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterTableStatementSuffixContextAttrs<'input> for AlterTableStatementSuffixContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterTableStatementSuffix(&mut self,)
	-> Result<Rc<AlterTableStatementSuffixContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterTableStatementSuffixContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 474, RULE_alterTableStatementSuffix);
        let mut _localctx: Rc<AlterTableStatementSuffixContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3191);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(335,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule alterStatementSuffixRename*/
					recog.base.set_state(3172);
					recog.alterStatementSuffixRename()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule alterStatementSuffixDropPartitions*/
					recog.base.set_state(3173);
					recog.alterStatementSuffixDropPartitions()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule alterStatementSuffixAddPartitions*/
					recog.base.set_state(3174);
					recog.alterStatementSuffixAddPartitions()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule alterStatementSuffixTouch*/
					recog.base.set_state(3175);
					recog.alterStatementSuffixTouch()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule alterStatementSuffixArchive*/
					recog.base.set_state(3176);
					recog.alterStatementSuffixArchive()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule alterStatementSuffixUnArchive*/
					recog.base.set_state(3177);
					recog.alterStatementSuffixUnArchive()?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule alterStatementSuffixProperties*/
					recog.base.set_state(3178);
					recog.alterStatementSuffixProperties()?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule alterStatementSuffixSkewedby*/
					recog.base.set_state(3179);
					recog.alterStatementSuffixSkewedby()?;

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule alterStatementSuffixExchangePartition*/
					recog.base.set_state(3180);
					recog.alterStatementSuffixExchangePartition()?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule alterStatementPartitionKeyType*/
					recog.base.set_state(3181);
					recog.alterStatementPartitionKeyType()?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule alterStatementSuffixDropConstraint*/
					recog.base.set_state(3182);
					recog.alterStatementSuffixDropConstraint()?;

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					/*InvokeRule alterStatementSuffixAddConstraint*/
					recog.base.set_state(3183);
					recog.alterStatementSuffixAddConstraint()?;

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					/*InvokeRule alterTblPartitionStatementSuffix*/
					recog.base.set_state(3184);
					recog.alterTblPartitionStatementSuffix()?;

					}
				}
			,
				14 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					/*InvokeRule partitionSpec*/
					recog.base.set_state(3185);
					recog.partitionSpec()?;

					/*InvokeRule alterTblPartitionStatementSuffix*/
					recog.base.set_state(3186);
					recog.alterTblPartitionStatementSuffix()?;

					}
				}
			,
				15 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					/*InvokeRule alterStatementSuffixSetOwner*/
					recog.base.set_state(3188);
					recog.alterStatementSuffixSetOwner()?;

					}
				}
			,
				16 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 16);
					recog.base.enter_outer_alt(None, 16);
					{
					/*InvokeRule alterStatementSuffixSetPartSpec*/
					recog.base.set_state(3189);
					recog.alterStatementSuffixSetPartSpec()?;

					}
				}
			,
				17 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 17);
					recog.base.enter_outer_alt(None, 17);
					{
					/*InvokeRule alterStatementSuffixExecute*/
					recog.base.set_state(3190);
					recog.alterStatementSuffixExecute()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterTblPartitionStatementSuffix ----------------
pub type AlterTblPartitionStatementSuffixContextAll<'input> = AlterTblPartitionStatementSuffixContext<'input>;


pub type AlterTblPartitionStatementSuffixContext<'input> = BaseParserRuleContext<'input,AlterTblPartitionStatementSuffixContextExt<'input>>;

#[derive(Clone)]
pub struct AlterTblPartitionStatementSuffixContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterTblPartitionStatementSuffixContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterTblPartitionStatementSuffixContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterTblPartitionStatementSuffix(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterTblPartitionStatementSuffix(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterTblPartitionStatementSuffixContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterTblPartitionStatementSuffix }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterTblPartitionStatementSuffix }
}
crate::tid!{AlterTblPartitionStatementSuffixContextExt<'a>}

impl<'input> AlterTblPartitionStatementSuffixContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterTblPartitionStatementSuffixContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterTblPartitionStatementSuffixContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterTblPartitionStatementSuffixContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterTblPartitionStatementSuffixContextExt<'input>>{

fn alterStatementSuffixFileFormat(&self) -> Option<Rc<AlterStatementSuffixFileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixLocation(&self) -> Option<Rc<AlterStatementSuffixLocationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixMergeFiles(&self) -> Option<Rc<AlterStatementSuffixMergeFilesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixSerdeProperties(&self) -> Option<Rc<AlterStatementSuffixSerdePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixRenamePart(&self) -> Option<Rc<AlterStatementSuffixRenamePartContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixBucketNum(&self) -> Option<Rc<AlterStatementSuffixBucketNumContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterTblPartitionStatementSuffixSkewedLocation(&self) -> Option<Rc<AlterTblPartitionStatementSuffixSkewedLocationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixClusterbySortby(&self) -> Option<Rc<AlterStatementSuffixClusterbySortbyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixCompact(&self) -> Option<Rc<AlterStatementSuffixCompactContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixUpdateStatsCol(&self) -> Option<Rc<AlterStatementSuffixUpdateStatsColContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixUpdateStats(&self) -> Option<Rc<AlterStatementSuffixUpdateStatsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixRenameCol(&self) -> Option<Rc<AlterStatementSuffixRenameColContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixAddCol(&self) -> Option<Rc<AlterStatementSuffixAddColContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixUpdateColumns(&self) -> Option<Rc<AlterStatementSuffixUpdateColumnsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixProtections(&self) -> Option<Rc<AlterStatementSuffixProtectionsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterTblPartitionStatementSuffixContextAttrs<'input> for AlterTblPartitionStatementSuffixContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterTblPartitionStatementSuffix(&mut self,)
	-> Result<Rc<AlterTblPartitionStatementSuffixContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterTblPartitionStatementSuffixContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 476, RULE_alterTblPartitionStatementSuffix);
        let mut _localctx: Rc<AlterTblPartitionStatementSuffixContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3208);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(336,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule alterStatementSuffixFileFormat*/
					recog.base.set_state(3193);
					recog.alterStatementSuffixFileFormat()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule alterStatementSuffixLocation*/
					recog.base.set_state(3194);
					recog.alterStatementSuffixLocation()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule alterStatementSuffixMergeFiles*/
					recog.base.set_state(3195);
					recog.alterStatementSuffixMergeFiles()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule alterStatementSuffixSerdeProperties*/
					recog.base.set_state(3196);
					recog.alterStatementSuffixSerdeProperties()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule alterStatementSuffixRenamePart*/
					recog.base.set_state(3197);
					recog.alterStatementSuffixRenamePart()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule alterStatementSuffixBucketNum*/
					recog.base.set_state(3198);
					recog.alterStatementSuffixBucketNum()?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule alterTblPartitionStatementSuffixSkewedLocation*/
					recog.base.set_state(3199);
					recog.alterTblPartitionStatementSuffixSkewedLocation()?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule alterStatementSuffixClusterbySortby*/
					recog.base.set_state(3200);
					recog.alterStatementSuffixClusterbySortby()?;

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule alterStatementSuffixCompact*/
					recog.base.set_state(3201);
					recog.alterStatementSuffixCompact()?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule alterStatementSuffixUpdateStatsCol*/
					recog.base.set_state(3202);
					recog.alterStatementSuffixUpdateStatsCol()?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule alterStatementSuffixUpdateStats*/
					recog.base.set_state(3203);
					recog.alterStatementSuffixUpdateStats()?;

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					/*InvokeRule alterStatementSuffixRenameCol*/
					recog.base.set_state(3204);
					recog.alterStatementSuffixRenameCol()?;

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					/*InvokeRule alterStatementSuffixAddCol*/
					recog.base.set_state(3205);
					recog.alterStatementSuffixAddCol()?;

					}
				}
			,
				14 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					/*InvokeRule alterStatementSuffixUpdateColumns*/
					recog.base.set_state(3206);
					recog.alterStatementSuffixUpdateColumns()?;

					}
				}
			,
				15 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					/*InvokeRule alterStatementSuffixProtections*/
					recog.base.set_state(3207);
					recog.alterStatementSuffixProtections()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementPartitionKeyType ----------------
pub type AlterStatementPartitionKeyTypeContextAll<'input> = AlterStatementPartitionKeyTypeContext<'input>;


pub type AlterStatementPartitionKeyTypeContext<'input> = BaseParserRuleContext<'input,AlterStatementPartitionKeyTypeContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementPartitionKeyTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementPartitionKeyTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementPartitionKeyTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementPartitionKeyType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementPartitionKeyType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementPartitionKeyTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementPartitionKeyType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementPartitionKeyType }
}
crate::tid!{AlterStatementPartitionKeyTypeContextExt<'a>}

impl<'input> AlterStatementPartitionKeyTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementPartitionKeyTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementPartitionKeyTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementPartitionKeyTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementPartitionKeyTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_PARTITION
/// Returns `None` if there is no child corresponding to token KW_PARTITION
fn KW_PARTITION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COLUMN
/// Returns `None` if there is no child corresponding to token KW_COLUMN
fn KW_COLUMN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLUMN, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnNameType(&self) -> Option<Rc<ColumnNameTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> AlterStatementPartitionKeyTypeContextAttrs<'input> for AlterStatementPartitionKeyTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementPartitionKeyType(&mut self,)
	-> Result<Rc<AlterStatementPartitionKeyTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementPartitionKeyTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 478, RULE_alterStatementPartitionKeyType);
        let mut _localctx: Rc<AlterStatementPartitionKeyTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3210);
			recog.base.match_token(KW_PARTITION,&mut recog.err_handler)?;

			recog.base.set_state(3211);
			recog.base.match_token(KW_COLUMN,&mut recog.err_handler)?;

			recog.base.set_state(3212);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnNameType*/
			recog.base.set_state(3213);
			recog.columnNameType()?;

			recog.base.set_state(3214);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterViewStatementSuffix ----------------
pub type AlterViewStatementSuffixContextAll<'input> = AlterViewStatementSuffixContext<'input>;


pub type AlterViewStatementSuffixContext<'input> = BaseParserRuleContext<'input,AlterViewStatementSuffixContextExt<'input>>;

#[derive(Clone)]
pub struct AlterViewStatementSuffixContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterViewStatementSuffixContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterViewStatementSuffixContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterViewStatementSuffix(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterViewStatementSuffix(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterViewStatementSuffixContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterViewStatementSuffix }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterViewStatementSuffix }
}
crate::tid!{AlterViewStatementSuffixContextExt<'a>}

impl<'input> AlterViewStatementSuffixContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterViewStatementSuffixContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterViewStatementSuffixContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterViewStatementSuffixContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterViewStatementSuffixContextExt<'input>>{

fn alterViewSuffixProperties(&self) -> Option<Rc<AlterViewSuffixPropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixRename(&self) -> Option<Rc<AlterStatementSuffixRenameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixAddPartitions(&self) -> Option<Rc<AlterStatementSuffixAddPartitionsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixDropPartitions(&self) -> Option<Rc<AlterStatementSuffixDropPartitionsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn selectStatementWithCTE(&self) -> Option<Rc<SelectStatementWithCTEContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterViewStatementSuffixContextAttrs<'input> for AlterViewStatementSuffixContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterViewStatementSuffix(&mut self,)
	-> Result<Rc<AlterViewStatementSuffixContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterViewStatementSuffixContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 480, RULE_alterViewStatementSuffix);
        let mut _localctx: Rc<AlterViewStatementSuffixContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3221);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_SET | KW_UNSET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule alterViewSuffixProperties*/
					recog.base.set_state(3216);
					recog.alterViewSuffixProperties()?;

					}
				}

			 KW_RENAME 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule alterStatementSuffixRename*/
					recog.base.set_state(3217);
					recog.alterStatementSuffixRename()?;

					}
				}

			 KW_ADD 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule alterStatementSuffixAddPartitions*/
					recog.base.set_state(3218);
					recog.alterStatementSuffixAddPartitions()?;

					}
				}

			 KW_DROP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule alterStatementSuffixDropPartitions*/
					recog.base.set_state(3219);
					recog.alterStatementSuffixDropPartitions()?;

					}
				}

			 KW_MAP | KW_REDUCE | KW_SELECT | KW_VALUES | KW_WITH | LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule selectStatementWithCTE*/
					recog.base.set_state(3220);
					recog.selectStatementWithCTE()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterMaterializedViewStatementSuffix ----------------
pub type AlterMaterializedViewStatementSuffixContextAll<'input> = AlterMaterializedViewStatementSuffixContext<'input>;


pub type AlterMaterializedViewStatementSuffixContext<'input> = BaseParserRuleContext<'input,AlterMaterializedViewStatementSuffixContextExt<'input>>;

#[derive(Clone)]
pub struct AlterMaterializedViewStatementSuffixContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterMaterializedViewStatementSuffixContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterMaterializedViewStatementSuffixContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterMaterializedViewStatementSuffix(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterMaterializedViewStatementSuffix(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterMaterializedViewStatementSuffixContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterMaterializedViewStatementSuffix }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterMaterializedViewStatementSuffix }
}
crate::tid!{AlterMaterializedViewStatementSuffixContextExt<'a>}

impl<'input> AlterMaterializedViewStatementSuffixContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterMaterializedViewStatementSuffixContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterMaterializedViewStatementSuffixContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterMaterializedViewStatementSuffixContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterMaterializedViewStatementSuffixContextExt<'input>>{

fn alterMaterializedViewSuffixRewrite(&self) -> Option<Rc<AlterMaterializedViewSuffixRewriteContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterMaterializedViewSuffixRebuild(&self) -> Option<Rc<AlterMaterializedViewSuffixRebuildContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterMaterializedViewStatementSuffixContextAttrs<'input> for AlterMaterializedViewStatementSuffixContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterMaterializedViewStatementSuffix(&mut self,)
	-> Result<Rc<AlterMaterializedViewStatementSuffixContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterMaterializedViewStatementSuffixContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 482, RULE_alterMaterializedViewStatementSuffix);
        let mut _localctx: Rc<AlterMaterializedViewStatementSuffixContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3225);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_DISABLE | KW_ENABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule alterMaterializedViewSuffixRewrite*/
					recog.base.set_state(3223);
					recog.alterMaterializedViewSuffixRewrite()?;

					}
				}

			 KW_REBUILD 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule alterMaterializedViewSuffixRebuild*/
					recog.base.set_state(3224);
					recog.alterMaterializedViewSuffixRebuild()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterMaterializedViewSuffixRewrite ----------------
pub type AlterMaterializedViewSuffixRewriteContextAll<'input> = AlterMaterializedViewSuffixRewriteContext<'input>;


pub type AlterMaterializedViewSuffixRewriteContext<'input> = BaseParserRuleContext<'input,AlterMaterializedViewSuffixRewriteContextExt<'input>>;

#[derive(Clone)]
pub struct AlterMaterializedViewSuffixRewriteContextExt<'input>{
	pub mvRewriteFlag: Option<Rc<RewriteEnabledContextAll<'input>>>,
	pub mvRewriteFlag2: Option<Rc<RewriteDisabledContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterMaterializedViewSuffixRewriteContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterMaterializedViewSuffixRewriteContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterMaterializedViewSuffixRewrite(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterMaterializedViewSuffixRewrite(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterMaterializedViewSuffixRewriteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterMaterializedViewSuffixRewrite }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterMaterializedViewSuffixRewrite }
}
crate::tid!{AlterMaterializedViewSuffixRewriteContextExt<'a>}

impl<'input> AlterMaterializedViewSuffixRewriteContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterMaterializedViewSuffixRewriteContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterMaterializedViewSuffixRewriteContextExt{
				mvRewriteFlag: None, mvRewriteFlag2: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterMaterializedViewSuffixRewriteContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterMaterializedViewSuffixRewriteContextExt<'input>>{

fn rewriteEnabled(&self) -> Option<Rc<RewriteEnabledContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn rewriteDisabled(&self) -> Option<Rc<RewriteDisabledContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterMaterializedViewSuffixRewriteContextAttrs<'input> for AlterMaterializedViewSuffixRewriteContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterMaterializedViewSuffixRewrite(&mut self,)
	-> Result<Rc<AlterMaterializedViewSuffixRewriteContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterMaterializedViewSuffixRewriteContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 484, RULE_alterMaterializedViewSuffixRewrite);
        let mut _localctx: Rc<AlterMaterializedViewSuffixRewriteContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3229);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ENABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule rewriteEnabled*/
					recog.base.set_state(3227);
					let tmp = recog.rewriteEnabled()?;
					 cast_mut::<_,AlterMaterializedViewSuffixRewriteContext >(&mut _localctx).mvRewriteFlag = Some(tmp.clone());
					  

					}
				}

			 KW_DISABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule rewriteDisabled*/
					recog.base.set_state(3228);
					let tmp = recog.rewriteDisabled()?;
					 cast_mut::<_,AlterMaterializedViewSuffixRewriteContext >(&mut _localctx).mvRewriteFlag2 = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterMaterializedViewSuffixRebuild ----------------
pub type AlterMaterializedViewSuffixRebuildContextAll<'input> = AlterMaterializedViewSuffixRebuildContext<'input>;


pub type AlterMaterializedViewSuffixRebuildContext<'input> = BaseParserRuleContext<'input,AlterMaterializedViewSuffixRebuildContextExt<'input>>;

#[derive(Clone)]
pub struct AlterMaterializedViewSuffixRebuildContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterMaterializedViewSuffixRebuildContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterMaterializedViewSuffixRebuildContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterMaterializedViewSuffixRebuild(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterMaterializedViewSuffixRebuild(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterMaterializedViewSuffixRebuildContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterMaterializedViewSuffixRebuild }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterMaterializedViewSuffixRebuild }
}
crate::tid!{AlterMaterializedViewSuffixRebuildContextExt<'a>}

impl<'input> AlterMaterializedViewSuffixRebuildContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterMaterializedViewSuffixRebuildContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterMaterializedViewSuffixRebuildContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterMaterializedViewSuffixRebuildContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterMaterializedViewSuffixRebuildContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_REBUILD
/// Returns `None` if there is no child corresponding to token KW_REBUILD
fn KW_REBUILD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REBUILD, 0)
}

}

impl<'input> AlterMaterializedViewSuffixRebuildContextAttrs<'input> for AlterMaterializedViewSuffixRebuildContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterMaterializedViewSuffixRebuild(&mut self,)
	-> Result<Rc<AlterMaterializedViewSuffixRebuildContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterMaterializedViewSuffixRebuildContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 486, RULE_alterMaterializedViewSuffixRebuild);
        let mut _localctx: Rc<AlterMaterializedViewSuffixRebuildContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3231);
			recog.base.match_token(KW_REBUILD,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterDatabaseStatementSuffix ----------------
pub type AlterDatabaseStatementSuffixContextAll<'input> = AlterDatabaseStatementSuffixContext<'input>;


pub type AlterDatabaseStatementSuffixContext<'input> = BaseParserRuleContext<'input,AlterDatabaseStatementSuffixContextExt<'input>>;

#[derive(Clone)]
pub struct AlterDatabaseStatementSuffixContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterDatabaseStatementSuffixContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterDatabaseStatementSuffixContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterDatabaseStatementSuffix(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterDatabaseStatementSuffix(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterDatabaseStatementSuffixContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterDatabaseStatementSuffix }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterDatabaseStatementSuffix }
}
crate::tid!{AlterDatabaseStatementSuffixContextExt<'a>}

impl<'input> AlterDatabaseStatementSuffixContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterDatabaseStatementSuffixContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterDatabaseStatementSuffixContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterDatabaseStatementSuffixContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterDatabaseStatementSuffixContextExt<'input>>{

fn alterDatabaseSuffixProperties(&self) -> Option<Rc<AlterDatabaseSuffixPropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterDatabaseSuffixSetOwner(&self) -> Option<Rc<AlterDatabaseSuffixSetOwnerContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterDatabaseSuffixSetLocation(&self) -> Option<Rc<AlterDatabaseSuffixSetLocationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterDatabaseStatementSuffixContextAttrs<'input> for AlterDatabaseStatementSuffixContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterDatabaseStatementSuffix(&mut self,)
	-> Result<Rc<AlterDatabaseStatementSuffixContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterDatabaseStatementSuffixContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 488, RULE_alterDatabaseStatementSuffix);
        let mut _localctx: Rc<AlterDatabaseStatementSuffixContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3236);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(340,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule alterDatabaseSuffixProperties*/
					recog.base.set_state(3233);
					recog.alterDatabaseSuffixProperties()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule alterDatabaseSuffixSetOwner*/
					recog.base.set_state(3234);
					recog.alterDatabaseSuffixSetOwner()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule alterDatabaseSuffixSetLocation*/
					recog.base.set_state(3235);
					recog.alterDatabaseSuffixSetLocation()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterDatabaseSuffixProperties ----------------
pub type AlterDatabaseSuffixPropertiesContextAll<'input> = AlterDatabaseSuffixPropertiesContext<'input>;


pub type AlterDatabaseSuffixPropertiesContext<'input> = BaseParserRuleContext<'input,AlterDatabaseSuffixPropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct AlterDatabaseSuffixPropertiesContextExt<'input>{
	pub name: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterDatabaseSuffixPropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterDatabaseSuffixPropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterDatabaseSuffixProperties(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterDatabaseSuffixProperties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterDatabaseSuffixPropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterDatabaseSuffixProperties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterDatabaseSuffixProperties }
}
crate::tid!{AlterDatabaseSuffixPropertiesContextExt<'a>}

impl<'input> AlterDatabaseSuffixPropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterDatabaseSuffixPropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterDatabaseSuffixPropertiesContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterDatabaseSuffixPropertiesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterDatabaseSuffixPropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DBPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_DBPROPERTIES
fn KW_DBPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DBPROPERTIES, 0)
}
fn dbProperties(&self) -> Option<Rc<DbPropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterDatabaseSuffixPropertiesContextAttrs<'input> for AlterDatabaseSuffixPropertiesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterDatabaseSuffixProperties(&mut self,)
	-> Result<Rc<AlterDatabaseSuffixPropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterDatabaseSuffixPropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 490, RULE_alterDatabaseSuffixProperties);
        let mut _localctx: Rc<AlterDatabaseSuffixPropertiesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(3238);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterDatabaseSuffixPropertiesContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(3239);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3240);
			recog.base.match_token(KW_DBPROPERTIES,&mut recog.err_handler)?;

			/*InvokeRule dbProperties*/
			recog.base.set_state(3241);
			recog.dbProperties()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterDatabaseSuffixSetOwner ----------------
pub type AlterDatabaseSuffixSetOwnerContextAll<'input> = AlterDatabaseSuffixSetOwnerContext<'input>;


pub type AlterDatabaseSuffixSetOwnerContext<'input> = BaseParserRuleContext<'input,AlterDatabaseSuffixSetOwnerContextExt<'input>>;

#[derive(Clone)]
pub struct AlterDatabaseSuffixSetOwnerContextExt<'input>{
	pub dbName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterDatabaseSuffixSetOwnerContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterDatabaseSuffixSetOwnerContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterDatabaseSuffixSetOwner(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterDatabaseSuffixSetOwner(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterDatabaseSuffixSetOwnerContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterDatabaseSuffixSetOwner }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterDatabaseSuffixSetOwner }
}
crate::tid!{AlterDatabaseSuffixSetOwnerContextExt<'a>}

impl<'input> AlterDatabaseSuffixSetOwnerContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterDatabaseSuffixSetOwnerContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterDatabaseSuffixSetOwnerContextExt{
				dbName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterDatabaseSuffixSetOwnerContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterDatabaseSuffixSetOwnerContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OWNER
/// Returns `None` if there is no child corresponding to token KW_OWNER
fn KW_OWNER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OWNER, 0)
}
fn principalName(&self) -> Option<Rc<PrincipalNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterDatabaseSuffixSetOwnerContextAttrs<'input> for AlterDatabaseSuffixSetOwnerContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterDatabaseSuffixSetOwner(&mut self,)
	-> Result<Rc<AlterDatabaseSuffixSetOwnerContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterDatabaseSuffixSetOwnerContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 492, RULE_alterDatabaseSuffixSetOwner);
        let mut _localctx: Rc<AlterDatabaseSuffixSetOwnerContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(3243);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterDatabaseSuffixSetOwnerContext >(&mut _localctx).dbName = Some(tmp.clone());
			  

			recog.base.set_state(3244);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3245);
			recog.base.match_token(KW_OWNER,&mut recog.err_handler)?;

			/*InvokeRule principalName*/
			recog.base.set_state(3246);
			recog.principalName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterDatabaseSuffixSetLocation ----------------
pub type AlterDatabaseSuffixSetLocationContextAll<'input> = AlterDatabaseSuffixSetLocationContext<'input>;


pub type AlterDatabaseSuffixSetLocationContext<'input> = BaseParserRuleContext<'input,AlterDatabaseSuffixSetLocationContextExt<'input>>;

#[derive(Clone)]
pub struct AlterDatabaseSuffixSetLocationContextExt<'input>{
	pub dbName: Option<Rc<Id_ContextAll<'input>>>,
	pub newLocation: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterDatabaseSuffixSetLocationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterDatabaseSuffixSetLocationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterDatabaseSuffixSetLocation(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterDatabaseSuffixSetLocation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterDatabaseSuffixSetLocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterDatabaseSuffixSetLocation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterDatabaseSuffixSetLocation }
}
crate::tid!{AlterDatabaseSuffixSetLocationContextExt<'a>}

impl<'input> AlterDatabaseSuffixSetLocationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterDatabaseSuffixSetLocationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterDatabaseSuffixSetLocationContextExt{
				newLocation: None, 
				dbName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterDatabaseSuffixSetLocationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterDatabaseSuffixSetLocationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCATION
/// Returns `None` if there is no child corresponding to token KW_LOCATION
fn KW_LOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MANAGEDLOCATION
/// Returns `None` if there is no child corresponding to token KW_MANAGEDLOCATION
fn KW_MANAGEDLOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MANAGEDLOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> AlterDatabaseSuffixSetLocationContextAttrs<'input> for AlterDatabaseSuffixSetLocationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterDatabaseSuffixSetLocation(&mut self,)
	-> Result<Rc<AlterDatabaseSuffixSetLocationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterDatabaseSuffixSetLocationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 494, RULE_alterDatabaseSuffixSetLocation);
        let mut _localctx: Rc<AlterDatabaseSuffixSetLocationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(3248);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterDatabaseSuffixSetLocationContext >(&mut _localctx).dbName = Some(tmp.clone());
			  

			recog.base.set_state(3249);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3250);
			_la = recog.base.input.la(1);
			if { !(_la==KW_LOCATION || _la==KW_MANAGEDLOCATION) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(3251);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,AlterDatabaseSuffixSetLocationContext >(&mut _localctx).newLocation = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterDatabaseSuffixSetManagedLocation ----------------
pub type AlterDatabaseSuffixSetManagedLocationContextAll<'input> = AlterDatabaseSuffixSetManagedLocationContext<'input>;


pub type AlterDatabaseSuffixSetManagedLocationContext<'input> = BaseParserRuleContext<'input,AlterDatabaseSuffixSetManagedLocationContextExt<'input>>;

#[derive(Clone)]
pub struct AlterDatabaseSuffixSetManagedLocationContextExt<'input>{
	pub dbName: Option<Rc<Id_ContextAll<'input>>>,
	pub newLocation: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterDatabaseSuffixSetManagedLocationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterDatabaseSuffixSetManagedLocationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterDatabaseSuffixSetManagedLocation(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterDatabaseSuffixSetManagedLocation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterDatabaseSuffixSetManagedLocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterDatabaseSuffixSetManagedLocation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterDatabaseSuffixSetManagedLocation }
}
crate::tid!{AlterDatabaseSuffixSetManagedLocationContextExt<'a>}

impl<'input> AlterDatabaseSuffixSetManagedLocationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterDatabaseSuffixSetManagedLocationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterDatabaseSuffixSetManagedLocationContextExt{
				newLocation: None, 
				dbName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterDatabaseSuffixSetManagedLocationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterDatabaseSuffixSetManagedLocationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MANAGEDLOCATION
/// Returns `None` if there is no child corresponding to token KW_MANAGEDLOCATION
fn KW_MANAGEDLOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MANAGEDLOCATION, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> AlterDatabaseSuffixSetManagedLocationContextAttrs<'input> for AlterDatabaseSuffixSetManagedLocationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterDatabaseSuffixSetManagedLocation(&mut self,)
	-> Result<Rc<AlterDatabaseSuffixSetManagedLocationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterDatabaseSuffixSetManagedLocationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 496, RULE_alterDatabaseSuffixSetManagedLocation);
        let mut _localctx: Rc<AlterDatabaseSuffixSetManagedLocationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(3253);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterDatabaseSuffixSetManagedLocationContext >(&mut _localctx).dbName = Some(tmp.clone());
			  

			recog.base.set_state(3254);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3255);
			recog.base.match_token(KW_MANAGEDLOCATION,&mut recog.err_handler)?;

			recog.base.set_state(3256);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,AlterDatabaseSuffixSetManagedLocationContext >(&mut _localctx).newLocation = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixRename ----------------
pub type AlterStatementSuffixRenameContextAll<'input> = AlterStatementSuffixRenameContext<'input>;


pub type AlterStatementSuffixRenameContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixRenameContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixRenameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixRenameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixRenameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixRename(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixRename(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixRenameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixRename }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixRename }
}
crate::tid!{AlterStatementSuffixRenameContextExt<'a>}

impl<'input> AlterStatementSuffixRenameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixRenameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixRenameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixRenameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixRenameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_RENAME
/// Returns `None` if there is no child corresponding to token KW_RENAME
fn KW_RENAME(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RENAME, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixRenameContextAttrs<'input> for AlterStatementSuffixRenameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixRename(&mut self,)
	-> Result<Rc<AlterStatementSuffixRenameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixRenameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 498, RULE_alterStatementSuffixRename);
        let mut _localctx: Rc<AlterStatementSuffixRenameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3258);
			recog.base.match_token(KW_RENAME,&mut recog.err_handler)?;

			recog.base.set_state(3259);
			recog.base.match_token(KW_TO,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(3260);
			recog.tableName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixAddCol ----------------
pub type AlterStatementSuffixAddColContextAll<'input> = AlterStatementSuffixAddColContext<'input>;


pub type AlterStatementSuffixAddColContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixAddColContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixAddColContextExt<'input>{
	pub add: Option<TokenType<'input>>,
	pub replace: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixAddColContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixAddColContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixAddCol(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixAddCol(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixAddColContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixAddCol }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixAddCol }
}
crate::tid!{AlterStatementSuffixAddColContextExt<'a>}

impl<'input> AlterStatementSuffixAddColContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixAddColContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixAddColContextExt{
				add: None, replace: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixAddColContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixAddColContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_COLUMNS
/// Returns `None` if there is no child corresponding to token KW_COLUMNS
fn KW_COLUMNS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnNameTypeList(&self) -> Option<Rc<ColumnNameTypeListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ADD
/// Returns `None` if there is no child corresponding to token KW_ADD
fn KW_ADD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REPLACE
/// Returns `None` if there is no child corresponding to token KW_REPLACE
fn KW_REPLACE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPLACE, 0)
}
fn restrictOrCascade(&self) -> Option<Rc<RestrictOrCascadeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixAddColContextAttrs<'input> for AlterStatementSuffixAddColContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixAddCol(&mut self,)
	-> Result<Rc<AlterStatementSuffixAddColContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixAddColContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 500, RULE_alterStatementSuffixAddCol);
        let mut _localctx: Rc<AlterStatementSuffixAddColContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3264);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ADD 
				=> {
					{
					recog.base.set_state(3262);
					let tmp = recog.base.match_token(KW_ADD,&mut recog.err_handler)?;
					 cast_mut::<_,AlterStatementSuffixAddColContext >(&mut _localctx).add = Some(tmp.clone());
					  

					}
				}

			 KW_REPLACE 
				=> {
					{
					recog.base.set_state(3263);
					let tmp = recog.base.match_token(KW_REPLACE,&mut recog.err_handler)?;
					 cast_mut::<_,AlterStatementSuffixAddColContext >(&mut _localctx).replace = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(3266);
			recog.base.match_token(KW_COLUMNS,&mut recog.err_handler)?;

			recog.base.set_state(3267);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnNameTypeList*/
			recog.base.set_state(3268);
			recog.columnNameTypeList()?;

			recog.base.set_state(3269);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(3271);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CASCADE || _la==KW_RESTRICT {
				{
				/*InvokeRule restrictOrCascade*/
				recog.base.set_state(3270);
				recog.restrictOrCascade()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixAddConstraint ----------------
pub type AlterStatementSuffixAddConstraintContextAll<'input> = AlterStatementSuffixAddConstraintContext<'input>;


pub type AlterStatementSuffixAddConstraintContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixAddConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixAddConstraintContextExt<'input>{
	pub fk: Option<Rc<AlterForeignKeyWithNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixAddConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixAddConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixAddConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixAddConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixAddConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixAddConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixAddConstraint }
}
crate::tid!{AlterStatementSuffixAddConstraintContextExt<'a>}

impl<'input> AlterStatementSuffixAddConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixAddConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixAddConstraintContextExt{
				fk: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixAddConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixAddConstraintContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ADD
/// Returns `None` if there is no child corresponding to token KW_ADD
fn KW_ADD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ADD, 0)
}
fn alterConstraintWithName(&self) -> Option<Rc<AlterConstraintWithNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterForeignKeyWithName(&self) -> Option<Rc<AlterForeignKeyWithNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixAddConstraintContextAttrs<'input> for AlterStatementSuffixAddConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixAddConstraint(&mut self,)
	-> Result<Rc<AlterStatementSuffixAddConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixAddConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 502, RULE_alterStatementSuffixAddConstraint);
        let mut _localctx: Rc<AlterStatementSuffixAddConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3273);
			recog.base.match_token(KW_ADD,&mut recog.err_handler)?;

			recog.base.set_state(3276);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(343,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule alterForeignKeyWithName*/
					recog.base.set_state(3274);
					let tmp = recog.alterForeignKeyWithName()?;
					 cast_mut::<_,AlterStatementSuffixAddConstraintContext >(&mut _localctx).fk = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					{
					/*InvokeRule alterConstraintWithName*/
					recog.base.set_state(3275);
					recog.alterConstraintWithName()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixUpdateColumns ----------------
pub type AlterStatementSuffixUpdateColumnsContextAll<'input> = AlterStatementSuffixUpdateColumnsContext<'input>;


pub type AlterStatementSuffixUpdateColumnsContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixUpdateColumnsContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixUpdateColumnsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixUpdateColumnsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixUpdateColumnsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixUpdateColumns(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixUpdateColumns(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixUpdateColumnsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixUpdateColumns }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixUpdateColumns }
}
crate::tid!{AlterStatementSuffixUpdateColumnsContextExt<'a>}

impl<'input> AlterStatementSuffixUpdateColumnsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixUpdateColumnsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixUpdateColumnsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixUpdateColumnsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixUpdateColumnsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UPDATE
/// Returns `None` if there is no child corresponding to token KW_UPDATE
fn KW_UPDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COLUMNS
/// Returns `None` if there is no child corresponding to token KW_COLUMNS
fn KW_COLUMNS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLUMNS, 0)
}
fn restrictOrCascade(&self) -> Option<Rc<RestrictOrCascadeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixUpdateColumnsContextAttrs<'input> for AlterStatementSuffixUpdateColumnsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixUpdateColumns(&mut self,)
	-> Result<Rc<AlterStatementSuffixUpdateColumnsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixUpdateColumnsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 504, RULE_alterStatementSuffixUpdateColumns);
        let mut _localctx: Rc<AlterStatementSuffixUpdateColumnsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3278);
			recog.base.match_token(KW_UPDATE,&mut recog.err_handler)?;

			recog.base.set_state(3279);
			recog.base.match_token(KW_COLUMNS,&mut recog.err_handler)?;

			recog.base.set_state(3281);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CASCADE || _la==KW_RESTRICT {
				{
				/*InvokeRule restrictOrCascade*/
				recog.base.set_state(3280);
				recog.restrictOrCascade()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixProtections ----------------
pub type AlterStatementSuffixProtectionsContextAll<'input> = AlterStatementSuffixProtectionsContext<'input>;


pub type AlterStatementSuffixProtectionsContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixProtectionsContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixProtectionsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixProtectionsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixProtectionsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixProtections(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixProtections(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixProtectionsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixProtections }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixProtections }
}
crate::tid!{AlterStatementSuffixProtectionsContextExt<'a>}

impl<'input> AlterStatementSuffixProtectionsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixProtectionsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixProtectionsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixProtectionsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixProtectionsContextExt<'input>>{

fn enableSpecification(&self) -> Option<Rc<EnableSpecificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_NO_DROP
/// Returns `None` if there is no child corresponding to token KW_NO_DROP
fn KW_NO_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NO_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CASCADE
/// Returns `None` if there is no child corresponding to token KW_CASCADE
fn KW_CASCADE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CASCADE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OFFLINE
/// Returns `None` if there is no child corresponding to token KW_OFFLINE
fn KW_OFFLINE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OFFLINE, 0)
}

}

impl<'input> AlterStatementSuffixProtectionsContextAttrs<'input> for AlterStatementSuffixProtectionsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixProtections(&mut self,)
	-> Result<Rc<AlterStatementSuffixProtectionsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixProtectionsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 506, RULE_alterStatementSuffixProtections);
        let mut _localctx: Rc<AlterStatementSuffixProtectionsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3291);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(346,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule enableSpecification*/
					recog.base.set_state(3283);
					recog.enableSpecification()?;

					recog.base.set_state(3284);
					recog.base.match_token(KW_NO_DROP,&mut recog.err_handler)?;

					recog.base.set_state(3286);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_CASCADE {
						{
						recog.base.set_state(3285);
						recog.base.match_token(KW_CASCADE,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule enableSpecification*/
					recog.base.set_state(3288);
					recog.enableSpecification()?;

					recog.base.set_state(3289);
					recog.base.match_token(KW_OFFLINE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixDropConstraint ----------------
pub type AlterStatementSuffixDropConstraintContextAll<'input> = AlterStatementSuffixDropConstraintContext<'input>;


pub type AlterStatementSuffixDropConstraintContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixDropConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixDropConstraintContextExt<'input>{
	pub cName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixDropConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixDropConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixDropConstraint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixDropConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixDropConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixDropConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixDropConstraint }
}
crate::tid!{AlterStatementSuffixDropConstraintContextExt<'a>}

impl<'input> AlterStatementSuffixDropConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixDropConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixDropConstraintContextExt{
				cName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixDropConstraintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixDropConstraintContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CONSTRAINT
/// Returns `None` if there is no child corresponding to token KW_CONSTRAINT
fn KW_CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONSTRAINT, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixDropConstraintContextAttrs<'input> for AlterStatementSuffixDropConstraintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixDropConstraint(&mut self,)
	-> Result<Rc<AlterStatementSuffixDropConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixDropConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 508, RULE_alterStatementSuffixDropConstraint);
        let mut _localctx: Rc<AlterStatementSuffixDropConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3293);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(3294);
			recog.base.match_token(KW_CONSTRAINT,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(3295);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterStatementSuffixDropConstraintContext >(&mut _localctx).cName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixRenameCol ----------------
pub type AlterStatementSuffixRenameColContextAll<'input> = AlterStatementSuffixRenameColContext<'input>;


pub type AlterStatementSuffixRenameColContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixRenameColContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixRenameColContextExt<'input>{
	pub oldName: Option<Rc<Id_ContextAll<'input>>>,
	pub newName: Option<Rc<Id_ContextAll<'input>>>,
	pub comment: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixRenameColContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixRenameColContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixRenameCol(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixRenameCol(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixRenameColContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixRenameCol }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixRenameCol }
}
crate::tid!{AlterStatementSuffixRenameColContextExt<'a>}

impl<'input> AlterStatementSuffixRenameColContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixRenameColContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixRenameColContextExt{
				comment: None, 
				oldName: None, newName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixRenameColContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixRenameColContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CHANGE
/// Returns `None` if there is no child corresponding to token KW_CHANGE
fn KW_CHANGE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CHANGE, 0)
}
fn colType(&self) -> Option<Rc<ColTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_COLUMN
/// Returns `None` if there is no child corresponding to token KW_COLUMN
fn KW_COLUMN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLUMN, 0)
}
fn alterColumnConstraint(&self) -> Option<Rc<AlterColumnConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMMENT
/// Returns `None` if there is no child corresponding to token KW_COMMENT
fn KW_COMMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMENT, 0)
}
fn alterStatementChangeColPosition(&self) -> Option<Rc<AlterStatementChangeColPositionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn restrictOrCascade(&self) -> Option<Rc<RestrictOrCascadeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> AlterStatementSuffixRenameColContextAttrs<'input> for AlterStatementSuffixRenameColContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixRenameCol(&mut self,)
	-> Result<Rc<AlterStatementSuffixRenameColContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixRenameColContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 510, RULE_alterStatementSuffixRenameCol);
        let mut _localctx: Rc<AlterStatementSuffixRenameColContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3297);
			recog.base.match_token(KW_CHANGE,&mut recog.err_handler)?;

			recog.base.set_state(3299);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COLUMN {
				{
				recog.base.set_state(3298);
				recog.base.match_token(KW_COLUMN,&mut recog.err_handler)?;

				}
			}

			/*InvokeRule id_*/
			recog.base.set_state(3301);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterStatementSuffixRenameColContext >(&mut _localctx).oldName = Some(tmp.clone());
			  

			/*InvokeRule id_*/
			recog.base.set_state(3302);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterStatementSuffixRenameColContext >(&mut _localctx).newName = Some(tmp.clone());
			  

			/*InvokeRule colType*/
			recog.base.set_state(3303);
			recog.colType()?;

			recog.base.set_state(3305);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CHECK || _la==KW_CONSTRAINT || _la==KW_DEFAULT || _la==KW_NOT || _la==KW_PRIMARY || _la==KW_REFERENCES || _la==KW_UNIQUE {
				{
				/*InvokeRule alterColumnConstraint*/
				recog.base.set_state(3304);
				recog.alterColumnConstraint()?;

				}
			}

			recog.base.set_state(3309);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COMMENT {
				{
				recog.base.set_state(3307);
				recog.base.match_token(KW_COMMENT,&mut recog.err_handler)?;

				recog.base.set_state(3308);
				let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
				 cast_mut::<_,AlterStatementSuffixRenameColContext >(&mut _localctx).comment = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(3312);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_AFTER || _la==KW_FIRST {
				{
				/*InvokeRule alterStatementChangeColPosition*/
				recog.base.set_state(3311);
				recog.alterStatementChangeColPosition()?;

				}
			}

			recog.base.set_state(3315);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CASCADE || _la==KW_RESTRICT {
				{
				/*InvokeRule restrictOrCascade*/
				recog.base.set_state(3314);
				recog.restrictOrCascade()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixUpdateStatsCol ----------------
pub type AlterStatementSuffixUpdateStatsColContextAll<'input> = AlterStatementSuffixUpdateStatsColContext<'input>;


pub type AlterStatementSuffixUpdateStatsColContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixUpdateStatsColContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixUpdateStatsColContextExt<'input>{
	pub colName: Option<Rc<Id_ContextAll<'input>>>,
	pub comment: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixUpdateStatsColContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixUpdateStatsColContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixUpdateStatsCol(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixUpdateStatsCol(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixUpdateStatsColContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixUpdateStatsCol }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixUpdateStatsCol }
}
crate::tid!{AlterStatementSuffixUpdateStatsColContextExt<'a>}

impl<'input> AlterStatementSuffixUpdateStatsColContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixUpdateStatsColContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixUpdateStatsColContextExt{
				comment: None, 
				colName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixUpdateStatsColContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixUpdateStatsColContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UPDATE
/// Returns `None` if there is no child corresponding to token KW_UPDATE
fn KW_UPDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STATISTICS
/// Returns `None` if there is no child corresponding to token KW_STATISTICS
fn KW_STATISTICS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STATISTICS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FOR
/// Returns `None` if there is no child corresponding to token KW_FOR
fn KW_FOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_COLUMN
/// Returns `None` if there is no child corresponding to token KW_COLUMN
fn KW_COLUMN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLUMN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMMENT
/// Returns `None` if there is no child corresponding to token KW_COMMENT
fn KW_COMMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> AlterStatementSuffixUpdateStatsColContextAttrs<'input> for AlterStatementSuffixUpdateStatsColContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixUpdateStatsCol(&mut self,)
	-> Result<Rc<AlterStatementSuffixUpdateStatsColContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixUpdateStatsColContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 512, RULE_alterStatementSuffixUpdateStatsCol);
        let mut _localctx: Rc<AlterStatementSuffixUpdateStatsColContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3317);
			recog.base.match_token(KW_UPDATE,&mut recog.err_handler)?;

			recog.base.set_state(3318);
			recog.base.match_token(KW_STATISTICS,&mut recog.err_handler)?;

			recog.base.set_state(3319);
			recog.base.match_token(KW_FOR,&mut recog.err_handler)?;

			recog.base.set_state(3321);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COLUMN {
				{
				recog.base.set_state(3320);
				recog.base.match_token(KW_COLUMN,&mut recog.err_handler)?;

				}
			}

			/*InvokeRule id_*/
			recog.base.set_state(3323);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterStatementSuffixUpdateStatsColContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			recog.base.set_state(3324);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			/*InvokeRule tableProperties*/
			recog.base.set_state(3325);
			recog.tableProperties()?;

			recog.base.set_state(3328);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COMMENT {
				{
				recog.base.set_state(3326);
				recog.base.match_token(KW_COMMENT,&mut recog.err_handler)?;

				recog.base.set_state(3327);
				let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
				 cast_mut::<_,AlterStatementSuffixUpdateStatsColContext >(&mut _localctx).comment = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixUpdateStats ----------------
pub type AlterStatementSuffixUpdateStatsContextAll<'input> = AlterStatementSuffixUpdateStatsContext<'input>;


pub type AlterStatementSuffixUpdateStatsContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixUpdateStatsContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixUpdateStatsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixUpdateStatsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixUpdateStatsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixUpdateStats(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixUpdateStats(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixUpdateStatsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixUpdateStats }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixUpdateStats }
}
crate::tid!{AlterStatementSuffixUpdateStatsContextExt<'a>}

impl<'input> AlterStatementSuffixUpdateStatsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixUpdateStatsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixUpdateStatsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixUpdateStatsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixUpdateStatsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UPDATE
/// Returns `None` if there is no child corresponding to token KW_UPDATE
fn KW_UPDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STATISTICS
/// Returns `None` if there is no child corresponding to token KW_STATISTICS
fn KW_STATISTICS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STATISTICS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixUpdateStatsContextAttrs<'input> for AlterStatementSuffixUpdateStatsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixUpdateStats(&mut self,)
	-> Result<Rc<AlterStatementSuffixUpdateStatsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixUpdateStatsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 514, RULE_alterStatementSuffixUpdateStats);
        let mut _localctx: Rc<AlterStatementSuffixUpdateStatsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3330);
			recog.base.match_token(KW_UPDATE,&mut recog.err_handler)?;

			recog.base.set_state(3331);
			recog.base.match_token(KW_STATISTICS,&mut recog.err_handler)?;

			recog.base.set_state(3332);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			/*InvokeRule tableProperties*/
			recog.base.set_state(3333);
			recog.tableProperties()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementChangeColPosition ----------------
pub type AlterStatementChangeColPositionContextAll<'input> = AlterStatementChangeColPositionContext<'input>;


pub type AlterStatementChangeColPositionContext<'input> = BaseParserRuleContext<'input,AlterStatementChangeColPositionContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementChangeColPositionContextExt<'input>{
	pub first: Option<TokenType<'input>>,
	pub afterCol: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementChangeColPositionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementChangeColPositionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementChangeColPosition(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementChangeColPosition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementChangeColPositionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementChangeColPosition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementChangeColPosition }
}
crate::tid!{AlterStatementChangeColPositionContextExt<'a>}

impl<'input> AlterStatementChangeColPositionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementChangeColPositionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementChangeColPositionContextExt{
				first: None, 
				afterCol: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementChangeColPositionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementChangeColPositionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_FIRST
/// Returns `None` if there is no child corresponding to token KW_FIRST
fn KW_FIRST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AFTER
/// Returns `None` if there is no child corresponding to token KW_AFTER
fn KW_AFTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AFTER, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementChangeColPositionContextAttrs<'input> for AlterStatementChangeColPositionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementChangeColPosition(&mut self,)
	-> Result<Rc<AlterStatementChangeColPositionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementChangeColPositionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 516, RULE_alterStatementChangeColPosition);
        let mut _localctx: Rc<AlterStatementChangeColPositionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3338);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_FIRST 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3335);
					let tmp = recog.base.match_token(KW_FIRST,&mut recog.err_handler)?;
					 cast_mut::<_,AlterStatementChangeColPositionContext >(&mut _localctx).first = Some(tmp.clone());
					  

					}
				}

			 KW_AFTER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3336);
					recog.base.match_token(KW_AFTER,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(3337);
					let tmp = recog.id_()?;
					 cast_mut::<_,AlterStatementChangeColPositionContext >(&mut _localctx).afterCol = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixAddPartitions ----------------
pub type AlterStatementSuffixAddPartitionsContextAll<'input> = AlterStatementSuffixAddPartitionsContext<'input>;


pub type AlterStatementSuffixAddPartitionsContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixAddPartitionsContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixAddPartitionsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixAddPartitionsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixAddPartitionsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixAddPartitions(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixAddPartitions(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixAddPartitionsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixAddPartitions }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixAddPartitions }
}
crate::tid!{AlterStatementSuffixAddPartitionsContextExt<'a>}

impl<'input> AlterStatementSuffixAddPartitionsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixAddPartitionsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixAddPartitionsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixAddPartitionsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixAddPartitionsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ADD
/// Returns `None` if there is no child corresponding to token KW_ADD
fn KW_ADD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ADD, 0)
}
fn ifNotExists(&self) -> Option<Rc<IfNotExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterStatementSuffixAddPartitionsElement_all(&self) ->  Vec<Rc<AlterStatementSuffixAddPartitionsElementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn alterStatementSuffixAddPartitionsElement(&self, i: usize) -> Option<Rc<AlterStatementSuffixAddPartitionsElementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> AlterStatementSuffixAddPartitionsContextAttrs<'input> for AlterStatementSuffixAddPartitionsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixAddPartitions(&mut self,)
	-> Result<Rc<AlterStatementSuffixAddPartitionsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixAddPartitionsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 518, RULE_alterStatementSuffixAddPartitions);
        let mut _localctx: Rc<AlterStatementSuffixAddPartitionsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3340);
			recog.base.match_token(KW_ADD,&mut recog.err_handler)?;

			recog.base.set_state(3342);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifNotExists*/
				recog.base.set_state(3341);
				recog.ifNotExists()?;

				}
			}

			recog.base.set_state(3345); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				/*InvokeRule alterStatementSuffixAddPartitionsElement*/
				recog.base.set_state(3344);
				recog.alterStatementSuffixAddPartitionsElement()?;

				}
				}
				recog.base.set_state(3347); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==KW_PARTITION) {break}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixAddPartitionsElement ----------------
pub type AlterStatementSuffixAddPartitionsElementContextAll<'input> = AlterStatementSuffixAddPartitionsElementContext<'input>;


pub type AlterStatementSuffixAddPartitionsElementContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixAddPartitionsElementContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixAddPartitionsElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixAddPartitionsElementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixAddPartitionsElementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixAddPartitionsElement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixAddPartitionsElement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixAddPartitionsElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixAddPartitionsElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixAddPartitionsElement }
}
crate::tid!{AlterStatementSuffixAddPartitionsElementContextExt<'a>}

impl<'input> AlterStatementSuffixAddPartitionsElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixAddPartitionsElementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixAddPartitionsElementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixAddPartitionsElementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixAddPartitionsElementContextExt<'input>>{

fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionLocation(&self) -> Option<Rc<PartitionLocationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixAddPartitionsElementContextAttrs<'input> for AlterStatementSuffixAddPartitionsElementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixAddPartitionsElement(&mut self,)
	-> Result<Rc<AlterStatementSuffixAddPartitionsElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixAddPartitionsElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 520, RULE_alterStatementSuffixAddPartitionsElement);
        let mut _localctx: Rc<AlterStatementSuffixAddPartitionsElementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule partitionSpec*/
			recog.base.set_state(3349);
			recog.partitionSpec()?;

			recog.base.set_state(3351);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_LOCATION {
				{
				/*InvokeRule partitionLocation*/
				recog.base.set_state(3350);
				recog.partitionLocation()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixTouch ----------------
pub type AlterStatementSuffixTouchContextAll<'input> = AlterStatementSuffixTouchContext<'input>;


pub type AlterStatementSuffixTouchContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixTouchContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixTouchContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixTouchContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixTouchContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixTouch(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixTouch(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixTouchContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixTouch }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixTouch }
}
crate::tid!{AlterStatementSuffixTouchContextExt<'a>}

impl<'input> AlterStatementSuffixTouchContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixTouchContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixTouchContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixTouchContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixTouchContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TOUCH
/// Returns `None` if there is no child corresponding to token KW_TOUCH
fn KW_TOUCH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TOUCH, 0)
}
fn partitionSpec_all(&self) ->  Vec<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionSpec(&self, i: usize) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> AlterStatementSuffixTouchContextAttrs<'input> for AlterStatementSuffixTouchContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixTouch(&mut self,)
	-> Result<Rc<AlterStatementSuffixTouchContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixTouchContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 522, RULE_alterStatementSuffixTouch);
        let mut _localctx: Rc<AlterStatementSuffixTouchContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3353);
			recog.base.match_token(KW_TOUCH,&mut recog.err_handler)?;

			recog.base.set_state(3357);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==KW_PARTITION {
				{
				{
				/*InvokeRule partitionSpec*/
				recog.base.set_state(3354);
				recog.partitionSpec()?;

				}
				}
				recog.base.set_state(3359);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixArchive ----------------
pub type AlterStatementSuffixArchiveContextAll<'input> = AlterStatementSuffixArchiveContext<'input>;


pub type AlterStatementSuffixArchiveContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixArchiveContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixArchiveContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixArchiveContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixArchiveContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixArchive(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixArchive(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixArchiveContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixArchive }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixArchive }
}
crate::tid!{AlterStatementSuffixArchiveContextExt<'a>}

impl<'input> AlterStatementSuffixArchiveContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixArchiveContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixArchiveContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixArchiveContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixArchiveContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ARCHIVE
/// Returns `None` if there is no child corresponding to token KW_ARCHIVE
fn KW_ARCHIVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ARCHIVE, 0)
}
fn partitionSpec_all(&self) ->  Vec<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionSpec(&self, i: usize) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> AlterStatementSuffixArchiveContextAttrs<'input> for AlterStatementSuffixArchiveContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixArchive(&mut self,)
	-> Result<Rc<AlterStatementSuffixArchiveContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixArchiveContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 524, RULE_alterStatementSuffixArchive);
        let mut _localctx: Rc<AlterStatementSuffixArchiveContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3360);
			recog.base.match_token(KW_ARCHIVE,&mut recog.err_handler)?;

			recog.base.set_state(3364);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==KW_PARTITION {
				{
				{
				/*InvokeRule partitionSpec*/
				recog.base.set_state(3361);
				recog.partitionSpec()?;

				}
				}
				recog.base.set_state(3366);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixUnArchive ----------------
pub type AlterStatementSuffixUnArchiveContextAll<'input> = AlterStatementSuffixUnArchiveContext<'input>;


pub type AlterStatementSuffixUnArchiveContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixUnArchiveContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixUnArchiveContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixUnArchiveContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixUnArchiveContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixUnArchive(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixUnArchive(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixUnArchiveContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixUnArchive }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixUnArchive }
}
crate::tid!{AlterStatementSuffixUnArchiveContextExt<'a>}

impl<'input> AlterStatementSuffixUnArchiveContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixUnArchiveContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixUnArchiveContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixUnArchiveContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixUnArchiveContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UNARCHIVE
/// Returns `None` if there is no child corresponding to token KW_UNARCHIVE
fn KW_UNARCHIVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNARCHIVE, 0)
}
fn partitionSpec_all(&self) ->  Vec<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionSpec(&self, i: usize) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> AlterStatementSuffixUnArchiveContextAttrs<'input> for AlterStatementSuffixUnArchiveContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixUnArchive(&mut self,)
	-> Result<Rc<AlterStatementSuffixUnArchiveContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixUnArchiveContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 526, RULE_alterStatementSuffixUnArchive);
        let mut _localctx: Rc<AlterStatementSuffixUnArchiveContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3367);
			recog.base.match_token(KW_UNARCHIVE,&mut recog.err_handler)?;

			recog.base.set_state(3371);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==KW_PARTITION {
				{
				{
				/*InvokeRule partitionSpec*/
				recog.base.set_state(3368);
				recog.partitionSpec()?;

				}
				}
				recog.base.set_state(3373);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionLocation ----------------
pub type PartitionLocationContextAll<'input> = PartitionLocationContext<'input>;


pub type PartitionLocationContext<'input> = BaseParserRuleContext<'input,PartitionLocationContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionLocationContextExt<'input>{
	pub locn: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitionLocationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitionLocationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionLocation(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitionLocation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitionLocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionLocation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionLocation }
}
crate::tid!{PartitionLocationContextExt<'a>}

impl<'input> PartitionLocationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionLocationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionLocationContextExt{
				locn: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionLocationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitionLocationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LOCATION
/// Returns `None` if there is no child corresponding to token KW_LOCATION
fn KW_LOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> PartitionLocationContextAttrs<'input> for PartitionLocationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionLocation(&mut self,)
	-> Result<Rc<PartitionLocationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionLocationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 528, RULE_partitionLocation);
        let mut _localctx: Rc<PartitionLocationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3374);
			recog.base.match_token(KW_LOCATION,&mut recog.err_handler)?;

			recog.base.set_state(3375);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,PartitionLocationContext >(&mut _localctx).locn = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixDropPartitions ----------------
pub type AlterStatementSuffixDropPartitionsContextAll<'input> = AlterStatementSuffixDropPartitionsContext<'input>;


pub type AlterStatementSuffixDropPartitionsContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixDropPartitionsContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixDropPartitionsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixDropPartitionsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixDropPartitionsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixDropPartitions(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixDropPartitions(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixDropPartitionsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixDropPartitions }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixDropPartitions }
}
crate::tid!{AlterStatementSuffixDropPartitionsContextExt<'a>}

impl<'input> AlterStatementSuffixDropPartitionsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixDropPartitionsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixDropPartitionsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixDropPartitionsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixDropPartitionsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_PARTITION in current rule
fn KW_PARTITION_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_PARTITION, starting from 0.
/// Returns `None` if number of children corresponding to token KW_PARTITION is less or equal than `i`.
fn KW_PARTITION(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITION, i)
}
fn partitionSelectorSpec_all(&self) ->  Vec<Rc<PartitionSelectorSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionSelectorSpec(&self, i: usize) -> Option<Rc<PartitionSelectorSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves first TerminalNode corresponding to token KW_PURGE
/// Returns `None` if there is no child corresponding to token KW_PURGE
fn KW_PURGE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PURGE, 0)
}
fn replicationClause(&self) -> Option<Rc<ReplicationClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixDropPartitionsContextAttrs<'input> for AlterStatementSuffixDropPartitionsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixDropPartitions(&mut self,)
	-> Result<Rc<AlterStatementSuffixDropPartitionsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixDropPartitionsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 530, RULE_alterStatementSuffixDropPartitions);
        let mut _localctx: Rc<AlterStatementSuffixDropPartitionsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3377);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(3379);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifExists*/
				recog.base.set_state(3378);
				recog.ifExists()?;

				}
			}

			recog.base.set_state(3381);
			recog.base.match_token(KW_PARTITION,&mut recog.err_handler)?;

			/*InvokeRule partitionSelectorSpec*/
			recog.base.set_state(3382);
			recog.partitionSelectorSpec()?;

			recog.base.set_state(3388);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3383);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				recog.base.set_state(3384);
				recog.base.match_token(KW_PARTITION,&mut recog.err_handler)?;

				/*InvokeRule partitionSelectorSpec*/
				recog.base.set_state(3385);
				recog.partitionSelectorSpec()?;

				}
				}
				recog.base.set_state(3390);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(3392);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PURGE {
				{
				recog.base.set_state(3391);
				recog.base.match_token(KW_PURGE,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(3395);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_FOR {
				{
				/*InvokeRule replicationClause*/
				recog.base.set_state(3394);
				recog.replicationClause()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixProperties ----------------
pub type AlterStatementSuffixPropertiesContextAll<'input> = AlterStatementSuffixPropertiesContext<'input>;


pub type AlterStatementSuffixPropertiesContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixPropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixPropertiesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixPropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixPropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixProperties(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixProperties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixPropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixProperties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixProperties }
}
crate::tid!{AlterStatementSuffixPropertiesContextExt<'a>}

impl<'input> AlterStatementSuffixPropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixPropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixPropertiesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixPropertiesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixPropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TBLPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_TBLPROPERTIES
fn KW_TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TBLPROPERTIES, 0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNSET
/// Returns `None` if there is no child corresponding to token KW_UNSET
fn KW_UNSET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNSET, 0)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixPropertiesContextAttrs<'input> for AlterStatementSuffixPropertiesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixProperties(&mut self,)
	-> Result<Rc<AlterStatementSuffixPropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixPropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 532, RULE_alterStatementSuffixProperties);
        let mut _localctx: Rc<AlterStatementSuffixPropertiesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3406);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_SET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3397);
					recog.base.match_token(KW_SET,&mut recog.err_handler)?;

					recog.base.set_state(3398);
					recog.base.match_token(KW_TBLPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule tableProperties*/
					recog.base.set_state(3399);
					recog.tableProperties()?;

					}
				}

			 KW_UNSET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3400);
					recog.base.match_token(KW_UNSET,&mut recog.err_handler)?;

					recog.base.set_state(3401);
					recog.base.match_token(KW_TBLPROPERTIES,&mut recog.err_handler)?;

					recog.base.set_state(3403);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_IF {
						{
						/*InvokeRule ifExists*/
						recog.base.set_state(3402);
						recog.ifExists()?;

						}
					}

					/*InvokeRule tableProperties*/
					recog.base.set_state(3405);
					recog.tableProperties()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterViewSuffixProperties ----------------
pub type AlterViewSuffixPropertiesContextAll<'input> = AlterViewSuffixPropertiesContext<'input>;


pub type AlterViewSuffixPropertiesContext<'input> = BaseParserRuleContext<'input,AlterViewSuffixPropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct AlterViewSuffixPropertiesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterViewSuffixPropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterViewSuffixPropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterViewSuffixProperties(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterViewSuffixProperties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterViewSuffixPropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterViewSuffixProperties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterViewSuffixProperties }
}
crate::tid!{AlterViewSuffixPropertiesContextExt<'a>}

impl<'input> AlterViewSuffixPropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterViewSuffixPropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterViewSuffixPropertiesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterViewSuffixPropertiesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterViewSuffixPropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TBLPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_TBLPROPERTIES
fn KW_TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TBLPROPERTIES, 0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNSET
/// Returns `None` if there is no child corresponding to token KW_UNSET
fn KW_UNSET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNSET, 0)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterViewSuffixPropertiesContextAttrs<'input> for AlterViewSuffixPropertiesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterViewSuffixProperties(&mut self,)
	-> Result<Rc<AlterViewSuffixPropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterViewSuffixPropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 534, RULE_alterViewSuffixProperties);
        let mut _localctx: Rc<AlterViewSuffixPropertiesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3417);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_SET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3408);
					recog.base.match_token(KW_SET,&mut recog.err_handler)?;

					recog.base.set_state(3409);
					recog.base.match_token(KW_TBLPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule tableProperties*/
					recog.base.set_state(3410);
					recog.tableProperties()?;

					}
				}

			 KW_UNSET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3411);
					recog.base.match_token(KW_UNSET,&mut recog.err_handler)?;

					recog.base.set_state(3412);
					recog.base.match_token(KW_TBLPROPERTIES,&mut recog.err_handler)?;

					recog.base.set_state(3414);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_IF {
						{
						/*InvokeRule ifExists*/
						recog.base.set_state(3413);
						recog.ifExists()?;

						}
					}

					/*InvokeRule tableProperties*/
					recog.base.set_state(3416);
					recog.tableProperties()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixSerdeProperties ----------------
pub type AlterStatementSuffixSerdePropertiesContextAll<'input> = AlterStatementSuffixSerdePropertiesContext<'input>;


pub type AlterStatementSuffixSerdePropertiesContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixSerdePropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixSerdePropertiesContextExt<'input>{
	pub serdeName: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixSerdePropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixSerdePropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixSerdeProperties(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixSerdeProperties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixSerdePropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixSerdeProperties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixSerdeProperties }
}
crate::tid!{AlterStatementSuffixSerdePropertiesContextExt<'a>}

impl<'input> AlterStatementSuffixSerdePropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixSerdePropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixSerdePropertiesContextExt{
				serdeName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixSerdePropertiesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixSerdePropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERDE
/// Returns `None` if there is no child corresponding to token KW_SERDE
fn KW_SERDE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERDE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_SERDEPROPERTIES
fn KW_SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERDEPROPERTIES, 0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNSET
/// Returns `None` if there is no child corresponding to token KW_UNSET
fn KW_UNSET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNSET, 0)
}

}

impl<'input> AlterStatementSuffixSerdePropertiesContextAttrs<'input> for AlterStatementSuffixSerdePropertiesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixSerdeProperties(&mut self,)
	-> Result<Rc<AlterStatementSuffixSerdePropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixSerdePropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 536, RULE_alterStatementSuffixSerdeProperties);
        let mut _localctx: Rc<AlterStatementSuffixSerdePropertiesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3434);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_SET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3419);
					recog.base.match_token(KW_SET,&mut recog.err_handler)?;

					recog.base.set_state(3429);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_SERDE 
						=> {
							{
							recog.base.set_state(3420);
							recog.base.match_token(KW_SERDE,&mut recog.err_handler)?;

							recog.base.set_state(3421);
							let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
							 cast_mut::<_,AlterStatementSuffixSerdePropertiesContext >(&mut _localctx).serdeName = Some(tmp.clone());
							  

							recog.base.set_state(3425);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(369,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(3422);
									recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

									recog.base.set_state(3423);
									recog.base.match_token(KW_SERDEPROPERTIES,&mut recog.err_handler)?;

									/*InvokeRule tableProperties*/
									recog.base.set_state(3424);
									recog.tableProperties()?;

									}
								}

								_ => {}
							}
							}
						}

					 KW_SERDEPROPERTIES 
						=> {
							{
							recog.base.set_state(3427);
							recog.base.match_token(KW_SERDEPROPERTIES,&mut recog.err_handler)?;

							/*InvokeRule tableProperties*/
							recog.base.set_state(3428);
							recog.tableProperties()?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}

			 KW_UNSET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3431);
					recog.base.match_token(KW_UNSET,&mut recog.err_handler)?;

					recog.base.set_state(3432);
					recog.base.match_token(KW_SERDEPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule tableProperties*/
					recog.base.set_state(3433);
					recog.tableProperties()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tablePartitionPrefix ----------------
pub type TablePartitionPrefixContextAll<'input> = TablePartitionPrefixContext<'input>;


pub type TablePartitionPrefixContext<'input> = BaseParserRuleContext<'input,TablePartitionPrefixContextExt<'input>>;

#[derive(Clone)]
pub struct TablePartitionPrefixContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TablePartitionPrefixContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TablePartitionPrefixContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tablePartitionPrefix(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tablePartitionPrefix(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TablePartitionPrefixContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tablePartitionPrefix }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tablePartitionPrefix }
}
crate::tid!{TablePartitionPrefixContextExt<'a>}

impl<'input> TablePartitionPrefixContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TablePartitionPrefixContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TablePartitionPrefixContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TablePartitionPrefixContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TablePartitionPrefixContextExt<'input>>{

fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TablePartitionPrefixContextAttrs<'input> for TablePartitionPrefixContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tablePartitionPrefix(&mut self,)
	-> Result<Rc<TablePartitionPrefixContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TablePartitionPrefixContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 538, RULE_tablePartitionPrefix);
        let mut _localctx: Rc<TablePartitionPrefixContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableName*/
			recog.base.set_state(3436);
			recog.tableName()?;

			recog.base.set_state(3438);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PARTITION {
				{
				/*InvokeRule partitionSpec*/
				recog.base.set_state(3437);
				recog.partitionSpec()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixFileFormat ----------------
pub type AlterStatementSuffixFileFormatContextAll<'input> = AlterStatementSuffixFileFormatContext<'input>;


pub type AlterStatementSuffixFileFormatContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixFileFormatContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixFileFormatContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixFileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixFileFormatContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixFileFormat(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixFileFormat(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixFileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixFileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixFileFormat }
}
crate::tid!{AlterStatementSuffixFileFormatContextExt<'a>}

impl<'input> AlterStatementSuffixFileFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixFileFormatContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixFileFormatContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixFileFormatContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixFileFormatContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FILEFORMAT
/// Returns `None` if there is no child corresponding to token KW_FILEFORMAT
fn KW_FILEFORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FILEFORMAT, 0)
}
fn fileFormat(&self) -> Option<Rc<FileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixFileFormatContextAttrs<'input> for AlterStatementSuffixFileFormatContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixFileFormat(&mut self,)
	-> Result<Rc<AlterStatementSuffixFileFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixFileFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 540, RULE_alterStatementSuffixFileFormat);
        let mut _localctx: Rc<AlterStatementSuffixFileFormatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3440);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3441);
			recog.base.match_token(KW_FILEFORMAT,&mut recog.err_handler)?;

			/*InvokeRule fileFormat*/
			recog.base.set_state(3442);
			recog.fileFormat()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixClusterbySortby ----------------
pub type AlterStatementSuffixClusterbySortbyContextAll<'input> = AlterStatementSuffixClusterbySortbyContext<'input>;


pub type AlterStatementSuffixClusterbySortbyContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixClusterbySortbyContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixClusterbySortbyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixClusterbySortbyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixClusterbySortbyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixClusterbySortby(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixClusterbySortby(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixClusterbySortbyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixClusterbySortby }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixClusterbySortby }
}
crate::tid!{AlterStatementSuffixClusterbySortbyContextExt<'a>}

impl<'input> AlterStatementSuffixClusterbySortbyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixClusterbySortbyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixClusterbySortbyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixClusterbySortbyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixClusterbySortbyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_NOT
/// Returns `None` if there is no child corresponding to token KW_NOT
fn KW_NOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CLUSTERED
/// Returns `None` if there is no child corresponding to token KW_CLUSTERED
fn KW_CLUSTERED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CLUSTERED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SORTED
/// Returns `None` if there is no child corresponding to token KW_SORTED
fn KW_SORTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SORTED, 0)
}
fn tableBuckets(&self) -> Option<Rc<TableBucketsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixClusterbySortbyContextAttrs<'input> for AlterStatementSuffixClusterbySortbyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixClusterbySortby(&mut self,)
	-> Result<Rc<AlterStatementSuffixClusterbySortbyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixClusterbySortbyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 542, RULE_alterStatementSuffixClusterbySortby);
        let mut _localctx: Rc<AlterStatementSuffixClusterbySortbyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3447);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_NOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3444);
					recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

					recog.base.set_state(3445);
					_la = recog.base.input.la(1);
					if { !(_la==KW_CLUSTERED || _la==KW_SORTED) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

			 KW_CLUSTERED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule tableBuckets*/
					recog.base.set_state(3446);
					recog.tableBuckets()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterTblPartitionStatementSuffixSkewedLocation ----------------
pub type AlterTblPartitionStatementSuffixSkewedLocationContextAll<'input> = AlterTblPartitionStatementSuffixSkewedLocationContext<'input>;


pub type AlterTblPartitionStatementSuffixSkewedLocationContext<'input> = BaseParserRuleContext<'input,AlterTblPartitionStatementSuffixSkewedLocationContextExt<'input>>;

#[derive(Clone)]
pub struct AlterTblPartitionStatementSuffixSkewedLocationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterTblPartitionStatementSuffixSkewedLocationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterTblPartitionStatementSuffixSkewedLocationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterTblPartitionStatementSuffixSkewedLocation(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterTblPartitionStatementSuffixSkewedLocation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterTblPartitionStatementSuffixSkewedLocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterTblPartitionStatementSuffixSkewedLocation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterTblPartitionStatementSuffixSkewedLocation }
}
crate::tid!{AlterTblPartitionStatementSuffixSkewedLocationContextExt<'a>}

impl<'input> AlterTblPartitionStatementSuffixSkewedLocationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterTblPartitionStatementSuffixSkewedLocationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterTblPartitionStatementSuffixSkewedLocationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterTblPartitionStatementSuffixSkewedLocationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterTblPartitionStatementSuffixSkewedLocationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SKEWED
/// Returns `None` if there is no child corresponding to token KW_SKEWED
fn KW_SKEWED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SKEWED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCATION
/// Returns `None` if there is no child corresponding to token KW_LOCATION
fn KW_LOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCATION, 0)
}
fn skewedLocations(&self) -> Option<Rc<SkewedLocationsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterTblPartitionStatementSuffixSkewedLocationContextAttrs<'input> for AlterTblPartitionStatementSuffixSkewedLocationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterTblPartitionStatementSuffixSkewedLocation(&mut self,)
	-> Result<Rc<AlterTblPartitionStatementSuffixSkewedLocationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterTblPartitionStatementSuffixSkewedLocationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 544, RULE_alterTblPartitionStatementSuffixSkewedLocation);
        let mut _localctx: Rc<AlterTblPartitionStatementSuffixSkewedLocationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3449);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3450);
			recog.base.match_token(KW_SKEWED,&mut recog.err_handler)?;

			recog.base.set_state(3451);
			recog.base.match_token(KW_LOCATION,&mut recog.err_handler)?;

			/*InvokeRule skewedLocations*/
			recog.base.set_state(3452);
			recog.skewedLocations()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- skewedLocations ----------------
pub type SkewedLocationsContextAll<'input> = SkewedLocationsContext<'input>;


pub type SkewedLocationsContext<'input> = BaseParserRuleContext<'input,SkewedLocationsContextExt<'input>>;

#[derive(Clone)]
pub struct SkewedLocationsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SkewedLocationsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SkewedLocationsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_skewedLocations(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_skewedLocations(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SkewedLocationsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_skewedLocations }
	//fn type_rule_index() -> usize where Self: Sized { RULE_skewedLocations }
}
crate::tid!{SkewedLocationsContextExt<'a>}

impl<'input> SkewedLocationsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SkewedLocationsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SkewedLocationsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SkewedLocationsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SkewedLocationsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn skewedLocationsList(&self) -> Option<Rc<SkewedLocationsListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> SkewedLocationsContextAttrs<'input> for SkewedLocationsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn skewedLocations(&mut self,)
	-> Result<Rc<SkewedLocationsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SkewedLocationsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 546, RULE_skewedLocations);
        let mut _localctx: Rc<SkewedLocationsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3454);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule skewedLocationsList*/
			recog.base.set_state(3455);
			recog.skewedLocationsList()?;

			recog.base.set_state(3456);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- skewedLocationsList ----------------
pub type SkewedLocationsListContextAll<'input> = SkewedLocationsListContext<'input>;


pub type SkewedLocationsListContext<'input> = BaseParserRuleContext<'input,SkewedLocationsListContextExt<'input>>;

#[derive(Clone)]
pub struct SkewedLocationsListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SkewedLocationsListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SkewedLocationsListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_skewedLocationsList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_skewedLocationsList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SkewedLocationsListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_skewedLocationsList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_skewedLocationsList }
}
crate::tid!{SkewedLocationsListContextExt<'a>}

impl<'input> SkewedLocationsListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SkewedLocationsListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SkewedLocationsListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SkewedLocationsListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SkewedLocationsListContextExt<'input>>{

fn skewedLocationMap_all(&self) ->  Vec<Rc<SkewedLocationMapContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn skewedLocationMap(&self, i: usize) -> Option<Rc<SkewedLocationMapContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> SkewedLocationsListContextAttrs<'input> for SkewedLocationsListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn skewedLocationsList(&mut self,)
	-> Result<Rc<SkewedLocationsListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SkewedLocationsListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 548, RULE_skewedLocationsList);
        let mut _localctx: Rc<SkewedLocationsListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule skewedLocationMap*/
			recog.base.set_state(3458);
			recog.skewedLocationMap()?;

			recog.base.set_state(3463);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3459);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule skewedLocationMap*/
				recog.base.set_state(3460);
				recog.skewedLocationMap()?;

				}
				}
				recog.base.set_state(3465);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- skewedLocationMap ----------------
pub type SkewedLocationMapContextAll<'input> = SkewedLocationMapContext<'input>;


pub type SkewedLocationMapContext<'input> = BaseParserRuleContext<'input,SkewedLocationMapContextExt<'input>>;

#[derive(Clone)]
pub struct SkewedLocationMapContextExt<'input>{
	pub key: Option<Rc<SkewedValueLocationElementContextAll<'input>>>,
	pub value: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SkewedLocationMapContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SkewedLocationMapContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_skewedLocationMap(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_skewedLocationMap(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SkewedLocationMapContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_skewedLocationMap }
	//fn type_rule_index() -> usize where Self: Sized { RULE_skewedLocationMap }
}
crate::tid!{SkewedLocationMapContextExt<'a>}

impl<'input> SkewedLocationMapContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SkewedLocationMapContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SkewedLocationMapContextExt{
				value: None, 
				key: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SkewedLocationMapContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SkewedLocationMapContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn skewedValueLocationElement(&self) -> Option<Rc<SkewedValueLocationElementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> SkewedLocationMapContextAttrs<'input> for SkewedLocationMapContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn skewedLocationMap(&mut self,)
	-> Result<Rc<SkewedLocationMapContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SkewedLocationMapContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 550, RULE_skewedLocationMap);
        let mut _localctx: Rc<SkewedLocationMapContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule skewedValueLocationElement*/
			recog.base.set_state(3466);
			let tmp = recog.skewedValueLocationElement()?;
			 cast_mut::<_,SkewedLocationMapContext >(&mut _localctx).key = Some(tmp.clone());
			  

			recog.base.set_state(3467);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(3468);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,SkewedLocationMapContext >(&mut _localctx).value = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixLocation ----------------
pub type AlterStatementSuffixLocationContextAll<'input> = AlterStatementSuffixLocationContext<'input>;


pub type AlterStatementSuffixLocationContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixLocationContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixLocationContextExt<'input>{
	pub newLoc: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixLocationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixLocationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixLocation(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixLocation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixLocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixLocation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixLocation }
}
crate::tid!{AlterStatementSuffixLocationContextExt<'a>}

impl<'input> AlterStatementSuffixLocationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixLocationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixLocationContextExt{
				newLoc: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixLocationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixLocationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCATION
/// Returns `None` if there is no child corresponding to token KW_LOCATION
fn KW_LOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> AlterStatementSuffixLocationContextAttrs<'input> for AlterStatementSuffixLocationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixLocation(&mut self,)
	-> Result<Rc<AlterStatementSuffixLocationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixLocationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 552, RULE_alterStatementSuffixLocation);
        let mut _localctx: Rc<AlterStatementSuffixLocationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3470);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3471);
			recog.base.match_token(KW_LOCATION,&mut recog.err_handler)?;

			recog.base.set_state(3472);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,AlterStatementSuffixLocationContext >(&mut _localctx).newLoc = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixSkewedby ----------------
pub type AlterStatementSuffixSkewedbyContextAll<'input> = AlterStatementSuffixSkewedbyContext<'input>;


pub type AlterStatementSuffixSkewedbyContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixSkewedbyContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixSkewedbyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixSkewedbyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixSkewedbyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixSkewedby(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixSkewedby(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixSkewedbyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixSkewedby }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixSkewedby }
}
crate::tid!{AlterStatementSuffixSkewedbyContextExt<'a>}

impl<'input> AlterStatementSuffixSkewedbyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixSkewedbyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixSkewedbyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixSkewedbyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixSkewedbyContextExt<'input>>{

fn tableSkewed(&self) -> Option<Rc<TableSkewedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOT
/// Returns `None` if there is no child corresponding to token KW_NOT
fn KW_NOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SKEWED
/// Returns `None` if there is no child corresponding to token KW_SKEWED
fn KW_SKEWED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SKEWED, 0)
}
fn storedAsDirs(&self) -> Option<Rc<StoredAsDirsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixSkewedbyContextAttrs<'input> for AlterStatementSuffixSkewedbyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixSkewedby(&mut self,)
	-> Result<Rc<AlterStatementSuffixSkewedbyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixSkewedbyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 554, RULE_alterStatementSuffixSkewedby);
        let mut _localctx: Rc<AlterStatementSuffixSkewedbyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3480);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_SKEWED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule tableSkewed*/
					recog.base.set_state(3474);
					recog.tableSkewed()?;

					}
				}

			 KW_NOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3475);
					recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

					recog.base.set_state(3478);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_SKEWED 
						=> {
							{
							recog.base.set_state(3476);
							recog.base.match_token(KW_SKEWED,&mut recog.err_handler)?;

							}
						}

					 KW_STORED 
						=> {
							{
							/*InvokeRule storedAsDirs*/
							recog.base.set_state(3477);
							recog.storedAsDirs()?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixExchangePartition ----------------
pub type AlterStatementSuffixExchangePartitionContextAll<'input> = AlterStatementSuffixExchangePartitionContext<'input>;


pub type AlterStatementSuffixExchangePartitionContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixExchangePartitionContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixExchangePartitionContextExt<'input>{
	pub exchangename: Option<Rc<TableNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixExchangePartitionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixExchangePartitionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixExchangePartition(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixExchangePartition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixExchangePartitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixExchangePartition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixExchangePartition }
}
crate::tid!{AlterStatementSuffixExchangePartitionContextExt<'a>}

impl<'input> AlterStatementSuffixExchangePartitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixExchangePartitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixExchangePartitionContextExt{
				exchangename: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixExchangePartitionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixExchangePartitionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_EXCHANGE
/// Returns `None` if there is no child corresponding to token KW_EXCHANGE
fn KW_EXCHANGE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXCHANGE, 0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixExchangePartitionContextAttrs<'input> for AlterStatementSuffixExchangePartitionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixExchangePartition(&mut self,)
	-> Result<Rc<AlterStatementSuffixExchangePartitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixExchangePartitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 556, RULE_alterStatementSuffixExchangePartition);
        let mut _localctx: Rc<AlterStatementSuffixExchangePartitionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3482);
			recog.base.match_token(KW_EXCHANGE,&mut recog.err_handler)?;

			/*InvokeRule partitionSpec*/
			recog.base.set_state(3483);
			recog.partitionSpec()?;

			recog.base.set_state(3484);
			recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

			recog.base.set_state(3485);
			recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(3486);
			let tmp = recog.tableName()?;
			 cast_mut::<_,AlterStatementSuffixExchangePartitionContext >(&mut _localctx).exchangename = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixRenamePart ----------------
pub type AlterStatementSuffixRenamePartContextAll<'input> = AlterStatementSuffixRenamePartContext<'input>;


pub type AlterStatementSuffixRenamePartContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixRenamePartContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixRenamePartContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixRenamePartContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixRenamePartContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixRenamePart(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixRenamePart(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixRenamePartContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixRenamePart }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixRenamePart }
}
crate::tid!{AlterStatementSuffixRenamePartContextExt<'a>}

impl<'input> AlterStatementSuffixRenamePartContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixRenamePartContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixRenamePartContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixRenamePartContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixRenamePartContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_RENAME
/// Returns `None` if there is no child corresponding to token KW_RENAME
fn KW_RENAME(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RENAME, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixRenamePartContextAttrs<'input> for AlterStatementSuffixRenamePartContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixRenamePart(&mut self,)
	-> Result<Rc<AlterStatementSuffixRenamePartContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixRenamePartContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 558, RULE_alterStatementSuffixRenamePart);
        let mut _localctx: Rc<AlterStatementSuffixRenamePartContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3488);
			recog.base.match_token(KW_RENAME,&mut recog.err_handler)?;

			recog.base.set_state(3489);
			recog.base.match_token(KW_TO,&mut recog.err_handler)?;

			/*InvokeRule partitionSpec*/
			recog.base.set_state(3490);
			recog.partitionSpec()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixStatsPart ----------------
pub type AlterStatementSuffixStatsPartContextAll<'input> = AlterStatementSuffixStatsPartContext<'input>;


pub type AlterStatementSuffixStatsPartContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixStatsPartContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixStatsPartContextExt<'input>{
	pub colName: Option<Rc<Id_ContextAll<'input>>>,
	pub comment: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixStatsPartContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixStatsPartContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixStatsPart(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixStatsPart(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixStatsPartContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixStatsPart }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixStatsPart }
}
crate::tid!{AlterStatementSuffixStatsPartContextExt<'a>}

impl<'input> AlterStatementSuffixStatsPartContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixStatsPartContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixStatsPartContextExt{
				comment: None, 
				colName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixStatsPartContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixStatsPartContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UPDATE
/// Returns `None` if there is no child corresponding to token KW_UPDATE
fn KW_UPDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STATISTICS
/// Returns `None` if there is no child corresponding to token KW_STATISTICS
fn KW_STATISTICS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STATISTICS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FOR
/// Returns `None` if there is no child corresponding to token KW_FOR
fn KW_FOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_COLUMN
/// Returns `None` if there is no child corresponding to token KW_COLUMN
fn KW_COLUMN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLUMN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMMENT
/// Returns `None` if there is no child corresponding to token KW_COMMENT
fn KW_COMMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> AlterStatementSuffixStatsPartContextAttrs<'input> for AlterStatementSuffixStatsPartContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixStatsPart(&mut self,)
	-> Result<Rc<AlterStatementSuffixStatsPartContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixStatsPartContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 560, RULE_alterStatementSuffixStatsPart);
        let mut _localctx: Rc<AlterStatementSuffixStatsPartContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3492);
			recog.base.match_token(KW_UPDATE,&mut recog.err_handler)?;

			recog.base.set_state(3493);
			recog.base.match_token(KW_STATISTICS,&mut recog.err_handler)?;

			recog.base.set_state(3494);
			recog.base.match_token(KW_FOR,&mut recog.err_handler)?;

			recog.base.set_state(3496);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COLUMN {
				{
				recog.base.set_state(3495);
				recog.base.match_token(KW_COLUMN,&mut recog.err_handler)?;

				}
			}

			/*InvokeRule id_*/
			recog.base.set_state(3498);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterStatementSuffixStatsPartContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			recog.base.set_state(3499);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			/*InvokeRule tableProperties*/
			recog.base.set_state(3500);
			recog.tableProperties()?;

			recog.base.set_state(3503);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COMMENT {
				{
				recog.base.set_state(3501);
				recog.base.match_token(KW_COMMENT,&mut recog.err_handler)?;

				recog.base.set_state(3502);
				let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
				 cast_mut::<_,AlterStatementSuffixStatsPartContext >(&mut _localctx).comment = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixMergeFiles ----------------
pub type AlterStatementSuffixMergeFilesContextAll<'input> = AlterStatementSuffixMergeFilesContext<'input>;


pub type AlterStatementSuffixMergeFilesContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixMergeFilesContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixMergeFilesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixMergeFilesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixMergeFilesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixMergeFiles(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixMergeFiles(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixMergeFilesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixMergeFiles }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixMergeFiles }
}
crate::tid!{AlterStatementSuffixMergeFilesContextExt<'a>}

impl<'input> AlterStatementSuffixMergeFilesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixMergeFilesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixMergeFilesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixMergeFilesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixMergeFilesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CONCATENATE
/// Returns `None` if there is no child corresponding to token KW_CONCATENATE
fn KW_CONCATENATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONCATENATE, 0)
}

}

impl<'input> AlterStatementSuffixMergeFilesContextAttrs<'input> for AlterStatementSuffixMergeFilesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixMergeFiles(&mut self,)
	-> Result<Rc<AlterStatementSuffixMergeFilesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixMergeFilesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 562, RULE_alterStatementSuffixMergeFiles);
        let mut _localctx: Rc<AlterStatementSuffixMergeFilesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3505);
			recog.base.match_token(KW_CONCATENATE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixBucketNum ----------------
pub type AlterStatementSuffixBucketNumContextAll<'input> = AlterStatementSuffixBucketNumContext<'input>;


pub type AlterStatementSuffixBucketNumContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixBucketNumContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixBucketNumContextExt<'input>{
	pub num: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixBucketNumContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixBucketNumContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixBucketNum(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixBucketNum(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixBucketNumContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixBucketNum }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixBucketNum }
}
crate::tid!{AlterStatementSuffixBucketNumContextExt<'a>}

impl<'input> AlterStatementSuffixBucketNumContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixBucketNumContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixBucketNumContextExt{
				num: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixBucketNumContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixBucketNumContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_INTO
/// Returns `None` if there is no child corresponding to token KW_INTO
fn KW_INTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INTO, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BUCKETS
/// Returns `None` if there is no child corresponding to token KW_BUCKETS
fn KW_BUCKETS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BUCKETS, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}

}

impl<'input> AlterStatementSuffixBucketNumContextAttrs<'input> for AlterStatementSuffixBucketNumContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixBucketNum(&mut self,)
	-> Result<Rc<AlterStatementSuffixBucketNumContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixBucketNumContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 564, RULE_alterStatementSuffixBucketNum);
        let mut _localctx: Rc<AlterStatementSuffixBucketNumContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3507);
			recog.base.match_token(KW_INTO,&mut recog.err_handler)?;

			recog.base.set_state(3508);
			let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
			 cast_mut::<_,AlterStatementSuffixBucketNumContext >(&mut _localctx).num = Some(tmp.clone());
			  

			recog.base.set_state(3509);
			recog.base.match_token(KW_BUCKETS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- blocking ----------------
pub type BlockingContextAll<'input> = BlockingContext<'input>;


pub type BlockingContext<'input> = BaseParserRuleContext<'input,BlockingContextExt<'input>>;

#[derive(Clone)]
pub struct BlockingContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for BlockingContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for BlockingContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_blocking(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_blocking(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for BlockingContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_blocking }
	//fn type_rule_index() -> usize where Self: Sized { RULE_blocking }
}
crate::tid!{BlockingContextExt<'a>}

impl<'input> BlockingContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BlockingContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BlockingContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BlockingContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<BlockingContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_AND
/// Returns `None` if there is no child corresponding to token KW_AND
fn KW_AND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AND, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WAIT
/// Returns `None` if there is no child corresponding to token KW_WAIT
fn KW_WAIT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WAIT, 0)
}

}

impl<'input> BlockingContextAttrs<'input> for BlockingContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn blocking(&mut self,)
	-> Result<Rc<BlockingContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BlockingContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 566, RULE_blocking);
        let mut _localctx: Rc<BlockingContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3511);
			recog.base.match_token(KW_AND,&mut recog.err_handler)?;

			recog.base.set_state(3512);
			recog.base.match_token(KW_WAIT,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- compactPool ----------------
pub type CompactPoolContextAll<'input> = CompactPoolContext<'input>;


pub type CompactPoolContext<'input> = BaseParserRuleContext<'input,CompactPoolContextExt<'input>>;

#[derive(Clone)]
pub struct CompactPoolContextExt<'input>{
	pub poolName: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CompactPoolContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CompactPoolContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_compactPool(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_compactPool(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CompactPoolContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_compactPool }
	//fn type_rule_index() -> usize where Self: Sized { RULE_compactPool }
}
crate::tid!{CompactPoolContextExt<'a>}

impl<'input> CompactPoolContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CompactPoolContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CompactPoolContextExt{
				poolName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CompactPoolContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CompactPoolContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_POOL
/// Returns `None` if there is no child corresponding to token KW_POOL
fn KW_POOL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_POOL, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> CompactPoolContextAttrs<'input> for CompactPoolContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn compactPool(&mut self,)
	-> Result<Rc<CompactPoolContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CompactPoolContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 568, RULE_compactPool);
        let mut _localctx: Rc<CompactPoolContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3514);
			recog.base.match_token(KW_POOL,&mut recog.err_handler)?;

			recog.base.set_state(3515);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,CompactPoolContext >(&mut _localctx).poolName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixCompact ----------------
pub type AlterStatementSuffixCompactContextAll<'input> = AlterStatementSuffixCompactContext<'input>;


pub type AlterStatementSuffixCompactContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixCompactContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixCompactContextExt<'input>{
	pub compactType: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixCompactContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixCompactContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixCompact(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixCompact(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixCompactContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixCompact }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixCompact }
}
crate::tid!{AlterStatementSuffixCompactContextExt<'a>}

impl<'input> AlterStatementSuffixCompactContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixCompactContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixCompactContextExt{
				compactType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixCompactContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixCompactContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_COMPACT
/// Returns `None` if there is no child corresponding to token KW_COMPACT
fn KW_COMPACT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMPACT, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn blocking(&self) -> Option<Rc<BlockingContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableImplBuckets(&self) -> Option<Rc<TableImplBucketsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orderByClause(&self) -> Option<Rc<OrderByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn compactPool(&self) -> Option<Rc<CompactPoolContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OVERWRITE
/// Returns `None` if there is no child corresponding to token KW_OVERWRITE
fn KW_OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OVERWRITE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TBLPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_TBLPROPERTIES
fn KW_TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TBLPROPERTIES, 0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixCompactContextAttrs<'input> for AlterStatementSuffixCompactContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixCompact(&mut self,)
	-> Result<Rc<AlterStatementSuffixCompactContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixCompactContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 570, RULE_alterStatementSuffixCompact);
        let mut _localctx: Rc<AlterStatementSuffixCompactContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3517);
			recog.base.match_token(KW_COMPACT,&mut recog.err_handler)?;

			recog.base.set_state(3518);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,AlterStatementSuffixCompactContext >(&mut _localctx).compactType = Some(tmp.clone());
			  

			recog.base.set_state(3520);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_AND {
				{
				/*InvokeRule blocking*/
				recog.base.set_state(3519);
				recog.blocking()?;

				}
			}

			recog.base.set_state(3523);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CLUSTERED {
				{
				/*InvokeRule tableImplBuckets*/
				recog.base.set_state(3522);
				recog.tableImplBuckets()?;

				}
			}

			recog.base.set_state(3526);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ORDER {
				{
				/*InvokeRule orderByClause*/
				recog.base.set_state(3525);
				recog.orderByClause()?;

				}
			}

			recog.base.set_state(3529);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_POOL {
				{
				/*InvokeRule compactPool*/
				recog.base.set_state(3528);
				recog.compactPool()?;

				}
			}

			recog.base.set_state(3535);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(383,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3531);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					recog.base.set_state(3532);
					recog.base.match_token(KW_OVERWRITE,&mut recog.err_handler)?;

					recog.base.set_state(3533);
					recog.base.match_token(KW_TBLPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule tableProperties*/
					recog.base.set_state(3534);
					recog.tableProperties()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixSetOwner ----------------
pub type AlterStatementSuffixSetOwnerContextAll<'input> = AlterStatementSuffixSetOwnerContext<'input>;


pub type AlterStatementSuffixSetOwnerContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixSetOwnerContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixSetOwnerContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixSetOwnerContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixSetOwnerContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixSetOwner(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixSetOwner(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixSetOwnerContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixSetOwner }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixSetOwner }
}
crate::tid!{AlterStatementSuffixSetOwnerContextExt<'a>}

impl<'input> AlterStatementSuffixSetOwnerContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixSetOwnerContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixSetOwnerContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixSetOwnerContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixSetOwnerContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OWNER
/// Returns `None` if there is no child corresponding to token KW_OWNER
fn KW_OWNER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OWNER, 0)
}
fn principalName(&self) -> Option<Rc<PrincipalNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixSetOwnerContextAttrs<'input> for AlterStatementSuffixSetOwnerContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixSetOwner(&mut self,)
	-> Result<Rc<AlterStatementSuffixSetOwnerContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixSetOwnerContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 572, RULE_alterStatementSuffixSetOwner);
        let mut _localctx: Rc<AlterStatementSuffixSetOwnerContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3537);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3538);
			recog.base.match_token(KW_OWNER,&mut recog.err_handler)?;

			/*InvokeRule principalName*/
			recog.base.set_state(3539);
			recog.principalName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixSetPartSpec ----------------
pub type AlterStatementSuffixSetPartSpecContextAll<'input> = AlterStatementSuffixSetPartSpecContext<'input>;


pub type AlterStatementSuffixSetPartSpecContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixSetPartSpecContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixSetPartSpecContextExt<'input>{
	pub spec: Option<Rc<PartitionTransformSpecContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixSetPartSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixSetPartSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixSetPartSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixSetPartSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixSetPartSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixSetPartSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixSetPartSpec }
}
crate::tid!{AlterStatementSuffixSetPartSpecContextExt<'a>}

impl<'input> AlterStatementSuffixSetPartSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixSetPartSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixSetPartSpecContextExt{
				spec: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixSetPartSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixSetPartSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PARTITION
/// Returns `None` if there is no child corresponding to token KW_PARTITION
fn KW_PARTITION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SPEC
/// Returns `None` if there is no child corresponding to token KW_SPEC
fn KW_SPEC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SPEC, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn partitionTransformSpec(&self) -> Option<Rc<PartitionTransformSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterStatementSuffixSetPartSpecContextAttrs<'input> for AlterStatementSuffixSetPartSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixSetPartSpec(&mut self,)
	-> Result<Rc<AlterStatementSuffixSetPartSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixSetPartSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 574, RULE_alterStatementSuffixSetPartSpec);
        let mut _localctx: Rc<AlterStatementSuffixSetPartSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3541);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3542);
			recog.base.match_token(KW_PARTITION,&mut recog.err_handler)?;

			recog.base.set_state(3543);
			recog.base.match_token(KW_SPEC,&mut recog.err_handler)?;

			recog.base.set_state(3544);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule partitionTransformSpec*/
			recog.base.set_state(3545);
			let tmp = recog.partitionTransformSpec()?;
			 cast_mut::<_,AlterStatementSuffixSetPartSpecContext >(&mut _localctx).spec = Some(tmp.clone());
			  

			recog.base.set_state(3546);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterStatementSuffixExecute ----------------
pub type AlterStatementSuffixExecuteContextAll<'input> = AlterStatementSuffixExecuteContext<'input>;


pub type AlterStatementSuffixExecuteContext<'input> = BaseParserRuleContext<'input,AlterStatementSuffixExecuteContextExt<'input>>;

#[derive(Clone)]
pub struct AlterStatementSuffixExecuteContextExt<'input>{
	pub rollbackParam: Option<TokenType<'input>>,
	pub expireParam: Option<TokenType<'input>>,
	pub snapshotParam: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterStatementSuffixExecuteContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterStatementSuffixExecuteContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterStatementSuffixExecute(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterStatementSuffixExecute(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterStatementSuffixExecuteContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterStatementSuffixExecute }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterStatementSuffixExecute }
}
crate::tid!{AlterStatementSuffixExecuteContextExt<'a>}

impl<'input> AlterStatementSuffixExecuteContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterStatementSuffixExecuteContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterStatementSuffixExecuteContextExt{
				rollbackParam: None, expireParam: None, snapshotParam: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterStatementSuffixExecuteContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterStatementSuffixExecuteContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_EXECUTE
/// Returns `None` if there is no child corresponding to token KW_EXECUTE
fn KW_EXECUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXECUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLLBACK
/// Returns `None` if there is no child corresponding to token KW_ROLLBACK
fn KW_ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLLBACK, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXPIRE_SNAPSHOTS
/// Returns `None` if there is no child corresponding to token KW_EXPIRE_SNAPSHOTS
fn KW_EXPIRE_SNAPSHOTS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXPIRE_SNAPSHOTS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SET_CURRENT_SNAPSHOT
/// Returns `None` if there is no child corresponding to token KW_SET_CURRENT_SNAPSHOT
fn KW_SET_CURRENT_SNAPSHOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET_CURRENT_SNAPSHOT, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}

}

impl<'input> AlterStatementSuffixExecuteContextAttrs<'input> for AlterStatementSuffixExecuteContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterStatementSuffixExecute(&mut self,)
	-> Result<Rc<AlterStatementSuffixExecuteContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterStatementSuffixExecuteContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 576, RULE_alterStatementSuffixExecute);
        let mut _localctx: Rc<AlterStatementSuffixExecuteContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3548);
			recog.base.match_token(KW_EXECUTE,&mut recog.err_handler)?;

			recog.base.set_state(3558);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ROLLBACK 
				=> {
					{
					recog.base.set_state(3549);
					recog.base.match_token(KW_ROLLBACK,&mut recog.err_handler)?;

					recog.base.set_state(3550);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3551);
					 cast_mut::<_,AlterStatementSuffixExecuteContext >(&mut _localctx).rollbackParam = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==StringLiteral || _la==Number) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,AlterStatementSuffixExecuteContext >(&mut _localctx).rollbackParam = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

			 KW_EXPIRE_SNAPSHOTS 
				=> {
					{
					recog.base.set_state(3552);
					recog.base.match_token(KW_EXPIRE_SNAPSHOTS,&mut recog.err_handler)?;

					recog.base.set_state(3553);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3554);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,AlterStatementSuffixExecuteContext >(&mut _localctx).expireParam = Some(tmp.clone());
					  

					}
				}

			 KW_SET_CURRENT_SNAPSHOT 
				=> {
					{
					recog.base.set_state(3555);
					recog.base.match_token(KW_SET_CURRENT_SNAPSHOT,&mut recog.err_handler)?;

					recog.base.set_state(3556);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(3557);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,AlterStatementSuffixExecuteContext >(&mut _localctx).snapshotParam = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(3560);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterIndexStatementSuffix ----------------
pub type AlterIndexStatementSuffixContextAll<'input> = AlterIndexStatementSuffixContext<'input>;


pub type AlterIndexStatementSuffixContext<'input> = BaseParserRuleContext<'input,AlterIndexStatementSuffixContextExt<'input>>;

#[derive(Clone)]
pub struct AlterIndexStatementSuffixContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterIndexStatementSuffixContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterIndexStatementSuffixContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterIndexStatementSuffix(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterIndexStatementSuffix(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterIndexStatementSuffixContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterIndexStatementSuffix }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterIndexStatementSuffix }
}
crate::tid!{AlterIndexStatementSuffixContextExt<'a>}

impl<'input> AlterIndexStatementSuffixContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterIndexStatementSuffixContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterIndexStatementSuffixContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterIndexStatementSuffixContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterIndexStatementSuffixContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_REBUILD
/// Returns `None` if there is no child corresponding to token KW_REBUILD
fn KW_REBUILD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REBUILD, 0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterIndexStatementSuffixContextAttrs<'input> for AlterIndexStatementSuffixContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterIndexStatementSuffix(&mut self,)
	-> Result<Rc<AlterIndexStatementSuffixContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterIndexStatementSuffixContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 578, RULE_alterIndexStatementSuffix);
        let mut _localctx: Rc<AlterIndexStatementSuffixContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(3562);
			recog.id_()?;

			recog.base.set_state(3563);
			recog.base.match_token(KW_ON,&mut recog.err_handler)?;

			/*InvokeRule tableName*/
			recog.base.set_state(3564);
			recog.tableName()?;

			recog.base.set_state(3566);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PARTITION {
				{
				/*InvokeRule partitionSpec*/
				recog.base.set_state(3565);
				recog.partitionSpec()?;

				}
			}

			recog.base.set_state(3568);
			recog.base.match_token(KW_REBUILD,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fileFormat ----------------
pub type FileFormatContextAll<'input> = FileFormatContext<'input>;


pub type FileFormatContext<'input> = BaseParserRuleContext<'input,FileFormatContextExt<'input>>;

#[derive(Clone)]
pub struct FileFormatContextExt<'input>{
	pub inFmt: Option<TokenType<'input>>,
	pub outFmt: Option<TokenType<'input>>,
	pub serdeCls: Option<TokenType<'input>>,
	pub inDriver: Option<TokenType<'input>>,
	pub outDriver: Option<TokenType<'input>>,
	pub genericSpec: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for FileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for FileFormatContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fileFormat(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_fileFormat(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for FileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fileFormat }
}
crate::tid!{FileFormatContextExt<'a>}

impl<'input> FileFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FileFormatContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FileFormatContextExt{
				inFmt: None, outFmt: None, serdeCls: None, inDriver: None, outDriver: None, 
				genericSpec: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FileFormatContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<FileFormatContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_INPUTFORMAT
/// Returns `None` if there is no child corresponding to token KW_INPUTFORMAT
fn KW_INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OUTPUTFORMAT
/// Returns `None` if there is no child corresponding to token KW_OUTPUTFORMAT
fn KW_OUTPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OUTPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERDE
/// Returns `None` if there is no child corresponding to token KW_SERDE
fn KW_SERDE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERDE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token StringLiteral in current rule
fn StringLiteral_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token StringLiteral, starting from 0.
/// Returns `None` if number of children corresponding to token StringLiteral is less or equal than `i`.
fn StringLiteral(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, i)
}
/// Retrieves first TerminalNode corresponding to token KW_INPUTDRIVER
/// Returns `None` if there is no child corresponding to token KW_INPUTDRIVER
fn KW_INPUTDRIVER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INPUTDRIVER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OUTPUTDRIVER
/// Returns `None` if there is no child corresponding to token KW_OUTPUTDRIVER
fn KW_OUTPUTDRIVER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OUTPUTDRIVER, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FileFormatContextAttrs<'input> for FileFormatContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fileFormat(&mut self,)
	-> Result<Rc<FileFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FileFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 580, RULE_fileFormat);
        let mut _localctx: Rc<FileFormatContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3583);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(387,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3570);
					recog.base.match_token(KW_INPUTFORMAT,&mut recog.err_handler)?;

					recog.base.set_state(3571);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,FileFormatContext >(&mut _localctx).inFmt = Some(tmp.clone());
					  

					recog.base.set_state(3572);
					recog.base.match_token(KW_OUTPUTFORMAT,&mut recog.err_handler)?;

					recog.base.set_state(3573);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,FileFormatContext >(&mut _localctx).outFmt = Some(tmp.clone());
					  

					recog.base.set_state(3574);
					recog.base.match_token(KW_SERDE,&mut recog.err_handler)?;

					recog.base.set_state(3575);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,FileFormatContext >(&mut _localctx).serdeCls = Some(tmp.clone());
					  

					recog.base.set_state(3580);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_INPUTDRIVER {
						{
						recog.base.set_state(3576);
						recog.base.match_token(KW_INPUTDRIVER,&mut recog.err_handler)?;

						recog.base.set_state(3577);
						let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
						 cast_mut::<_,FileFormatContext >(&mut _localctx).inDriver = Some(tmp.clone());
						  

						recog.base.set_state(3578);
						recog.base.match_token(KW_OUTPUTDRIVER,&mut recog.err_handler)?;

						recog.base.set_state(3579);
						let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
						 cast_mut::<_,FileFormatContext >(&mut _localctx).outDriver = Some(tmp.clone());
						  

						}
					}

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule id_*/
					recog.base.set_state(3582);
					let tmp = recog.id_()?;
					 cast_mut::<_,FileFormatContext >(&mut _localctx).genericSpec = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterDataConnectorStatementSuffix ----------------
pub type AlterDataConnectorStatementSuffixContextAll<'input> = AlterDataConnectorStatementSuffixContext<'input>;


pub type AlterDataConnectorStatementSuffixContext<'input> = BaseParserRuleContext<'input,AlterDataConnectorStatementSuffixContextExt<'input>>;

#[derive(Clone)]
pub struct AlterDataConnectorStatementSuffixContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterDataConnectorStatementSuffixContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterDataConnectorStatementSuffixContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterDataConnectorStatementSuffix(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterDataConnectorStatementSuffix(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterDataConnectorStatementSuffixContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterDataConnectorStatementSuffix }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterDataConnectorStatementSuffix }
}
crate::tid!{AlterDataConnectorStatementSuffixContextExt<'a>}

impl<'input> AlterDataConnectorStatementSuffixContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterDataConnectorStatementSuffixContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterDataConnectorStatementSuffixContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterDataConnectorStatementSuffixContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterDataConnectorStatementSuffixContextExt<'input>>{

fn alterDataConnectorSuffixProperties(&self) -> Option<Rc<AlterDataConnectorSuffixPropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterDataConnectorSuffixSetOwner(&self) -> Option<Rc<AlterDataConnectorSuffixSetOwnerContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterDataConnectorSuffixSetUrl(&self) -> Option<Rc<AlterDataConnectorSuffixSetUrlContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterDataConnectorStatementSuffixContextAttrs<'input> for AlterDataConnectorStatementSuffixContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterDataConnectorStatementSuffix(&mut self,)
	-> Result<Rc<AlterDataConnectorStatementSuffixContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterDataConnectorStatementSuffixContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 582, RULE_alterDataConnectorStatementSuffix);
        let mut _localctx: Rc<AlterDataConnectorStatementSuffixContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3588);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(388,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule alterDataConnectorSuffixProperties*/
					recog.base.set_state(3585);
					recog.alterDataConnectorSuffixProperties()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule alterDataConnectorSuffixSetOwner*/
					recog.base.set_state(3586);
					recog.alterDataConnectorSuffixSetOwner()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule alterDataConnectorSuffixSetUrl*/
					recog.base.set_state(3587);
					recog.alterDataConnectorSuffixSetUrl()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterDataConnectorSuffixProperties ----------------
pub type AlterDataConnectorSuffixPropertiesContextAll<'input> = AlterDataConnectorSuffixPropertiesContext<'input>;


pub type AlterDataConnectorSuffixPropertiesContext<'input> = BaseParserRuleContext<'input,AlterDataConnectorSuffixPropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct AlterDataConnectorSuffixPropertiesContextExt<'input>{
	pub name: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterDataConnectorSuffixPropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterDataConnectorSuffixPropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterDataConnectorSuffixProperties(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterDataConnectorSuffixProperties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterDataConnectorSuffixPropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterDataConnectorSuffixProperties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterDataConnectorSuffixProperties }
}
crate::tid!{AlterDataConnectorSuffixPropertiesContextExt<'a>}

impl<'input> AlterDataConnectorSuffixPropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterDataConnectorSuffixPropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterDataConnectorSuffixPropertiesContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterDataConnectorSuffixPropertiesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterDataConnectorSuffixPropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DCPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_DCPROPERTIES
fn KW_DCPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DCPROPERTIES, 0)
}
fn dcProperties(&self) -> Option<Rc<DcPropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterDataConnectorSuffixPropertiesContextAttrs<'input> for AlterDataConnectorSuffixPropertiesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterDataConnectorSuffixProperties(&mut self,)
	-> Result<Rc<AlterDataConnectorSuffixPropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterDataConnectorSuffixPropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 584, RULE_alterDataConnectorSuffixProperties);
        let mut _localctx: Rc<AlterDataConnectorSuffixPropertiesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(3590);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterDataConnectorSuffixPropertiesContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(3591);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3592);
			recog.base.match_token(KW_DCPROPERTIES,&mut recog.err_handler)?;

			/*InvokeRule dcProperties*/
			recog.base.set_state(3593);
			recog.dcProperties()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterDataConnectorSuffixSetOwner ----------------
pub type AlterDataConnectorSuffixSetOwnerContextAll<'input> = AlterDataConnectorSuffixSetOwnerContext<'input>;


pub type AlterDataConnectorSuffixSetOwnerContext<'input> = BaseParserRuleContext<'input,AlterDataConnectorSuffixSetOwnerContextExt<'input>>;

#[derive(Clone)]
pub struct AlterDataConnectorSuffixSetOwnerContextExt<'input>{
	pub dcName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterDataConnectorSuffixSetOwnerContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterDataConnectorSuffixSetOwnerContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterDataConnectorSuffixSetOwner(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterDataConnectorSuffixSetOwner(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterDataConnectorSuffixSetOwnerContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterDataConnectorSuffixSetOwner }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterDataConnectorSuffixSetOwner }
}
crate::tid!{AlterDataConnectorSuffixSetOwnerContextExt<'a>}

impl<'input> AlterDataConnectorSuffixSetOwnerContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterDataConnectorSuffixSetOwnerContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterDataConnectorSuffixSetOwnerContextExt{
				dcName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterDataConnectorSuffixSetOwnerContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterDataConnectorSuffixSetOwnerContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OWNER
/// Returns `None` if there is no child corresponding to token KW_OWNER
fn KW_OWNER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OWNER, 0)
}
fn principalName(&self) -> Option<Rc<PrincipalNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterDataConnectorSuffixSetOwnerContextAttrs<'input> for AlterDataConnectorSuffixSetOwnerContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterDataConnectorSuffixSetOwner(&mut self,)
	-> Result<Rc<AlterDataConnectorSuffixSetOwnerContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterDataConnectorSuffixSetOwnerContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 586, RULE_alterDataConnectorSuffixSetOwner);
        let mut _localctx: Rc<AlterDataConnectorSuffixSetOwnerContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(3595);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterDataConnectorSuffixSetOwnerContext >(&mut _localctx).dcName = Some(tmp.clone());
			  

			recog.base.set_state(3596);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3597);
			recog.base.match_token(KW_OWNER,&mut recog.err_handler)?;

			/*InvokeRule principalName*/
			recog.base.set_state(3598);
			recog.principalName()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterDataConnectorSuffixSetUrl ----------------
pub type AlterDataConnectorSuffixSetUrlContextAll<'input> = AlterDataConnectorSuffixSetUrlContext<'input>;


pub type AlterDataConnectorSuffixSetUrlContext<'input> = BaseParserRuleContext<'input,AlterDataConnectorSuffixSetUrlContextExt<'input>>;

#[derive(Clone)]
pub struct AlterDataConnectorSuffixSetUrlContextExt<'input>{
	pub dcName: Option<Rc<Id_ContextAll<'input>>>,
	pub newUri: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterDataConnectorSuffixSetUrlContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterDataConnectorSuffixSetUrlContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterDataConnectorSuffixSetUrl(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterDataConnectorSuffixSetUrl(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterDataConnectorSuffixSetUrlContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterDataConnectorSuffixSetUrl }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterDataConnectorSuffixSetUrl }
}
crate::tid!{AlterDataConnectorSuffixSetUrlContextExt<'a>}

impl<'input> AlterDataConnectorSuffixSetUrlContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterDataConnectorSuffixSetUrlContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterDataConnectorSuffixSetUrlContextExt{
				newUri: None, 
				dcName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterDataConnectorSuffixSetUrlContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterDataConnectorSuffixSetUrlContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_URL
/// Returns `None` if there is no child corresponding to token KW_URL
fn KW_URL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_URL, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> AlterDataConnectorSuffixSetUrlContextAttrs<'input> for AlterDataConnectorSuffixSetUrlContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterDataConnectorSuffixSetUrl(&mut self,)
	-> Result<Rc<AlterDataConnectorSuffixSetUrlContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterDataConnectorSuffixSetUrlContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 588, RULE_alterDataConnectorSuffixSetUrl);
        let mut _localctx: Rc<AlterDataConnectorSuffixSetUrlContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(3600);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterDataConnectorSuffixSetUrlContext >(&mut _localctx).dcName = Some(tmp.clone());
			  

			recog.base.set_state(3601);
			recog.base.match_token(KW_SET,&mut recog.err_handler)?;

			recog.base.set_state(3602);
			recog.base.match_token(KW_URL,&mut recog.err_handler)?;

			recog.base.set_state(3603);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,AlterDataConnectorSuffixSetUrlContext >(&mut _localctx).newUri = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- likeTableOrFile ----------------
pub type LikeTableOrFileContextAll<'input> = LikeTableOrFileContext<'input>;


pub type LikeTableOrFileContext<'input> = BaseParserRuleContext<'input,LikeTableOrFileContextExt<'input>>;

#[derive(Clone)]
pub struct LikeTableOrFileContextExt<'input>{
	pub format: Option<Rc<Id_ContextAll<'input>>>,
	pub uri: Option<TokenType<'input>>,
	pub likeName: Option<Rc<TableNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for LikeTableOrFileContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for LikeTableOrFileContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_likeTableOrFile(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_likeTableOrFile(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for LikeTableOrFileContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_likeTableOrFile }
	//fn type_rule_index() -> usize where Self: Sized { RULE_likeTableOrFile }
}
crate::tid!{LikeTableOrFileContextExt<'a>}

impl<'input> LikeTableOrFileContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LikeTableOrFileContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LikeTableOrFileContextExt{
				uri: None, 
				format: None, likeName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LikeTableOrFileContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<LikeTableOrFileContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LIKE
/// Returns `None` if there is no child corresponding to token KW_LIKE
fn KW_LIKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FILE
/// Returns `None` if there is no child corresponding to token KW_FILE
fn KW_FILE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FILE, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LikeTableOrFileContextAttrs<'input> for LikeTableOrFileContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn likeTableOrFile(&mut self,)
	-> Result<Rc<LikeTableOrFileContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LikeTableOrFileContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 590, RULE_likeTableOrFile);
        let mut _localctx: Rc<LikeTableOrFileContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3614);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(389,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3605);
					recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

					recog.base.set_state(3606);
					recog.base.match_token(KW_FILE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3607);
					recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

					recog.base.set_state(3608);
					recog.base.match_token(KW_FILE,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(3609);
					let tmp = recog.id_()?;
					 cast_mut::<_,LikeTableOrFileContext >(&mut _localctx).format = Some(tmp.clone());
					  

					recog.base.set_state(3610);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,LikeTableOrFileContext >(&mut _localctx).uri = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3612);
					recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

					/*InvokeRule tableName*/
					recog.base.set_state(3613);
					let tmp = recog.tableName()?;
					 cast_mut::<_,LikeTableOrFileContext >(&mut _localctx).likeName = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createTableStatement ----------------
pub type CreateTableStatementContextAll<'input> = CreateTableStatementContext<'input>;


pub type CreateTableStatementContext<'input> = BaseParserRuleContext<'input,CreateTableStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateTableStatementContextExt<'input>{
	pub temp: Option<TokenType<'input>>,
	pub trans: Option<TokenType<'input>>,
	pub ext: Option<TokenType<'input>>,
	pub name: Option<Rc<TableNameContextAll<'input>>>,
	pub mgd: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateTableStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateTableStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createTableStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createTableStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateTableStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createTableStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createTableStatement }
}
crate::tid!{CreateTableStatementContextExt<'a>}

impl<'input> CreateTableStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateTableStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateTableStatementContextExt{
				temp: None, trans: None, ext: None, mgd: None, 
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateTableStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateTableStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn likeTableOrFile(&self) -> Option<Rc<LikeTableOrFileContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifNotExists(&self) -> Option<Rc<IfNotExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_TEMPORARY
/// Returns `None` if there is no child corresponding to token KW_TEMPORARY
fn KW_TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TEMPORARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRANSACTIONAL
/// Returns `None` if there is no child corresponding to token KW_TRANSACTIONAL
fn KW_TRANSACTIONAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRANSACTIONAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXTERNAL
/// Returns `None` if there is no child corresponding to token KW_EXTERNAL
fn KW_EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXTERNAL, 0)
}
fn createTablePartitionSpec(&self) -> Option<Rc<CreateTablePartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableRowFormat(&self) -> Option<Rc<TableRowFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableFileFormat(&self) -> Option<Rc<TableFileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableLocation(&self) -> Option<Rc<TableLocationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tablePropertiesPrefixed(&self) -> Option<Rc<TablePropertiesPrefixedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnNameTypeOrConstraintList(&self) -> Option<Rc<ColumnNameTypeOrConstraintListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn tableComment(&self) -> Option<Rc<TableCommentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableBuckets(&self) -> Option<Rc<TableBucketsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableSkewed(&self) -> Option<Rc<TableSkewedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
fn selectStatementWithCTE(&self) -> Option<Rc<SelectStatementWithCTEContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_MANAGED
/// Returns `None` if there is no child corresponding to token KW_MANAGED
fn KW_MANAGED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MANAGED, 0)
}

}

impl<'input> CreateTableStatementContextAttrs<'input> for CreateTableStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createTableStatement(&mut self,)
	-> Result<Rc<CreateTableStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateTableStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 592, RULE_createTableStatement);
        let mut _localctx: Rc<CreateTableStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3739);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(426,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3616);
					recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

					recog.base.set_state(3618);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_TEMPORARY {
						{
						recog.base.set_state(3617);
						let tmp = recog.base.match_token(KW_TEMPORARY,&mut recog.err_handler)?;
						 cast_mut::<_,CreateTableStatementContext >(&mut _localctx).temp = Some(tmp.clone());
						  

						}
					}

					recog.base.set_state(3621);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_TRANSACTIONAL {
						{
						recog.base.set_state(3620);
						let tmp = recog.base.match_token(KW_TRANSACTIONAL,&mut recog.err_handler)?;
						 cast_mut::<_,CreateTableStatementContext >(&mut _localctx).trans = Some(tmp.clone());
						  

						}
					}

					recog.base.set_state(3624);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_EXTERNAL {
						{
						recog.base.set_state(3623);
						let tmp = recog.base.match_token(KW_EXTERNAL,&mut recog.err_handler)?;
						 cast_mut::<_,CreateTableStatementContext >(&mut _localctx).ext = Some(tmp.clone());
						  

						}
					}

					recog.base.set_state(3626);
					recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

					recog.base.set_state(3628);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_IF {
						{
						/*InvokeRule ifNotExists*/
						recog.base.set_state(3627);
						recog.ifNotExists()?;

						}
					}

					/*InvokeRule tableName*/
					recog.base.set_state(3630);
					let tmp = recog.tableName()?;
					 cast_mut::<_,CreateTableStatementContext >(&mut _localctx).name = Some(tmp.clone());
					  

					recog.base.set_state(3681);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_LIKE 
						=> {
							{
							/*InvokeRule likeTableOrFile*/
							recog.base.set_state(3631);
							recog.likeTableOrFile()?;

							recog.base.set_state(3633);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_PARTITIONED {
								{
								/*InvokeRule createTablePartitionSpec*/
								recog.base.set_state(3632);
								recog.createTablePartitionSpec()?;

								}
							}

							recog.base.set_state(3636);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_ROW {
								{
								/*InvokeRule tableRowFormat*/
								recog.base.set_state(3635);
								recog.tableRowFormat()?;

								}
							}

							recog.base.set_state(3639);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_STORED {
								{
								/*InvokeRule tableFileFormat*/
								recog.base.set_state(3638);
								recog.tableFileFormat()?;

								}
							}

							recog.base.set_state(3642);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_LOCATION {
								{
								/*InvokeRule tableLocation*/
								recog.base.set_state(3641);
								recog.tableLocation()?;

								}
							}

							recog.base.set_state(3645);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_TBLPROPERTIES {
								{
								/*InvokeRule tablePropertiesPrefixed*/
								recog.base.set_state(3644);
								recog.tablePropertiesPrefixed()?;

								}
							}

							}
						}

					 EOF | KW_ABORT | KW_ALTER | KW_ANALYZE | KW_AS | KW_CLUSTERED | KW_COMMENT |
					 KW_COMMIT | KW_CREATE | KW_DELETE | KW_DESC | KW_DESCRIBE | KW_DISABLE |
					 KW_DROP | KW_ENABLE | KW_EXECUTE | KW_EXPLAIN | KW_EXPORT | KW_FROM |
					 KW_GRANT | KW_IMPORT | KW_INSERT | KW_KILL | KW_LOAD | KW_LOCATION |
					 KW_LOCK | KW_MAP | KW_MERGE | KW_MSCK | KW_PARTITIONED | KW_PREPARE |
					 KW_REDUCE | KW_RELOAD | KW_REPL | KW_REPLACE | KW_REVOKE | KW_ROLLBACK |
					 KW_ROW | KW_SELECT | KW_SET | KW_SHOW | KW_SKEWED | KW_START | KW_STORED |
					 KW_TBLPROPERTIES | KW_TRUNCATE | KW_UNLOCK | KW_UPDATE | KW_USE | KW_VALUES |
					 KW_WITH | SEMICOLON | LPAREN 
						=> {
							{
							recog.base.set_state(3651);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(399,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(3647);
									recog.base.match_token(LPAREN,&mut recog.err_handler)?;

									/*InvokeRule columnNameTypeOrConstraintList*/
									recog.base.set_state(3648);
									recog.columnNameTypeOrConstraintList()?;

									recog.base.set_state(3649);
									recog.base.match_token(RPAREN,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							recog.base.set_state(3654);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_COMMENT {
								{
								/*InvokeRule tableComment*/
								recog.base.set_state(3653);
								recog.tableComment()?;

								}
							}

							recog.base.set_state(3657);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_PARTITIONED {
								{
								/*InvokeRule createTablePartitionSpec*/
								recog.base.set_state(3656);
								recog.createTablePartitionSpec()?;

								}
							}

							recog.base.set_state(3660);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_CLUSTERED {
								{
								/*InvokeRule tableBuckets*/
								recog.base.set_state(3659);
								recog.tableBuckets()?;

								}
							}

							recog.base.set_state(3663);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_SKEWED {
								{
								/*InvokeRule tableSkewed*/
								recog.base.set_state(3662);
								recog.tableSkewed()?;

								}
							}

							recog.base.set_state(3666);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_ROW {
								{
								/*InvokeRule tableRowFormat*/
								recog.base.set_state(3665);
								recog.tableRowFormat()?;

								}
							}

							recog.base.set_state(3669);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_STORED {
								{
								/*InvokeRule tableFileFormat*/
								recog.base.set_state(3668);
								recog.tableFileFormat()?;

								}
							}

							recog.base.set_state(3672);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_LOCATION {
								{
								/*InvokeRule tableLocation*/
								recog.base.set_state(3671);
								recog.tableLocation()?;

								}
							}

							recog.base.set_state(3675);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_TBLPROPERTIES {
								{
								/*InvokeRule tablePropertiesPrefixed*/
								recog.base.set_state(3674);
								recog.tablePropertiesPrefixed()?;

								}
							}

							recog.base.set_state(3679);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_AS {
								{
								recog.base.set_state(3677);
								recog.base.match_token(KW_AS,&mut recog.err_handler)?;

								/*InvokeRule selectStatementWithCTE*/
								recog.base.set_state(3678);
								recog.selectStatementWithCTE()?;

								}
							}

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3683);
					recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

					recog.base.set_state(3684);
					let tmp = recog.base.match_token(KW_MANAGED,&mut recog.err_handler)?;
					 cast_mut::<_,CreateTableStatementContext >(&mut _localctx).mgd = Some(tmp.clone());
					  

					recog.base.set_state(3685);
					recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

					recog.base.set_state(3687);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_IF {
						{
						/*InvokeRule ifNotExists*/
						recog.base.set_state(3686);
						recog.ifNotExists()?;

						}
					}

					/*InvokeRule tableName*/
					recog.base.set_state(3689);
					let tmp = recog.tableName()?;
					 cast_mut::<_,CreateTableStatementContext >(&mut _localctx).name = Some(tmp.clone());
					  

					recog.base.set_state(3737);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_LIKE 
						=> {
							{
							/*InvokeRule likeTableOrFile*/
							recog.base.set_state(3690);
							recog.likeTableOrFile()?;

							recog.base.set_state(3692);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_ROW {
								{
								/*InvokeRule tableRowFormat*/
								recog.base.set_state(3691);
								recog.tableRowFormat()?;

								}
							}

							recog.base.set_state(3695);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_STORED {
								{
								/*InvokeRule tableFileFormat*/
								recog.base.set_state(3694);
								recog.tableFileFormat()?;

								}
							}

							recog.base.set_state(3698);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_LOCATION {
								{
								/*InvokeRule tableLocation*/
								recog.base.set_state(3697);
								recog.tableLocation()?;

								}
							}

							recog.base.set_state(3701);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_TBLPROPERTIES {
								{
								/*InvokeRule tablePropertiesPrefixed*/
								recog.base.set_state(3700);
								recog.tablePropertiesPrefixed()?;

								}
							}

							}
						}

					 EOF | KW_ABORT | KW_ALTER | KW_ANALYZE | KW_AS | KW_CLUSTERED | KW_COMMENT |
					 KW_COMMIT | KW_CREATE | KW_DELETE | KW_DESC | KW_DESCRIBE | KW_DISABLE |
					 KW_DROP | KW_ENABLE | KW_EXECUTE | KW_EXPLAIN | KW_EXPORT | KW_FROM |
					 KW_GRANT | KW_IMPORT | KW_INSERT | KW_KILL | KW_LOAD | KW_LOCATION |
					 KW_LOCK | KW_MAP | KW_MERGE | KW_MSCK | KW_PARTITIONED | KW_PREPARE |
					 KW_REDUCE | KW_RELOAD | KW_REPL | KW_REPLACE | KW_REVOKE | KW_ROLLBACK |
					 KW_ROW | KW_SELECT | KW_SET | KW_SHOW | KW_SKEWED | KW_START | KW_STORED |
					 KW_TBLPROPERTIES | KW_TRUNCATE | KW_UNLOCK | KW_UPDATE | KW_USE | KW_VALUES |
					 KW_WITH | SEMICOLON | LPAREN 
						=> {
							{
							recog.base.set_state(3707);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(415,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(3703);
									recog.base.match_token(LPAREN,&mut recog.err_handler)?;

									/*InvokeRule columnNameTypeOrConstraintList*/
									recog.base.set_state(3704);
									recog.columnNameTypeOrConstraintList()?;

									recog.base.set_state(3705);
									recog.base.match_token(RPAREN,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							recog.base.set_state(3710);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_COMMENT {
								{
								/*InvokeRule tableComment*/
								recog.base.set_state(3709);
								recog.tableComment()?;

								}
							}

							recog.base.set_state(3713);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_PARTITIONED {
								{
								/*InvokeRule createTablePartitionSpec*/
								recog.base.set_state(3712);
								recog.createTablePartitionSpec()?;

								}
							}

							recog.base.set_state(3716);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_CLUSTERED {
								{
								/*InvokeRule tableBuckets*/
								recog.base.set_state(3715);
								recog.tableBuckets()?;

								}
							}

							recog.base.set_state(3719);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_SKEWED {
								{
								/*InvokeRule tableSkewed*/
								recog.base.set_state(3718);
								recog.tableSkewed()?;

								}
							}

							recog.base.set_state(3722);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_ROW {
								{
								/*InvokeRule tableRowFormat*/
								recog.base.set_state(3721);
								recog.tableRowFormat()?;

								}
							}

							recog.base.set_state(3725);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_STORED {
								{
								/*InvokeRule tableFileFormat*/
								recog.base.set_state(3724);
								recog.tableFileFormat()?;

								}
							}

							recog.base.set_state(3728);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_LOCATION {
								{
								/*InvokeRule tableLocation*/
								recog.base.set_state(3727);
								recog.tableLocation()?;

								}
							}

							recog.base.set_state(3731);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_TBLPROPERTIES {
								{
								/*InvokeRule tablePropertiesPrefixed*/
								recog.base.set_state(3730);
								recog.tablePropertiesPrefixed()?;

								}
							}

							recog.base.set_state(3735);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_AS {
								{
								recog.base.set_state(3733);
								recog.base.match_token(KW_AS,&mut recog.err_handler)?;

								/*InvokeRule selectStatementWithCTE*/
								recog.base.set_state(3734);
								recog.selectStatementWithCTE()?;

								}
							}

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createDataConnectorStatement ----------------
pub type CreateDataConnectorStatementContextAll<'input> = CreateDataConnectorStatementContext<'input>;


pub type CreateDataConnectorStatementContext<'input> = BaseParserRuleContext<'input,CreateDataConnectorStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateDataConnectorStatementContextExt<'input>{
	pub name: Option<Rc<Id_ContextAll<'input>>>,
	pub dcprops: Option<Rc<DcPropertiesContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateDataConnectorStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateDataConnectorStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createDataConnectorStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createDataConnectorStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateDataConnectorStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createDataConnectorStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createDataConnectorStatement }
}
crate::tid!{CreateDataConnectorStatementContextExt<'a>}

impl<'input> CreateDataConnectorStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateDataConnectorStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateDataConnectorStatementContextExt{
				name: None, dcprops: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateDataConnectorStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateDataConnectorStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATACONNECTOR
/// Returns `None` if there is no child corresponding to token KW_DATACONNECTOR
fn KW_DATACONNECTOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATACONNECTOR, 0)
}
fn dataConnectorType(&self) -> Option<Rc<DataConnectorTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dataConnectorUrl(&self) -> Option<Rc<DataConnectorUrlContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifNotExists(&self) -> Option<Rc<IfNotExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dataConnectorComment(&self) -> Option<Rc<DataConnectorCommentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DCPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_DCPROPERTIES
fn KW_DCPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DCPROPERTIES, 0)
}
fn dcProperties(&self) -> Option<Rc<DcPropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateDataConnectorStatementContextAttrs<'input> for CreateDataConnectorStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createDataConnectorStatement(&mut self,)
	-> Result<Rc<CreateDataConnectorStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateDataConnectorStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 594, RULE_createDataConnectorStatement);
        let mut _localctx: Rc<CreateDataConnectorStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3741);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(3742);
			recog.base.match_token(KW_DATACONNECTOR,&mut recog.err_handler)?;

			recog.base.set_state(3744);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifNotExists*/
				recog.base.set_state(3743);
				recog.ifNotExists()?;

				}
			}

			/*InvokeRule id_*/
			recog.base.set_state(3746);
			let tmp = recog.id_()?;
			 cast_mut::<_,CreateDataConnectorStatementContext >(&mut _localctx).name = Some(tmp.clone());
			  

			/*InvokeRule dataConnectorType*/
			recog.base.set_state(3747);
			recog.dataConnectorType()?;

			/*InvokeRule dataConnectorUrl*/
			recog.base.set_state(3748);
			recog.dataConnectorUrl()?;

			recog.base.set_state(3750);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_COMMENT {
				{
				/*InvokeRule dataConnectorComment*/
				recog.base.set_state(3749);
				recog.dataConnectorComment()?;

				}
			}

			recog.base.set_state(3755);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(429,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3752);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					recog.base.set_state(3753);
					recog.base.match_token(KW_DCPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule dcProperties*/
					recog.base.set_state(3754);
					let tmp = recog.dcProperties()?;
					 cast_mut::<_,CreateDataConnectorStatementContext >(&mut _localctx).dcprops = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dataConnectorComment ----------------
pub type DataConnectorCommentContextAll<'input> = DataConnectorCommentContext<'input>;


pub type DataConnectorCommentContext<'input> = BaseParserRuleContext<'input,DataConnectorCommentContextExt<'input>>;

#[derive(Clone)]
pub struct DataConnectorCommentContextExt<'input>{
	pub comment: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DataConnectorCommentContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DataConnectorCommentContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dataConnectorComment(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dataConnectorComment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DataConnectorCommentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dataConnectorComment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dataConnectorComment }
}
crate::tid!{DataConnectorCommentContextExt<'a>}

impl<'input> DataConnectorCommentContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DataConnectorCommentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DataConnectorCommentContextExt{
				comment: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DataConnectorCommentContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DataConnectorCommentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_COMMENT
/// Returns `None` if there is no child corresponding to token KW_COMMENT
fn KW_COMMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> DataConnectorCommentContextAttrs<'input> for DataConnectorCommentContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dataConnectorComment(&mut self,)
	-> Result<Rc<DataConnectorCommentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DataConnectorCommentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 596, RULE_dataConnectorComment);
        let mut _localctx: Rc<DataConnectorCommentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3757);
			recog.base.match_token(KW_COMMENT,&mut recog.err_handler)?;

			recog.base.set_state(3758);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,DataConnectorCommentContext >(&mut _localctx).comment = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dataConnectorUrl ----------------
pub type DataConnectorUrlContextAll<'input> = DataConnectorUrlContext<'input>;


pub type DataConnectorUrlContext<'input> = BaseParserRuleContext<'input,DataConnectorUrlContextExt<'input>>;

#[derive(Clone)]
pub struct DataConnectorUrlContextExt<'input>{
	pub url: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DataConnectorUrlContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DataConnectorUrlContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dataConnectorUrl(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dataConnectorUrl(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DataConnectorUrlContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dataConnectorUrl }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dataConnectorUrl }
}
crate::tid!{DataConnectorUrlContextExt<'a>}

impl<'input> DataConnectorUrlContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DataConnectorUrlContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DataConnectorUrlContextExt{
				url: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DataConnectorUrlContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DataConnectorUrlContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_URL
/// Returns `None` if there is no child corresponding to token KW_URL
fn KW_URL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_URL, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> DataConnectorUrlContextAttrs<'input> for DataConnectorUrlContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dataConnectorUrl(&mut self,)
	-> Result<Rc<DataConnectorUrlContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DataConnectorUrlContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 598, RULE_dataConnectorUrl);
        let mut _localctx: Rc<DataConnectorUrlContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3760);
			recog.base.match_token(KW_URL,&mut recog.err_handler)?;

			recog.base.set_state(3761);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,DataConnectorUrlContext >(&mut _localctx).url = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dataConnectorType ----------------
pub type DataConnectorTypeContextAll<'input> = DataConnectorTypeContext<'input>;


pub type DataConnectorTypeContext<'input> = BaseParserRuleContext<'input,DataConnectorTypeContextExt<'input>>;

#[derive(Clone)]
pub struct DataConnectorTypeContextExt<'input>{
	pub dcType: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DataConnectorTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DataConnectorTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dataConnectorType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dataConnectorType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DataConnectorTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dataConnectorType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dataConnectorType }
}
crate::tid!{DataConnectorTypeContextExt<'a>}

impl<'input> DataConnectorTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DataConnectorTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DataConnectorTypeContextExt{
				dcType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DataConnectorTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DataConnectorTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TYPE
/// Returns `None` if there is no child corresponding to token KW_TYPE
fn KW_TYPE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> DataConnectorTypeContextAttrs<'input> for DataConnectorTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dataConnectorType(&mut self,)
	-> Result<Rc<DataConnectorTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DataConnectorTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 600, RULE_dataConnectorType);
        let mut _localctx: Rc<DataConnectorTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3763);
			recog.base.match_token(KW_TYPE,&mut recog.err_handler)?;

			recog.base.set_state(3764);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,DataConnectorTypeContext >(&mut _localctx).dcType = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dcProperties ----------------
pub type DcPropertiesContextAll<'input> = DcPropertiesContext<'input>;


pub type DcPropertiesContext<'input> = BaseParserRuleContext<'input,DcPropertiesContextExt<'input>>;

#[derive(Clone)]
pub struct DcPropertiesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DcPropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DcPropertiesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dcProperties(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dcProperties(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DcPropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dcProperties }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dcProperties }
}
crate::tid!{DcPropertiesContextExt<'a>}

impl<'input> DcPropertiesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DcPropertiesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DcPropertiesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DcPropertiesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DcPropertiesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn dbPropertiesList(&self) -> Option<Rc<DbPropertiesListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> DcPropertiesContextAttrs<'input> for DcPropertiesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dcProperties(&mut self,)
	-> Result<Rc<DcPropertiesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DcPropertiesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 602, RULE_dcProperties);
        let mut _localctx: Rc<DcPropertiesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3766);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule dbPropertiesList*/
			recog.base.set_state(3767);
			recog.dbPropertiesList()?;

			recog.base.set_state(3768);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropDataConnectorStatement ----------------
pub type DropDataConnectorStatementContextAll<'input> = DropDataConnectorStatementContext<'input>;


pub type DropDataConnectorStatementContext<'input> = BaseParserRuleContext<'input,DropDataConnectorStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropDataConnectorStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropDataConnectorStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropDataConnectorStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropDataConnectorStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropDataConnectorStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropDataConnectorStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropDataConnectorStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropDataConnectorStatement }
}
crate::tid!{DropDataConnectorStatementContextExt<'a>}

impl<'input> DropDataConnectorStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropDataConnectorStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropDataConnectorStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DropDataConnectorStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropDataConnectorStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATACONNECTOR
/// Returns `None` if there is no child corresponding to token KW_DATACONNECTOR
fn KW_DATACONNECTOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATACONNECTOR, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DropDataConnectorStatementContextAttrs<'input> for DropDataConnectorStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropDataConnectorStatement(&mut self,)
	-> Result<Rc<DropDataConnectorStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropDataConnectorStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 604, RULE_dropDataConnectorStatement);
        let mut _localctx: Rc<DropDataConnectorStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3770);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(3771);
			recog.base.match_token(KW_DATACONNECTOR,&mut recog.err_handler)?;

			recog.base.set_state(3773);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifExists*/
				recog.base.set_state(3772);
				recog.ifExists()?;

				}
			}

			/*InvokeRule id_*/
			recog.base.set_state(3775);
			recog.id_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableAllColumns ----------------
pub type TableAllColumnsContextAll<'input> = TableAllColumnsContext<'input>;


pub type TableAllColumnsContext<'input> = BaseParserRuleContext<'input,TableAllColumnsContextExt<'input>>;

#[derive(Clone)]
pub struct TableAllColumnsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableAllColumnsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableAllColumnsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableAllColumns(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableAllColumns(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableAllColumnsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableAllColumns }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableAllColumns }
}
crate::tid!{TableAllColumnsContextExt<'a>}

impl<'input> TableAllColumnsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableAllColumnsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableAllColumnsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableAllColumnsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableAllColumnsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token STAR
/// Returns `None` if there is no child corresponding to token STAR
fn STAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(STAR, 0)
}
fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}

}

impl<'input> TableAllColumnsContextAttrs<'input> for TableAllColumnsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableAllColumns(&mut self,)
	-> Result<Rc<TableAllColumnsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableAllColumnsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 606, RULE_tableAllColumns);
        let mut _localctx: Rc<TableAllColumnsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3782);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 STAR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3777);
					recog.base.match_token(STAR,&mut recog.err_handler)?;

					}
				}

			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT | KW_BATCH |
			 KW_BEFORE | KW_BUCKET | KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CBO |
			 KW_CHANGE | KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS |
			 KW_COLLECTION | KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS |
			 KW_COMPUTE | KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_DATA |
			 KW_DATABASES | KW_DATETIME | KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES |
			 KW_DCPROPERTIES | KW_DEBUG | KW_DEFAULT | KW_DEFERRED | KW_DEFINED |
			 KW_DELIMITED | KW_DEPENDENCY | KW_DESC | KW_DETAIL | KW_DIRECTORIES |
			 KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE | KW_DISTRIBUTED | KW_DO |
			 KW_DUMP | KW_ELEM_TYPE | KW_ENABLE | KW_ENFORCED | KW_ESCAPED | KW_EVERY |
			 KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED | KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN |
			 KW_EXPORT | KW_EXPRESSION | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST |
			 KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_HOLD_DDLTIME | KW_HOUR |
			 KW_IDXPROPERTIES | KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER |
			 KW_INPUTFORMAT | KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY |
			 KW_KEYS | KW_KEY_TYPE | KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES |
			 KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED |
			 KW_MANAGEDLOCATION | KW_MANAGEMENT | KW_MAPJOIN | KW_MAPPING | KW_MATCHED |
			 KW_MATERIALIZED | KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK |
			 KW_NORELY | KW_NOSCAN | KW_NOVALIDATE | KW_NO_DROP | KW_NULLS | KW_OFFLINE |
			 KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT |
			 KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH |
			 KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION |
			 KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY |
			 KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD | KW_RELY |
			 KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL | KW_REPLACE |
			 KW_REPLICATION | KW_RESOURCE | KW_RESPECT | KW_RESTRICT | KW_REWRITE |
			 KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY | KW_SCHEMA |
			 KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER |
			 KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW | KW_SHOW_DATABASE |
			 KW_SKEWED | KW_SNAPSHOT | KW_SORT | KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS |
			 KW_STATUS | KW_STORED | KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY |
			 KW_SYSTEM_TIME | KW_SYSTEM_VERSION | KW_TABLES | KW_TBLPROPERTIES | KW_TEMPORARY |
			 KW_TERMINATED | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH | KW_TRANSACTION |
			 KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TYPE | KW_UNARCHIVE |
			 KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK | KW_UNMANAGED | KW_UNSET |
			 KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC | KW_UTCTIMESTAMP | KW_VALIDATE |
			 KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW | KW_VIEWS | KW_WAIT | KW_WEEK |
			 KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD | KW_WRITE | KW_YEAR | KW_ZONE |
			 Identifier 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule tableName*/
					recog.base.set_state(3778);
					recog.tableName()?;

					recog.base.set_state(3779);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					recog.base.set_state(3780);
					recog.base.match_token(STAR,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableOrColumn ----------------
pub type TableOrColumnContextAll<'input> = TableOrColumnContext<'input>;


pub type TableOrColumnContext<'input> = BaseParserRuleContext<'input,TableOrColumnContextExt<'input>>;

#[derive(Clone)]
pub struct TableOrColumnContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableOrColumnContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableOrColumnContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableOrColumn(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableOrColumn(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableOrColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableOrColumn }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableOrColumn }
}
crate::tid!{TableOrColumnContextExt<'a>}

impl<'input> TableOrColumnContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableOrColumnContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableOrColumnContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableOrColumnContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableOrColumnContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableOrColumnContextAttrs<'input> for TableOrColumnContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableOrColumn(&mut self,)
	-> Result<Rc<TableOrColumnContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableOrColumnContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 608, RULE_tableOrColumn);
        let mut _localctx: Rc<TableOrColumnContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(3784);
			recog.id_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- defaultValue ----------------
pub type DefaultValueContextAll<'input> = DefaultValueContext<'input>;


pub type DefaultValueContext<'input> = BaseParserRuleContext<'input,DefaultValueContextExt<'input>>;

#[derive(Clone)]
pub struct DefaultValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DefaultValueContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DefaultValueContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_defaultValue(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_defaultValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DefaultValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_defaultValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_defaultValue }
}
crate::tid!{DefaultValueContextExt<'a>}

impl<'input> DefaultValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DefaultValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DefaultValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DefaultValueContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DefaultValueContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DEFAULT
/// Returns `None` if there is no child corresponding to token KW_DEFAULT
fn KW_DEFAULT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEFAULT, 0)
}

}

impl<'input> DefaultValueContextAttrs<'input> for DefaultValueContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn defaultValue(&mut self,)
	-> Result<Rc<DefaultValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DefaultValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 610, RULE_defaultValue);
        let mut _localctx: Rc<DefaultValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3786);
			recog.base.match_token(KW_DEFAULT,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expressionList ----------------
pub type ExpressionListContextAll<'input> = ExpressionListContext<'input>;


pub type ExpressionListContext<'input> = BaseParserRuleContext<'input,ExpressionListContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExpressionListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExpressionListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expressionList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_expressionList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExpressionListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionList }
}
crate::tid!{ExpressionListContextExt<'a>}

impl<'input> ExpressionListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExpressionListContextExt<'input>>{

fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ExpressionListContextAttrs<'input> for ExpressionListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expressionList(&mut self,)
	-> Result<Rc<ExpressionListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 612, RULE_expressionList);
        let mut _localctx: Rc<ExpressionListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(3788);
			recog.expression()?;

			recog.base.set_state(3793);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3789);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(3790);
				recog.expression()?;

				}
				}
				recog.base.set_state(3795);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aliasList ----------------
pub type AliasListContextAll<'input> = AliasListContext<'input>;


pub type AliasListContext<'input> = BaseParserRuleContext<'input,AliasListContextExt<'input>>;

#[derive(Clone)]
pub struct AliasListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AliasListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AliasListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_aliasList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_aliasList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AliasListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasList }
}
crate::tid!{AliasListContextExt<'a>}

impl<'input> AliasListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AliasListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AliasListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AliasListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AliasListContextExt<'input>>{

fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> AliasListContextAttrs<'input> for AliasListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aliasList(&mut self,)
	-> Result<Rc<AliasListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AliasListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 614, RULE_aliasList);
        let mut _localctx: Rc<AliasListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(3796);
			recog.id_()?;

			recog.base.set_state(3801);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3797);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(3798);
				recog.id_()?;

				}
				}
				recog.base.set_state(3803);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fromClause ----------------
pub type FromClauseContextAll<'input> = FromClauseContext<'input>;


pub type FromClauseContext<'input> = BaseParserRuleContext<'input,FromClauseContextExt<'input>>;

#[derive(Clone)]
pub struct FromClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for FromClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for FromClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fromClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_fromClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for FromClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fromClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fromClause }
}
crate::tid!{FromClauseContextExt<'a>}

impl<'input> FromClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FromClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FromClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FromClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<FromClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}
fn fromSource(&self) -> Option<Rc<FromSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FromClauseContextAttrs<'input> for FromClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fromClause(&mut self,)
	-> Result<Rc<FromClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FromClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 616, RULE_fromClause);
        let mut _localctx: Rc<FromClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3804);
			recog.base.match_token(KW_FROM,&mut recog.err_handler)?;

			/*InvokeRule fromSource*/
			recog.base.set_state(3805);
			recog.fromSource()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fromSource ----------------
pub type FromSourceContextAll<'input> = FromSourceContext<'input>;


pub type FromSourceContext<'input> = BaseParserRuleContext<'input,FromSourceContextExt<'input>>;

#[derive(Clone)]
pub struct FromSourceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for FromSourceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for FromSourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fromSource(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_fromSource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for FromSourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fromSource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fromSource }
}
crate::tid!{FromSourceContextExt<'a>}

impl<'input> FromSourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FromSourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FromSourceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FromSourceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<FromSourceContextExt<'input>>{

fn uniqueJoinToken(&self) -> Option<Rc<UniqueJoinTokenContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn uniqueJoinSource_all(&self) ->  Vec<Rc<UniqueJoinSourceContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn uniqueJoinSource(&self, i: usize) -> Option<Rc<UniqueJoinSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn joinSource(&self) -> Option<Rc<JoinSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FromSourceContextAttrs<'input> for FromSourceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fromSource(&mut self,)
	-> Result<Rc<FromSourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FromSourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 618, RULE_fromSource);
        let mut _localctx: Rc<FromSourceContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3816);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_UNIQUEJOIN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule uniqueJoinToken*/
					recog.base.set_state(3807);
					recog.uniqueJoinToken()?;

					/*InvokeRule uniqueJoinSource*/
					recog.base.set_state(3808);
					recog.uniqueJoinSource()?;

					recog.base.set_state(3811); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						recog.base.set_state(3809);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule uniqueJoinSource*/
						recog.base.set_state(3810);
						recog.uniqueJoinSource()?;

						}
						}
						recog.base.set_state(3813); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==COMMA) {break}
					}
					}
				}

			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT | KW_BATCH |
			 KW_BEFORE | KW_BUCKET | KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CBO |
			 KW_CHANGE | KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS |
			 KW_COLLECTION | KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS |
			 KW_COMPUTE | KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_DATA |
			 KW_DATABASES | KW_DATETIME | KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES |
			 KW_DCPROPERTIES | KW_DEBUG | KW_DEFAULT | KW_DEFERRED | KW_DEFINED |
			 KW_DELIMITED | KW_DEPENDENCY | KW_DESC | KW_DETAIL | KW_DIRECTORIES |
			 KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE | KW_DISTRIBUTED | KW_DO |
			 KW_DUMP | KW_ELEM_TYPE | KW_ENABLE | KW_ENFORCED | KW_ESCAPED | KW_EVERY |
			 KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED | KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN |
			 KW_EXPORT | KW_EXPRESSION | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST |
			 KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_HOLD_DDLTIME | KW_HOUR |
			 KW_IDXPROPERTIES | KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER |
			 KW_INPUTFORMAT | KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY |
			 KW_KEYS | KW_KEY_TYPE | KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES |
			 KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED |
			 KW_MANAGEDLOCATION | KW_MANAGEMENT | KW_MAPJOIN | KW_MAPPING | KW_MATCHED |
			 KW_MATERIALIZED | KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK |
			 KW_NORELY | KW_NOSCAN | KW_NOVALIDATE | KW_NO_DROP | KW_NULLS | KW_OFFLINE |
			 KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT |
			 KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH |
			 KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION |
			 KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY |
			 KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD | KW_RELY |
			 KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL | KW_REPLACE |
			 KW_REPLICATION | KW_RESOURCE | KW_RESPECT | KW_RESTRICT | KW_REWRITE |
			 KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY | KW_SCHEMA |
			 KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER |
			 KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW | KW_SHOW_DATABASE |
			 KW_SKEWED | KW_SNAPSHOT | KW_SORT | KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS |
			 KW_STATUS | KW_STORED | KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY |
			 KW_SYSTEM_TIME | KW_SYSTEM_VERSION | KW_TABLE | KW_TABLES | KW_TBLPROPERTIES |
			 KW_TEMPORARY | KW_TERMINATED | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH |
			 KW_TRANSACTION | KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TYPE |
			 KW_UNARCHIVE | KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK | KW_UNMANAGED |
			 KW_UNSET | KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC | KW_UTCTIMESTAMP |
			 KW_VALIDATE | KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW | KW_VIEWS |
			 KW_WAIT | KW_WEEK | KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD | KW_WRITE |
			 KW_YEAR | KW_ZONE | LPAREN | Identifier 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule joinSource*/
					recog.base.set_state(3815);
					recog.joinSource()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- atomjoinSource ----------------
pub type AtomjoinSourceContextAll<'input> = AtomjoinSourceContext<'input>;


pub type AtomjoinSourceContext<'input> = BaseParserRuleContext<'input,AtomjoinSourceContextExt<'input>>;

#[derive(Clone)]
pub struct AtomjoinSourceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AtomjoinSourceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AtomjoinSourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_atomjoinSource(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_atomjoinSource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AtomjoinSourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_atomjoinSource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_atomjoinSource }
}
crate::tid!{AtomjoinSourceContextExt<'a>}

impl<'input> AtomjoinSourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AtomjoinSourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AtomjoinSourceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AtomjoinSourceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AtomjoinSourceContextExt<'input>>{

fn tableSource(&self) -> Option<Rc<TableSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn lateralView_all(&self) ->  Vec<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn lateralView(&self, i: usize) -> Option<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn virtualTableSource(&self) -> Option<Rc<VirtualTableSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn subQuerySource(&self) -> Option<Rc<SubQuerySourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionedTableFunction(&self) -> Option<Rc<PartitionedTableFunctionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn joinSource(&self) -> Option<Rc<JoinSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> AtomjoinSourceContextAttrs<'input> for AtomjoinSourceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn atomjoinSource(&mut self,)
	-> Result<Rc<AtomjoinSourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AtomjoinSourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 620, RULE_atomjoinSource);
        let mut _localctx: Rc<AtomjoinSourceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(3850);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(440,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule tableSource*/
					recog.base.set_state(3818);
					recog.tableSource()?;

					recog.base.set_state(3822);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(436,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule lateralView*/
							recog.base.set_state(3819);
							recog.lateralView()?;

							}
							} 
						}
						recog.base.set_state(3824);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(436,&mut recog.base)?;
					}
					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule virtualTableSource*/
					recog.base.set_state(3825);
					recog.virtualTableSource()?;

					recog.base.set_state(3829);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(437,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule lateralView*/
							recog.base.set_state(3826);
							recog.lateralView()?;

							}
							} 
						}
						recog.base.set_state(3831);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(437,&mut recog.base)?;
					}
					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule subQuerySource*/
					recog.base.set_state(3832);
					recog.subQuerySource()?;

					recog.base.set_state(3836);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(438,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule lateralView*/
							recog.base.set_state(3833);
							recog.lateralView()?;

							}
							} 
						}
						recog.base.set_state(3838);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(438,&mut recog.base)?;
					}
					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule partitionedTableFunction*/
					recog.base.set_state(3839);
					recog.partitionedTableFunction()?;

					recog.base.set_state(3843);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(439,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule lateralView*/
							recog.base.set_state(3840);
							recog.lateralView()?;

							}
							} 
						}
						recog.base.set_state(3845);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(439,&mut recog.base)?;
					}
					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(3846);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule joinSource*/
					recog.base.set_state(3847);
					recog.joinSource()?;

					recog.base.set_state(3848);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinSource ----------------
pub type JoinSourceContextAll<'input> = JoinSourceContext<'input>;


pub type JoinSourceContext<'input> = BaseParserRuleContext<'input,JoinSourceContextExt<'input>>;

#[derive(Clone)]
pub struct JoinSourceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for JoinSourceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for JoinSourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinSource(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_joinSource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for JoinSourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinSource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinSource }
}
crate::tid!{JoinSourceContextExt<'a>}

impl<'input> JoinSourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinSourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinSourceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinSourceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<JoinSourceContextExt<'input>>{

fn atomjoinSource(&self) -> Option<Rc<AtomjoinSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn joinToken_all(&self) ->  Vec<Rc<JoinTokenContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn joinToken(&self, i: usize) -> Option<Rc<JoinTokenContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn joinSourcePart_all(&self) ->  Vec<Rc<JoinSourcePartContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn joinSourcePart(&self, i: usize) -> Option<Rc<JoinSourcePartContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_ON in current rule
fn KW_ON_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_ON, starting from 0.
/// Returns `None` if number of children corresponding to token KW_ON is less or equal than `i`.
fn KW_ON(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_USING in current rule
fn KW_USING_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_USING, starting from 0.
/// Returns `None` if number of children corresponding to token KW_USING is less or equal than `i`.
fn KW_USING(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USING, i)
}
fn columnParenthesesList_all(&self) ->  Vec<Rc<ColumnParenthesesListContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnParenthesesList(&self, i: usize) -> Option<Rc<ColumnParenthesesListContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> JoinSourceContextAttrs<'input> for JoinSourceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinSource(&mut self,)
	-> Result<Rc<JoinSourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinSourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 622, RULE_joinSource);
        let mut _localctx: Rc<JoinSourceContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule atomjoinSource*/
			recog.base.set_state(3852);
			recog.atomjoinSource()?;

			recog.base.set_state(3863);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==KW_CROSS || ((((_la - 134)) & !0x3f) == 0 && ((1usize << (_la - 134)) & ((1usize << (KW_FULL - 134)) | (1usize << (KW_INNER - 134)) | (1usize << (KW_JOIN - 134)))) != 0) || _la==KW_LEFT || _la==KW_RIGHT || _la==COMMA {
				{
				{
				/*InvokeRule joinToken*/
				recog.base.set_state(3853);
				recog.joinToken()?;

				/*InvokeRule joinSourcePart*/
				recog.base.set_state(3854);
				recog.joinSourcePart()?;

				recog.base.set_state(3859);
				recog.err_handler.sync(&mut recog.base)?;
				match recog.base.input.la(1) {
				 KW_ON 
					=> {
				    	{
				    	recog.base.set_state(3855);
				    	recog.base.match_token(KW_ON,&mut recog.err_handler)?;

				    	/*InvokeRule expression*/
				    	recog.base.set_state(3856);
				    	recog.expression()?;

				    	}
				    }

				 KW_USING 
					=> {
				    	{
				    	recog.base.set_state(3857);
				    	recog.base.match_token(KW_USING,&mut recog.err_handler)?;

				    	/*InvokeRule columnParenthesesList*/
				    	recog.base.set_state(3858);
				    	recog.columnParenthesesList()?;

				    	}
				    }

				 EOF | KW_ABORT | KW_ALTER | KW_ANALYZE | KW_CLUSTER | KW_COMMIT | KW_CREATE |
				 KW_CROSS | KW_DELETE | KW_DESC | KW_DESCRIBE | KW_DISABLE | KW_DISTRIBUTE |
				 KW_DROP | KW_ENABLE | KW_EXCEPT | KW_EXECUTE | KW_EXPLAIN | KW_EXPORT |
				 KW_FROM | KW_FULL | KW_GRANT | KW_GROUP | KW_HAVING | KW_IMPORT | KW_INNER |
				 KW_INSERT | KW_INTERSECT | KW_JOIN | KW_KILL | KW_LEFT | KW_LIMIT |
				 KW_LOAD | KW_LOCK | KW_MAP | KW_MERGE | KW_MINUS | KW_MSCK | KW_ORDER |
				 KW_PREPARE | KW_QUALIFY | KW_REDUCE | KW_RELOAD | KW_REPL | KW_REPLACE |
				 KW_REVOKE | KW_RIGHT | KW_ROLLBACK | KW_SELECT | KW_SET | KW_SHOW |
				 KW_SORT | KW_START | KW_TRUNCATE | KW_UNION | KW_UNLOCK | KW_UPDATE |
				 KW_USE | KW_VALUES | KW_WHERE | KW_WINDOW | KW_WITH | COMMA | SEMICOLON |
				 LPAREN | RPAREN 
					=> {
				    }

					_ => {}
				}
				}
				}
				recog.base.set_state(3865);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinSourcePart ----------------
pub type JoinSourcePartContextAll<'input> = JoinSourcePartContext<'input>;


pub type JoinSourcePartContext<'input> = BaseParserRuleContext<'input,JoinSourcePartContextExt<'input>>;

#[derive(Clone)]
pub struct JoinSourcePartContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for JoinSourcePartContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for JoinSourcePartContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinSourcePart(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_joinSourcePart(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for JoinSourcePartContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinSourcePart }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinSourcePart }
}
crate::tid!{JoinSourcePartContextExt<'a>}

impl<'input> JoinSourcePartContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinSourcePartContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinSourcePartContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinSourcePartContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<JoinSourcePartContextExt<'input>>{

fn tableSource(&self) -> Option<Rc<TableSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn virtualTableSource(&self) -> Option<Rc<VirtualTableSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn subQuerySource(&self) -> Option<Rc<SubQuerySourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionedTableFunction(&self) -> Option<Rc<PartitionedTableFunctionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn lateralView_all(&self) ->  Vec<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn lateralView(&self, i: usize) -> Option<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> JoinSourcePartContextAttrs<'input> for JoinSourcePartContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinSourcePart(&mut self,)
	-> Result<Rc<JoinSourcePartContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinSourcePartContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 624, RULE_joinSourcePart);
        let mut _localctx: Rc<JoinSourcePartContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3870);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(443,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule tableSource*/
					recog.base.set_state(3866);
					recog.tableSource()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule virtualTableSource*/
					recog.base.set_state(3867);
					recog.virtualTableSource()?;

					}
				}
			,
				3 =>{
					{
					/*InvokeRule subQuerySource*/
					recog.base.set_state(3868);
					recog.subQuerySource()?;

					}
				}
			,
				4 =>{
					{
					/*InvokeRule partitionedTableFunction*/
					recog.base.set_state(3869);
					recog.partitionedTableFunction()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(3875);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(444,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule lateralView*/
					recog.base.set_state(3872);
					recog.lateralView()?;

					}
					} 
				}
				recog.base.set_state(3877);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(444,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- uniqueJoinSource ----------------
pub type UniqueJoinSourceContextAll<'input> = UniqueJoinSourceContext<'input>;


pub type UniqueJoinSourceContext<'input> = BaseParserRuleContext<'input,UniqueJoinSourceContextExt<'input>>;

#[derive(Clone)]
pub struct UniqueJoinSourceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for UniqueJoinSourceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for UniqueJoinSourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_uniqueJoinSource(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_uniqueJoinSource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for UniqueJoinSourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_uniqueJoinSource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_uniqueJoinSource }
}
crate::tid!{UniqueJoinSourceContextExt<'a>}

impl<'input> UniqueJoinSourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UniqueJoinSourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UniqueJoinSourceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UniqueJoinSourceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<UniqueJoinSourceContextExt<'input>>{

fn uniqueJoinTableSource(&self) -> Option<Rc<UniqueJoinTableSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn uniqueJoinExpr(&self) -> Option<Rc<UniqueJoinExprContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_PRESERVE
/// Returns `None` if there is no child corresponding to token KW_PRESERVE
fn KW_PRESERVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PRESERVE, 0)
}

}

impl<'input> UniqueJoinSourceContextAttrs<'input> for UniqueJoinSourceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn uniqueJoinSource(&mut self,)
	-> Result<Rc<UniqueJoinSourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UniqueJoinSourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 626, RULE_uniqueJoinSource);
        let mut _localctx: Rc<UniqueJoinSourceContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3879);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PRESERVE {
				{
				recog.base.set_state(3878);
				recog.base.match_token(KW_PRESERVE,&mut recog.err_handler)?;

				}
			}

			/*InvokeRule uniqueJoinTableSource*/
			recog.base.set_state(3881);
			recog.uniqueJoinTableSource()?;

			/*InvokeRule uniqueJoinExpr*/
			recog.base.set_state(3882);
			recog.uniqueJoinExpr()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- uniqueJoinExpr ----------------
pub type UniqueJoinExprContextAll<'input> = UniqueJoinExprContext<'input>;


pub type UniqueJoinExprContext<'input> = BaseParserRuleContext<'input,UniqueJoinExprContextExt<'input>>;

#[derive(Clone)]
pub struct UniqueJoinExprContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for UniqueJoinExprContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for UniqueJoinExprContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_uniqueJoinExpr(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_uniqueJoinExpr(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for UniqueJoinExprContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_uniqueJoinExpr }
	//fn type_rule_index() -> usize where Self: Sized { RULE_uniqueJoinExpr }
}
crate::tid!{UniqueJoinExprContextExt<'a>}

impl<'input> UniqueJoinExprContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UniqueJoinExprContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UniqueJoinExprContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UniqueJoinExprContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<UniqueJoinExprContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn expressionList(&self) -> Option<Rc<ExpressionListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> UniqueJoinExprContextAttrs<'input> for UniqueJoinExprContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn uniqueJoinExpr(&mut self,)
	-> Result<Rc<UniqueJoinExprContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UniqueJoinExprContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 628, RULE_uniqueJoinExpr);
        let mut _localctx: Rc<UniqueJoinExprContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3884);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule expressionList*/
			recog.base.set_state(3885);
			recog.expressionList()?;

			recog.base.set_state(3886);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- uniqueJoinToken ----------------
pub type UniqueJoinTokenContextAll<'input> = UniqueJoinTokenContext<'input>;


pub type UniqueJoinTokenContext<'input> = BaseParserRuleContext<'input,UniqueJoinTokenContextExt<'input>>;

#[derive(Clone)]
pub struct UniqueJoinTokenContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for UniqueJoinTokenContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for UniqueJoinTokenContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_uniqueJoinToken(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_uniqueJoinToken(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for UniqueJoinTokenContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_uniqueJoinToken }
	//fn type_rule_index() -> usize where Self: Sized { RULE_uniqueJoinToken }
}
crate::tid!{UniqueJoinTokenContextExt<'a>}

impl<'input> UniqueJoinTokenContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UniqueJoinTokenContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UniqueJoinTokenContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UniqueJoinTokenContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<UniqueJoinTokenContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UNIQUEJOIN
/// Returns `None` if there is no child corresponding to token KW_UNIQUEJOIN
fn KW_UNIQUEJOIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNIQUEJOIN, 0)
}

}

impl<'input> UniqueJoinTokenContextAttrs<'input> for UniqueJoinTokenContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn uniqueJoinToken(&mut self,)
	-> Result<Rc<UniqueJoinTokenContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UniqueJoinTokenContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 630, RULE_uniqueJoinToken);
        let mut _localctx: Rc<UniqueJoinTokenContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3888);
			recog.base.match_token(KW_UNIQUEJOIN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinToken ----------------
pub type JoinTokenContextAll<'input> = JoinTokenContext<'input>;


pub type JoinTokenContext<'input> = BaseParserRuleContext<'input,JoinTokenContextExt<'input>>;

#[derive(Clone)]
pub struct JoinTokenContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for JoinTokenContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for JoinTokenContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinToken(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_joinToken(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for JoinTokenContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinToken }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinToken }
}
crate::tid!{JoinTokenContextExt<'a>}

impl<'input> JoinTokenContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinTokenContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinTokenContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinTokenContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<JoinTokenContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_JOIN
/// Returns `None` if there is no child corresponding to token KW_JOIN
fn KW_JOIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_JOIN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INNER
/// Returns `None` if there is no child corresponding to token KW_INNER
fn KW_INNER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INNER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CROSS
/// Returns `None` if there is no child corresponding to token KW_CROSS
fn KW_CROSS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CROSS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LEFT
/// Returns `None` if there is no child corresponding to token KW_LEFT
fn KW_LEFT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RIGHT
/// Returns `None` if there is no child corresponding to token KW_RIGHT
fn KW_RIGHT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FULL
/// Returns `None` if there is no child corresponding to token KW_FULL
fn KW_FULL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FULL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OUTER
/// Returns `None` if there is no child corresponding to token KW_OUTER
fn KW_OUTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OUTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SEMI
/// Returns `None` if there is no child corresponding to token KW_SEMI
fn KW_SEMI(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SEMI, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ANTI
/// Returns `None` if there is no child corresponding to token KW_ANTI
fn KW_ANTI(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ANTI, 0)
}

}

impl<'input> JoinTokenContextAttrs<'input> for JoinTokenContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinToken(&mut self,)
	-> Result<Rc<JoinTokenContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinTokenContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 632, RULE_joinToken);
        let mut _localctx: Rc<JoinTokenContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3904);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 COMMA 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3890);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					}
				}

			 KW_CROSS | KW_FULL | KW_INNER | KW_JOIN | KW_LEFT | KW_RIGHT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3901);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_INNER 
						=> {
					    	{
					    	recog.base.set_state(3891);
					    	recog.base.match_token(KW_INNER,&mut recog.err_handler)?;

					    	}
					    }

					 KW_CROSS 
						=> {
					    	{
					    	recog.base.set_state(3892);
					    	recog.base.match_token(KW_CROSS,&mut recog.err_handler)?;

					    	}
					    }

					 KW_FULL | KW_RIGHT 
						=> {
					    	{
					    	recog.base.set_state(3893);
					    	_la = recog.base.input.la(1);
					    	if { !(_la==KW_FULL || _la==KW_RIGHT) } {
					    		recog.err_handler.recover_inline(&mut recog.base)?;

					    	}
					    	else {
					    		if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					    		recog.err_handler.report_match(&mut recog.base);
					    		recog.base.consume(&mut recog.err_handler);
					    	}
					    	recog.base.set_state(3895);
					    	recog.err_handler.sync(&mut recog.base)?;
					    	_la = recog.base.input.la(1);
					    	if _la==KW_OUTER {
					    		{
					    		recog.base.set_state(3894);
					    		recog.base.match_token(KW_OUTER,&mut recog.err_handler)?;

					    		}
					    	}

					    	}
					    }

					 KW_LEFT 
						=> {
					    	{
					    	recog.base.set_state(3897);
					    	recog.base.match_token(KW_LEFT,&mut recog.err_handler)?;

					    	recog.base.set_state(3899);
					    	recog.err_handler.sync(&mut recog.base)?;
					    	_la = recog.base.input.la(1);
					    	if _la==KW_ANTI || _la==KW_OUTER || _la==KW_SEMI {
					    		{
					    		recog.base.set_state(3898);
					    		_la = recog.base.input.la(1);
					    		if { !(_la==KW_ANTI || _la==KW_OUTER || _la==KW_SEMI) } {
					    			recog.err_handler.recover_inline(&mut recog.base)?;

					    		}
					    		else {
					    			if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					    			recog.err_handler.report_match(&mut recog.base);
					    			recog.base.consume(&mut recog.err_handler);
					    		}
					    		}
					    	}

					    	}
					    }

					 KW_JOIN 
						=> {
					    }

						_ => {}
					}
					recog.base.set_state(3903);
					recog.base.match_token(KW_JOIN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- lateralView ----------------
pub type LateralViewContextAll<'input> = LateralViewContext<'input>;


pub type LateralViewContext<'input> = BaseParserRuleContext<'input,LateralViewContextExt<'input>>;

#[derive(Clone)]
pub struct LateralViewContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for LateralViewContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for LateralViewContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_lateralView(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_lateralView(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for LateralViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_lateralView }
	//fn type_rule_index() -> usize where Self: Sized { RULE_lateralView }
}
crate::tid!{LateralViewContextExt<'a>}

impl<'input> LateralViewContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LateralViewContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LateralViewContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LateralViewContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<LateralViewContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LATERAL
/// Returns `None` if there is no child corresponding to token KW_LATERAL
fn KW_LATERAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LATERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VIEW
/// Returns `None` if there is no child corresponding to token KW_VIEW
fn KW_VIEW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VIEW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OUTER
/// Returns `None` if there is no child corresponding to token KW_OUTER
fn KW_OUTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OUTER, 0)
}
fn function_(&self) -> Option<Rc<Function_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
fn valuesClause(&self) -> Option<Rc<ValuesClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}

}

impl<'input> LateralViewContextAttrs<'input> for LateralViewContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn lateralView(&mut self,)
	-> Result<Rc<LateralViewContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LateralViewContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 634, RULE_lateralView);
        let mut _localctx: Rc<LateralViewContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(3963);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(459,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3906);
					recog.base.match_token(KW_LATERAL,&mut recog.err_handler)?;

					recog.base.set_state(3907);
					recog.base.match_token(KW_VIEW,&mut recog.err_handler)?;

					recog.base.set_state(3908);
					recog.base.match_token(KW_OUTER,&mut recog.err_handler)?;

					/*InvokeRule function_*/
					recog.base.set_state(3909);
					recog.function_()?;

					/*InvokeRule tableAlias*/
					recog.base.set_state(3910);
					recog.tableAlias()?;

					recog.base.set_state(3920);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_AS {
						{
						recog.base.set_state(3911);
						recog.base.match_token(KW_AS,&mut recog.err_handler)?;

						/*InvokeRule id_*/
						recog.base.set_state(3912);
						recog.id_()?;

						recog.base.set_state(3917);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(450,&mut recog.base)?;
						while { _alt!=2 && _alt!=INVALID_ALT } {
							if _alt==1 {
								{
								{
								recog.base.set_state(3913);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule id_*/
								recog.base.set_state(3914);
								recog.id_()?;

								}
								} 
							}
							recog.base.set_state(3919);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(450,&mut recog.base)?;
						}
						}
					}

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3923);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA {
						{
						recog.base.set_state(3922);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3925);
					recog.base.match_token(KW_LATERAL,&mut recog.err_handler)?;

					recog.base.set_state(3961);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_VIEW 
						=> {
							{
							recog.base.set_state(3926);
							recog.base.match_token(KW_VIEW,&mut recog.err_handler)?;

							/*InvokeRule function_*/
							recog.base.set_state(3927);
							recog.function_()?;

							/*InvokeRule tableAlias*/
							recog.base.set_state(3928);
							recog.tableAlias()?;

							recog.base.set_state(3938);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_AS {
								{
								recog.base.set_state(3929);
								recog.base.match_token(KW_AS,&mut recog.err_handler)?;

								/*InvokeRule id_*/
								recog.base.set_state(3930);
								recog.id_()?;

								recog.base.set_state(3935);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(453,&mut recog.base)?;
								while { _alt!=2 && _alt!=INVALID_ALT } {
									if _alt==1 {
										{
										{
										recog.base.set_state(3931);
										recog.base.match_token(COMMA,&mut recog.err_handler)?;

										/*InvokeRule id_*/
										recog.base.set_state(3932);
										recog.id_()?;

										}
										} 
									}
									recog.base.set_state(3937);
									recog.err_handler.sync(&mut recog.base)?;
									_alt = recog.interpreter.adaptive_predict(453,&mut recog.base)?;
								}
								}
							}

							}
						}

					 KW_TABLE 
						=> {
							{
							recog.base.set_state(3940);
							recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

							recog.base.set_state(3941);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule valuesClause*/
							recog.base.set_state(3942);
							recog.valuesClause()?;

							recog.base.set_state(3943);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							recog.base.set_state(3945);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_AS {
								{
								recog.base.set_state(3944);
								recog.base.match_token(KW_AS,&mut recog.err_handler)?;

								}
							}

							/*InvokeRule tableAlias*/
							recog.base.set_state(3947);
							recog.tableAlias()?;

							recog.base.set_state(3959);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(457,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(3948);
									recog.base.match_token(LPAREN,&mut recog.err_handler)?;

									/*InvokeRule id_*/
									recog.base.set_state(3949);
									recog.id_()?;

									recog.base.set_state(3954);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
									while _la==COMMA {
										{
										{
										recog.base.set_state(3950);
										recog.base.match_token(COMMA,&mut recog.err_handler)?;

										/*InvokeRule id_*/
										recog.base.set_state(3951);
										recog.id_()?;

										}
										}
										recog.base.set_state(3956);
										recog.err_handler.sync(&mut recog.base)?;
										_la = recog.base.input.la(1);
									}
									recog.base.set_state(3957);
									recog.base.match_token(RPAREN,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableAlias ----------------
pub type TableAliasContextAll<'input> = TableAliasContext<'input>;


pub type TableAliasContext<'input> = BaseParserRuleContext<'input,TableAliasContextExt<'input>>;

#[derive(Clone)]
pub struct TableAliasContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableAliasContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableAlias(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableAlias }
}
crate::tid!{TableAliasContextExt<'a>}

impl<'input> TableAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableAliasContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableAliasContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableAliasContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableAliasContextAttrs<'input> for TableAliasContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableAlias(&mut self,)
	-> Result<Rc<TableAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 636, RULE_tableAlias);
        let mut _localctx: Rc<TableAliasContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(3965);
			recog.id_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableBucketSample ----------------
pub type TableBucketSampleContextAll<'input> = TableBucketSampleContext<'input>;


pub type TableBucketSampleContext<'input> = BaseParserRuleContext<'input,TableBucketSampleContextExt<'input>>;

#[derive(Clone)]
pub struct TableBucketSampleContextExt<'input>{
	pub numerator: Option<TokenType<'input>>,
	pub denominator: Option<TokenType<'input>>,
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub expr:Vec<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableBucketSampleContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableBucketSampleContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableBucketSample(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableBucketSample(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableBucketSampleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableBucketSample }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableBucketSample }
}
crate::tid!{TableBucketSampleContextExt<'a>}

impl<'input> TableBucketSampleContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableBucketSampleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableBucketSampleContextExt{
				numerator: None, denominator: None, 
				expression: None, 
				expr: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableBucketSampleContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableBucketSampleContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TABLESAMPLE
/// Returns `None` if there is no child corresponding to token KW_TABLESAMPLE
fn KW_TABLESAMPLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLESAMPLE, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BUCKET
/// Returns `None` if there is no child corresponding to token KW_BUCKET
fn KW_BUCKET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BUCKET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OUT
/// Returns `None` if there is no child corresponding to token KW_OUT
fn KW_OUT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OUT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OF
/// Returns `None` if there is no child corresponding to token KW_OF
fn KW_OF(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OF, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token Number in current rule
fn Number_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token Number, starting from 0.
/// Returns `None` if number of children corresponding to token Number is less or equal than `i`.
fn Number(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, i)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableBucketSampleContextAttrs<'input> for TableBucketSampleContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableBucketSample(&mut self,)
	-> Result<Rc<TableBucketSampleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableBucketSampleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 638, RULE_tableBucketSample);
        let mut _localctx: Rc<TableBucketSampleContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3967);
			recog.base.match_token(KW_TABLESAMPLE,&mut recog.err_handler)?;

			recog.base.set_state(3968);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(3969);
			recog.base.match_token(KW_BUCKET,&mut recog.err_handler)?;

			recog.base.set_state(3970);
			let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
			 cast_mut::<_,TableBucketSampleContext >(&mut _localctx).numerator = Some(tmp.clone());
			  

			recog.base.set_state(3971);
			recog.base.match_token(KW_OUT,&mut recog.err_handler)?;

			recog.base.set_state(3972);
			recog.base.match_token(KW_OF,&mut recog.err_handler)?;

			recog.base.set_state(3973);
			let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
			 cast_mut::<_,TableBucketSampleContext >(&mut _localctx).denominator = Some(tmp.clone());
			  

			recog.base.set_state(3983);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ON {
				{
				recog.base.set_state(3974);
				recog.base.match_token(KW_ON,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(3975);
				let tmp = recog.expression()?;
				 cast_mut::<_,TableBucketSampleContext >(&mut _localctx).expression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,TableBucketSampleContext >(&mut _localctx).expression.clone().unwrap()
				 ;
				 cast_mut::<_,TableBucketSampleContext >(&mut _localctx).expr.push(temp);
				  
				recog.base.set_state(3980);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(3976);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3977);
					let tmp = recog.expression()?;
					 cast_mut::<_,TableBucketSampleContext >(&mut _localctx).expression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,TableBucketSampleContext >(&mut _localctx).expression.clone().unwrap()
					 ;
					 cast_mut::<_,TableBucketSampleContext >(&mut _localctx).expr.push(temp);
					  
					}
					}
					recog.base.set_state(3982);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(3985);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- splitSample ----------------
pub type SplitSampleContextAll<'input> = SplitSampleContext<'input>;


pub type SplitSampleContext<'input> = BaseParserRuleContext<'input,SplitSampleContextExt<'input>>;

#[derive(Clone)]
pub struct SplitSampleContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SplitSampleContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SplitSampleContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_splitSample(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_splitSample(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SplitSampleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_splitSample }
	//fn type_rule_index() -> usize where Self: Sized { RULE_splitSample }
}
crate::tid!{SplitSampleContextExt<'a>}

impl<'input> SplitSampleContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SplitSampleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SplitSampleContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SplitSampleContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SplitSampleContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TABLESAMPLE
/// Returns `None` if there is no child corresponding to token KW_TABLESAMPLE
fn KW_TABLESAMPLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLESAMPLE, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}
/// Retrieves first TerminalNode corresponding to token ByteLengthLiteral
/// Returns `None` if there is no child corresponding to token ByteLengthLiteral
fn ByteLengthLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(ByteLengthLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PERCENT
/// Returns `None` if there is no child corresponding to token KW_PERCENT
fn KW_PERCENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PERCENT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROWS
/// Returns `None` if there is no child corresponding to token KW_ROWS
fn KW_ROWS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROWS, 0)
}

}

impl<'input> SplitSampleContextAttrs<'input> for SplitSampleContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn splitSample(&mut self,)
	-> Result<Rc<SplitSampleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SplitSampleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 640, RULE_splitSample);
        let mut _localctx: Rc<SplitSampleContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3987);
			recog.base.match_token(KW_TABLESAMPLE,&mut recog.err_handler)?;

			recog.base.set_state(3988);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(3992);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 Number 
				=> {
					{
					recog.base.set_state(3989);
					recog.base.match_token(Number,&mut recog.err_handler)?;

					recog.base.set_state(3990);
					_la = recog.base.input.la(1);
					if { !(_la==KW_PERCENT || _la==KW_ROWS) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

			 ByteLengthLiteral 
				=> {
					{
					recog.base.set_state(3991);
					recog.base.match_token(ByteLengthLiteral,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(3994);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableSample ----------------
pub type TableSampleContextAll<'input> = TableSampleContext<'input>;


pub type TableSampleContext<'input> = BaseParserRuleContext<'input,TableSampleContextExt<'input>>;

#[derive(Clone)]
pub struct TableSampleContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableSampleContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableSampleContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableSample(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableSample(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableSampleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableSample }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableSample }
}
crate::tid!{TableSampleContextExt<'a>}

impl<'input> TableSampleContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableSampleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableSampleContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableSampleContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableSampleContextExt<'input>>{

fn tableBucketSample(&self) -> Option<Rc<TableBucketSampleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn splitSample(&self) -> Option<Rc<SplitSampleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableSampleContextAttrs<'input> for TableSampleContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableSample(&mut self,)
	-> Result<Rc<TableSampleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableSampleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 642, RULE_tableSample);
        let mut _localctx: Rc<TableSampleContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3998);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(463,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule tableBucketSample*/
					recog.base.set_state(3996);
					recog.tableBucketSample()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule splitSample*/
					recog.base.set_state(3997);
					recog.splitSample()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableSource ----------------
pub type TableSourceContextAll<'input> = TableSourceContext<'input>;


pub type TableSourceContext<'input> = BaseParserRuleContext<'input,TableSourceContextExt<'input>>;

#[derive(Clone)]
pub struct TableSourceContextExt<'input>{
	pub tabname: Option<Rc<TableNameContextAll<'input>>>,
	pub props: Option<Rc<TablePropertiesContextAll<'input>>>,
	pub ts: Option<Rc<TableSampleContextAll<'input>>>,
	pub asOf: Option<Rc<AsOfClauseContextAll<'input>>>,
	pub alias: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableSourceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableSourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableSource(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableSource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableSourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableSource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableSource }
}
crate::tid!{TableSourceContextExt<'a>}

impl<'input> TableSourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableSourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableSourceContextExt{
				tabname: None, props: None, ts: None, asOf: None, alias: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableSourceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableSourceContextExt<'input>>{

fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableProperties(&self) -> Option<Rc<TablePropertiesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableSample(&self) -> Option<Rc<TableSampleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn asOfClause(&self) -> Option<Rc<AsOfClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}

}

impl<'input> TableSourceContextAttrs<'input> for TableSourceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableSource(&mut self,)
	-> Result<Rc<TableSourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableSourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 644, RULE_tableSource);
        let mut _localctx: Rc<TableSourceContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableName*/
			recog.base.set_state(4000);
			let tmp = recog.tableName()?;
			 cast_mut::<_,TableSourceContext >(&mut _localctx).tabname = Some(tmp.clone());
			  

			recog.base.set_state(4002);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(464,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule tableProperties*/
					recog.base.set_state(4001);
					let tmp = recog.tableProperties()?;
					 cast_mut::<_,TableSourceContext >(&mut _localctx).props = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			recog.base.set_state(4005);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_TABLESAMPLE {
				{
				/*InvokeRule tableSample*/
				recog.base.set_state(4004);
				let tmp = recog.tableSample()?;
				 cast_mut::<_,TableSourceContext >(&mut _localctx).ts = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(4008);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_FOR {
				{
				/*InvokeRule asOfClause*/
				recog.base.set_state(4007);
				let tmp = recog.asOfClause()?;
				 cast_mut::<_,TableSourceContext >(&mut _localctx).asOf = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(4014);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(468,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(4011);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_AS {
						{
						recog.base.set_state(4010);
						recog.base.match_token(KW_AS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule id_*/
					recog.base.set_state(4013);
					let tmp = recog.id_()?;
					 cast_mut::<_,TableSourceContext >(&mut _localctx).alias = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- asOfClause ----------------
pub type AsOfClauseContextAll<'input> = AsOfClauseContext<'input>;


pub type AsOfClauseContext<'input> = BaseParserRuleContext<'input,AsOfClauseContextExt<'input>>;

#[derive(Clone)]
pub struct AsOfClauseContextExt<'input>{
	pub asOfTime: Option<Rc<ExpressionContextAll<'input>>>,
	pub asOfVersion: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AsOfClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AsOfClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_asOfClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_asOfClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AsOfClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_asOfClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_asOfClause }
}
crate::tid!{AsOfClauseContextExt<'a>}

impl<'input> AsOfClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AsOfClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AsOfClauseContextExt{
				asOfVersion: None, 
				asOfTime: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AsOfClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AsOfClauseContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token KW_FOR in current rule
fn KW_FOR_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_FOR, starting from 0.
/// Returns `None` if number of children corresponding to token KW_FOR is less or equal than `i`.
fn KW_FOR(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FOR, i)
}
/// Retrieves first TerminalNode corresponding to token KW_SYSTEM_TIME
/// Returns `None` if there is no child corresponding to token KW_SYSTEM_TIME
fn KW_SYSTEM_TIME(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SYSTEM_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OF
/// Returns `None` if there is no child corresponding to token KW_OF
fn KW_OF(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OF, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SYSTEM_VERSION
/// Returns `None` if there is no child corresponding to token KW_SYSTEM_VERSION
fn KW_SYSTEM_VERSION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SYSTEM_VERSION, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}

}

impl<'input> AsOfClauseContextAttrs<'input> for AsOfClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn asOfClause(&mut self,)
	-> Result<Rc<AsOfClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AsOfClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 646, RULE_asOfClause);
        let mut _localctx: Rc<AsOfClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4016);
			recog.base.match_token(KW_FOR,&mut recog.err_handler)?;

			recog.base.set_state(4026);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_SYSTEM_TIME 
				=> {
					{
					recog.base.set_state(4017);
					recog.base.match_token(KW_SYSTEM_TIME,&mut recog.err_handler)?;

					recog.base.set_state(4018);
					recog.base.match_token(KW_AS,&mut recog.err_handler)?;

					recog.base.set_state(4019);
					recog.base.match_token(KW_OF,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(4020);
					let tmp = recog.expression()?;
					 cast_mut::<_,AsOfClauseContext >(&mut _localctx).asOfTime = Some(tmp.clone());
					  

					}
				}

			 KW_FOR 
				=> {
					{
					recog.base.set_state(4021);
					recog.base.match_token(KW_FOR,&mut recog.err_handler)?;

					recog.base.set_state(4022);
					recog.base.match_token(KW_SYSTEM_VERSION,&mut recog.err_handler)?;

					recog.base.set_state(4023);
					recog.base.match_token(KW_AS,&mut recog.err_handler)?;

					recog.base.set_state(4024);
					recog.base.match_token(KW_OF,&mut recog.err_handler)?;

					recog.base.set_state(4025);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,AsOfClauseContext >(&mut _localctx).asOfVersion = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- uniqueJoinTableSource ----------------
pub type UniqueJoinTableSourceContextAll<'input> = UniqueJoinTableSourceContext<'input>;


pub type UniqueJoinTableSourceContext<'input> = BaseParserRuleContext<'input,UniqueJoinTableSourceContextExt<'input>>;

#[derive(Clone)]
pub struct UniqueJoinTableSourceContextExt<'input>{
	pub tabname: Option<Rc<TableNameContextAll<'input>>>,
	pub ts: Option<Rc<TableSampleContextAll<'input>>>,
	pub alias: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for UniqueJoinTableSourceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for UniqueJoinTableSourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_uniqueJoinTableSource(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_uniqueJoinTableSource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for UniqueJoinTableSourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_uniqueJoinTableSource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_uniqueJoinTableSource }
}
crate::tid!{UniqueJoinTableSourceContextExt<'a>}

impl<'input> UniqueJoinTableSourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UniqueJoinTableSourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UniqueJoinTableSourceContextExt{
				tabname: None, ts: None, alias: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait UniqueJoinTableSourceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<UniqueJoinTableSourceContextExt<'input>>{

fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableSample(&self) -> Option<Rc<TableSampleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}

}

impl<'input> UniqueJoinTableSourceContextAttrs<'input> for UniqueJoinTableSourceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn uniqueJoinTableSource(&mut self,)
	-> Result<Rc<UniqueJoinTableSourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UniqueJoinTableSourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 648, RULE_uniqueJoinTableSource);
        let mut _localctx: Rc<UniqueJoinTableSourceContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableName*/
			recog.base.set_state(4028);
			let tmp = recog.tableName()?;
			 cast_mut::<_,UniqueJoinTableSourceContext >(&mut _localctx).tabname = Some(tmp.clone());
			  

			recog.base.set_state(4030);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_TABLESAMPLE {
				{
				/*InvokeRule tableSample*/
				recog.base.set_state(4029);
				let tmp = recog.tableSample()?;
				 cast_mut::<_,UniqueJoinTableSourceContext >(&mut _localctx).ts = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(4036);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << KW_ABORT) | (1usize << KW_ACTIVATE) | (1usize << KW_ACTIVE) | (1usize << KW_ADD) | (1usize << KW_ADMIN) | (1usize << KW_AFTER) | (1usize << KW_ALLOC_FRACTION) | (1usize << KW_ANALYZE) | (1usize << KW_ARCHIVE) | (1usize << KW_AS) | (1usize << KW_ASC) | (1usize << KW_AST) | (1usize << KW_AT) | (1usize << KW_AUTOCOMMIT) | (1usize << KW_BATCH) | (1usize << KW_BEFORE) | (1usize << KW_BUCKET) | (1usize << KW_BUCKETS))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (KW_CACHE - 33)) | (1usize << (KW_CASCADE - 33)) | (1usize << (KW_CBO - 33)) | (1usize << (KW_CHANGE - 33)) | (1usize << (KW_CHECK - 33)) | (1usize << (KW_CLUSTER - 33)) | (1usize << (KW_CLUSTERED - 33)) | (1usize << (KW_CLUSTERSTATUS - 33)) | (1usize << (KW_COLLECTION - 33)) | (1usize << (KW_COLUMNS - 33)) | (1usize << (KW_COMMENT - 33)) | (1usize << (KW_COMPACT - 33)) | (1usize << (KW_COMPACTIONS - 33)) | (1usize << (KW_COMPUTE - 33)) | (1usize << (KW_CONCATENATE - 33)) | (1usize << (KW_CONTINUE - 33)) | (1usize << (KW_COST - 33)) | (1usize << (KW_CRON - 33)))) != 0) || ((((_la - 66)) & !0x3f) == 0 && ((1usize << (_la - 66)) & ((1usize << (KW_DATA - 66)) | (1usize << (KW_DATABASES - 66)) | (1usize << (KW_DATETIME - 66)) | (1usize << (KW_DAY - 66)) | (1usize << (KW_DAYOFWEEK - 66)) | (1usize << (KW_DBPROPERTIES - 66)) | (1usize << (KW_DCPROPERTIES - 66)) | (1usize << (KW_DEBUG - 66)) | (1usize << (KW_DEFAULT - 66)) | (1usize << (KW_DEFERRED - 66)) | (1usize << (KW_DEFINED - 66)) | (1usize << (KW_DELIMITED - 66)) | (1usize << (KW_DEPENDENCY - 66)) | (1usize << (KW_DESC - 66)) | (1usize << (KW_DETAIL - 66)) | (1usize << (KW_DIRECTORIES - 66)) | (1usize << (KW_DIRECTORY - 66)) | (1usize << (KW_DISABLE - 66)) | (1usize << (KW_DISTRIBUTE - 66)) | (1usize << (KW_DISTRIBUTED - 66)) | (1usize << (KW_DO - 66)))) != 0) || ((((_la - 98)) & !0x3f) == 0 && ((1usize << (_la - 98)) & ((1usize << (KW_DUMP - 98)) | (1usize << (KW_ELEM_TYPE - 98)) | (1usize << (KW_ENABLE - 98)) | (1usize << (KW_ENFORCED - 98)) | (1usize << (KW_ESCAPED - 98)) | (1usize << (KW_EVERY - 98)) | (1usize << (KW_EXCLUSIVE - 98)) | (1usize << (KW_EXECUTE - 98)) | (1usize << (KW_EXECUTED - 98)) | (1usize << (KW_EXPIRE_SNAPSHOTS - 98)) | (1usize << (KW_EXPLAIN - 98)) | (1usize << (KW_EXPORT - 98)) | (1usize << (KW_EXPRESSION - 98)) | (1usize << (KW_FIELDS - 98)) | (1usize << (KW_FILE - 98)) | (1usize << (KW_FILEFORMAT - 98)) | (1usize << (KW_FIRST - 98)))) != 0) || ((((_la - 131)) & !0x3f) == 0 && ((1usize << (_la - 131)) & ((1usize << (KW_FORMAT - 131)) | (1usize << (KW_FORMATTED - 131)) | (1usize << (KW_FUNCTIONS - 131)) | (1usize << (KW_HOLD_DDLTIME - 131)) | (1usize << (KW_HOUR - 131)) | (1usize << (KW_IDXPROPERTIES - 131)) | (1usize << (KW_IGNORE - 131)) | (1usize << (KW_INDEX - 131)) | (1usize << (KW_INDEXES - 131)) | (1usize << (KW_INPATH - 131)) | (1usize << (KW_INPUTDRIVER - 131)) | (1usize << (KW_INPUTFORMAT - 131)) | (1usize << (KW_ISOLATION - 131)) | (1usize << (KW_ITEMS - 131)) | (1usize << (KW_JAR - 131)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (KW_JOINCOST - 164)) | (1usize << (KW_KEY - 164)) | (1usize << (KW_KEYS - 164)) | (1usize << (KW_KEY_TYPE - 164)) | (1usize << (KW_KILL - 164)) | (1usize << (KW_LAST - 164)) | (1usize << (KW_LEVEL - 164)) | (1usize << (KW_LIMIT - 164)) | (1usize << (KW_LINES - 164)) | (1usize << (KW_LOAD - 164)) | (1usize << (KW_LOCATION - 164)) | (1usize << (KW_LOCK - 164)) | (1usize << (KW_LOCKS - 164)) | (1usize << (KW_LOGICAL - 164)) | (1usize << (KW_LONG - 164)) | (1usize << (KW_MANAGED - 164)) | (1usize << (KW_MANAGEDLOCATION - 164)) | (1usize << (KW_MANAGEMENT - 164)) | (1usize << (KW_MAPJOIN - 164)) | (1usize << (KW_MAPPING - 164)) | (1usize << (KW_MATCHED - 164)) | (1usize << (KW_MATERIALIZED - 164)) | (1usize << (KW_METADATA - 164)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (KW_MINUTE - 197)) | (1usize << (KW_MONTH - 197)) | (1usize << (KW_MOVE - 197)) | (1usize << (KW_MSCK - 197)) | (1usize << (KW_NORELY - 197)) | (1usize << (KW_NOSCAN - 197)) | (1usize << (KW_NOVALIDATE - 197)) | (1usize << (KW_NO_DROP - 197)) | (1usize << (KW_NULLS - 197)) | (1usize << (KW_OFFLINE - 197)) | (1usize << (KW_OFFSET - 197)) | (1usize << (KW_OPERATOR - 197)) | (1usize << (KW_OPTION - 197)) | (1usize << (KW_OUTPUTDRIVER - 197)) | (1usize << (KW_OUTPUTFORMAT - 197)) | (1usize << (KW_OVERWRITE - 197)) | (1usize << (KW_OWNER - 197)) | (1usize << (KW_PARTITIONED - 197)) | (1usize << (KW_PARTITIONS - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (KW_PATH - 229)) | (1usize << (KW_PLAN - 229)) | (1usize << (KW_PLANS - 229)) | (1usize << (KW_PLUS - 229)) | (1usize << (KW_POOL - 229)) | (1usize << (KW_PRINCIPALS - 229)) | (1usize << (KW_PROTECTION - 229)) | (1usize << (KW_PURGE - 229)) | (1usize << (KW_QUARTER - 229)) | (1usize << (KW_QUERY - 229)) | (1usize << (KW_QUERY_PARALLELISM - 229)) | (1usize << (KW_READ - 229)) | (1usize << (KW_READONLY - 229)) | (1usize << (KW_REBUILD - 229)) | (1usize << (KW_RECORDREADER - 229)) | (1usize << (KW_RECORDWRITER - 229)) | (1usize << (KW_RELOAD - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (KW_RELY - 261)) | (1usize << (KW_REMOTE - 261)) | (1usize << (KW_RENAME - 261)) | (1usize << (KW_REOPTIMIZATION - 261)) | (1usize << (KW_REPAIR - 261)) | (1usize << (KW_REPL - 261)) | (1usize << (KW_REPLACE - 261)) | (1usize << (KW_REPLICATION - 261)) | (1usize << (KW_RESOURCE - 261)) | (1usize << (KW_RESPECT - 261)) | (1usize << (KW_RESTRICT - 261)) | (1usize << (KW_REWRITE - 261)) | (1usize << (KW_ROLE - 261)) | (1usize << (KW_ROLES - 261)) | (1usize << (KW_SCHEDULED - 261)) | (1usize << (KW_SCHEDULING_POLICY - 261)) | (1usize << (KW_SCHEMA - 261)) | (1usize << (KW_SCHEMAS - 261)) | (1usize << (KW_SECOND - 261)) | (1usize << (KW_SEMI - 261)) | (1usize << (KW_SERDE - 261)) | (1usize << (KW_SERDEPROPERTIES - 261)) | (1usize << (KW_SERVER - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (KW_SETS - 293)) | (1usize << (KW_SET_CURRENT_SNAPSHOT - 293)) | (1usize << (KW_SHARED - 293)) | (1usize << (KW_SHOW - 293)) | (1usize << (KW_SHOW_DATABASE - 293)) | (1usize << (KW_SKEWED - 293)) | (1usize << (KW_SNAPSHOT - 293)) | (1usize << (KW_SORT - 293)) | (1usize << (KW_SORTED - 293)) | (1usize << (KW_SPEC - 293)) | (1usize << (KW_SSL - 293)) | (1usize << (KW_STATISTICS - 293)) | (1usize << (KW_STATUS - 293)) | (1usize << (KW_STORED - 293)) | (1usize << (KW_STREAMTABLE - 293)) | (1usize << (KW_STRING - 293)) | (1usize << (KW_STRUCT - 293)) | (1usize << (KW_SUMMARY - 293)) | (1usize << (KW_SYSTEM_TIME - 293)) | (1usize << (KW_SYSTEM_VERSION - 293)) | (1usize << (KW_TABLES - 293)) | (1usize << (KW_TBLPROPERTIES - 293)) | (1usize << (KW_TEMPORARY - 293)) | (1usize << (KW_TERMINATED - 293)))) != 0) || ((((_la - 327)) & !0x3f) == 0 && ((1usize << (_la - 327)) & ((1usize << (KW_TIMESTAMPTZ - 327)) | (1usize << (KW_TINYINT - 327)) | (1usize << (KW_TOUCH - 327)) | (1usize << (KW_TRANSACTION - 327)) | (1usize << (KW_TRANSACTIONAL - 327)) | (1usize << (KW_TRANSACTIONS - 327)) | (1usize << (KW_TRIM - 327)) | (1usize << (KW_TYPE - 327)) | (1usize << (KW_UNARCHIVE - 327)) | (1usize << (KW_UNDO - 327)) | (1usize << (KW_UNIONTYPE - 327)) | (1usize << (KW_UNKNOWN - 327)) | (1usize << (KW_UNLOCK - 327)) | (1usize << (KW_UNMANAGED - 327)) | (1usize << (KW_UNSET - 327)) | (1usize << (KW_UNSIGNED - 327)) | (1usize << (KW_URI - 327)) | (1usize << (KW_URL - 327)) | (1usize << (KW_USE - 327)))) != 0) || ((((_la - 359)) & !0x3f) == 0 && ((1usize << (_la - 359)) & ((1usize << (KW_UTC - 359)) | (1usize << (KW_UTCTIMESTAMP - 359)) | (1usize << (KW_VALIDATE - 359)) | (1usize << (KW_VALUE_TYPE - 359)) | (1usize << (KW_VECTORIZATION - 359)) | (1usize << (KW_VIEW - 359)) | (1usize << (KW_VIEWS - 359)) | (1usize << (KW_WAIT - 359)) | (1usize << (KW_WEEK - 359)) | (1usize << (KW_WHILE - 359)) | (1usize << (KW_WITHIN - 359)) | (1usize << (KW_WORK - 359)) | (1usize << (KW_WORKLOAD - 359)) | (1usize << (KW_WRITE - 359)) | (1usize << (KW_YEAR - 359)) | (1usize << (KW_ZONE - 359)))) != 0) || _la==Identifier {
				{
				recog.base.set_state(4033);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==KW_AS {
					{
					recog.base.set_state(4032);
					recog.base.match_token(KW_AS,&mut recog.err_handler)?;

					}
				}

				/*InvokeRule id_*/
				recog.base.set_state(4035);
				let tmp = recog.id_()?;
				 cast_mut::<_,UniqueJoinTableSourceContext >(&mut _localctx).alias = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableName ----------------
pub type TableNameContextAll<'input> = TableNameContext<'input>;


pub type TableNameContext<'input> = BaseParserRuleContext<'input,TableNameContextExt<'input>>;

#[derive(Clone)]
pub struct TableNameContextExt<'input>{
	pub db: Option<Rc<Id_ContextAll<'input>>>,
	pub tab: Option<Rc<Id_ContextAll<'input>>>,
	pub meta: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableName }
}
crate::tid!{TableNameContextExt<'a>}

impl<'input> TableNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableNameContextExt{
				db: None, tab: None, meta: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableNameContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, i)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> TableNameContextAttrs<'input> for TableNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableName(&mut self,)
	-> Result<Rc<TableNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 650, RULE_tableName);
        let mut _localctx: Rc<TableNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4046);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(474,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule id_*/
					recog.base.set_state(4038);
					let tmp = recog.id_()?;
					 cast_mut::<_,TableNameContext >(&mut _localctx).db = Some(tmp.clone());
					  

					recog.base.set_state(4039);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(4040);
					let tmp = recog.id_()?;
					 cast_mut::<_,TableNameContext >(&mut _localctx).tab = Some(tmp.clone());
					  

					recog.base.set_state(4043);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(473,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4041);
							recog.base.match_token(DOT,&mut recog.err_handler)?;

							/*InvokeRule id_*/
							recog.base.set_state(4042);
							let tmp = recog.id_()?;
							 cast_mut::<_,TableNameContext >(&mut _localctx).meta = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule id_*/
					recog.base.set_state(4045);
					let tmp = recog.id_()?;
					 cast_mut::<_,TableNameContext >(&mut _localctx).tab = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- viewName ----------------
pub type ViewNameContextAll<'input> = ViewNameContext<'input>;


pub type ViewNameContext<'input> = BaseParserRuleContext<'input,ViewNameContextExt<'input>>;

#[derive(Clone)]
pub struct ViewNameContextExt<'input>{
	pub db: Option<Rc<Id_ContextAll<'input>>>,
	pub view: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ViewNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ViewNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_viewName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_viewName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ViewNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_viewName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_viewName }
}
crate::tid!{ViewNameContextExt<'a>}

impl<'input> ViewNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ViewNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ViewNameContextExt{
				db: None, view: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ViewNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ViewNameContextExt<'input>>{

fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}

}

impl<'input> ViewNameContextAttrs<'input> for ViewNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn viewName(&mut self,)
	-> Result<Rc<ViewNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ViewNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 652, RULE_viewName);
        let mut _localctx: Rc<ViewNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4051);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(475,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule id_*/
					recog.base.set_state(4048);
					let tmp = recog.id_()?;
					 cast_mut::<_,ViewNameContext >(&mut _localctx).db = Some(tmp.clone());
					  

					recog.base.set_state(4049);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule id_*/
			recog.base.set_state(4053);
			let tmp = recog.id_()?;
			 cast_mut::<_,ViewNameContext >(&mut _localctx).view = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- subQuerySource ----------------
pub type SubQuerySourceContextAll<'input> = SubQuerySourceContext<'input>;


pub type SubQuerySourceContext<'input> = BaseParserRuleContext<'input,SubQuerySourceContextExt<'input>>;

#[derive(Clone)]
pub struct SubQuerySourceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SubQuerySourceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SubQuerySourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_subQuerySource(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_subQuerySource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SubQuerySourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_subQuerySource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_subQuerySource }
}
crate::tid!{SubQuerySourceContextExt<'a>}

impl<'input> SubQuerySourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SubQuerySourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SubQuerySourceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SubQuerySourceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SubQuerySourceContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn queryStatementExpression(&self) -> Option<Rc<QueryStatementExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}

}

impl<'input> SubQuerySourceContextAttrs<'input> for SubQuerySourceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn subQuerySource(&mut self,)
	-> Result<Rc<SubQuerySourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SubQuerySourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 654, RULE_subQuerySource);
        let mut _localctx: Rc<SubQuerySourceContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4055);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule queryStatementExpression*/
			recog.base.set_state(4056);
			recog.queryStatementExpression()?;

			recog.base.set_state(4057);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(4059);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_AS {
				{
				recog.base.set_state(4058);
				recog.base.match_token(KW_AS,&mut recog.err_handler)?;

				}
			}

			/*InvokeRule id_*/
			recog.base.set_state(4061);
			recog.id_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitioningSpec ----------------
pub type PartitioningSpecContextAll<'input> = PartitioningSpecContext<'input>;


pub type PartitioningSpecContext<'input> = BaseParserRuleContext<'input,PartitioningSpecContextExt<'input>>;

#[derive(Clone)]
pub struct PartitioningSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitioningSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitioningSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitioningSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitioningSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitioningSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitioningSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitioningSpec }
}
crate::tid!{PartitioningSpecContextExt<'a>}

impl<'input> PartitioningSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitioningSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitioningSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitioningSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitioningSpecContextExt<'input>>{

fn partitionByClause(&self) -> Option<Rc<PartitionByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orderByClause(&self) -> Option<Rc<OrderByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn distributeByClause(&self) -> Option<Rc<DistributeByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sortByClause(&self) -> Option<Rc<SortByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn clusterByClause(&self) -> Option<Rc<ClusterByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitioningSpecContextAttrs<'input> for PartitioningSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitioningSpec(&mut self,)
	-> Result<Rc<PartitioningSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitioningSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 656, RULE_partitioningSpec);
        let mut _localctx: Rc<PartitioningSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4074);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_PARTITION 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule partitionByClause*/
					recog.base.set_state(4063);
					recog.partitionByClause()?;

					recog.base.set_state(4065);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_ORDER {
						{
						/*InvokeRule orderByClause*/
						recog.base.set_state(4064);
						recog.orderByClause()?;

						}
					}

					}
				}

			 KW_ORDER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule orderByClause*/
					recog.base.set_state(4067);
					recog.orderByClause()?;

					}
				}

			 KW_DISTRIBUTE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule distributeByClause*/
					recog.base.set_state(4068);
					recog.distributeByClause()?;

					recog.base.set_state(4070);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_SORT {
						{
						/*InvokeRule sortByClause*/
						recog.base.set_state(4069);
						recog.sortByClause()?;

						}
					}

					}
				}

			 KW_SORT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule sortByClause*/
					recog.base.set_state(4072);
					recog.sortByClause()?;

					}
				}

			 KW_CLUSTER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule clusterByClause*/
					recog.base.set_state(4073);
					recog.clusterByClause()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionTableFunctionSource ----------------
pub type PartitionTableFunctionSourceContextAll<'input> = PartitionTableFunctionSourceContext<'input>;


pub type PartitionTableFunctionSourceContext<'input> = BaseParserRuleContext<'input,PartitionTableFunctionSourceContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionTableFunctionSourceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitionTableFunctionSourceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitionTableFunctionSourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionTableFunctionSource(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitionTableFunctionSource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitionTableFunctionSourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionTableFunctionSource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionTableFunctionSource }
}
crate::tid!{PartitionTableFunctionSourceContextExt<'a>}

impl<'input> PartitionTableFunctionSourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionTableFunctionSourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionTableFunctionSourceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionTableFunctionSourceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitionTableFunctionSourceContextExt<'input>>{

fn subQuerySource(&self) -> Option<Rc<SubQuerySourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableSource(&self) -> Option<Rc<TableSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionedTableFunction(&self) -> Option<Rc<PartitionedTableFunctionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionTableFunctionSourceContextAttrs<'input> for PartitionTableFunctionSourceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionTableFunctionSource(&mut self,)
	-> Result<Rc<PartitionTableFunctionSourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionTableFunctionSourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 658, RULE_partitionTableFunctionSource);
        let mut _localctx: Rc<PartitionTableFunctionSourceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4079);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(480,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule subQuerySource*/
					recog.base.set_state(4076);
					recog.subQuerySource()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule tableSource*/
					recog.base.set_state(4077);
					recog.tableSource()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule partitionedTableFunction*/
					recog.base.set_state(4078);
					recog.partitionedTableFunction()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionedTableFunction ----------------
pub type PartitionedTableFunctionContextAll<'input> = PartitionedTableFunctionContext<'input>;


pub type PartitionedTableFunctionContext<'input> = BaseParserRuleContext<'input,PartitionedTableFunctionContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionedTableFunctionContextExt<'input>{
	pub n: Option<Rc<Id_ContextAll<'input>>>,
	pub ptfsrc: Option<Rc<PartitionTableFunctionSourceContextAll<'input>>>,
	pub spec: Option<Rc<PartitioningSpecContextAll<'input>>>,
	pub alias: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitionedTableFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitionedTableFunctionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionedTableFunction(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitionedTableFunction(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitionedTableFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionedTableFunction }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionedTableFunction }
}
crate::tid!{PartitionedTableFunctionContextExt<'a>}

impl<'input> PartitionedTableFunctionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionedTableFunctionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionedTableFunctionContextExt{
				n: None, ptfsrc: None, spec: None, alias: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionedTableFunctionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitionedTableFunctionContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
/// Retrieves first TerminalNode corresponding to token KW_ON
/// Returns `None` if there is no child corresponding to token KW_ON
fn KW_ON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ON, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn partitionTableFunctionSource(&self) -> Option<Rc<PartitionTableFunctionSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token Identifier in current rule
fn Identifier_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token Identifier, starting from 0.
/// Returns `None` if number of children corresponding to token Identifier is less or equal than `i`.
fn Identifier(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Identifier, i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn partitioningSpec(&self) -> Option<Rc<PartitioningSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PartitionedTableFunctionContextAttrs<'input> for PartitionedTableFunctionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionedTableFunction(&mut self,)
	-> Result<Rc<PartitionedTableFunctionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionedTableFunctionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 660, RULE_partitionedTableFunction);
        let mut _localctx: Rc<PartitionedTableFunctionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(4081);
			let tmp = recog.id_()?;
			 cast_mut::<_,PartitionedTableFunctionContext >(&mut _localctx).n = Some(tmp.clone());
			  

			recog.base.set_state(4082);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(4083);
			recog.base.match_token(KW_ON,&mut recog.err_handler)?;

			/*InvokeRule partitionTableFunctionSource*/
			recog.base.set_state(4084);
			let tmp = recog.partitionTableFunctionSource()?;
			 cast_mut::<_,PartitionedTableFunctionContext >(&mut _localctx).ptfsrc = Some(tmp.clone());
			  

			recog.base.set_state(4086);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_CLUSTER || _la==KW_DISTRIBUTE || _la==KW_ORDER || _la==KW_PARTITION || _la==KW_SORT {
				{
				/*InvokeRule partitioningSpec*/
				recog.base.set_state(4085);
				let tmp = recog.partitioningSpec()?;
				 cast_mut::<_,PartitionedTableFunctionContext >(&mut _localctx).spec = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(4103);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==Identifier {
				{
				recog.base.set_state(4088);
				recog.base.match_token(Identifier,&mut recog.err_handler)?;

				recog.base.set_state(4089);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(4090);
				recog.expression()?;

				recog.base.set_state(4091);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				recog.base.set_state(4100);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(4092);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					recog.base.set_state(4093);
					recog.base.match_token(Identifier,&mut recog.err_handler)?;

					recog.base.set_state(4094);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(4095);
					recog.expression()?;

					recog.base.set_state(4096);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
					}
					recog.base.set_state(4102);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(4105);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(4107);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(484,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule id_*/
					recog.base.set_state(4106);
					let tmp = recog.id_()?;
					 cast_mut::<_,PartitionedTableFunctionContext >(&mut _localctx).alias = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whereClause ----------------
pub type WhereClauseContextAll<'input> = WhereClauseContext<'input>;


pub type WhereClauseContext<'input> = BaseParserRuleContext<'input,WhereClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WhereClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for WhereClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for WhereClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whereClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_whereClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for WhereClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whereClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whereClause }
}
crate::tid!{WhereClauseContextExt<'a>}

impl<'input> WhereClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhereClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhereClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WhereClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<WhereClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_WHERE
/// Returns `None` if there is no child corresponding to token KW_WHERE
fn KW_WHERE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WHERE, 0)
}
fn searchCondition(&self) -> Option<Rc<SearchConditionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WhereClauseContextAttrs<'input> for WhereClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whereClause(&mut self,)
	-> Result<Rc<WhereClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhereClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 662, RULE_whereClause);
        let mut _localctx: Rc<WhereClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4109);
			recog.base.match_token(KW_WHERE,&mut recog.err_handler)?;

			/*InvokeRule searchCondition*/
			recog.base.set_state(4110);
			recog.searchCondition()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- searchCondition ----------------
pub type SearchConditionContextAll<'input> = SearchConditionContext<'input>;


pub type SearchConditionContext<'input> = BaseParserRuleContext<'input,SearchConditionContextExt<'input>>;

#[derive(Clone)]
pub struct SearchConditionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SearchConditionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SearchConditionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_searchCondition(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_searchCondition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SearchConditionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_searchCondition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_searchCondition }
}
crate::tid!{SearchConditionContextExt<'a>}

impl<'input> SearchConditionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SearchConditionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SearchConditionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SearchConditionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SearchConditionContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SearchConditionContextAttrs<'input> for SearchConditionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn searchCondition(&mut self,)
	-> Result<Rc<SearchConditionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SearchConditionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 664, RULE_searchCondition);
        let mut _localctx: Rc<SearchConditionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(4112);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- valuesSource ----------------
pub type ValuesSourceContextAll<'input> = ValuesSourceContext<'input>;


pub type ValuesSourceContext<'input> = BaseParserRuleContext<'input,ValuesSourceContextExt<'input>>;

#[derive(Clone)]
pub struct ValuesSourceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ValuesSourceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ValuesSourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_valuesSource(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_valuesSource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ValuesSourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valuesSource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valuesSource }
}
crate::tid!{ValuesSourceContextExt<'a>}

impl<'input> ValuesSourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ValuesSourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ValuesSourceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ValuesSourceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ValuesSourceContextExt<'input>>{

fn valuesClause(&self) -> Option<Rc<ValuesClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ValuesSourceContextAttrs<'input> for ValuesSourceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn valuesSource(&mut self,)
	-> Result<Rc<ValuesSourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ValuesSourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 666, RULE_valuesSource);
        let mut _localctx: Rc<ValuesSourceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule valuesClause*/
			recog.base.set_state(4114);
			recog.valuesClause()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- valuesClause ----------------
pub type ValuesClauseContextAll<'input> = ValuesClauseContext<'input>;


pub type ValuesClauseContext<'input> = BaseParserRuleContext<'input,ValuesClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ValuesClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ValuesClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ValuesClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_valuesClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_valuesClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ValuesClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valuesClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valuesClause }
}
crate::tid!{ValuesClauseContextExt<'a>}

impl<'input> ValuesClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ValuesClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ValuesClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ValuesClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ValuesClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_VALUES
/// Returns `None` if there is no child corresponding to token KW_VALUES
fn KW_VALUES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VALUES, 0)
}
fn valuesTableConstructor(&self) -> Option<Rc<ValuesTableConstructorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ValuesClauseContextAttrs<'input> for ValuesClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn valuesClause(&mut self,)
	-> Result<Rc<ValuesClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ValuesClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 668, RULE_valuesClause);
        let mut _localctx: Rc<ValuesClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4116);
			recog.base.match_token(KW_VALUES,&mut recog.err_handler)?;

			/*InvokeRule valuesTableConstructor*/
			recog.base.set_state(4117);
			recog.valuesTableConstructor()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- valuesTableConstructor ----------------
pub type ValuesTableConstructorContextAll<'input> = ValuesTableConstructorContext<'input>;


pub type ValuesTableConstructorContext<'input> = BaseParserRuleContext<'input,ValuesTableConstructorContextExt<'input>>;

#[derive(Clone)]
pub struct ValuesTableConstructorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ValuesTableConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ValuesTableConstructorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_valuesTableConstructor(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_valuesTableConstructor(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ValuesTableConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valuesTableConstructor }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valuesTableConstructor }
}
crate::tid!{ValuesTableConstructorContextExt<'a>}

impl<'input> ValuesTableConstructorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ValuesTableConstructorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ValuesTableConstructorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ValuesTableConstructorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ValuesTableConstructorContextExt<'input>>{

fn valueRowConstructor_all(&self) ->  Vec<Rc<ValueRowConstructorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn valueRowConstructor(&self, i: usize) -> Option<Rc<ValueRowConstructorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn firstValueRowConstructor(&self) -> Option<Rc<FirstValueRowConstructorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ValuesTableConstructorContextAttrs<'input> for ValuesTableConstructorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn valuesTableConstructor(&mut self,)
	-> Result<Rc<ValuesTableConstructorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ValuesTableConstructorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 670, RULE_valuesTableConstructor);
        let mut _localctx: Rc<ValuesTableConstructorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4135);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(487,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule valueRowConstructor*/
					recog.base.set_state(4119);
					recog.valueRowConstructor()?;

					recog.base.set_state(4124);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(4120);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule valueRowConstructor*/
						recog.base.set_state(4121);
						recog.valueRowConstructor()?;

						}
						}
						recog.base.set_state(4126);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule firstValueRowConstructor*/
					recog.base.set_state(4127);
					recog.firstValueRowConstructor()?;

					recog.base.set_state(4132);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(4128);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule valueRowConstructor*/
						recog.base.set_state(4129);
						recog.valueRowConstructor()?;

						}
						}
						recog.base.set_state(4134);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- valueRowConstructor ----------------
pub type ValueRowConstructorContextAll<'input> = ValueRowConstructorContext<'input>;


pub type ValueRowConstructorContext<'input> = BaseParserRuleContext<'input,ValueRowConstructorContextExt<'input>>;

#[derive(Clone)]
pub struct ValueRowConstructorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ValueRowConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ValueRowConstructorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_valueRowConstructor(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_valueRowConstructor(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ValueRowConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueRowConstructor }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueRowConstructor }
}
crate::tid!{ValueRowConstructorContextExt<'a>}

impl<'input> ValueRowConstructorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ValueRowConstructorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ValueRowConstructorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ValueRowConstructorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ValueRowConstructorContextExt<'input>>{

fn expressionsInParenthesis(&self) -> Option<Rc<ExpressionsInParenthesisContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ValueRowConstructorContextAttrs<'input> for ValueRowConstructorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn valueRowConstructor(&mut self,)
	-> Result<Rc<ValueRowConstructorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ValueRowConstructorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 672, RULE_valueRowConstructor);
        let mut _localctx: Rc<ValueRowConstructorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expressionsInParenthesis*/
			recog.base.set_state(4137);
			recog.expressionsInParenthesis()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- firstValueRowConstructor ----------------
pub type FirstValueRowConstructorContextAll<'input> = FirstValueRowConstructorContext<'input>;


pub type FirstValueRowConstructorContext<'input> = BaseParserRuleContext<'input,FirstValueRowConstructorContextExt<'input>>;

#[derive(Clone)]
pub struct FirstValueRowConstructorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for FirstValueRowConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for FirstValueRowConstructorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_firstValueRowConstructor(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_firstValueRowConstructor(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for FirstValueRowConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_firstValueRowConstructor }
	//fn type_rule_index() -> usize where Self: Sized { RULE_firstValueRowConstructor }
}
crate::tid!{FirstValueRowConstructorContextExt<'a>}

impl<'input> FirstValueRowConstructorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FirstValueRowConstructorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FirstValueRowConstructorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FirstValueRowConstructorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<FirstValueRowConstructorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn firstExpressionsWithAlias(&self) -> Option<Rc<FirstExpressionsWithAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> FirstValueRowConstructorContextAttrs<'input> for FirstValueRowConstructorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn firstValueRowConstructor(&mut self,)
	-> Result<Rc<FirstValueRowConstructorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FirstValueRowConstructorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 674, RULE_firstValueRowConstructor);
        let mut _localctx: Rc<FirstValueRowConstructorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4139);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule firstExpressionsWithAlias*/
			recog.base.set_state(4140);
			recog.firstExpressionsWithAlias()?;

			recog.base.set_state(4141);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- virtualTableSource ----------------
pub type VirtualTableSourceContextAll<'input> = VirtualTableSourceContext<'input>;


pub type VirtualTableSourceContext<'input> = BaseParserRuleContext<'input,VirtualTableSourceContextExt<'input>>;

#[derive(Clone)]
pub struct VirtualTableSourceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for VirtualTableSourceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for VirtualTableSourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_virtualTableSource(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_virtualTableSource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for VirtualTableSourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_virtualTableSource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_virtualTableSource }
}
crate::tid!{VirtualTableSourceContextExt<'a>}

impl<'input> VirtualTableSourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<VirtualTableSourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,VirtualTableSourceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait VirtualTableSourceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<VirtualTableSourceContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TABLE
/// Returns `None` if there is no child corresponding to token KW_TABLE
fn KW_TABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
fn valuesClause(&self) -> Option<Rc<ValuesClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> VirtualTableSourceContextAttrs<'input> for VirtualTableSourceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn virtualTableSource(&mut self,)
	-> Result<Rc<VirtualTableSourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = VirtualTableSourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 676, RULE_virtualTableSource);
        let mut _localctx: Rc<VirtualTableSourceContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4143);
			recog.base.match_token(KW_TABLE,&mut recog.err_handler)?;

			recog.base.set_state(4144);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule valuesClause*/
			recog.base.set_state(4145);
			recog.valuesClause()?;

			recog.base.set_state(4146);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			recog.base.set_state(4148);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_AS {
				{
				recog.base.set_state(4147);
				recog.base.match_token(KW_AS,&mut recog.err_handler)?;

				}
			}

			/*InvokeRule tableAlias*/
			recog.base.set_state(4150);
			recog.tableAlias()?;

			recog.base.set_state(4160);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LPAREN {
				{
				recog.base.set_state(4151);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(4152);
				recog.id_()?;

				recog.base.set_state(4157);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(4153);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(4154);
					recog.id_()?;

					}
					}
					recog.base.set_state(4159);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(4162);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectClause ----------------
pub type SelectClauseContextAll<'input> = SelectClauseContext<'input>;


pub type SelectClauseContext<'input> = BaseParserRuleContext<'input,SelectClauseContextExt<'input>>;

#[derive(Clone)]
pub struct SelectClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SelectClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SelectClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_selectClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SelectClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectClause }
}
crate::tid!{SelectClauseContextExt<'a>}

impl<'input> SelectClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SelectClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SELECT
/// Returns `None` if there is no child corresponding to token KW_SELECT
fn KW_SELECT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SELECT, 0)
}
fn selectList(&self) -> Option<Rc<SelectListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRANSFORM
/// Returns `None` if there is no child corresponding to token KW_TRANSFORM
fn KW_TRANSFORM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRANSFORM, 0)
}
fn selectTrfmClause(&self) -> Option<Rc<SelectTrfmClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token QUERY_HINT
/// Returns `None` if there is no child corresponding to token QUERY_HINT
fn QUERY_HINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(QUERY_HINT, 0)
}
fn all_distinct(&self) -> Option<Rc<All_distinctContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn trfmClause(&self) -> Option<Rc<TrfmClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SelectClauseContextAttrs<'input> for SelectClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectClause(&mut self,)
	-> Result<Rc<SelectClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 678, RULE_selectClause);
        let mut _localctx: Rc<SelectClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4177);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_SELECT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4164);
					recog.base.match_token(KW_SELECT,&mut recog.err_handler)?;

					recog.base.set_state(4166);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==QUERY_HINT {
						{
						recog.base.set_state(4165);
						recog.base.match_token(QUERY_HINT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4174);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER |
					 KW_ALL | KW_ALLOC_FRACTION | KW_ANALYZE | KW_ARCHIVE | KW_ARRAY | KW_ASC |
					 KW_AST | KW_AT | KW_AUTOCOMMIT | KW_BATCH | KW_BEFORE | KW_BIGINT |
					 KW_BINARY | KW_BOOLEAN | KW_BUCKET | KW_BUCKETS | KW_CACHE | KW_CASCADE |
					 KW_CASE | KW_CAST | KW_CBO | KW_CHANGE | KW_CHECK | KW_CLUSTER | KW_CLUSTERED |
					 KW_CLUSTERSTATUS | KW_COLLECTION | KW_COLUMNS | KW_COMMENT | KW_COMPACT |
					 KW_COMPACTIONS | KW_COMPUTE | KW_CONCATENATE | KW_CONTINUE | KW_COST |
					 KW_CRON | KW_CURRENT_DATE | KW_CURRENT_TIMESTAMP | KW_DATA | KW_DATABASES |
					 KW_DATE | KW_DATETIME | KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES | KW_DCPROPERTIES |
					 KW_DEBUG | KW_DEFAULT | KW_DEFERRED | KW_DEFINED | KW_DELIMITED | KW_DEPENDENCY |
					 KW_DESC | KW_DETAIL | KW_DIRECTORIES | KW_DIRECTORY | KW_DISABLE |
					 KW_DISTINCT | KW_DISTRIBUTE | KW_DISTRIBUTED | KW_DO | KW_DOUBLE |
					 KW_DUMP | KW_ELEM_TYPE | KW_ENABLE | KW_ENFORCED | KW_ESCAPED | KW_EVERY |
					 KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED | KW_EXISTS | KW_EXPIRE_SNAPSHOTS |
					 KW_EXPLAIN | KW_EXPORT | KW_EXPRESSION | KW_EXTRACT | KW_FALSE | KW_FIELDS |
					 KW_FILE | KW_FILEFORMAT | KW_FIRST | KW_FLOAT | KW_FLOOR | KW_FORMAT |
					 KW_FORMATTED | KW_FUNCTIONS | KW_GROUPING | KW_HOLD_DDLTIME | KW_HOUR |
					 KW_IDXPROPERTIES | KW_IF | KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH |
					 KW_INPUTDRIVER | KW_INPUTFORMAT | KW_INT | KW_INTERVAL | KW_ISOLATION |
					 KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY | KW_KEYS | KW_KEY_TYPE |
					 KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES | KW_LOAD | KW_LOCATION |
					 KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED | KW_MANAGEDLOCATION |
					 KW_MANAGEMENT | KW_MAP | KW_MAPJOIN | KW_MAPPING | KW_MATCHED | KW_MATERIALIZED |
					 KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK | KW_NORELY |
					 KW_NOSCAN | KW_NOT | KW_NOVALIDATE | KW_NO_DROP | KW_NULL | KW_NULLS |
					 KW_OFFLINE | KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER |
					 KW_OUTPUTFORMAT | KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS |
					 KW_PATH | KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS |
					 KW_PROTECTION | KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM |
					 KW_READ | KW_READONLY | KW_REAL | KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER |
					 KW_RELOAD | KW_RELY | KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR |
					 KW_REPL | KW_REPLACE | KW_REPLICATION | KW_RESOURCE | KW_RESPECT |
					 KW_RESTRICT | KW_REWRITE | KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY |
					 KW_SCHEMA | KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES |
					 KW_SERVER | KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW |
					 KW_SHOW_DATABASE | KW_SKEWED | KW_SMALLINT | KW_SNAPSHOT | KW_SORT |
					 KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS | KW_STATUS | KW_STORED |
					 KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY | KW_SYSTEM_TIME |
					 KW_SYSTEM_VERSION | KW_TABLES | KW_TBLPROPERTIES | KW_TEMPORARY | KW_TERMINATED |
					 KW_TIMESTAMP | KW_TIMESTAMPLOCALTZ | KW_TIMESTAMPTZ | KW_TINYINT |
					 KW_TOUCH | KW_TRANSACTION | KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM |
					 KW_TRUE | KW_TYPE | KW_UNARCHIVE | KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN |
					 KW_UNLOCK | KW_UNMANAGED | KW_UNSET | KW_UNSIGNED | KW_URI | KW_URL |
					 KW_USE | KW_UTC | KW_UTCTIMESTAMP | KW_VALIDATE | KW_VALUE_TYPE | KW_VECTORIZATION |
					 KW_VIEW | KW_VIEWS | KW_WAIT | KW_WEEK | KW_WHILE | KW_WITHIN | KW_WORK |
					 KW_WORKLOAD | KW_WRITE | KW_YEAR | KW_ZONE | LPAREN | PLUS | MINUS |
					 STAR | TILDE | QUESTION | StringLiteral | IntegralLiteral | NumberLiteral |
					 Number | Identifier | CharSetName 
						=> {
							{
							recog.base.set_state(4169);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_ALL || _la==KW_DISTINCT {
								{
								/*InvokeRule all_distinct*/
								recog.base.set_state(4168);
								recog.all_distinct()?;

								}
							}

							/*InvokeRule selectList*/
							recog.base.set_state(4171);
							recog.selectList()?;

							}
						}

					 KW_TRANSFORM 
						=> {
							{
							recog.base.set_state(4172);
							recog.base.match_token(KW_TRANSFORM,&mut recog.err_handler)?;

							/*InvokeRule selectTrfmClause*/
							recog.base.set_state(4173);
							recog.selectTrfmClause()?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}

			 KW_MAP | KW_REDUCE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule trfmClause*/
					recog.base.set_state(4176);
					recog.trfmClause()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- all_distinct ----------------
pub type All_distinctContextAll<'input> = All_distinctContext<'input>;


pub type All_distinctContext<'input> = BaseParserRuleContext<'input,All_distinctContextExt<'input>>;

#[derive(Clone)]
pub struct All_distinctContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for All_distinctContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for All_distinctContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_all_distinct(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_all_distinct(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for All_distinctContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_all_distinct }
	//fn type_rule_index() -> usize where Self: Sized { RULE_all_distinct }
}
crate::tid!{All_distinctContextExt<'a>}

impl<'input> All_distinctContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<All_distinctContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,All_distinctContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait All_distinctContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<All_distinctContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ALL
/// Returns `None` if there is no child corresponding to token KW_ALL
fn KW_ALL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DISTINCT
/// Returns `None` if there is no child corresponding to token KW_DISTINCT
fn KW_DISTINCT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISTINCT, 0)
}

}

impl<'input> All_distinctContextAttrs<'input> for All_distinctContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn all_distinct(&mut self,)
	-> Result<Rc<All_distinctContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = All_distinctContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 680, RULE_all_distinct);
        let mut _localctx: Rc<All_distinctContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4179);
			_la = recog.base.input.la(1);
			if { !(_la==KW_ALL || _la==KW_DISTINCT) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectList ----------------
pub type SelectListContextAll<'input> = SelectListContext<'input>;


pub type SelectListContext<'input> = BaseParserRuleContext<'input,SelectListContextExt<'input>>;

#[derive(Clone)]
pub struct SelectListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SelectListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SelectListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_selectList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SelectListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectList }
}
crate::tid!{SelectListContextExt<'a>}

impl<'input> SelectListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SelectListContextExt<'input>>{

fn selectItem_all(&self) ->  Vec<Rc<SelectItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn selectItem(&self, i: usize) -> Option<Rc<SelectItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> SelectListContextAttrs<'input> for SelectListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectList(&mut self,)
	-> Result<Rc<SelectListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 682, RULE_selectList);
        let mut _localctx: Rc<SelectListContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule selectItem*/
			recog.base.set_state(4181);
			recog.selectItem()?;

			recog.base.set_state(4186);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(495,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(4182);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule selectItem*/
					recog.base.set_state(4183);
					recog.selectItem()?;

					}
					} 
				}
				recog.base.set_state(4188);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(495,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectTrfmClause ----------------
pub type SelectTrfmClauseContextAll<'input> = SelectTrfmClauseContext<'input>;


pub type SelectTrfmClauseContext<'input> = BaseParserRuleContext<'input,SelectTrfmClauseContextExt<'input>>;

#[derive(Clone)]
pub struct SelectTrfmClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SelectTrfmClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SelectTrfmClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectTrfmClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_selectTrfmClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SelectTrfmClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectTrfmClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectTrfmClause }
}
crate::tid!{SelectTrfmClauseContextExt<'a>}

impl<'input> SelectTrfmClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectTrfmClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectTrfmClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectTrfmClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SelectTrfmClauseContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
fn selectExpressionList(&self) -> Option<Rc<SelectExpressionListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
fn rowFormat_all(&self) ->  Vec<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rowFormat(&self, i: usize) -> Option<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn recordWriter(&self) -> Option<Rc<RecordWriterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_USING
/// Returns `None` if there is no child corresponding to token KW_USING
fn KW_USING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USING, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn recordReader(&self) -> Option<Rc<RecordReaderContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
fn aliasList(&self) -> Option<Rc<AliasListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnNameTypeList(&self) -> Option<Rc<ColumnNameTypeListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SelectTrfmClauseContextAttrs<'input> for SelectTrfmClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectTrfmClause(&mut self,)
	-> Result<Rc<SelectTrfmClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectTrfmClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 684, RULE_selectTrfmClause);
        let mut _localctx: Rc<SelectTrfmClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4189);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule selectExpressionList*/
			recog.base.set_state(4190);
			recog.selectExpressionList()?;

			recog.base.set_state(4191);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			/*InvokeRule rowFormat*/
			recog.base.set_state(4192);
			recog.rowFormat()?;

			/*InvokeRule recordWriter*/
			recog.base.set_state(4193);
			recog.recordWriter()?;

			recog.base.set_state(4194);
			recog.base.match_token(KW_USING,&mut recog.err_handler)?;

			recog.base.set_state(4195);
			recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

			recog.base.set_state(4208);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_AS {
				{
				recog.base.set_state(4196);
				recog.base.match_token(KW_AS,&mut recog.err_handler)?;

				recog.base.set_state(4206);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(497,&mut recog.base)? {
					1 =>{
						{
						recog.base.set_state(4197);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						recog.base.set_state(4200);
						recog.err_handler.sync(&mut recog.base)?;
						match  recog.interpreter.adaptive_predict(496,&mut recog.base)? {
							1 =>{
								{
								/*InvokeRule aliasList*/
								recog.base.set_state(4198);
								recog.aliasList()?;

								}
							}
						,
							2 =>{
								{
								/*InvokeRule columnNameTypeList*/
								recog.base.set_state(4199);
								recog.columnNameTypeList()?;

								}
							}

							_ => {}
						}
						recog.base.set_state(4202);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}
				,
					2 =>{
						{
						/*InvokeRule aliasList*/
						recog.base.set_state(4204);
						recog.aliasList()?;

						}
					}
				,
					3 =>{
						{
						/*InvokeRule columnNameTypeList*/
						recog.base.set_state(4205);
						recog.columnNameTypeList()?;

						}
					}

					_ => {}
				}
				}
			}

			/*InvokeRule rowFormat*/
			recog.base.set_state(4210);
			recog.rowFormat()?;

			/*InvokeRule recordReader*/
			recog.base.set_state(4211);
			recog.recordReader()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectItem ----------------
pub type SelectItemContextAll<'input> = SelectItemContext<'input>;


pub type SelectItemContext<'input> = BaseParserRuleContext<'input,SelectItemContextExt<'input>>;

#[derive(Clone)]
pub struct SelectItemContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SelectItemContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SelectItemContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectItem(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_selectItem(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SelectItemContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectItem }
}
crate::tid!{SelectItemContextExt<'a>}

impl<'input> SelectItemContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectItemContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectItemContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectItemContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SelectItemContextExt<'input>>{

fn tableAllColumns(&self) -> Option<Rc<TableAllColumnsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> SelectItemContextAttrs<'input> for SelectItemContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectItem(&mut self,)
	-> Result<Rc<SelectItemContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectItemContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 686, RULE_selectItem);
        let mut _localctx: Rc<SelectItemContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4233);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(502,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule tableAllColumns*/
					recog.base.set_state(4213);
					recog.tableAllColumns()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					{
					/*InvokeRule expression*/
					recog.base.set_state(4214);
					recog.expression()?;

					recog.base.set_state(4231);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(501,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4216);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_AS {
								{
								recog.base.set_state(4215);
								recog.base.match_token(KW_AS,&mut recog.err_handler)?;

								}
							}

							/*InvokeRule id_*/
							recog.base.set_state(4218);
							recog.id_()?;

							}
						}

						x if x == 2=>{
							{
							recog.base.set_state(4219);
							recog.base.match_token(KW_AS,&mut recog.err_handler)?;

							recog.base.set_state(4220);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule id_*/
							recog.base.set_state(4221);
							recog.id_()?;

							recog.base.set_state(4226);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMA {
								{
								{
								recog.base.set_state(4222);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule id_*/
								recog.base.set_state(4223);
								recog.id_()?;

								}
								}
								recog.base.set_state(4228);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							recog.base.set_state(4229);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- trfmClause ----------------
pub type TrfmClauseContextAll<'input> = TrfmClauseContext<'input>;


pub type TrfmClauseContext<'input> = BaseParserRuleContext<'input,TrfmClauseContextExt<'input>>;

#[derive(Clone)]
pub struct TrfmClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TrfmClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TrfmClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_trfmClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_trfmClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TrfmClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_trfmClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_trfmClause }
}
crate::tid!{TrfmClauseContextExt<'a>}

impl<'input> TrfmClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TrfmClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TrfmClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TrfmClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TrfmClauseContextExt<'input>>{

fn selectExpressionList(&self) -> Option<Rc<SelectExpressionListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn rowFormat_all(&self) ->  Vec<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rowFormat(&self, i: usize) -> Option<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn recordWriter(&self) -> Option<Rc<RecordWriterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_USING
/// Returns `None` if there is no child corresponding to token KW_USING
fn KW_USING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USING, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn recordReader(&self) -> Option<Rc<RecordReaderContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_MAP
/// Returns `None` if there is no child corresponding to token KW_MAP
fn KW_MAP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REDUCE
/// Returns `None` if there is no child corresponding to token KW_REDUCE
fn KW_REDUCE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REDUCE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn aliasList(&self) -> Option<Rc<AliasListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnNameTypeList(&self) -> Option<Rc<ColumnNameTypeListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TrfmClauseContextAttrs<'input> for TrfmClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn trfmClause(&mut self,)
	-> Result<Rc<TrfmClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TrfmClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 688, RULE_trfmClause);
        let mut _localctx: Rc<TrfmClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4235);
			_la = recog.base.input.la(1);
			if { !(_la==KW_MAP || _la==KW_REDUCE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			/*InvokeRule selectExpressionList*/
			recog.base.set_state(4236);
			recog.selectExpressionList()?;

			/*InvokeRule rowFormat*/
			recog.base.set_state(4237);
			recog.rowFormat()?;

			/*InvokeRule recordWriter*/
			recog.base.set_state(4238);
			recog.recordWriter()?;

			recog.base.set_state(4239);
			recog.base.match_token(KW_USING,&mut recog.err_handler)?;

			recog.base.set_state(4240);
			recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

			recog.base.set_state(4253);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_AS {
				{
				recog.base.set_state(4241);
				recog.base.match_token(KW_AS,&mut recog.err_handler)?;

				recog.base.set_state(4251);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(504,&mut recog.base)? {
					1 =>{
						{
						recog.base.set_state(4242);
						recog.base.match_token(LPAREN,&mut recog.err_handler)?;

						recog.base.set_state(4245);
						recog.err_handler.sync(&mut recog.base)?;
						match  recog.interpreter.adaptive_predict(503,&mut recog.base)? {
							1 =>{
								{
								/*InvokeRule aliasList*/
								recog.base.set_state(4243);
								recog.aliasList()?;

								}
							}
						,
							2 =>{
								{
								/*InvokeRule columnNameTypeList*/
								recog.base.set_state(4244);
								recog.columnNameTypeList()?;

								}
							}

							_ => {}
						}
						recog.base.set_state(4247);
						recog.base.match_token(RPAREN,&mut recog.err_handler)?;

						}
					}
				,
					2 =>{
						{
						/*InvokeRule aliasList*/
						recog.base.set_state(4249);
						recog.aliasList()?;

						}
					}
				,
					3 =>{
						{
						/*InvokeRule columnNameTypeList*/
						recog.base.set_state(4250);
						recog.columnNameTypeList()?;

						}
					}

					_ => {}
				}
				}
			}

			/*InvokeRule rowFormat*/
			recog.base.set_state(4255);
			recog.rowFormat()?;

			/*InvokeRule recordReader*/
			recog.base.set_state(4256);
			recog.recordReader()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectExpression ----------------
pub type SelectExpressionContextAll<'input> = SelectExpressionContext<'input>;


pub type SelectExpressionContext<'input> = BaseParserRuleContext<'input,SelectExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct SelectExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SelectExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SelectExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_selectExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SelectExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectExpression }
}
crate::tid!{SelectExpressionContextExt<'a>}

impl<'input> SelectExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SelectExpressionContextExt<'input>>{

fn tableAllColumns(&self) -> Option<Rc<TableAllColumnsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SelectExpressionContextAttrs<'input> for SelectExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectExpression(&mut self,)
	-> Result<Rc<SelectExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 690, RULE_selectExpression);
        let mut _localctx: Rc<SelectExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4260);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(506,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule tableAllColumns*/
					recog.base.set_state(4258);
					recog.tableAllColumns()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule expression*/
					recog.base.set_state(4259);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectExpressionList ----------------
pub type SelectExpressionListContextAll<'input> = SelectExpressionListContext<'input>;


pub type SelectExpressionListContext<'input> = BaseParserRuleContext<'input,SelectExpressionListContextExt<'input>>;

#[derive(Clone)]
pub struct SelectExpressionListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SelectExpressionListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SelectExpressionListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectExpressionList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_selectExpressionList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SelectExpressionListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectExpressionList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectExpressionList }
}
crate::tid!{SelectExpressionListContextExt<'a>}

impl<'input> SelectExpressionListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectExpressionListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectExpressionListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectExpressionListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SelectExpressionListContextExt<'input>>{

fn selectExpression_all(&self) ->  Vec<Rc<SelectExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn selectExpression(&self, i: usize) -> Option<Rc<SelectExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> SelectExpressionListContextAttrs<'input> for SelectExpressionListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectExpressionList(&mut self,)
	-> Result<Rc<SelectExpressionListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectExpressionListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 692, RULE_selectExpressionList);
        let mut _localctx: Rc<SelectExpressionListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule selectExpression*/
			recog.base.set_state(4262);
			recog.selectExpression()?;

			recog.base.set_state(4267);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4263);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule selectExpression*/
				recog.base.set_state(4264);
				recog.selectExpression()?;

				}
				}
				recog.base.set_state(4269);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- window_clause ----------------
pub type Window_clauseContextAll<'input> = Window_clauseContext<'input>;


pub type Window_clauseContext<'input> = BaseParserRuleContext<'input,Window_clauseContextExt<'input>>;

#[derive(Clone)]
pub struct Window_clauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Window_clauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Window_clauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_window_clause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_window_clause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Window_clauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_window_clause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_window_clause }
}
crate::tid!{Window_clauseContextExt<'a>}

impl<'input> Window_clauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Window_clauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Window_clauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Window_clauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Window_clauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_WINDOW
/// Returns `None` if there is no child corresponding to token KW_WINDOW
fn KW_WINDOW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WINDOW, 0)
}
fn window_defn_all(&self) ->  Vec<Rc<Window_defnContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn window_defn(&self, i: usize) -> Option<Rc<Window_defnContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> Window_clauseContextAttrs<'input> for Window_clauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn window_clause(&mut self,)
	-> Result<Rc<Window_clauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Window_clauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 694, RULE_window_clause);
        let mut _localctx: Rc<Window_clauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4270);
			recog.base.match_token(KW_WINDOW,&mut recog.err_handler)?;

			/*InvokeRule window_defn*/
			recog.base.set_state(4271);
			recog.window_defn()?;

			recog.base.set_state(4276);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4272);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule window_defn*/
				recog.base.set_state(4273);
				recog.window_defn()?;

				}
				}
				recog.base.set_state(4278);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- window_defn ----------------
pub type Window_defnContextAll<'input> = Window_defnContext<'input>;


pub type Window_defnContext<'input> = BaseParserRuleContext<'input,Window_defnContextExt<'input>>;

#[derive(Clone)]
pub struct Window_defnContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Window_defnContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Window_defnContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_window_defn(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_window_defn(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Window_defnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_window_defn }
	//fn type_rule_index() -> usize where Self: Sized { RULE_window_defn }
}
crate::tid!{Window_defnContextExt<'a>}

impl<'input> Window_defnContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Window_defnContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Window_defnContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Window_defnContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Window_defnContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
fn window_specification(&self) -> Option<Rc<Window_specificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> Window_defnContextAttrs<'input> for Window_defnContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn window_defn(&mut self,)
	-> Result<Rc<Window_defnContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Window_defnContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 696, RULE_window_defn);
        let mut _localctx: Rc<Window_defnContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(4279);
			recog.id_()?;

			recog.base.set_state(4280);
			recog.base.match_token(KW_AS,&mut recog.err_handler)?;

			/*InvokeRule window_specification*/
			recog.base.set_state(4281);
			recog.window_specification()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- window_specification ----------------
pub type Window_specificationContextAll<'input> = Window_specificationContext<'input>;


pub type Window_specificationContext<'input> = BaseParserRuleContext<'input,Window_specificationContextExt<'input>>;

#[derive(Clone)]
pub struct Window_specificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Window_specificationContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Window_specificationContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_window_specification(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_window_specification(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Window_specificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_window_specification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_window_specification }
}
crate::tid!{Window_specificationContextExt<'a>}

impl<'input> Window_specificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Window_specificationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Window_specificationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Window_specificationContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Window_specificationContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn partitioningSpec(&self) -> Option<Rc<PartitioningSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn window_frame(&self) -> Option<Rc<Window_frameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> Window_specificationContextAttrs<'input> for Window_specificationContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn window_specification(&mut self,)
	-> Result<Rc<Window_specificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Window_specificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 698, RULE_window_specification);
        let mut _localctx: Rc<Window_specificationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4295);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT | KW_BATCH |
			 KW_BEFORE | KW_BUCKET | KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CBO |
			 KW_CHANGE | KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS |
			 KW_COLLECTION | KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS |
			 KW_COMPUTE | KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_DATA |
			 KW_DATABASES | KW_DATETIME | KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES |
			 KW_DCPROPERTIES | KW_DEBUG | KW_DEFAULT | KW_DEFERRED | KW_DEFINED |
			 KW_DELIMITED | KW_DEPENDENCY | KW_DESC | KW_DETAIL | KW_DIRECTORIES |
			 KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE | KW_DISTRIBUTED | KW_DO |
			 KW_DUMP | KW_ELEM_TYPE | KW_ENABLE | KW_ENFORCED | KW_ESCAPED | KW_EVERY |
			 KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED | KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN |
			 KW_EXPORT | KW_EXPRESSION | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST |
			 KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_HOLD_DDLTIME | KW_HOUR |
			 KW_IDXPROPERTIES | KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER |
			 KW_INPUTFORMAT | KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY |
			 KW_KEYS | KW_KEY_TYPE | KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES |
			 KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED |
			 KW_MANAGEDLOCATION | KW_MANAGEMENT | KW_MAPJOIN | KW_MAPPING | KW_MATCHED |
			 KW_MATERIALIZED | KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK |
			 KW_NORELY | KW_NOSCAN | KW_NOVALIDATE | KW_NO_DROP | KW_NULLS | KW_OFFLINE |
			 KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT |
			 KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH |
			 KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION |
			 KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY |
			 KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD | KW_RELY |
			 KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL | KW_REPLACE |
			 KW_REPLICATION | KW_RESOURCE | KW_RESPECT | KW_RESTRICT | KW_REWRITE |
			 KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY | KW_SCHEMA |
			 KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER |
			 KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW | KW_SHOW_DATABASE |
			 KW_SKEWED | KW_SNAPSHOT | KW_SORT | KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS |
			 KW_STATUS | KW_STORED | KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY |
			 KW_SYSTEM_TIME | KW_SYSTEM_VERSION | KW_TABLES | KW_TBLPROPERTIES | KW_TEMPORARY |
			 KW_TERMINATED | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH | KW_TRANSACTION |
			 KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TYPE | KW_UNARCHIVE |
			 KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK | KW_UNMANAGED | KW_UNSET |
			 KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC | KW_UTCTIMESTAMP | KW_VALIDATE |
			 KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW | KW_VIEWS | KW_WAIT | KW_WEEK |
			 KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD | KW_WRITE | KW_YEAR | KW_ZONE |
			 Identifier 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule id_*/
					recog.base.set_state(4283);
					recog.id_()?;

					}
				}

			 LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4284);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(4286);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(509,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule id_*/
							recog.base.set_state(4285);
							recog.id_()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(4289);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_CLUSTER || _la==KW_DISTRIBUTE || _la==KW_ORDER || _la==KW_PARTITION || _la==KW_SORT {
						{
						/*InvokeRule partitioningSpec*/
						recog.base.set_state(4288);
						recog.partitioningSpec()?;

						}
					}

					recog.base.set_state(4292);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_RANGE || _la==KW_ROWS {
						{
						/*InvokeRule window_frame*/
						recog.base.set_state(4291);
						recog.window_frame()?;

						}
					}

					recog.base.set_state(4294);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- window_frame ----------------
pub type Window_frameContextAll<'input> = Window_frameContext<'input>;


pub type Window_frameContext<'input> = BaseParserRuleContext<'input,Window_frameContextExt<'input>>;

#[derive(Clone)]
pub struct Window_frameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Window_frameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Window_frameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_window_frame(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_window_frame(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Window_frameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_window_frame }
	//fn type_rule_index() -> usize where Self: Sized { RULE_window_frame }
}
crate::tid!{Window_frameContextExt<'a>}

impl<'input> Window_frameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Window_frameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Window_frameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Window_frameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Window_frameContextExt<'input>>{

fn window_range_expression(&self) -> Option<Rc<Window_range_expressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn window_value_expression(&self) -> Option<Rc<Window_value_expressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> Window_frameContextAttrs<'input> for Window_frameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn window_frame(&mut self,)
	-> Result<Rc<Window_frameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Window_frameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 700, RULE_window_frame);
        let mut _localctx: Rc<Window_frameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4299);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ROWS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule window_range_expression*/
					recog.base.set_state(4297);
					recog.window_range_expression()?;

					}
				}

			 KW_RANGE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule window_value_expression*/
					recog.base.set_state(4298);
					recog.window_value_expression()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- window_range_expression ----------------
pub type Window_range_expressionContextAll<'input> = Window_range_expressionContext<'input>;


pub type Window_range_expressionContext<'input> = BaseParserRuleContext<'input,Window_range_expressionContextExt<'input>>;

#[derive(Clone)]
pub struct Window_range_expressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Window_range_expressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Window_range_expressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_window_range_expression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_window_range_expression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Window_range_expressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_window_range_expression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_window_range_expression }
}
crate::tid!{Window_range_expressionContextExt<'a>}

impl<'input> Window_range_expressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Window_range_expressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Window_range_expressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Window_range_expressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Window_range_expressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ROWS
/// Returns `None` if there is no child corresponding to token KW_ROWS
fn KW_ROWS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROWS, 0)
}
fn window_frame_start_boundary(&self) -> Option<Rc<Window_frame_start_boundaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_BETWEEN
/// Returns `None` if there is no child corresponding to token KW_BETWEEN
fn KW_BETWEEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BETWEEN, 0)
}
fn window_frame_boundary_all(&self) ->  Vec<Rc<Window_frame_boundaryContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn window_frame_boundary(&self, i: usize) -> Option<Rc<Window_frame_boundaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_AND
/// Returns `None` if there is no child corresponding to token KW_AND
fn KW_AND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AND, 0)
}

}

impl<'input> Window_range_expressionContextAttrs<'input> for Window_range_expressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn window_range_expression(&mut self,)
	-> Result<Rc<Window_range_expressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Window_range_expressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 702, RULE_window_range_expression);
        let mut _localctx: Rc<Window_range_expressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4301);
			recog.base.match_token(KW_ROWS,&mut recog.err_handler)?;

			recog.base.set_state(4308);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_CURRENT | KW_UNBOUNDED | Number 
				=> {
					{
					/*InvokeRule window_frame_start_boundary*/
					recog.base.set_state(4302);
					recog.window_frame_start_boundary()?;

					}
				}

			 KW_BETWEEN 
				=> {
					{
					recog.base.set_state(4303);
					recog.base.match_token(KW_BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule window_frame_boundary*/
					recog.base.set_state(4304);
					recog.window_frame_boundary()?;

					recog.base.set_state(4305);
					recog.base.match_token(KW_AND,&mut recog.err_handler)?;

					/*InvokeRule window_frame_boundary*/
					recog.base.set_state(4306);
					recog.window_frame_boundary()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- window_value_expression ----------------
pub type Window_value_expressionContextAll<'input> = Window_value_expressionContext<'input>;


pub type Window_value_expressionContext<'input> = BaseParserRuleContext<'input,Window_value_expressionContextExt<'input>>;

#[derive(Clone)]
pub struct Window_value_expressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Window_value_expressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Window_value_expressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_window_value_expression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_window_value_expression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Window_value_expressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_window_value_expression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_window_value_expression }
}
crate::tid!{Window_value_expressionContextExt<'a>}

impl<'input> Window_value_expressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Window_value_expressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Window_value_expressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Window_value_expressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Window_value_expressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_RANGE
/// Returns `None` if there is no child corresponding to token KW_RANGE
fn KW_RANGE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RANGE, 0)
}
fn window_frame_start_boundary(&self) -> Option<Rc<Window_frame_start_boundaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_BETWEEN
/// Returns `None` if there is no child corresponding to token KW_BETWEEN
fn KW_BETWEEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BETWEEN, 0)
}
fn window_frame_boundary_all(&self) ->  Vec<Rc<Window_frame_boundaryContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn window_frame_boundary(&self, i: usize) -> Option<Rc<Window_frame_boundaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_AND
/// Returns `None` if there is no child corresponding to token KW_AND
fn KW_AND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AND, 0)
}

}

impl<'input> Window_value_expressionContextAttrs<'input> for Window_value_expressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn window_value_expression(&mut self,)
	-> Result<Rc<Window_value_expressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Window_value_expressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 704, RULE_window_value_expression);
        let mut _localctx: Rc<Window_value_expressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4310);
			recog.base.match_token(KW_RANGE,&mut recog.err_handler)?;

			recog.base.set_state(4317);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_CURRENT | KW_UNBOUNDED | Number 
				=> {
					{
					/*InvokeRule window_frame_start_boundary*/
					recog.base.set_state(4311);
					recog.window_frame_start_boundary()?;

					}
				}

			 KW_BETWEEN 
				=> {
					{
					recog.base.set_state(4312);
					recog.base.match_token(KW_BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule window_frame_boundary*/
					recog.base.set_state(4313);
					recog.window_frame_boundary()?;

					recog.base.set_state(4314);
					recog.base.match_token(KW_AND,&mut recog.err_handler)?;

					/*InvokeRule window_frame_boundary*/
					recog.base.set_state(4315);
					recog.window_frame_boundary()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- window_frame_start_boundary ----------------
pub type Window_frame_start_boundaryContextAll<'input> = Window_frame_start_boundaryContext<'input>;


pub type Window_frame_start_boundaryContext<'input> = BaseParserRuleContext<'input,Window_frame_start_boundaryContextExt<'input>>;

#[derive(Clone)]
pub struct Window_frame_start_boundaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Window_frame_start_boundaryContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Window_frame_start_boundaryContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_window_frame_start_boundary(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_window_frame_start_boundary(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Window_frame_start_boundaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_window_frame_start_boundary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_window_frame_start_boundary }
}
crate::tid!{Window_frame_start_boundaryContextExt<'a>}

impl<'input> Window_frame_start_boundaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Window_frame_start_boundaryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Window_frame_start_boundaryContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Window_frame_start_boundaryContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Window_frame_start_boundaryContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UNBOUNDED
/// Returns `None` if there is no child corresponding to token KW_UNBOUNDED
fn KW_UNBOUNDED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNBOUNDED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PRECEDING
/// Returns `None` if there is no child corresponding to token KW_PRECEDING
fn KW_PRECEDING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PRECEDING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CURRENT
/// Returns `None` if there is no child corresponding to token KW_CURRENT
fn KW_CURRENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CURRENT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROW
/// Returns `None` if there is no child corresponding to token KW_ROW
fn KW_ROW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROW, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}

}

impl<'input> Window_frame_start_boundaryContextAttrs<'input> for Window_frame_start_boundaryContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn window_frame_start_boundary(&mut self,)
	-> Result<Rc<Window_frame_start_boundaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Window_frame_start_boundaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 706, RULE_window_frame_start_boundary);
        let mut _localctx: Rc<Window_frame_start_boundaryContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4325);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_UNBOUNDED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4319);
					recog.base.match_token(KW_UNBOUNDED,&mut recog.err_handler)?;

					recog.base.set_state(4320);
					recog.base.match_token(KW_PRECEDING,&mut recog.err_handler)?;

					}
				}

			 KW_CURRENT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4321);
					recog.base.match_token(KW_CURRENT,&mut recog.err_handler)?;

					recog.base.set_state(4322);
					recog.base.match_token(KW_ROW,&mut recog.err_handler)?;

					}
				}

			 Number 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4323);
					recog.base.match_token(Number,&mut recog.err_handler)?;

					recog.base.set_state(4324);
					recog.base.match_token(KW_PRECEDING,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- window_frame_boundary ----------------
pub type Window_frame_boundaryContextAll<'input> = Window_frame_boundaryContext<'input>;


pub type Window_frame_boundaryContext<'input> = BaseParserRuleContext<'input,Window_frame_boundaryContextExt<'input>>;

#[derive(Clone)]
pub struct Window_frame_boundaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Window_frame_boundaryContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Window_frame_boundaryContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_window_frame_boundary(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_window_frame_boundary(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Window_frame_boundaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_window_frame_boundary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_window_frame_boundary }
}
crate::tid!{Window_frame_boundaryContextExt<'a>}

impl<'input> Window_frame_boundaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Window_frame_boundaryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Window_frame_boundaryContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Window_frame_boundaryContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Window_frame_boundaryContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UNBOUNDED
/// Returns `None` if there is no child corresponding to token KW_UNBOUNDED
fn KW_UNBOUNDED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNBOUNDED, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PRECEDING
/// Returns `None` if there is no child corresponding to token KW_PRECEDING
fn KW_PRECEDING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PRECEDING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FOLLOWING
/// Returns `None` if there is no child corresponding to token KW_FOLLOWING
fn KW_FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FOLLOWING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CURRENT
/// Returns `None` if there is no child corresponding to token KW_CURRENT
fn KW_CURRENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CURRENT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROW
/// Returns `None` if there is no child corresponding to token KW_ROW
fn KW_ROW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROW, 0)
}

}

impl<'input> Window_frame_boundaryContextAttrs<'input> for Window_frame_boundaryContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn window_frame_boundary(&mut self,)
	-> Result<Rc<Window_frame_boundaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Window_frame_boundaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 708, RULE_window_frame_boundary);
        let mut _localctx: Rc<Window_frame_boundaryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4331);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_UNBOUNDED | Number 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4327);
					_la = recog.base.input.la(1);
					if { !(_la==KW_UNBOUNDED || _la==Number) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(4328);
					_la = recog.base.input.la(1);
					if { !(_la==KW_FOLLOWING || _la==KW_PRECEDING) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

			 KW_CURRENT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4329);
					recog.base.match_token(KW_CURRENT,&mut recog.err_handler)?;

					recog.base.set_state(4330);
					recog.base.match_token(KW_ROW,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupByClause ----------------
pub type GroupByClauseContextAll<'input> = GroupByClauseContext<'input>;


pub type GroupByClauseContext<'input> = BaseParserRuleContext<'input,GroupByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct GroupByClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for GroupByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for GroupByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupByClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_groupByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for GroupByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupByClause }
}
crate::tid!{GroupByClauseContextExt<'a>}

impl<'input> GroupByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupByClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupByClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<GroupByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_GROUP
/// Returns `None` if there is no child corresponding to token KW_GROUP
fn KW_GROUP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
fn groupby_expression(&self) -> Option<Rc<Groupby_expressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GroupByClauseContextAttrs<'input> for GroupByClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupByClause(&mut self,)
	-> Result<Rc<GroupByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 710, RULE_groupByClause);
        let mut _localctx: Rc<GroupByClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4333);
			recog.base.match_token(KW_GROUP,&mut recog.err_handler)?;

			recog.base.set_state(4334);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			/*InvokeRule groupby_expression*/
			recog.base.set_state(4335);
			recog.groupby_expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupby_expression ----------------
pub type Groupby_expressionContextAll<'input> = Groupby_expressionContext<'input>;


pub type Groupby_expressionContext<'input> = BaseParserRuleContext<'input,Groupby_expressionContextExt<'input>>;

#[derive(Clone)]
pub struct Groupby_expressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Groupby_expressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Groupby_expressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupby_expression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_groupby_expression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Groupby_expressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupby_expression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupby_expression }
}
crate::tid!{Groupby_expressionContextExt<'a>}

impl<'input> Groupby_expressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Groupby_expressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Groupby_expressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Groupby_expressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Groupby_expressionContextExt<'input>>{

fn rollupStandard(&self) -> Option<Rc<RollupStandardContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn rollupOldSyntax(&self) -> Option<Rc<RollupOldSyntaxContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn groupByEmpty(&self) -> Option<Rc<GroupByEmptyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> Groupby_expressionContextAttrs<'input> for Groupby_expressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupby_expression(&mut self,)
	-> Result<Rc<Groupby_expressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Groupby_expressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 712, RULE_groupby_expression);
        let mut _localctx: Rc<Groupby_expressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4340);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(518,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule rollupStandard*/
					recog.base.set_state(4337);
					recog.rollupStandard()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule rollupOldSyntax*/
					recog.base.set_state(4338);
					recog.rollupOldSyntax()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule groupByEmpty*/
					recog.base.set_state(4339);
					recog.groupByEmpty()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupByEmpty ----------------
pub type GroupByEmptyContextAll<'input> = GroupByEmptyContext<'input>;


pub type GroupByEmptyContext<'input> = BaseParserRuleContext<'input,GroupByEmptyContextExt<'input>>;

#[derive(Clone)]
pub struct GroupByEmptyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for GroupByEmptyContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for GroupByEmptyContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupByEmpty(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_groupByEmpty(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for GroupByEmptyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupByEmpty }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupByEmpty }
}
crate::tid!{GroupByEmptyContextExt<'a>}

impl<'input> GroupByEmptyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupByEmptyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupByEmptyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupByEmptyContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<GroupByEmptyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> GroupByEmptyContextAttrs<'input> for GroupByEmptyContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupByEmpty(&mut self,)
	-> Result<Rc<GroupByEmptyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupByEmptyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 714, RULE_groupByEmpty);
        let mut _localctx: Rc<GroupByEmptyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4342);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(4343);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rollupStandard ----------------
pub type RollupStandardContextAll<'input> = RollupStandardContext<'input>;


pub type RollupStandardContext<'input> = BaseParserRuleContext<'input,RollupStandardContextExt<'input>>;

#[derive(Clone)]
pub struct RollupStandardContextExt<'input>{
	pub rollup: Option<TokenType<'input>>,
	pub cube: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RollupStandardContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RollupStandardContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rollupStandard(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rollupStandard(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RollupStandardContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rollupStandard }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rollupStandard }
}
crate::tid!{RollupStandardContextExt<'a>}

impl<'input> RollupStandardContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RollupStandardContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RollupStandardContextExt{
				rollup: None, cube: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RollupStandardContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RollupStandardContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLLUP
/// Returns `None` if there is no child corresponding to token KW_ROLLUP
fn KW_ROLLUP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLLUP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CUBE
/// Returns `None` if there is no child corresponding to token KW_CUBE
fn KW_CUBE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CUBE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> RollupStandardContextAttrs<'input> for RollupStandardContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rollupStandard(&mut self,)
	-> Result<Rc<RollupStandardContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RollupStandardContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 716, RULE_rollupStandard);
        let mut _localctx: Rc<RollupStandardContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4347);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ROLLUP 
				=> {
					{
					recog.base.set_state(4345);
					let tmp = recog.base.match_token(KW_ROLLUP,&mut recog.err_handler)?;
					 cast_mut::<_,RollupStandardContext >(&mut _localctx).rollup = Some(tmp.clone());
					  

					}
				}

			 KW_CUBE 
				=> {
					{
					recog.base.set_state(4346);
					let tmp = recog.base.match_token(KW_CUBE,&mut recog.err_handler)?;
					 cast_mut::<_,RollupStandardContext >(&mut _localctx).cube = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(4349);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(4350);
			recog.expression()?;

			recog.base.set_state(4355);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4351);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(4352);
				recog.expression()?;

				}
				}
				recog.base.set_state(4357);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(4358);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rollupOldSyntax ----------------
pub type RollupOldSyntaxContextAll<'input> = RollupOldSyntaxContext<'input>;


pub type RollupOldSyntaxContext<'input> = BaseParserRuleContext<'input,RollupOldSyntaxContextExt<'input>>;

#[derive(Clone)]
pub struct RollupOldSyntaxContextExt<'input>{
	pub expr: Option<Rc<ExpressionsNotInParenthesisContextAll<'input>>>,
	pub rollup: Option<TokenType<'input>>,
	pub cube: Option<TokenType<'input>>,
	pub sets: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RollupOldSyntaxContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RollupOldSyntaxContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rollupOldSyntax(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rollupOldSyntax(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RollupOldSyntaxContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rollupOldSyntax }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rollupOldSyntax }
}
crate::tid!{RollupOldSyntaxContextExt<'a>}

impl<'input> RollupOldSyntaxContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RollupOldSyntaxContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RollupOldSyntaxContextExt{
				rollup: None, cube: None, sets: None, 
				expr: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RollupOldSyntaxContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RollupOldSyntaxContextExt<'input>>{

fn expressionsNotInParenthesis(&self) -> Option<Rc<ExpressionsNotInParenthesisContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLLUP
/// Returns `None` if there is no child corresponding to token KW_ROLLUP
fn KW_ROLLUP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLLUP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CUBE
/// Returns `None` if there is no child corresponding to token KW_CUBE
fn KW_CUBE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CUBE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SETS
/// Returns `None` if there is no child corresponding to token KW_SETS
fn KW_SETS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SETS, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn groupingSetExpression_all(&self) ->  Vec<Rc<GroupingSetExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn groupingSetExpression(&self, i: usize) -> Option<Rc<GroupingSetExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_GROUPING
/// Returns `None` if there is no child corresponding to token KW_GROUPING
fn KW_GROUPING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GROUPING, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> RollupOldSyntaxContextAttrs<'input> for RollupOldSyntaxContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rollupOldSyntax(&mut self,)
	-> Result<Rc<RollupOldSyntaxContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RollupOldSyntaxContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 718, RULE_rollupOldSyntax);
        let mut _localctx: Rc<RollupOldSyntaxContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expressionsNotInParenthesis*/
			recog.base.set_state(4360);
			let tmp = recog.expressionsNotInParenthesis()?;
			 cast_mut::<_,RollupOldSyntaxContext >(&mut _localctx).expr = Some(tmp.clone());
			  

			recog.base.set_state(4365);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(521,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(4361);
					let tmp = recog.base.match_token(KW_WITH,&mut recog.err_handler)?;
					 cast_mut::<_,RollupOldSyntaxContext >(&mut _localctx).rollup = Some(tmp.clone());
					  

					recog.base.set_state(4362);
					recog.base.match_token(KW_ROLLUP,&mut recog.err_handler)?;

					}
				}

				x if x == 2=>{
					{
					recog.base.set_state(4363);
					let tmp = recog.base.match_token(KW_WITH,&mut recog.err_handler)?;
					 cast_mut::<_,RollupOldSyntaxContext >(&mut _localctx).cube = Some(tmp.clone());
					  

					recog.base.set_state(4364);
					recog.base.match_token(KW_CUBE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			recog.base.set_state(4380);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_GROUPING {
				{
				recog.base.set_state(4367);
				let tmp = recog.base.match_token(KW_GROUPING,&mut recog.err_handler)?;
				 cast_mut::<_,RollupOldSyntaxContext >(&mut _localctx).sets = Some(tmp.clone());
				  

				recog.base.set_state(4368);
				recog.base.match_token(KW_SETS,&mut recog.err_handler)?;

				recog.base.set_state(4369);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				/*InvokeRule groupingSetExpression*/
				recog.base.set_state(4370);
				recog.groupingSetExpression()?;

				recog.base.set_state(4375);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(4371);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule groupingSetExpression*/
					recog.base.set_state(4372);
					recog.groupingSetExpression()?;

					}
					}
					recog.base.set_state(4377);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				recog.base.set_state(4378);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingSetExpression ----------------
pub type GroupingSetExpressionContextAll<'input> = GroupingSetExpressionContext<'input>;


pub type GroupingSetExpressionContext<'input> = BaseParserRuleContext<'input,GroupingSetExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingSetExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for GroupingSetExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for GroupingSetExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupingSetExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_groupingSetExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for GroupingSetExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingSetExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingSetExpression }
}
crate::tid!{GroupingSetExpressionContextExt<'a>}

impl<'input> GroupingSetExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingSetExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingSetExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupingSetExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<GroupingSetExpressionContextExt<'input>>{

fn groupingSetExpressionMultiple(&self) -> Option<Rc<GroupingSetExpressionMultipleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn groupingExpressionSingle(&self) -> Option<Rc<GroupingExpressionSingleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GroupingSetExpressionContextAttrs<'input> for GroupingSetExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingSetExpression(&mut self,)
	-> Result<Rc<GroupingSetExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingSetExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 720, RULE_groupingSetExpression);
        let mut _localctx: Rc<GroupingSetExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4384);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(524,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule groupingSetExpressionMultiple*/
					recog.base.set_state(4382);
					recog.groupingSetExpressionMultiple()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule groupingExpressionSingle*/
					recog.base.set_state(4383);
					recog.groupingExpressionSingle()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingSetExpressionMultiple ----------------
pub type GroupingSetExpressionMultipleContextAll<'input> = GroupingSetExpressionMultipleContext<'input>;


pub type GroupingSetExpressionMultipleContext<'input> = BaseParserRuleContext<'input,GroupingSetExpressionMultipleContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingSetExpressionMultipleContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for GroupingSetExpressionMultipleContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for GroupingSetExpressionMultipleContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupingSetExpressionMultiple(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_groupingSetExpressionMultiple(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for GroupingSetExpressionMultipleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingSetExpressionMultiple }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingSetExpressionMultiple }
}
crate::tid!{GroupingSetExpressionMultipleContextExt<'a>}

impl<'input> GroupingSetExpressionMultipleContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingSetExpressionMultipleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingSetExpressionMultipleContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupingSetExpressionMultipleContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<GroupingSetExpressionMultipleContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> GroupingSetExpressionMultipleContextAttrs<'input> for GroupingSetExpressionMultipleContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingSetExpressionMultiple(&mut self,)
	-> Result<Rc<GroupingSetExpressionMultipleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingSetExpressionMultipleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 722, RULE_groupingSetExpressionMultiple);
        let mut _localctx: Rc<GroupingSetExpressionMultipleContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4386);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(4388);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << KW_ABORT) | (1usize << KW_ACTIVATE) | (1usize << KW_ACTIVE) | (1usize << KW_ADD) | (1usize << KW_ADMIN) | (1usize << KW_AFTER) | (1usize << KW_ALLOC_FRACTION) | (1usize << KW_ANALYZE) | (1usize << KW_ARCHIVE) | (1usize << KW_ARRAY) | (1usize << KW_ASC) | (1usize << KW_AST) | (1usize << KW_AT) | (1usize << KW_AUTOCOMMIT) | (1usize << KW_BATCH) | (1usize << KW_BEFORE) | (1usize << KW_BIGINT) | (1usize << KW_BINARY) | (1usize << KW_BOOLEAN) | (1usize << KW_BUCKET) | (1usize << KW_BUCKETS))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (KW_CACHE - 33)) | (1usize << (KW_CASCADE - 33)) | (1usize << (KW_CASE - 33)) | (1usize << (KW_CAST - 33)) | (1usize << (KW_CBO - 33)) | (1usize << (KW_CHANGE - 33)) | (1usize << (KW_CHECK - 33)) | (1usize << (KW_CLUSTER - 33)) | (1usize << (KW_CLUSTERED - 33)) | (1usize << (KW_CLUSTERSTATUS - 33)) | (1usize << (KW_COLLECTION - 33)) | (1usize << (KW_COLUMNS - 33)) | (1usize << (KW_COMMENT - 33)) | (1usize << (KW_COMPACT - 33)) | (1usize << (KW_COMPACTIONS - 33)) | (1usize << (KW_COMPUTE - 33)) | (1usize << (KW_CONCATENATE - 33)) | (1usize << (KW_CONTINUE - 33)) | (1usize << (KW_COST - 33)) | (1usize << (KW_CRON - 33)) | (1usize << (KW_CURRENT_DATE - 33)) | (1usize << (KW_CURRENT_TIMESTAMP - 33)))) != 0) || ((((_la - 66)) & !0x3f) == 0 && ((1usize << (_la - 66)) & ((1usize << (KW_DATA - 66)) | (1usize << (KW_DATABASES - 66)) | (1usize << (KW_DATE - 66)) | (1usize << (KW_DATETIME - 66)) | (1usize << (KW_DAY - 66)) | (1usize << (KW_DAYOFWEEK - 66)) | (1usize << (KW_DBPROPERTIES - 66)) | (1usize << (KW_DCPROPERTIES - 66)) | (1usize << (KW_DEBUG - 66)) | (1usize << (KW_DEFAULT - 66)) | (1usize << (KW_DEFERRED - 66)) | (1usize << (KW_DEFINED - 66)) | (1usize << (KW_DELIMITED - 66)) | (1usize << (KW_DEPENDENCY - 66)) | (1usize << (KW_DESC - 66)) | (1usize << (KW_DETAIL - 66)) | (1usize << (KW_DIRECTORIES - 66)) | (1usize << (KW_DIRECTORY - 66)) | (1usize << (KW_DISABLE - 66)) | (1usize << (KW_DISTRIBUTE - 66)) | (1usize << (KW_DISTRIBUTED - 66)) | (1usize << (KW_DO - 66)) | (1usize << (KW_DOUBLE - 66)))) != 0) || ((((_la - 98)) & !0x3f) == 0 && ((1usize << (_la - 98)) & ((1usize << (KW_DUMP - 98)) | (1usize << (KW_ELEM_TYPE - 98)) | (1usize << (KW_ENABLE - 98)) | (1usize << (KW_ENFORCED - 98)) | (1usize << (KW_ESCAPED - 98)) | (1usize << (KW_EVERY - 98)) | (1usize << (KW_EXCLUSIVE - 98)) | (1usize << (KW_EXECUTE - 98)) | (1usize << (KW_EXECUTED - 98)) | (1usize << (KW_EXISTS - 98)) | (1usize << (KW_EXPIRE_SNAPSHOTS - 98)) | (1usize << (KW_EXPLAIN - 98)) | (1usize << (KW_EXPORT - 98)) | (1usize << (KW_EXPRESSION - 98)) | (1usize << (KW_EXTRACT - 98)) | (1usize << (KW_FALSE - 98)) | (1usize << (KW_FIELDS - 98)) | (1usize << (KW_FILE - 98)) | (1usize << (KW_FILEFORMAT - 98)) | (1usize << (KW_FIRST - 98)) | (1usize << (KW_FLOAT - 98)) | (1usize << (KW_FLOOR - 98)))) != 0) || ((((_la - 131)) & !0x3f) == 0 && ((1usize << (_la - 131)) & ((1usize << (KW_FORMAT - 131)) | (1usize << (KW_FORMATTED - 131)) | (1usize << (KW_FUNCTIONS - 131)) | (1usize << (KW_GROUPING - 131)) | (1usize << (KW_HOLD_DDLTIME - 131)) | (1usize << (KW_HOUR - 131)) | (1usize << (KW_IDXPROPERTIES - 131)) | (1usize << (KW_IF - 131)) | (1usize << (KW_IGNORE - 131)) | (1usize << (KW_INDEX - 131)) | (1usize << (KW_INDEXES - 131)) | (1usize << (KW_INPATH - 131)) | (1usize << (KW_INPUTDRIVER - 131)) | (1usize << (KW_INPUTFORMAT - 131)) | (1usize << (KW_INT - 131)) | (1usize << (KW_INTERVAL - 131)) | (1usize << (KW_ISOLATION - 131)) | (1usize << (KW_ITEMS - 131)) | (1usize << (KW_JAR - 131)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (KW_JOINCOST - 164)) | (1usize << (KW_KEY - 164)) | (1usize << (KW_KEYS - 164)) | (1usize << (KW_KEY_TYPE - 164)) | (1usize << (KW_KILL - 164)) | (1usize << (KW_LAST - 164)) | (1usize << (KW_LEVEL - 164)) | (1usize << (KW_LIMIT - 164)) | (1usize << (KW_LINES - 164)) | (1usize << (KW_LOAD - 164)) | (1usize << (KW_LOCATION - 164)) | (1usize << (KW_LOCK - 164)) | (1usize << (KW_LOCKS - 164)) | (1usize << (KW_LOGICAL - 164)) | (1usize << (KW_LONG - 164)) | (1usize << (KW_MANAGED - 164)) | (1usize << (KW_MANAGEDLOCATION - 164)) | (1usize << (KW_MANAGEMENT - 164)) | (1usize << (KW_MAP - 164)) | (1usize << (KW_MAPJOIN - 164)) | (1usize << (KW_MAPPING - 164)) | (1usize << (KW_MATCHED - 164)) | (1usize << (KW_MATERIALIZED - 164)) | (1usize << (KW_METADATA - 164)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (KW_MINUTE - 197)) | (1usize << (KW_MONTH - 197)) | (1usize << (KW_MOVE - 197)) | (1usize << (KW_MSCK - 197)) | (1usize << (KW_NORELY - 197)) | (1usize << (KW_NOSCAN - 197)) | (1usize << (KW_NOT - 197)) | (1usize << (KW_NOVALIDATE - 197)) | (1usize << (KW_NO_DROP - 197)) | (1usize << (KW_NULL - 197)) | (1usize << (KW_NULLS - 197)) | (1usize << (KW_OFFLINE - 197)) | (1usize << (KW_OFFSET - 197)) | (1usize << (KW_OPERATOR - 197)) | (1usize << (KW_OPTION - 197)) | (1usize << (KW_OUTPUTDRIVER - 197)) | (1usize << (KW_OUTPUTFORMAT - 197)) | (1usize << (KW_OVERWRITE - 197)) | (1usize << (KW_OWNER - 197)) | (1usize << (KW_PARTITIONED - 197)) | (1usize << (KW_PARTITIONS - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (KW_PATH - 229)) | (1usize << (KW_PLAN - 229)) | (1usize << (KW_PLANS - 229)) | (1usize << (KW_PLUS - 229)) | (1usize << (KW_POOL - 229)) | (1usize << (KW_PRINCIPALS - 229)) | (1usize << (KW_PROTECTION - 229)) | (1usize << (KW_PURGE - 229)) | (1usize << (KW_QUARTER - 229)) | (1usize << (KW_QUERY - 229)) | (1usize << (KW_QUERY_PARALLELISM - 229)) | (1usize << (KW_READ - 229)) | (1usize << (KW_READONLY - 229)) | (1usize << (KW_REAL - 229)) | (1usize << (KW_REBUILD - 229)) | (1usize << (KW_RECORDREADER - 229)) | (1usize << (KW_RECORDWRITER - 229)) | (1usize << (KW_RELOAD - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (KW_RELY - 261)) | (1usize << (KW_REMOTE - 261)) | (1usize << (KW_RENAME - 261)) | (1usize << (KW_REOPTIMIZATION - 261)) | (1usize << (KW_REPAIR - 261)) | (1usize << (KW_REPL - 261)) | (1usize << (KW_REPLACE - 261)) | (1usize << (KW_REPLICATION - 261)) | (1usize << (KW_RESOURCE - 261)) | (1usize << (KW_RESPECT - 261)) | (1usize << (KW_RESTRICT - 261)) | (1usize << (KW_REWRITE - 261)) | (1usize << (KW_ROLE - 261)) | (1usize << (KW_ROLES - 261)) | (1usize << (KW_SCHEDULED - 261)) | (1usize << (KW_SCHEDULING_POLICY - 261)) | (1usize << (KW_SCHEMA - 261)) | (1usize << (KW_SCHEMAS - 261)) | (1usize << (KW_SECOND - 261)) | (1usize << (KW_SEMI - 261)) | (1usize << (KW_SERDE - 261)) | (1usize << (KW_SERDEPROPERTIES - 261)) | (1usize << (KW_SERVER - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (KW_SETS - 293)) | (1usize << (KW_SET_CURRENT_SNAPSHOT - 293)) | (1usize << (KW_SHARED - 293)) | (1usize << (KW_SHOW - 293)) | (1usize << (KW_SHOW_DATABASE - 293)) | (1usize << (KW_SKEWED - 293)) | (1usize << (KW_SMALLINT - 293)) | (1usize << (KW_SNAPSHOT - 293)) | (1usize << (KW_SORT - 293)) | (1usize << (KW_SORTED - 293)) | (1usize << (KW_SPEC - 293)) | (1usize << (KW_SSL - 293)) | (1usize << (KW_STATISTICS - 293)) | (1usize << (KW_STATUS - 293)) | (1usize << (KW_STORED - 293)) | (1usize << (KW_STREAMTABLE - 293)) | (1usize << (KW_STRING - 293)) | (1usize << (KW_STRUCT - 293)) | (1usize << (KW_SUMMARY - 293)) | (1usize << (KW_SYSTEM_TIME - 293)) | (1usize << (KW_SYSTEM_VERSION - 293)) | (1usize << (KW_TABLES - 293)) | (1usize << (KW_TBLPROPERTIES - 293)) | (1usize << (KW_TEMPORARY - 293)) | (1usize << (KW_TERMINATED - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (KW_TIMESTAMP - 325)) | (1usize << (KW_TIMESTAMPLOCALTZ - 325)) | (1usize << (KW_TIMESTAMPTZ - 325)) | (1usize << (KW_TINYINT - 325)) | (1usize << (KW_TOUCH - 325)) | (1usize << (KW_TRANSACTION - 325)) | (1usize << (KW_TRANSACTIONAL - 325)) | (1usize << (KW_TRANSACTIONS - 325)) | (1usize << (KW_TRIM - 325)) | (1usize << (KW_TRUE - 325)) | (1usize << (KW_TYPE - 325)) | (1usize << (KW_UNARCHIVE - 325)) | (1usize << (KW_UNDO - 325)) | (1usize << (KW_UNIONTYPE - 325)) | (1usize << (KW_UNKNOWN - 325)) | (1usize << (KW_UNLOCK - 325)) | (1usize << (KW_UNMANAGED - 325)) | (1usize << (KW_UNSET - 325)) | (1usize << (KW_UNSIGNED - 325)) | (1usize << (KW_URI - 325)) | (1usize << (KW_URL - 325)) | (1usize << (KW_USE - 325)))) != 0) || ((((_la - 359)) & !0x3f) == 0 && ((1usize << (_la - 359)) & ((1usize << (KW_UTC - 359)) | (1usize << (KW_UTCTIMESTAMP - 359)) | (1usize << (KW_VALIDATE - 359)) | (1usize << (KW_VALUE_TYPE - 359)) | (1usize << (KW_VECTORIZATION - 359)) | (1usize << (KW_VIEW - 359)) | (1usize << (KW_VIEWS - 359)) | (1usize << (KW_WAIT - 359)) | (1usize << (KW_WEEK - 359)) | (1usize << (KW_WHILE - 359)) | (1usize << (KW_WITHIN - 359)) | (1usize << (KW_WORK - 359)) | (1usize << (KW_WORKLOAD - 359)) | (1usize << (KW_WRITE - 359)) | (1usize << (KW_YEAR - 359)) | (1usize << (KW_ZONE - 359)) | (1usize << (LPAREN - 359)))) != 0) || ((((_la - 399)) & !0x3f) == 0 && ((1usize << (_la - 399)) & ((1usize << (PLUS - 399)) | (1usize << (MINUS - 399)) | (1usize << (TILDE - 399)) | (1usize << (QUESTION - 399)) | (1usize << (StringLiteral - 399)) | (1usize << (IntegralLiteral - 399)) | (1usize << (NumberLiteral - 399)) | (1usize << (Number - 399)) | (1usize << (Identifier - 399)) | (1usize << (CharSetName - 399)))) != 0) {
				{
				/*InvokeRule expression*/
				recog.base.set_state(4387);
				recog.expression()?;

				}
			}

			recog.base.set_state(4394);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4390);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(4391);
				recog.expression()?;

				}
				}
				recog.base.set_state(4396);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(4397);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingExpressionSingle ----------------
pub type GroupingExpressionSingleContextAll<'input> = GroupingExpressionSingleContext<'input>;


pub type GroupingExpressionSingleContext<'input> = BaseParserRuleContext<'input,GroupingExpressionSingleContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingExpressionSingleContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for GroupingExpressionSingleContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for GroupingExpressionSingleContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupingExpressionSingle(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_groupingExpressionSingle(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for GroupingExpressionSingleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingExpressionSingle }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingExpressionSingle }
}
crate::tid!{GroupingExpressionSingleContextExt<'a>}

impl<'input> GroupingExpressionSingleContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingExpressionSingleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingExpressionSingleContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupingExpressionSingleContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<GroupingExpressionSingleContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GroupingExpressionSingleContextAttrs<'input> for GroupingExpressionSingleContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingExpressionSingle(&mut self,)
	-> Result<Rc<GroupingExpressionSingleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingExpressionSingleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 724, RULE_groupingExpressionSingle);
        let mut _localctx: Rc<GroupingExpressionSingleContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(4399);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- havingClause ----------------
pub type HavingClauseContextAll<'input> = HavingClauseContext<'input>;


pub type HavingClauseContext<'input> = BaseParserRuleContext<'input,HavingClauseContextExt<'input>>;

#[derive(Clone)]
pub struct HavingClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for HavingClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for HavingClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_havingClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_havingClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for HavingClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_havingClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_havingClause }
}
crate::tid!{HavingClauseContextExt<'a>}

impl<'input> HavingClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HavingClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HavingClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait HavingClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<HavingClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_HAVING
/// Returns `None` if there is no child corresponding to token KW_HAVING
fn KW_HAVING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_HAVING, 0)
}
fn havingCondition(&self) -> Option<Rc<HavingConditionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> HavingClauseContextAttrs<'input> for HavingClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn havingClause(&mut self,)
	-> Result<Rc<HavingClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HavingClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 726, RULE_havingClause);
        let mut _localctx: Rc<HavingClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4401);
			recog.base.match_token(KW_HAVING,&mut recog.err_handler)?;

			/*InvokeRule havingCondition*/
			recog.base.set_state(4402);
			recog.havingCondition()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- qualifyClause ----------------
pub type QualifyClauseContextAll<'input> = QualifyClauseContext<'input>;


pub type QualifyClauseContext<'input> = BaseParserRuleContext<'input,QualifyClauseContextExt<'input>>;

#[derive(Clone)]
pub struct QualifyClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for QualifyClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for QualifyClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_qualifyClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_qualifyClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for QualifyClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_qualifyClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_qualifyClause }
}
crate::tid!{QualifyClauseContextExt<'a>}

impl<'input> QualifyClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QualifyClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QualifyClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QualifyClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<QualifyClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_QUALIFY
/// Returns `None` if there is no child corresponding to token KW_QUALIFY
fn KW_QUALIFY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUALIFY, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QualifyClauseContextAttrs<'input> for QualifyClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn qualifyClause(&mut self,)
	-> Result<Rc<QualifyClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QualifyClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 728, RULE_qualifyClause);
        let mut _localctx: Rc<QualifyClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4404);
			recog.base.match_token(KW_QUALIFY,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(4405);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- havingCondition ----------------
pub type HavingConditionContextAll<'input> = HavingConditionContext<'input>;


pub type HavingConditionContext<'input> = BaseParserRuleContext<'input,HavingConditionContextExt<'input>>;

#[derive(Clone)]
pub struct HavingConditionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for HavingConditionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for HavingConditionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_havingCondition(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_havingCondition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for HavingConditionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_havingCondition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_havingCondition }
}
crate::tid!{HavingConditionContextExt<'a>}

impl<'input> HavingConditionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HavingConditionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HavingConditionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait HavingConditionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<HavingConditionContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> HavingConditionContextAttrs<'input> for HavingConditionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn havingCondition(&mut self,)
	-> Result<Rc<HavingConditionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HavingConditionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 730, RULE_havingCondition);
        let mut _localctx: Rc<HavingConditionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(4407);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expressionsInParenthesis ----------------
pub type ExpressionsInParenthesisContextAll<'input> = ExpressionsInParenthesisContext<'input>;


pub type ExpressionsInParenthesisContext<'input> = BaseParserRuleContext<'input,ExpressionsInParenthesisContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionsInParenthesisContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExpressionsInParenthesisContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExpressionsInParenthesisContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expressionsInParenthesis(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_expressionsInParenthesis(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExpressionsInParenthesisContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionsInParenthesis }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionsInParenthesis }
}
crate::tid!{ExpressionsInParenthesisContextExt<'a>}

impl<'input> ExpressionsInParenthesisContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionsInParenthesisContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionsInParenthesisContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionsInParenthesisContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExpressionsInParenthesisContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn expressionsNotInParenthesis(&self) -> Option<Rc<ExpressionsNotInParenthesisContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> ExpressionsInParenthesisContextAttrs<'input> for ExpressionsInParenthesisContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expressionsInParenthesis(&mut self,)
	-> Result<Rc<ExpressionsInParenthesisContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionsInParenthesisContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 732, RULE_expressionsInParenthesis);
        let mut _localctx: Rc<ExpressionsInParenthesisContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4409);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule expressionsNotInParenthesis*/
			recog.base.set_state(4410);
			recog.expressionsNotInParenthesis()?;

			recog.base.set_state(4411);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expressionsNotInParenthesis ----------------
pub type ExpressionsNotInParenthesisContextAll<'input> = ExpressionsNotInParenthesisContext<'input>;


pub type ExpressionsNotInParenthesisContext<'input> = BaseParserRuleContext<'input,ExpressionsNotInParenthesisContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionsNotInParenthesisContextExt<'input>{
	pub first: Option<Rc<ExpressionOrDefaultContextAll<'input>>>,
	pub more: Option<Rc<ExpressionPartContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExpressionsNotInParenthesisContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExpressionsNotInParenthesisContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expressionsNotInParenthesis(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_expressionsNotInParenthesis(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExpressionsNotInParenthesisContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionsNotInParenthesis }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionsNotInParenthesis }
}
crate::tid!{ExpressionsNotInParenthesisContextExt<'a>}

impl<'input> ExpressionsNotInParenthesisContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionsNotInParenthesisContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionsNotInParenthesisContextExt{
				first: None, more: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionsNotInParenthesisContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExpressionsNotInParenthesisContextExt<'input>>{

fn expressionOrDefault(&self) -> Option<Rc<ExpressionOrDefaultContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expressionPart(&self) -> Option<Rc<ExpressionPartContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExpressionsNotInParenthesisContextAttrs<'input> for ExpressionsNotInParenthesisContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expressionsNotInParenthesis(&mut self,)
	-> Result<Rc<ExpressionsNotInParenthesisContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionsNotInParenthesisContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 734, RULE_expressionsNotInParenthesis);
        let mut _localctx: Rc<ExpressionsNotInParenthesisContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expressionOrDefault*/
			recog.base.set_state(4413);
			let tmp = recog.expressionOrDefault()?;
			 cast_mut::<_,ExpressionsNotInParenthesisContext >(&mut _localctx).first = Some(tmp.clone());
			  

			recog.base.set_state(4415);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				/*InvokeRule expressionPart*/
				recog.base.set_state(4414);
				let tmp = recog.expressionPart()?;
				 cast_mut::<_,ExpressionsNotInParenthesisContext >(&mut _localctx).more = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expressionPart ----------------
pub type ExpressionPartContextAll<'input> = ExpressionPartContext<'input>;


pub type ExpressionPartContext<'input> = BaseParserRuleContext<'input,ExpressionPartContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionPartContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExpressionPartContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExpressionPartContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expressionPart(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_expressionPart(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExpressionPartContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionPart }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionPart }
}
crate::tid!{ExpressionPartContextExt<'a>}

impl<'input> ExpressionPartContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionPartContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionPartContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionPartContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExpressionPartContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn expressionOrDefault_all(&self) ->  Vec<Rc<ExpressionOrDefaultContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expressionOrDefault(&self, i: usize) -> Option<Rc<ExpressionOrDefaultContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ExpressionPartContextAttrs<'input> for ExpressionPartContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expressionPart(&mut self,)
	-> Result<Rc<ExpressionPartContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionPartContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 736, RULE_expressionPart);
        let mut _localctx: Rc<ExpressionPartContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4419); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				recog.base.set_state(4417);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule expressionOrDefault*/
				recog.base.set_state(4418);
				recog.expressionOrDefault()?;

				}
				}
				recog.base.set_state(4421); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==COMMA) {break}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expressionOrDefault ----------------
pub type ExpressionOrDefaultContextAll<'input> = ExpressionOrDefaultContext<'input>;


pub type ExpressionOrDefaultContext<'input> = BaseParserRuleContext<'input,ExpressionOrDefaultContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionOrDefaultContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExpressionOrDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExpressionOrDefaultContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expressionOrDefault(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_expressionOrDefault(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExpressionOrDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionOrDefault }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionOrDefault }
}
crate::tid!{ExpressionOrDefaultContextExt<'a>}

impl<'input> ExpressionOrDefaultContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionOrDefaultContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionOrDefaultContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionOrDefaultContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExpressionOrDefaultContextExt<'input>>{

fn defaultValue(&self) -> Option<Rc<DefaultValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExpressionOrDefaultContextAttrs<'input> for ExpressionOrDefaultContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expressionOrDefault(&mut self,)
	-> Result<Rc<ExpressionOrDefaultContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionOrDefaultContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 738, RULE_expressionOrDefault);
        let mut _localctx: Rc<ExpressionOrDefaultContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4425);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(529,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule defaultValue*/
					recog.base.set_state(4423);
					recog.defaultValue()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule expression*/
					recog.base.set_state(4424);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- firstExpressionsWithAlias ----------------
pub type FirstExpressionsWithAliasContextAll<'input> = FirstExpressionsWithAliasContext<'input>;


pub type FirstExpressionsWithAliasContext<'input> = BaseParserRuleContext<'input,FirstExpressionsWithAliasContextExt<'input>>;

#[derive(Clone)]
pub struct FirstExpressionsWithAliasContextExt<'input>{
	pub first: Option<Rc<ExpressionContextAll<'input>>>,
	pub colAlias: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for FirstExpressionsWithAliasContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for FirstExpressionsWithAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_firstExpressionsWithAlias(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_firstExpressionsWithAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for FirstExpressionsWithAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_firstExpressionsWithAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_firstExpressionsWithAlias }
}
crate::tid!{FirstExpressionsWithAliasContextExt<'a>}

impl<'input> FirstExpressionsWithAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FirstExpressionsWithAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FirstExpressionsWithAliasContextExt{
				first: None, colAlias: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FirstExpressionsWithAliasContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<FirstExpressionsWithAliasContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn expressionWithAlias_all(&self) ->  Vec<Rc<ExpressionWithAliasContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expressionWithAlias(&self, i: usize) -> Option<Rc<ExpressionWithAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FirstExpressionsWithAliasContextAttrs<'input> for FirstExpressionsWithAliasContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn firstExpressionsWithAlias(&mut self,)
	-> Result<Rc<FirstExpressionsWithAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FirstExpressionsWithAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 740, RULE_firstExpressionsWithAlias);
        let mut _localctx: Rc<FirstExpressionsWithAliasContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(4427);
			let tmp = recog.expression()?;
			 cast_mut::<_,FirstExpressionsWithAliasContext >(&mut _localctx).first = Some(tmp.clone());
			  

			recog.base.set_state(4429);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_AS {
				{
				recog.base.set_state(4428);
				recog.base.match_token(KW_AS,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(4432);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << KW_ABORT) | (1usize << KW_ACTIVATE) | (1usize << KW_ACTIVE) | (1usize << KW_ADD) | (1usize << KW_ADMIN) | (1usize << KW_AFTER) | (1usize << KW_ALLOC_FRACTION) | (1usize << KW_ANALYZE) | (1usize << KW_ARCHIVE) | (1usize << KW_ASC) | (1usize << KW_AST) | (1usize << KW_AT) | (1usize << KW_AUTOCOMMIT) | (1usize << KW_BATCH) | (1usize << KW_BEFORE) | (1usize << KW_BUCKET) | (1usize << KW_BUCKETS))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (KW_CACHE - 33)) | (1usize << (KW_CASCADE - 33)) | (1usize << (KW_CBO - 33)) | (1usize << (KW_CHANGE - 33)) | (1usize << (KW_CHECK - 33)) | (1usize << (KW_CLUSTER - 33)) | (1usize << (KW_CLUSTERED - 33)) | (1usize << (KW_CLUSTERSTATUS - 33)) | (1usize << (KW_COLLECTION - 33)) | (1usize << (KW_COLUMNS - 33)) | (1usize << (KW_COMMENT - 33)) | (1usize << (KW_COMPACT - 33)) | (1usize << (KW_COMPACTIONS - 33)) | (1usize << (KW_COMPUTE - 33)) | (1usize << (KW_CONCATENATE - 33)) | (1usize << (KW_CONTINUE - 33)) | (1usize << (KW_COST - 33)) | (1usize << (KW_CRON - 33)))) != 0) || ((((_la - 66)) & !0x3f) == 0 && ((1usize << (_la - 66)) & ((1usize << (KW_DATA - 66)) | (1usize << (KW_DATABASES - 66)) | (1usize << (KW_DATETIME - 66)) | (1usize << (KW_DAY - 66)) | (1usize << (KW_DAYOFWEEK - 66)) | (1usize << (KW_DBPROPERTIES - 66)) | (1usize << (KW_DCPROPERTIES - 66)) | (1usize << (KW_DEBUG - 66)) | (1usize << (KW_DEFAULT - 66)) | (1usize << (KW_DEFERRED - 66)) | (1usize << (KW_DEFINED - 66)) | (1usize << (KW_DELIMITED - 66)) | (1usize << (KW_DEPENDENCY - 66)) | (1usize << (KW_DESC - 66)) | (1usize << (KW_DETAIL - 66)) | (1usize << (KW_DIRECTORIES - 66)) | (1usize << (KW_DIRECTORY - 66)) | (1usize << (KW_DISABLE - 66)) | (1usize << (KW_DISTRIBUTE - 66)) | (1usize << (KW_DISTRIBUTED - 66)) | (1usize << (KW_DO - 66)))) != 0) || ((((_la - 98)) & !0x3f) == 0 && ((1usize << (_la - 98)) & ((1usize << (KW_DUMP - 98)) | (1usize << (KW_ELEM_TYPE - 98)) | (1usize << (KW_ENABLE - 98)) | (1usize << (KW_ENFORCED - 98)) | (1usize << (KW_ESCAPED - 98)) | (1usize << (KW_EVERY - 98)) | (1usize << (KW_EXCLUSIVE - 98)) | (1usize << (KW_EXECUTE - 98)) | (1usize << (KW_EXECUTED - 98)) | (1usize << (KW_EXPIRE_SNAPSHOTS - 98)) | (1usize << (KW_EXPLAIN - 98)) | (1usize << (KW_EXPORT - 98)) | (1usize << (KW_EXPRESSION - 98)) | (1usize << (KW_FIELDS - 98)) | (1usize << (KW_FILE - 98)) | (1usize << (KW_FILEFORMAT - 98)) | (1usize << (KW_FIRST - 98)))) != 0) || ((((_la - 131)) & !0x3f) == 0 && ((1usize << (_la - 131)) & ((1usize << (KW_FORMAT - 131)) | (1usize << (KW_FORMATTED - 131)) | (1usize << (KW_FUNCTIONS - 131)) | (1usize << (KW_HOLD_DDLTIME - 131)) | (1usize << (KW_HOUR - 131)) | (1usize << (KW_IDXPROPERTIES - 131)) | (1usize << (KW_IGNORE - 131)) | (1usize << (KW_INDEX - 131)) | (1usize << (KW_INDEXES - 131)) | (1usize << (KW_INPATH - 131)) | (1usize << (KW_INPUTDRIVER - 131)) | (1usize << (KW_INPUTFORMAT - 131)) | (1usize << (KW_ISOLATION - 131)) | (1usize << (KW_ITEMS - 131)) | (1usize << (KW_JAR - 131)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (KW_JOINCOST - 164)) | (1usize << (KW_KEY - 164)) | (1usize << (KW_KEYS - 164)) | (1usize << (KW_KEY_TYPE - 164)) | (1usize << (KW_KILL - 164)) | (1usize << (KW_LAST - 164)) | (1usize << (KW_LEVEL - 164)) | (1usize << (KW_LIMIT - 164)) | (1usize << (KW_LINES - 164)) | (1usize << (KW_LOAD - 164)) | (1usize << (KW_LOCATION - 164)) | (1usize << (KW_LOCK - 164)) | (1usize << (KW_LOCKS - 164)) | (1usize << (KW_LOGICAL - 164)) | (1usize << (KW_LONG - 164)) | (1usize << (KW_MANAGED - 164)) | (1usize << (KW_MANAGEDLOCATION - 164)) | (1usize << (KW_MANAGEMENT - 164)) | (1usize << (KW_MAPJOIN - 164)) | (1usize << (KW_MAPPING - 164)) | (1usize << (KW_MATCHED - 164)) | (1usize << (KW_MATERIALIZED - 164)) | (1usize << (KW_METADATA - 164)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (KW_MINUTE - 197)) | (1usize << (KW_MONTH - 197)) | (1usize << (KW_MOVE - 197)) | (1usize << (KW_MSCK - 197)) | (1usize << (KW_NORELY - 197)) | (1usize << (KW_NOSCAN - 197)) | (1usize << (KW_NOVALIDATE - 197)) | (1usize << (KW_NO_DROP - 197)) | (1usize << (KW_NULLS - 197)) | (1usize << (KW_OFFLINE - 197)) | (1usize << (KW_OFFSET - 197)) | (1usize << (KW_OPERATOR - 197)) | (1usize << (KW_OPTION - 197)) | (1usize << (KW_OUTPUTDRIVER - 197)) | (1usize << (KW_OUTPUTFORMAT - 197)) | (1usize << (KW_OVERWRITE - 197)) | (1usize << (KW_OWNER - 197)) | (1usize << (KW_PARTITIONED - 197)) | (1usize << (KW_PARTITIONS - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (KW_PATH - 229)) | (1usize << (KW_PLAN - 229)) | (1usize << (KW_PLANS - 229)) | (1usize << (KW_PLUS - 229)) | (1usize << (KW_POOL - 229)) | (1usize << (KW_PRINCIPALS - 229)) | (1usize << (KW_PROTECTION - 229)) | (1usize << (KW_PURGE - 229)) | (1usize << (KW_QUARTER - 229)) | (1usize << (KW_QUERY - 229)) | (1usize << (KW_QUERY_PARALLELISM - 229)) | (1usize << (KW_READ - 229)) | (1usize << (KW_READONLY - 229)) | (1usize << (KW_REBUILD - 229)) | (1usize << (KW_RECORDREADER - 229)) | (1usize << (KW_RECORDWRITER - 229)) | (1usize << (KW_RELOAD - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (KW_RELY - 261)) | (1usize << (KW_REMOTE - 261)) | (1usize << (KW_RENAME - 261)) | (1usize << (KW_REOPTIMIZATION - 261)) | (1usize << (KW_REPAIR - 261)) | (1usize << (KW_REPL - 261)) | (1usize << (KW_REPLACE - 261)) | (1usize << (KW_REPLICATION - 261)) | (1usize << (KW_RESOURCE - 261)) | (1usize << (KW_RESPECT - 261)) | (1usize << (KW_RESTRICT - 261)) | (1usize << (KW_REWRITE - 261)) | (1usize << (KW_ROLE - 261)) | (1usize << (KW_ROLES - 261)) | (1usize << (KW_SCHEDULED - 261)) | (1usize << (KW_SCHEDULING_POLICY - 261)) | (1usize << (KW_SCHEMA - 261)) | (1usize << (KW_SCHEMAS - 261)) | (1usize << (KW_SECOND - 261)) | (1usize << (KW_SEMI - 261)) | (1usize << (KW_SERDE - 261)) | (1usize << (KW_SERDEPROPERTIES - 261)) | (1usize << (KW_SERVER - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (KW_SETS - 293)) | (1usize << (KW_SET_CURRENT_SNAPSHOT - 293)) | (1usize << (KW_SHARED - 293)) | (1usize << (KW_SHOW - 293)) | (1usize << (KW_SHOW_DATABASE - 293)) | (1usize << (KW_SKEWED - 293)) | (1usize << (KW_SNAPSHOT - 293)) | (1usize << (KW_SORT - 293)) | (1usize << (KW_SORTED - 293)) | (1usize << (KW_SPEC - 293)) | (1usize << (KW_SSL - 293)) | (1usize << (KW_STATISTICS - 293)) | (1usize << (KW_STATUS - 293)) | (1usize << (KW_STORED - 293)) | (1usize << (KW_STREAMTABLE - 293)) | (1usize << (KW_STRING - 293)) | (1usize << (KW_STRUCT - 293)) | (1usize << (KW_SUMMARY - 293)) | (1usize << (KW_SYSTEM_TIME - 293)) | (1usize << (KW_SYSTEM_VERSION - 293)) | (1usize << (KW_TABLES - 293)) | (1usize << (KW_TBLPROPERTIES - 293)) | (1usize << (KW_TEMPORARY - 293)) | (1usize << (KW_TERMINATED - 293)))) != 0) || ((((_la - 327)) & !0x3f) == 0 && ((1usize << (_la - 327)) & ((1usize << (KW_TIMESTAMPTZ - 327)) | (1usize << (KW_TINYINT - 327)) | (1usize << (KW_TOUCH - 327)) | (1usize << (KW_TRANSACTION - 327)) | (1usize << (KW_TRANSACTIONAL - 327)) | (1usize << (KW_TRANSACTIONS - 327)) | (1usize << (KW_TRIM - 327)) | (1usize << (KW_TYPE - 327)) | (1usize << (KW_UNARCHIVE - 327)) | (1usize << (KW_UNDO - 327)) | (1usize << (KW_UNIONTYPE - 327)) | (1usize << (KW_UNKNOWN - 327)) | (1usize << (KW_UNLOCK - 327)) | (1usize << (KW_UNMANAGED - 327)) | (1usize << (KW_UNSET - 327)) | (1usize << (KW_UNSIGNED - 327)) | (1usize << (KW_URI - 327)) | (1usize << (KW_URL - 327)) | (1usize << (KW_USE - 327)))) != 0) || ((((_la - 359)) & !0x3f) == 0 && ((1usize << (_la - 359)) & ((1usize << (KW_UTC - 359)) | (1usize << (KW_UTCTIMESTAMP - 359)) | (1usize << (KW_VALIDATE - 359)) | (1usize << (KW_VALUE_TYPE - 359)) | (1usize << (KW_VECTORIZATION - 359)) | (1usize << (KW_VIEW - 359)) | (1usize << (KW_VIEWS - 359)) | (1usize << (KW_WAIT - 359)) | (1usize << (KW_WEEK - 359)) | (1usize << (KW_WHILE - 359)) | (1usize << (KW_WITHIN - 359)) | (1usize << (KW_WORK - 359)) | (1usize << (KW_WORKLOAD - 359)) | (1usize << (KW_WRITE - 359)) | (1usize << (KW_YEAR - 359)) | (1usize << (KW_ZONE - 359)))) != 0) || _la==Identifier {
				{
				/*InvokeRule id_*/
				recog.base.set_state(4431);
				let tmp = recog.id_()?;
				 cast_mut::<_,FirstExpressionsWithAliasContext >(&mut _localctx).colAlias = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(4438);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4434);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule expressionWithAlias*/
				recog.base.set_state(4435);
				recog.expressionWithAlias()?;

				}
				}
				recog.base.set_state(4440);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expressionWithAlias ----------------
pub type ExpressionWithAliasContextAll<'input> = ExpressionWithAliasContext<'input>;


pub type ExpressionWithAliasContext<'input> = BaseParserRuleContext<'input,ExpressionWithAliasContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionWithAliasContextExt<'input>{
	pub alias: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExpressionWithAliasContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExpressionWithAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expressionWithAlias(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_expressionWithAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExpressionWithAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionWithAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionWithAlias }
}
crate::tid!{ExpressionWithAliasContextExt<'a>}

impl<'input> ExpressionWithAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionWithAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionWithAliasContextExt{
				alias: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionWithAliasContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExpressionWithAliasContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExpressionWithAliasContextAttrs<'input> for ExpressionWithAliasContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expressionWithAlias(&mut self,)
	-> Result<Rc<ExpressionWithAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionWithAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 742, RULE_expressionWithAlias);
        let mut _localctx: Rc<ExpressionWithAliasContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(4441);
			recog.expression()?;

			recog.base.set_state(4443);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_AS {
				{
				recog.base.set_state(4442);
				recog.base.match_token(KW_AS,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(4446);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << KW_ABORT) | (1usize << KW_ACTIVATE) | (1usize << KW_ACTIVE) | (1usize << KW_ADD) | (1usize << KW_ADMIN) | (1usize << KW_AFTER) | (1usize << KW_ALLOC_FRACTION) | (1usize << KW_ANALYZE) | (1usize << KW_ARCHIVE) | (1usize << KW_ASC) | (1usize << KW_AST) | (1usize << KW_AT) | (1usize << KW_AUTOCOMMIT) | (1usize << KW_BATCH) | (1usize << KW_BEFORE) | (1usize << KW_BUCKET) | (1usize << KW_BUCKETS))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (KW_CACHE - 33)) | (1usize << (KW_CASCADE - 33)) | (1usize << (KW_CBO - 33)) | (1usize << (KW_CHANGE - 33)) | (1usize << (KW_CHECK - 33)) | (1usize << (KW_CLUSTER - 33)) | (1usize << (KW_CLUSTERED - 33)) | (1usize << (KW_CLUSTERSTATUS - 33)) | (1usize << (KW_COLLECTION - 33)) | (1usize << (KW_COLUMNS - 33)) | (1usize << (KW_COMMENT - 33)) | (1usize << (KW_COMPACT - 33)) | (1usize << (KW_COMPACTIONS - 33)) | (1usize << (KW_COMPUTE - 33)) | (1usize << (KW_CONCATENATE - 33)) | (1usize << (KW_CONTINUE - 33)) | (1usize << (KW_COST - 33)) | (1usize << (KW_CRON - 33)))) != 0) || ((((_la - 66)) & !0x3f) == 0 && ((1usize << (_la - 66)) & ((1usize << (KW_DATA - 66)) | (1usize << (KW_DATABASES - 66)) | (1usize << (KW_DATETIME - 66)) | (1usize << (KW_DAY - 66)) | (1usize << (KW_DAYOFWEEK - 66)) | (1usize << (KW_DBPROPERTIES - 66)) | (1usize << (KW_DCPROPERTIES - 66)) | (1usize << (KW_DEBUG - 66)) | (1usize << (KW_DEFAULT - 66)) | (1usize << (KW_DEFERRED - 66)) | (1usize << (KW_DEFINED - 66)) | (1usize << (KW_DELIMITED - 66)) | (1usize << (KW_DEPENDENCY - 66)) | (1usize << (KW_DESC - 66)) | (1usize << (KW_DETAIL - 66)) | (1usize << (KW_DIRECTORIES - 66)) | (1usize << (KW_DIRECTORY - 66)) | (1usize << (KW_DISABLE - 66)) | (1usize << (KW_DISTRIBUTE - 66)) | (1usize << (KW_DISTRIBUTED - 66)) | (1usize << (KW_DO - 66)))) != 0) || ((((_la - 98)) & !0x3f) == 0 && ((1usize << (_la - 98)) & ((1usize << (KW_DUMP - 98)) | (1usize << (KW_ELEM_TYPE - 98)) | (1usize << (KW_ENABLE - 98)) | (1usize << (KW_ENFORCED - 98)) | (1usize << (KW_ESCAPED - 98)) | (1usize << (KW_EVERY - 98)) | (1usize << (KW_EXCLUSIVE - 98)) | (1usize << (KW_EXECUTE - 98)) | (1usize << (KW_EXECUTED - 98)) | (1usize << (KW_EXPIRE_SNAPSHOTS - 98)) | (1usize << (KW_EXPLAIN - 98)) | (1usize << (KW_EXPORT - 98)) | (1usize << (KW_EXPRESSION - 98)) | (1usize << (KW_FIELDS - 98)) | (1usize << (KW_FILE - 98)) | (1usize << (KW_FILEFORMAT - 98)) | (1usize << (KW_FIRST - 98)))) != 0) || ((((_la - 131)) & !0x3f) == 0 && ((1usize << (_la - 131)) & ((1usize << (KW_FORMAT - 131)) | (1usize << (KW_FORMATTED - 131)) | (1usize << (KW_FUNCTIONS - 131)) | (1usize << (KW_HOLD_DDLTIME - 131)) | (1usize << (KW_HOUR - 131)) | (1usize << (KW_IDXPROPERTIES - 131)) | (1usize << (KW_IGNORE - 131)) | (1usize << (KW_INDEX - 131)) | (1usize << (KW_INDEXES - 131)) | (1usize << (KW_INPATH - 131)) | (1usize << (KW_INPUTDRIVER - 131)) | (1usize << (KW_INPUTFORMAT - 131)) | (1usize << (KW_ISOLATION - 131)) | (1usize << (KW_ITEMS - 131)) | (1usize << (KW_JAR - 131)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (KW_JOINCOST - 164)) | (1usize << (KW_KEY - 164)) | (1usize << (KW_KEYS - 164)) | (1usize << (KW_KEY_TYPE - 164)) | (1usize << (KW_KILL - 164)) | (1usize << (KW_LAST - 164)) | (1usize << (KW_LEVEL - 164)) | (1usize << (KW_LIMIT - 164)) | (1usize << (KW_LINES - 164)) | (1usize << (KW_LOAD - 164)) | (1usize << (KW_LOCATION - 164)) | (1usize << (KW_LOCK - 164)) | (1usize << (KW_LOCKS - 164)) | (1usize << (KW_LOGICAL - 164)) | (1usize << (KW_LONG - 164)) | (1usize << (KW_MANAGED - 164)) | (1usize << (KW_MANAGEDLOCATION - 164)) | (1usize << (KW_MANAGEMENT - 164)) | (1usize << (KW_MAPJOIN - 164)) | (1usize << (KW_MAPPING - 164)) | (1usize << (KW_MATCHED - 164)) | (1usize << (KW_MATERIALIZED - 164)) | (1usize << (KW_METADATA - 164)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (KW_MINUTE - 197)) | (1usize << (KW_MONTH - 197)) | (1usize << (KW_MOVE - 197)) | (1usize << (KW_MSCK - 197)) | (1usize << (KW_NORELY - 197)) | (1usize << (KW_NOSCAN - 197)) | (1usize << (KW_NOVALIDATE - 197)) | (1usize << (KW_NO_DROP - 197)) | (1usize << (KW_NULLS - 197)) | (1usize << (KW_OFFLINE - 197)) | (1usize << (KW_OFFSET - 197)) | (1usize << (KW_OPERATOR - 197)) | (1usize << (KW_OPTION - 197)) | (1usize << (KW_OUTPUTDRIVER - 197)) | (1usize << (KW_OUTPUTFORMAT - 197)) | (1usize << (KW_OVERWRITE - 197)) | (1usize << (KW_OWNER - 197)) | (1usize << (KW_PARTITIONED - 197)) | (1usize << (KW_PARTITIONS - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (KW_PATH - 229)) | (1usize << (KW_PLAN - 229)) | (1usize << (KW_PLANS - 229)) | (1usize << (KW_PLUS - 229)) | (1usize << (KW_POOL - 229)) | (1usize << (KW_PRINCIPALS - 229)) | (1usize << (KW_PROTECTION - 229)) | (1usize << (KW_PURGE - 229)) | (1usize << (KW_QUARTER - 229)) | (1usize << (KW_QUERY - 229)) | (1usize << (KW_QUERY_PARALLELISM - 229)) | (1usize << (KW_READ - 229)) | (1usize << (KW_READONLY - 229)) | (1usize << (KW_REBUILD - 229)) | (1usize << (KW_RECORDREADER - 229)) | (1usize << (KW_RECORDWRITER - 229)) | (1usize << (KW_RELOAD - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (KW_RELY - 261)) | (1usize << (KW_REMOTE - 261)) | (1usize << (KW_RENAME - 261)) | (1usize << (KW_REOPTIMIZATION - 261)) | (1usize << (KW_REPAIR - 261)) | (1usize << (KW_REPL - 261)) | (1usize << (KW_REPLACE - 261)) | (1usize << (KW_REPLICATION - 261)) | (1usize << (KW_RESOURCE - 261)) | (1usize << (KW_RESPECT - 261)) | (1usize << (KW_RESTRICT - 261)) | (1usize << (KW_REWRITE - 261)) | (1usize << (KW_ROLE - 261)) | (1usize << (KW_ROLES - 261)) | (1usize << (KW_SCHEDULED - 261)) | (1usize << (KW_SCHEDULING_POLICY - 261)) | (1usize << (KW_SCHEMA - 261)) | (1usize << (KW_SCHEMAS - 261)) | (1usize << (KW_SECOND - 261)) | (1usize << (KW_SEMI - 261)) | (1usize << (KW_SERDE - 261)) | (1usize << (KW_SERDEPROPERTIES - 261)) | (1usize << (KW_SERVER - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (KW_SETS - 293)) | (1usize << (KW_SET_CURRENT_SNAPSHOT - 293)) | (1usize << (KW_SHARED - 293)) | (1usize << (KW_SHOW - 293)) | (1usize << (KW_SHOW_DATABASE - 293)) | (1usize << (KW_SKEWED - 293)) | (1usize << (KW_SNAPSHOT - 293)) | (1usize << (KW_SORT - 293)) | (1usize << (KW_SORTED - 293)) | (1usize << (KW_SPEC - 293)) | (1usize << (KW_SSL - 293)) | (1usize << (KW_STATISTICS - 293)) | (1usize << (KW_STATUS - 293)) | (1usize << (KW_STORED - 293)) | (1usize << (KW_STREAMTABLE - 293)) | (1usize << (KW_STRING - 293)) | (1usize << (KW_STRUCT - 293)) | (1usize << (KW_SUMMARY - 293)) | (1usize << (KW_SYSTEM_TIME - 293)) | (1usize << (KW_SYSTEM_VERSION - 293)) | (1usize << (KW_TABLES - 293)) | (1usize << (KW_TBLPROPERTIES - 293)) | (1usize << (KW_TEMPORARY - 293)) | (1usize << (KW_TERMINATED - 293)))) != 0) || ((((_la - 327)) & !0x3f) == 0 && ((1usize << (_la - 327)) & ((1usize << (KW_TIMESTAMPTZ - 327)) | (1usize << (KW_TINYINT - 327)) | (1usize << (KW_TOUCH - 327)) | (1usize << (KW_TRANSACTION - 327)) | (1usize << (KW_TRANSACTIONAL - 327)) | (1usize << (KW_TRANSACTIONS - 327)) | (1usize << (KW_TRIM - 327)) | (1usize << (KW_TYPE - 327)) | (1usize << (KW_UNARCHIVE - 327)) | (1usize << (KW_UNDO - 327)) | (1usize << (KW_UNIONTYPE - 327)) | (1usize << (KW_UNKNOWN - 327)) | (1usize << (KW_UNLOCK - 327)) | (1usize << (KW_UNMANAGED - 327)) | (1usize << (KW_UNSET - 327)) | (1usize << (KW_UNSIGNED - 327)) | (1usize << (KW_URI - 327)) | (1usize << (KW_URL - 327)) | (1usize << (KW_USE - 327)))) != 0) || ((((_la - 359)) & !0x3f) == 0 && ((1usize << (_la - 359)) & ((1usize << (KW_UTC - 359)) | (1usize << (KW_UTCTIMESTAMP - 359)) | (1usize << (KW_VALIDATE - 359)) | (1usize << (KW_VALUE_TYPE - 359)) | (1usize << (KW_VECTORIZATION - 359)) | (1usize << (KW_VIEW - 359)) | (1usize << (KW_VIEWS - 359)) | (1usize << (KW_WAIT - 359)) | (1usize << (KW_WEEK - 359)) | (1usize << (KW_WHILE - 359)) | (1usize << (KW_WITHIN - 359)) | (1usize << (KW_WORK - 359)) | (1usize << (KW_WORKLOAD - 359)) | (1usize << (KW_WRITE - 359)) | (1usize << (KW_YEAR - 359)) | (1usize << (KW_ZONE - 359)))) != 0) || _la==Identifier {
				{
				/*InvokeRule id_*/
				recog.base.set_state(4445);
				let tmp = recog.id_()?;
				 cast_mut::<_,ExpressionWithAliasContext >(&mut _localctx).alias = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expressions ----------------
pub type ExpressionsContextAll<'input> = ExpressionsContext<'input>;


pub type ExpressionsContext<'input> = BaseParserRuleContext<'input,ExpressionsContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExpressionsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExpressionsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expressions(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_expressions(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExpressionsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressions }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressions }
}
crate::tid!{ExpressionsContextExt<'a>}

impl<'input> ExpressionsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExpressionsContextExt<'input>>{

fn expressionsInParenthesis(&self) -> Option<Rc<ExpressionsInParenthesisContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expressionsNotInParenthesis(&self) -> Option<Rc<ExpressionsNotInParenthesisContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExpressionsContextAttrs<'input> for ExpressionsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expressions(&mut self,)
	-> Result<Rc<ExpressionsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 744, RULE_expressions);
        let mut _localctx: Rc<ExpressionsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4450);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(535,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule expressionsInParenthesis*/
					recog.base.set_state(4448);
					recog.expressionsInParenthesis()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule expressionsNotInParenthesis*/
					recog.base.set_state(4449);
					recog.expressionsNotInParenthesis()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnRefOrderInParenthesis ----------------
pub type ColumnRefOrderInParenthesisContextAll<'input> = ColumnRefOrderInParenthesisContext<'input>;


pub type ColumnRefOrderInParenthesisContext<'input> = BaseParserRuleContext<'input,ColumnRefOrderInParenthesisContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnRefOrderInParenthesisContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnRefOrderInParenthesisContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnRefOrderInParenthesisContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnRefOrderInParenthesis(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnRefOrderInParenthesis(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnRefOrderInParenthesisContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnRefOrderInParenthesis }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnRefOrderInParenthesis }
}
crate::tid!{ColumnRefOrderInParenthesisContextExt<'a>}

impl<'input> ColumnRefOrderInParenthesisContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnRefOrderInParenthesisContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnRefOrderInParenthesisContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnRefOrderInParenthesisContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnRefOrderInParenthesisContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn columnRefOrder_all(&self) ->  Vec<Rc<ColumnRefOrderContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnRefOrder(&self, i: usize) -> Option<Rc<ColumnRefOrderContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnRefOrderInParenthesisContextAttrs<'input> for ColumnRefOrderInParenthesisContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnRefOrderInParenthesis(&mut self,)
	-> Result<Rc<ColumnRefOrderInParenthesisContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnRefOrderInParenthesisContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 746, RULE_columnRefOrderInParenthesis);
        let mut _localctx: Rc<ColumnRefOrderInParenthesisContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4452);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule columnRefOrder*/
			recog.base.set_state(4453);
			recog.columnRefOrder()?;

			recog.base.set_state(4458);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4454);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnRefOrder*/
				recog.base.set_state(4455);
				recog.columnRefOrder()?;

				}
				}
				recog.base.set_state(4460);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(4461);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnRefOrderNotInParenthesis ----------------
pub type ColumnRefOrderNotInParenthesisContextAll<'input> = ColumnRefOrderNotInParenthesisContext<'input>;


pub type ColumnRefOrderNotInParenthesisContext<'input> = BaseParserRuleContext<'input,ColumnRefOrderNotInParenthesisContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnRefOrderNotInParenthesisContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ColumnRefOrderNotInParenthesisContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ColumnRefOrderNotInParenthesisContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnRefOrderNotInParenthesis(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_columnRefOrderNotInParenthesis(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ColumnRefOrderNotInParenthesisContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnRefOrderNotInParenthesis }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnRefOrderNotInParenthesis }
}
crate::tid!{ColumnRefOrderNotInParenthesisContextExt<'a>}

impl<'input> ColumnRefOrderNotInParenthesisContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnRefOrderNotInParenthesisContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnRefOrderNotInParenthesisContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnRefOrderNotInParenthesisContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ColumnRefOrderNotInParenthesisContextExt<'input>>{

fn columnRefOrder_all(&self) ->  Vec<Rc<ColumnRefOrderContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnRefOrder(&self, i: usize) -> Option<Rc<ColumnRefOrderContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColumnRefOrderNotInParenthesisContextAttrs<'input> for ColumnRefOrderNotInParenthesisContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnRefOrderNotInParenthesis(&mut self,)
	-> Result<Rc<ColumnRefOrderNotInParenthesisContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnRefOrderNotInParenthesisContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 748, RULE_columnRefOrderNotInParenthesis);
        let mut _localctx: Rc<ColumnRefOrderNotInParenthesisContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule columnRefOrder*/
			recog.base.set_state(4463);
			recog.columnRefOrder()?;

			recog.base.set_state(4468);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4464);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnRefOrder*/
				recog.base.set_state(4465);
				recog.columnRefOrder()?;

				}
				}
				recog.base.set_state(4470);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- orderByClause ----------------
pub type OrderByClauseContextAll<'input> = OrderByClauseContext<'input>;


pub type OrderByClauseContext<'input> = BaseParserRuleContext<'input,OrderByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct OrderByClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for OrderByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for OrderByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_orderByClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_orderByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for OrderByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_orderByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_orderByClause }
}
crate::tid!{OrderByClauseContextExt<'a>}

impl<'input> OrderByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OrderByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OrderByClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait OrderByClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<OrderByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ORDER
/// Returns `None` if there is no child corresponding to token KW_ORDER
fn KW_ORDER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
fn columnRefOrder_all(&self) ->  Vec<Rc<ColumnRefOrderContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn columnRefOrder(&self, i: usize) -> Option<Rc<ColumnRefOrderContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> OrderByClauseContextAttrs<'input> for OrderByClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn orderByClause(&mut self,)
	-> Result<Rc<OrderByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OrderByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 750, RULE_orderByClause);
        let mut _localctx: Rc<OrderByClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4471);
			recog.base.match_token(KW_ORDER,&mut recog.err_handler)?;

			recog.base.set_state(4472);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			/*InvokeRule columnRefOrder*/
			recog.base.set_state(4473);
			recog.columnRefOrder()?;

			recog.base.set_state(4478);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4474);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule columnRefOrder*/
				recog.base.set_state(4475);
				recog.columnRefOrder()?;

				}
				}
				recog.base.set_state(4480);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- clusterByClause ----------------
pub type ClusterByClauseContextAll<'input> = ClusterByClauseContext<'input>;


pub type ClusterByClauseContext<'input> = BaseParserRuleContext<'input,ClusterByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ClusterByClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ClusterByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ClusterByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_clusterByClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_clusterByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ClusterByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_clusterByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_clusterByClause }
}
crate::tid!{ClusterByClauseContextExt<'a>}

impl<'input> ClusterByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ClusterByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ClusterByClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ClusterByClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ClusterByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CLUSTER
/// Returns `None` if there is no child corresponding to token KW_CLUSTER
fn KW_CLUSTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
fn expressions(&self) -> Option<Rc<ExpressionsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ClusterByClauseContextAttrs<'input> for ClusterByClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn clusterByClause(&mut self,)
	-> Result<Rc<ClusterByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ClusterByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 752, RULE_clusterByClause);
        let mut _localctx: Rc<ClusterByClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4481);
			recog.base.match_token(KW_CLUSTER,&mut recog.err_handler)?;

			recog.base.set_state(4482);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			/*InvokeRule expressions*/
			recog.base.set_state(4483);
			recog.expressions()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionByClause ----------------
pub type PartitionByClauseContextAll<'input> = PartitionByClauseContext<'input>;


pub type PartitionByClauseContext<'input> = BaseParserRuleContext<'input,PartitionByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionByClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitionByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitionByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionByClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitionByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitionByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionByClause }
}
crate::tid!{PartitionByClauseContextExt<'a>}

impl<'input> PartitionByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionByClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionByClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitionByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_PARTITION
/// Returns `None` if there is no child corresponding to token KW_PARTITION
fn KW_PARTITION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
fn expressions(&self) -> Option<Rc<ExpressionsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionByClauseContextAttrs<'input> for PartitionByClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionByClause(&mut self,)
	-> Result<Rc<PartitionByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 754, RULE_partitionByClause);
        let mut _localctx: Rc<PartitionByClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4485);
			recog.base.match_token(KW_PARTITION,&mut recog.err_handler)?;

			recog.base.set_state(4486);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			/*InvokeRule expressions*/
			recog.base.set_state(4487);
			recog.expressions()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- distributeByClause ----------------
pub type DistributeByClauseContextAll<'input> = DistributeByClauseContext<'input>;


pub type DistributeByClauseContext<'input> = BaseParserRuleContext<'input,DistributeByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct DistributeByClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DistributeByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DistributeByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_distributeByClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_distributeByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DistributeByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_distributeByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_distributeByClause }
}
crate::tid!{DistributeByClauseContextExt<'a>}

impl<'input> DistributeByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DistributeByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DistributeByClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DistributeByClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DistributeByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DISTRIBUTE
/// Returns `None` if there is no child corresponding to token KW_DISTRIBUTE
fn KW_DISTRIBUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISTRIBUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
fn expressions(&self) -> Option<Rc<ExpressionsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DistributeByClauseContextAttrs<'input> for DistributeByClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn distributeByClause(&mut self,)
	-> Result<Rc<DistributeByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DistributeByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 756, RULE_distributeByClause);
        let mut _localctx: Rc<DistributeByClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4489);
			recog.base.match_token(KW_DISTRIBUTE,&mut recog.err_handler)?;

			recog.base.set_state(4490);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			/*InvokeRule expressions*/
			recog.base.set_state(4491);
			recog.expressions()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sortByClause ----------------
pub type SortByClauseContextAll<'input> = SortByClauseContext<'input>;


pub type SortByClauseContext<'input> = BaseParserRuleContext<'input,SortByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct SortByClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SortByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SortByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sortByClause(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_sortByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SortByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sortByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sortByClause }
}
crate::tid!{SortByClauseContextExt<'a>}

impl<'input> SortByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SortByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SortByClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SortByClauseContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SortByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_SORT
/// Returns `None` if there is no child corresponding to token KW_SORT
fn KW_SORT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SORT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BY
/// Returns `None` if there is no child corresponding to token KW_BY
fn KW_BY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BY, 0)
}
fn columnRefOrderInParenthesis(&self) -> Option<Rc<ColumnRefOrderInParenthesisContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnRefOrderNotInParenthesis(&self) -> Option<Rc<ColumnRefOrderNotInParenthesisContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SortByClauseContextAttrs<'input> for SortByClauseContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sortByClause(&mut self,)
	-> Result<Rc<SortByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SortByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 758, RULE_sortByClause);
        let mut _localctx: Rc<SortByClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4493);
			recog.base.match_token(KW_SORT,&mut recog.err_handler)?;

			recog.base.set_state(4494);
			recog.base.match_token(KW_BY,&mut recog.err_handler)?;

			recog.base.set_state(4497);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(539,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule columnRefOrderInParenthesis*/
					recog.base.set_state(4495);
					recog.columnRefOrderInParenthesis()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule columnRefOrderNotInParenthesis*/
					recog.base.set_state(4496);
					recog.columnRefOrderNotInParenthesis()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- trimFunction ----------------
pub type TrimFunctionContextAll<'input> = TrimFunctionContext<'input>;


pub type TrimFunctionContext<'input> = BaseParserRuleContext<'input,TrimFunctionContextExt<'input>>;

#[derive(Clone)]
pub struct TrimFunctionContextExt<'input>{
	pub leading: Option<TokenType<'input>>,
	pub trailing: Option<TokenType<'input>>,
	pub trim_characters: Option<Rc<SelectExpressionContextAll<'input>>>,
	pub str: Option<Rc<SelectExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TrimFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TrimFunctionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_trimFunction(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_trimFunction(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TrimFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_trimFunction }
	//fn type_rule_index() -> usize where Self: Sized { RULE_trimFunction }
}
crate::tid!{TrimFunctionContextExt<'a>}

impl<'input> TrimFunctionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TrimFunctionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TrimFunctionContextExt{
				leading: None, trailing: None, 
				trim_characters: None, str: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TrimFunctionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TrimFunctionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TRIM
/// Returns `None` if there is no child corresponding to token KW_TRIM
fn KW_TRIM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRIM, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn selectExpression_all(&self) ->  Vec<Rc<SelectExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn selectExpression(&self, i: usize) -> Option<Rc<SelectExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_BOTH
/// Returns `None` if there is no child corresponding to token KW_BOTH
fn KW_BOTH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BOTH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LEADING
/// Returns `None` if there is no child corresponding to token KW_LEADING
fn KW_LEADING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LEADING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRAILING
/// Returns `None` if there is no child corresponding to token KW_TRAILING
fn KW_TRAILING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRAILING, 0)
}

}

impl<'input> TrimFunctionContextAttrs<'input> for TrimFunctionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn trimFunction(&mut self,)
	-> Result<Rc<TrimFunctionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TrimFunctionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 760, RULE_trimFunction);
        let mut _localctx: Rc<TrimFunctionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4499);
			recog.base.match_token(KW_TRIM,&mut recog.err_handler)?;

			recog.base.set_state(4500);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			recog.base.set_state(4504);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_LEADING 
				=> {
			    	{
			    	recog.base.set_state(4501);
			    	let tmp = recog.base.match_token(KW_LEADING,&mut recog.err_handler)?;
			    	 cast_mut::<_,TrimFunctionContext >(&mut _localctx).leading = Some(tmp.clone());
			    	  

			    	}
			    }

			 KW_TRAILING 
				=> {
			    	{
			    	recog.base.set_state(4502);
			    	let tmp = recog.base.match_token(KW_TRAILING,&mut recog.err_handler)?;
			    	 cast_mut::<_,TrimFunctionContext >(&mut _localctx).trailing = Some(tmp.clone());
			    	  

			    	}
			    }

			 KW_BOTH 
				=> {
			    	{
			    	recog.base.set_state(4503);
			    	recog.base.match_token(KW_BOTH,&mut recog.err_handler)?;

			    	}
			    }

			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ARRAY | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT |
			 KW_BATCH | KW_BEFORE | KW_BIGINT | KW_BINARY | KW_BOOLEAN | KW_BUCKET |
			 KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CASE | KW_CAST | KW_CBO | KW_CHANGE |
			 KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS | KW_COLLECTION |
			 KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS | KW_COMPUTE |
			 KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_CURRENT_DATE |
			 KW_CURRENT_TIMESTAMP | KW_DATA | KW_DATABASES | KW_DATE | KW_DATETIME |
			 KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES | KW_DCPROPERTIES | KW_DEBUG |
			 KW_DEFAULT | KW_DEFERRED | KW_DEFINED | KW_DELIMITED | KW_DEPENDENCY |
			 KW_DESC | KW_DETAIL | KW_DIRECTORIES | KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE |
			 KW_DISTRIBUTED | KW_DO | KW_DOUBLE | KW_DUMP | KW_ELEM_TYPE | KW_ENABLE |
			 KW_ENFORCED | KW_ESCAPED | KW_EVERY | KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED |
			 KW_EXISTS | KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN | KW_EXPORT | KW_EXPRESSION |
			 KW_EXTRACT | KW_FALSE | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST |
			 KW_FLOAT | KW_FLOOR | KW_FORMAT | KW_FORMATTED | KW_FROM | KW_FUNCTIONS |
			 KW_GROUPING | KW_HOLD_DDLTIME | KW_HOUR | KW_IDXPROPERTIES | KW_IF |
			 KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER | KW_INPUTFORMAT |
			 KW_INT | KW_INTERVAL | KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST |
			 KW_KEY | KW_KEYS | KW_KEY_TYPE | KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT |
			 KW_LINES | KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL |
			 KW_LONG | KW_MANAGED | KW_MANAGEDLOCATION | KW_MANAGEMENT | KW_MAP |
			 KW_MAPJOIN | KW_MAPPING | KW_MATCHED | KW_MATERIALIZED | KW_METADATA |
			 KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK | KW_NORELY | KW_NOSCAN | KW_NOT |
			 KW_NOVALIDATE | KW_NO_DROP | KW_NULL | KW_NULLS | KW_OFFLINE | KW_OFFSET |
			 KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT | KW_OVERWRITE |
			 KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH | KW_PLAN | KW_PLANS |
			 KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION | KW_PURGE | KW_QUARTER |
			 KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY | KW_REAL | KW_REBUILD |
			 KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD | KW_RELY | KW_REMOTE |
			 KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL | KW_REPLACE | KW_REPLICATION |
			 KW_RESOURCE | KW_RESPECT | KW_RESTRICT | KW_REWRITE | KW_ROLE | KW_ROLES |
			 KW_SCHEDULED | KW_SCHEDULING_POLICY | KW_SCHEMA | KW_SCHEMAS | KW_SECOND |
			 KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER | KW_SETS | KW_SET_CURRENT_SNAPSHOT |
			 KW_SHARED | KW_SHOW | KW_SHOW_DATABASE | KW_SKEWED | KW_SMALLINT | KW_SNAPSHOT |
			 KW_SORT | KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS | KW_STATUS |
			 KW_STORED | KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY | KW_SYSTEM_TIME |
			 KW_SYSTEM_VERSION | KW_TABLES | KW_TBLPROPERTIES | KW_TEMPORARY | KW_TERMINATED |
			 KW_TIMESTAMP | KW_TIMESTAMPLOCALTZ | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH |
			 KW_TRANSACTION | KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TRUE |
			 KW_TYPE | KW_UNARCHIVE | KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK |
			 KW_UNMANAGED | KW_UNSET | KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC |
			 KW_UTCTIMESTAMP | KW_VALIDATE | KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW |
			 KW_VIEWS | KW_WAIT | KW_WEEK | KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD |
			 KW_WRITE | KW_YEAR | KW_ZONE | LPAREN | PLUS | MINUS | STAR | TILDE |
			 QUESTION | StringLiteral | IntegralLiteral | NumberLiteral | Number |
			 Identifier | CharSetName 
				=> {
			    }

				_ => {}
			}
			recog.base.set_state(4507);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << KW_ABORT) | (1usize << KW_ACTIVATE) | (1usize << KW_ACTIVE) | (1usize << KW_ADD) | (1usize << KW_ADMIN) | (1usize << KW_AFTER) | (1usize << KW_ALLOC_FRACTION) | (1usize << KW_ANALYZE) | (1usize << KW_ARCHIVE) | (1usize << KW_ARRAY) | (1usize << KW_ASC) | (1usize << KW_AST) | (1usize << KW_AT) | (1usize << KW_AUTOCOMMIT) | (1usize << KW_BATCH) | (1usize << KW_BEFORE) | (1usize << KW_BIGINT) | (1usize << KW_BINARY) | (1usize << KW_BOOLEAN) | (1usize << KW_BUCKET) | (1usize << KW_BUCKETS))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (KW_CACHE - 33)) | (1usize << (KW_CASCADE - 33)) | (1usize << (KW_CASE - 33)) | (1usize << (KW_CAST - 33)) | (1usize << (KW_CBO - 33)) | (1usize << (KW_CHANGE - 33)) | (1usize << (KW_CHECK - 33)) | (1usize << (KW_CLUSTER - 33)) | (1usize << (KW_CLUSTERED - 33)) | (1usize << (KW_CLUSTERSTATUS - 33)) | (1usize << (KW_COLLECTION - 33)) | (1usize << (KW_COLUMNS - 33)) | (1usize << (KW_COMMENT - 33)) | (1usize << (KW_COMPACT - 33)) | (1usize << (KW_COMPACTIONS - 33)) | (1usize << (KW_COMPUTE - 33)) | (1usize << (KW_CONCATENATE - 33)) | (1usize << (KW_CONTINUE - 33)) | (1usize << (KW_COST - 33)) | (1usize << (KW_CRON - 33)) | (1usize << (KW_CURRENT_DATE - 33)) | (1usize << (KW_CURRENT_TIMESTAMP - 33)))) != 0) || ((((_la - 66)) & !0x3f) == 0 && ((1usize << (_la - 66)) & ((1usize << (KW_DATA - 66)) | (1usize << (KW_DATABASES - 66)) | (1usize << (KW_DATE - 66)) | (1usize << (KW_DATETIME - 66)) | (1usize << (KW_DAY - 66)) | (1usize << (KW_DAYOFWEEK - 66)) | (1usize << (KW_DBPROPERTIES - 66)) | (1usize << (KW_DCPROPERTIES - 66)) | (1usize << (KW_DEBUG - 66)) | (1usize << (KW_DEFAULT - 66)) | (1usize << (KW_DEFERRED - 66)) | (1usize << (KW_DEFINED - 66)) | (1usize << (KW_DELIMITED - 66)) | (1usize << (KW_DEPENDENCY - 66)) | (1usize << (KW_DESC - 66)) | (1usize << (KW_DETAIL - 66)) | (1usize << (KW_DIRECTORIES - 66)) | (1usize << (KW_DIRECTORY - 66)) | (1usize << (KW_DISABLE - 66)) | (1usize << (KW_DISTRIBUTE - 66)) | (1usize << (KW_DISTRIBUTED - 66)) | (1usize << (KW_DO - 66)) | (1usize << (KW_DOUBLE - 66)))) != 0) || ((((_la - 98)) & !0x3f) == 0 && ((1usize << (_la - 98)) & ((1usize << (KW_DUMP - 98)) | (1usize << (KW_ELEM_TYPE - 98)) | (1usize << (KW_ENABLE - 98)) | (1usize << (KW_ENFORCED - 98)) | (1usize << (KW_ESCAPED - 98)) | (1usize << (KW_EVERY - 98)) | (1usize << (KW_EXCLUSIVE - 98)) | (1usize << (KW_EXECUTE - 98)) | (1usize << (KW_EXECUTED - 98)) | (1usize << (KW_EXISTS - 98)) | (1usize << (KW_EXPIRE_SNAPSHOTS - 98)) | (1usize << (KW_EXPLAIN - 98)) | (1usize << (KW_EXPORT - 98)) | (1usize << (KW_EXPRESSION - 98)) | (1usize << (KW_EXTRACT - 98)) | (1usize << (KW_FALSE - 98)) | (1usize << (KW_FIELDS - 98)) | (1usize << (KW_FILE - 98)) | (1usize << (KW_FILEFORMAT - 98)) | (1usize << (KW_FIRST - 98)) | (1usize << (KW_FLOAT - 98)) | (1usize << (KW_FLOOR - 98)))) != 0) || ((((_la - 131)) & !0x3f) == 0 && ((1usize << (_la - 131)) & ((1usize << (KW_FORMAT - 131)) | (1usize << (KW_FORMATTED - 131)) | (1usize << (KW_FUNCTIONS - 131)) | (1usize << (KW_GROUPING - 131)) | (1usize << (KW_HOLD_DDLTIME - 131)) | (1usize << (KW_HOUR - 131)) | (1usize << (KW_IDXPROPERTIES - 131)) | (1usize << (KW_IF - 131)) | (1usize << (KW_IGNORE - 131)) | (1usize << (KW_INDEX - 131)) | (1usize << (KW_INDEXES - 131)) | (1usize << (KW_INPATH - 131)) | (1usize << (KW_INPUTDRIVER - 131)) | (1usize << (KW_INPUTFORMAT - 131)) | (1usize << (KW_INT - 131)) | (1usize << (KW_INTERVAL - 131)) | (1usize << (KW_ISOLATION - 131)) | (1usize << (KW_ITEMS - 131)) | (1usize << (KW_JAR - 131)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (KW_JOINCOST - 164)) | (1usize << (KW_KEY - 164)) | (1usize << (KW_KEYS - 164)) | (1usize << (KW_KEY_TYPE - 164)) | (1usize << (KW_KILL - 164)) | (1usize << (KW_LAST - 164)) | (1usize << (KW_LEVEL - 164)) | (1usize << (KW_LIMIT - 164)) | (1usize << (KW_LINES - 164)) | (1usize << (KW_LOAD - 164)) | (1usize << (KW_LOCATION - 164)) | (1usize << (KW_LOCK - 164)) | (1usize << (KW_LOCKS - 164)) | (1usize << (KW_LOGICAL - 164)) | (1usize << (KW_LONG - 164)) | (1usize << (KW_MANAGED - 164)) | (1usize << (KW_MANAGEDLOCATION - 164)) | (1usize << (KW_MANAGEMENT - 164)) | (1usize << (KW_MAP - 164)) | (1usize << (KW_MAPJOIN - 164)) | (1usize << (KW_MAPPING - 164)) | (1usize << (KW_MATCHED - 164)) | (1usize << (KW_MATERIALIZED - 164)) | (1usize << (KW_METADATA - 164)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (KW_MINUTE - 197)) | (1usize << (KW_MONTH - 197)) | (1usize << (KW_MOVE - 197)) | (1usize << (KW_MSCK - 197)) | (1usize << (KW_NORELY - 197)) | (1usize << (KW_NOSCAN - 197)) | (1usize << (KW_NOT - 197)) | (1usize << (KW_NOVALIDATE - 197)) | (1usize << (KW_NO_DROP - 197)) | (1usize << (KW_NULL - 197)) | (1usize << (KW_NULLS - 197)) | (1usize << (KW_OFFLINE - 197)) | (1usize << (KW_OFFSET - 197)) | (1usize << (KW_OPERATOR - 197)) | (1usize << (KW_OPTION - 197)) | (1usize << (KW_OUTPUTDRIVER - 197)) | (1usize << (KW_OUTPUTFORMAT - 197)) | (1usize << (KW_OVERWRITE - 197)) | (1usize << (KW_OWNER - 197)) | (1usize << (KW_PARTITIONED - 197)) | (1usize << (KW_PARTITIONS - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (KW_PATH - 229)) | (1usize << (KW_PLAN - 229)) | (1usize << (KW_PLANS - 229)) | (1usize << (KW_PLUS - 229)) | (1usize << (KW_POOL - 229)) | (1usize << (KW_PRINCIPALS - 229)) | (1usize << (KW_PROTECTION - 229)) | (1usize << (KW_PURGE - 229)) | (1usize << (KW_QUARTER - 229)) | (1usize << (KW_QUERY - 229)) | (1usize << (KW_QUERY_PARALLELISM - 229)) | (1usize << (KW_READ - 229)) | (1usize << (KW_READONLY - 229)) | (1usize << (KW_REAL - 229)) | (1usize << (KW_REBUILD - 229)) | (1usize << (KW_RECORDREADER - 229)) | (1usize << (KW_RECORDWRITER - 229)) | (1usize << (KW_RELOAD - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (KW_RELY - 261)) | (1usize << (KW_REMOTE - 261)) | (1usize << (KW_RENAME - 261)) | (1usize << (KW_REOPTIMIZATION - 261)) | (1usize << (KW_REPAIR - 261)) | (1usize << (KW_REPL - 261)) | (1usize << (KW_REPLACE - 261)) | (1usize << (KW_REPLICATION - 261)) | (1usize << (KW_RESOURCE - 261)) | (1usize << (KW_RESPECT - 261)) | (1usize << (KW_RESTRICT - 261)) | (1usize << (KW_REWRITE - 261)) | (1usize << (KW_ROLE - 261)) | (1usize << (KW_ROLES - 261)) | (1usize << (KW_SCHEDULED - 261)) | (1usize << (KW_SCHEDULING_POLICY - 261)) | (1usize << (KW_SCHEMA - 261)) | (1usize << (KW_SCHEMAS - 261)) | (1usize << (KW_SECOND - 261)) | (1usize << (KW_SEMI - 261)) | (1usize << (KW_SERDE - 261)) | (1usize << (KW_SERDEPROPERTIES - 261)) | (1usize << (KW_SERVER - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (KW_SETS - 293)) | (1usize << (KW_SET_CURRENT_SNAPSHOT - 293)) | (1usize << (KW_SHARED - 293)) | (1usize << (KW_SHOW - 293)) | (1usize << (KW_SHOW_DATABASE - 293)) | (1usize << (KW_SKEWED - 293)) | (1usize << (KW_SMALLINT - 293)) | (1usize << (KW_SNAPSHOT - 293)) | (1usize << (KW_SORT - 293)) | (1usize << (KW_SORTED - 293)) | (1usize << (KW_SPEC - 293)) | (1usize << (KW_SSL - 293)) | (1usize << (KW_STATISTICS - 293)) | (1usize << (KW_STATUS - 293)) | (1usize << (KW_STORED - 293)) | (1usize << (KW_STREAMTABLE - 293)) | (1usize << (KW_STRING - 293)) | (1usize << (KW_STRUCT - 293)) | (1usize << (KW_SUMMARY - 293)) | (1usize << (KW_SYSTEM_TIME - 293)) | (1usize << (KW_SYSTEM_VERSION - 293)) | (1usize << (KW_TABLES - 293)) | (1usize << (KW_TBLPROPERTIES - 293)) | (1usize << (KW_TEMPORARY - 293)) | (1usize << (KW_TERMINATED - 293)))) != 0) || ((((_la - 325)) & !0x3f) == 0 && ((1usize << (_la - 325)) & ((1usize << (KW_TIMESTAMP - 325)) | (1usize << (KW_TIMESTAMPLOCALTZ - 325)) | (1usize << (KW_TIMESTAMPTZ - 325)) | (1usize << (KW_TINYINT - 325)) | (1usize << (KW_TOUCH - 325)) | (1usize << (KW_TRANSACTION - 325)) | (1usize << (KW_TRANSACTIONAL - 325)) | (1usize << (KW_TRANSACTIONS - 325)) | (1usize << (KW_TRIM - 325)) | (1usize << (KW_TRUE - 325)) | (1usize << (KW_TYPE - 325)) | (1usize << (KW_UNARCHIVE - 325)) | (1usize << (KW_UNDO - 325)) | (1usize << (KW_UNIONTYPE - 325)) | (1usize << (KW_UNKNOWN - 325)) | (1usize << (KW_UNLOCK - 325)) | (1usize << (KW_UNMANAGED - 325)) | (1usize << (KW_UNSET - 325)) | (1usize << (KW_UNSIGNED - 325)) | (1usize << (KW_URI - 325)) | (1usize << (KW_URL - 325)) | (1usize << (KW_USE - 325)))) != 0) || ((((_la - 359)) & !0x3f) == 0 && ((1usize << (_la - 359)) & ((1usize << (KW_UTC - 359)) | (1usize << (KW_UTCTIMESTAMP - 359)) | (1usize << (KW_VALIDATE - 359)) | (1usize << (KW_VALUE_TYPE - 359)) | (1usize << (KW_VECTORIZATION - 359)) | (1usize << (KW_VIEW - 359)) | (1usize << (KW_VIEWS - 359)) | (1usize << (KW_WAIT - 359)) | (1usize << (KW_WEEK - 359)) | (1usize << (KW_WHILE - 359)) | (1usize << (KW_WITHIN - 359)) | (1usize << (KW_WORK - 359)) | (1usize << (KW_WORKLOAD - 359)) | (1usize << (KW_WRITE - 359)) | (1usize << (KW_YEAR - 359)) | (1usize << (KW_ZONE - 359)) | (1usize << (LPAREN - 359)))) != 0) || ((((_la - 399)) & !0x3f) == 0 && ((1usize << (_la - 399)) & ((1usize << (PLUS - 399)) | (1usize << (MINUS - 399)) | (1usize << (STAR - 399)) | (1usize << (TILDE - 399)) | (1usize << (QUESTION - 399)) | (1usize << (StringLiteral - 399)) | (1usize << (IntegralLiteral - 399)) | (1usize << (NumberLiteral - 399)) | (1usize << (Number - 399)) | (1usize << (Identifier - 399)) | (1usize << (CharSetName - 399)))) != 0) {
				{
				/*InvokeRule selectExpression*/
				recog.base.set_state(4506);
				let tmp = recog.selectExpression()?;
				 cast_mut::<_,TrimFunctionContext >(&mut _localctx).trim_characters = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(4509);
			recog.base.match_token(KW_FROM,&mut recog.err_handler)?;

			/*InvokeRule selectExpression*/
			recog.base.set_state(4510);
			let tmp = recog.selectExpression()?;
			 cast_mut::<_,TrimFunctionContext >(&mut _localctx).str = Some(tmp.clone());
			  

			recog.base.set_state(4511);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- function_ ----------------
pub type Function_ContextAll<'input> = Function_Context<'input>;


pub type Function_Context<'input> = BaseParserRuleContext<'input,Function_ContextExt<'input>>;

#[derive(Clone)]
pub struct Function_ContextExt<'input>{
	pub star: Option<TokenType<'input>>,
	pub dist: Option<Rc<All_distinctContextAll<'input>>>,
	pub within: Option<TokenType<'input>>,
	pub ordBy: Option<Rc<OrderByClauseContextAll<'input>>>,
	pub nt: Option<Rc<Null_treatmentContextAll<'input>>>,
	pub ws: Option<Rc<Window_specificationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Function_Context<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Function_Context<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_function_(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_function_(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Function_ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_function_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_function_ }
}
crate::tid!{Function_ContextExt<'a>}

impl<'input> Function_ContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Function_ContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Function_ContextExt{
				star: None, within: None, 
				dist: None, ordBy: None, nt: None, ws: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait Function_ContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Function_ContextExt<'input>>{

fn trimFunction(&self) -> Option<Rc<TrimFunctionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn functionName(&self) -> Option<Rc<FunctionNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token LPAREN in current rule
fn LPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LPAREN is less or equal than `i`.
fn LPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RPAREN in current rule
fn RPAREN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RPAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RPAREN is less or equal than `i`.
fn RPAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, i)
}
/// Retrieves first TerminalNode corresponding to token KW_GROUP
/// Returns `None` if there is no child corresponding to token KW_GROUP
fn KW_GROUP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OVER
/// Returns `None` if there is no child corresponding to token KW_OVER
fn KW_OVER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OVER, 0)
}
/// Retrieves first TerminalNode corresponding to token STAR
/// Returns `None` if there is no child corresponding to token STAR
fn STAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(STAR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITHIN
/// Returns `None` if there is no child corresponding to token KW_WITHIN
fn KW_WITHIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITHIN, 0)
}
fn orderByClause(&self) -> Option<Rc<OrderByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn window_specification(&self) -> Option<Rc<Window_specificationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn null_treatment(&self) -> Option<Rc<Null_treatmentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn selectExpression_all(&self) ->  Vec<Rc<SelectExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn selectExpression(&self, i: usize) -> Option<Rc<SelectExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn all_distinct(&self) -> Option<Rc<All_distinctContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> Function_ContextAttrs<'input> for Function_Context<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn function_(&mut self,)
	-> Result<Rc<Function_ContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Function_ContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 762, RULE_function_);
        let mut _localctx: Rc<Function_ContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4553);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(548,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule trimFunction*/
					recog.base.set_state(4513);
					recog.trimFunction()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule functionName*/
					recog.base.set_state(4514);
					recog.functionName()?;

					recog.base.set_state(4515);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					recog.base.set_state(4530);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(545,&mut recog.base)? {
						1 =>{
							{
							recog.base.set_state(4516);
							let tmp = recog.base.match_token(STAR,&mut recog.err_handler)?;
							 cast_mut::<_,Function_Context >(&mut _localctx).star = Some(tmp.clone());
							  

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(4518);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_ALL || _la==KW_DISTINCT {
								{
								/*InvokeRule all_distinct*/
								recog.base.set_state(4517);
								let tmp = recog.all_distinct()?;
								 cast_mut::<_,Function_Context >(&mut _localctx).dist = Some(tmp.clone());
								  

								}
							}

							recog.base.set_state(4528);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(544,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule selectExpression*/
									recog.base.set_state(4520);
									recog.selectExpression()?;

									recog.base.set_state(4525);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
									while _la==COMMA {
										{
										{
										recog.base.set_state(4521);
										recog.base.match_token(COMMA,&mut recog.err_handler)?;

										/*InvokeRule selectExpression*/
										recog.base.set_state(4522);
										recog.selectExpression()?;

										}
										}
										recog.base.set_state(4527);
										recog.err_handler.sync(&mut recog.base)?;
										_la = recog.base.input.la(1);
									}
									}
								}

								_ => {}
							}
							}
						}

						_ => {}
					}
					recog.base.set_state(4551);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(547,&mut recog.base)? {
						1 =>{
							{
							recog.base.set_state(4532);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							recog.base.set_state(4533);
							let tmp = recog.base.match_token(KW_WITHIN,&mut recog.err_handler)?;
							 cast_mut::<_,Function_Context >(&mut _localctx).within = Some(tmp.clone());
							  

							recog.base.set_state(4534);
							recog.base.match_token(KW_GROUP,&mut recog.err_handler)?;

							recog.base.set_state(4535);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule orderByClause*/
							recog.base.set_state(4536);
							let tmp = recog.orderByClause()?;
							 cast_mut::<_,Function_Context >(&mut _localctx).ordBy = Some(tmp.clone());
							  

							recog.base.set_state(4537);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(4539);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							recog.base.set_state(4541);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==KW_IGNORE || _la==KW_RESPECT {
								{
								/*InvokeRule null_treatment*/
								recog.base.set_state(4540);
								let tmp = recog.null_treatment()?;
								 cast_mut::<_,Function_Context >(&mut _localctx).nt = Some(tmp.clone());
								  

								}
							}

							recog.base.set_state(4543);
							recog.base.match_token(KW_OVER,&mut recog.err_handler)?;

							/*InvokeRule window_specification*/
							recog.base.set_state(4544);
							let tmp = recog.window_specification()?;
							 cast_mut::<_,Function_Context >(&mut _localctx).ws = Some(tmp.clone());
							  

							}
						}
					,
						3 =>{
							{
							/*InvokeRule null_treatment*/
							recog.base.set_state(4545);
							let tmp = recog.null_treatment()?;
							 cast_mut::<_,Function_Context >(&mut _localctx).nt = Some(tmp.clone());
							  

							recog.base.set_state(4546);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							recog.base.set_state(4547);
							recog.base.match_token(KW_OVER,&mut recog.err_handler)?;

							/*InvokeRule window_specification*/
							recog.base.set_state(4548);
							let tmp = recog.window_specification()?;
							 cast_mut::<_,Function_Context >(&mut _localctx).ws = Some(tmp.clone());
							  

							}
						}
					,
						4 =>{
							{
							recog.base.set_state(4550);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- null_treatment ----------------
pub type Null_treatmentContextAll<'input> = Null_treatmentContext<'input>;


pub type Null_treatmentContext<'input> = BaseParserRuleContext<'input,Null_treatmentContextExt<'input>>;

#[derive(Clone)]
pub struct Null_treatmentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Null_treatmentContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Null_treatmentContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_null_treatment(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_null_treatment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Null_treatmentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_null_treatment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_null_treatment }
}
crate::tid!{Null_treatmentContextExt<'a>}

impl<'input> Null_treatmentContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Null_treatmentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Null_treatmentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Null_treatmentContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Null_treatmentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_RESPECT
/// Returns `None` if there is no child corresponding to token KW_RESPECT
fn KW_RESPECT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RESPECT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NULLS
/// Returns `None` if there is no child corresponding to token KW_NULLS
fn KW_NULLS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IGNORE
/// Returns `None` if there is no child corresponding to token KW_IGNORE
fn KW_IGNORE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IGNORE, 0)
}

}

impl<'input> Null_treatmentContextAttrs<'input> for Null_treatmentContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn null_treatment(&mut self,)
	-> Result<Rc<Null_treatmentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Null_treatmentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 764, RULE_null_treatment);
        let mut _localctx: Rc<Null_treatmentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4559);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_RESPECT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4555);
					recog.base.match_token(KW_RESPECT,&mut recog.err_handler)?;

					recog.base.set_state(4556);
					recog.base.match_token(KW_NULLS,&mut recog.err_handler)?;

					}
				}

			 KW_IGNORE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4557);
					recog.base.match_token(KW_IGNORE,&mut recog.err_handler)?;

					recog.base.set_state(4558);
					recog.base.match_token(KW_NULLS,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionName ----------------
pub type FunctionNameContextAll<'input> = FunctionNameContext<'input>;


pub type FunctionNameContext<'input> = BaseParserRuleContext<'input,FunctionNameContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for FunctionNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for FunctionNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_functionName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for FunctionNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionName }
}
crate::tid!{FunctionNameContextExt<'a>}

impl<'input> FunctionNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<FunctionNameContextExt<'input>>{

fn functionIdentifier(&self) -> Option<Rc<FunctionIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sql11ReservedKeywordsUsedAsFunctionName(&self) -> Option<Rc<Sql11ReservedKeywordsUsedAsFunctionNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionNameContextAttrs<'input> for FunctionNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionName(&mut self,)
	-> Result<Rc<FunctionNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 766, RULE_functionName);
        let mut _localctx: Rc<FunctionNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4563);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT | KW_BATCH |
			 KW_BEFORE | KW_BUCKET | KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CBO |
			 KW_CHANGE | KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS |
			 KW_COLLECTION | KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS |
			 KW_COMPUTE | KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_DATA |
			 KW_DATABASES | KW_DATETIME | KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES |
			 KW_DCPROPERTIES | KW_DEBUG | KW_DEFAULT | KW_DEFERRED | KW_DEFINED |
			 KW_DELIMITED | KW_DEPENDENCY | KW_DESC | KW_DETAIL | KW_DIRECTORIES |
			 KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE | KW_DISTRIBUTED | KW_DO |
			 KW_DUMP | KW_ELEM_TYPE | KW_ENABLE | KW_ENFORCED | KW_ESCAPED | KW_EVERY |
			 KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED | KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN |
			 KW_EXPORT | KW_EXPRESSION | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST |
			 KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_HOLD_DDLTIME | KW_HOUR |
			 KW_IDXPROPERTIES | KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER |
			 KW_INPUTFORMAT | KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY |
			 KW_KEYS | KW_KEY_TYPE | KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES |
			 KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED |
			 KW_MANAGEDLOCATION | KW_MANAGEMENT | KW_MAPJOIN | KW_MAPPING | KW_MATCHED |
			 KW_MATERIALIZED | KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK |
			 KW_NORELY | KW_NOSCAN | KW_NOVALIDATE | KW_NO_DROP | KW_NULLS | KW_OFFLINE |
			 KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT |
			 KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH |
			 KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION |
			 KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY |
			 KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD | KW_RELY |
			 KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL | KW_REPLACE |
			 KW_REPLICATION | KW_RESOURCE | KW_RESPECT | KW_RESTRICT | KW_REWRITE |
			 KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY | KW_SCHEMA |
			 KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER |
			 KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW | KW_SHOW_DATABASE |
			 KW_SKEWED | KW_SNAPSHOT | KW_SORT | KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS |
			 KW_STATUS | KW_STORED | KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY |
			 KW_SYSTEM_TIME | KW_SYSTEM_VERSION | KW_TABLES | KW_TBLPROPERTIES | KW_TEMPORARY |
			 KW_TERMINATED | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH | KW_TRANSACTION |
			 KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TYPE | KW_UNARCHIVE |
			 KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK | KW_UNMANAGED | KW_UNSET |
			 KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC | KW_UTCTIMESTAMP | KW_VALIDATE |
			 KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW | KW_VIEWS | KW_WAIT | KW_WEEK |
			 KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD | KW_WRITE | KW_YEAR | KW_ZONE |
			 Identifier 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule functionIdentifier*/
					recog.base.set_state(4561);
					recog.functionIdentifier()?;

					}
				}

			 KW_ARRAY | KW_BIGINT | KW_BINARY | KW_BOOLEAN | KW_CURRENT_DATE | KW_CURRENT_TIMESTAMP |
			 KW_DATE | KW_DOUBLE | KW_FLOAT | KW_GROUPING | KW_IF | KW_INT | KW_MAP |
			 KW_REAL | KW_SMALLINT | KW_TIMESTAMP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule sql11ReservedKeywordsUsedAsFunctionName*/
					recog.base.set_state(4562);
					recog.sql11ReservedKeywordsUsedAsFunctionName()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- castExpression ----------------
pub type CastExpressionContextAll<'input> = CastExpressionContext<'input>;


pub type CastExpressionContext<'input> = BaseParserRuleContext<'input,CastExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct CastExpressionContextExt<'input>{
	pub toType: Option<Rc<PrimitiveTypeContextAll<'input>>>,
	pub fmt: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CastExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CastExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_castExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_castExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CastExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_castExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_castExpression }
}
crate::tid!{CastExpressionContextExt<'a>}

impl<'input> CastExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CastExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CastExpressionContextExt{
				fmt: None, 
				toType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CastExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CastExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CAST
/// Returns `None` if there is no child corresponding to token KW_CAST
fn KW_CAST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_AS
/// Returns `None` if there is no child corresponding to token KW_AS
fn KW_AS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AS, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn primitiveType(&self) -> Option<Rc<PrimitiveTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FORMAT
/// Returns `None` if there is no child corresponding to token KW_FORMAT
fn KW_FORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FORMAT, 0)
}

}

impl<'input> CastExpressionContextAttrs<'input> for CastExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn castExpression(&mut self,)
	-> Result<Rc<CastExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CastExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 768, RULE_castExpression);
        let mut _localctx: Rc<CastExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4565);
			recog.base.match_token(KW_CAST,&mut recog.err_handler)?;

			recog.base.set_state(4566);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(4567);
			recog.expression()?;

			recog.base.set_state(4568);
			recog.base.match_token(KW_AS,&mut recog.err_handler)?;

			/*InvokeRule primitiveType*/
			recog.base.set_state(4569);
			let tmp = recog.primitiveType()?;
			 cast_mut::<_,CastExpressionContext >(&mut _localctx).toType = Some(tmp.clone());
			  

			recog.base.set_state(4572);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_FORMAT {
				{
				recog.base.set_state(4570);
				let tmp = recog.base.match_token(KW_FORMAT,&mut recog.err_handler)?;
				 cast_mut::<_,CastExpressionContext >(&mut _localctx).fmt = Some(tmp.clone());
				  

				recog.base.set_state(4571);
				recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(4574);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- caseExpression ----------------
pub type CaseExpressionContextAll<'input> = CaseExpressionContext<'input>;


pub type CaseExpressionContext<'input> = BaseParserRuleContext<'input,CaseExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct CaseExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CaseExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CaseExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_caseExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_caseExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CaseExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_caseExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_caseExpression }
}
crate::tid!{CaseExpressionContextExt<'a>}

impl<'input> CaseExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CaseExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CaseExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CaseExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CaseExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CASE
/// Returns `None` if there is no child corresponding to token KW_CASE
fn KW_CASE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CASE, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_END
/// Returns `None` if there is no child corresponding to token KW_END
fn KW_END(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_END, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_WHEN in current rule
fn KW_WHEN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_WHEN, starting from 0.
/// Returns `None` if number of children corresponding to token KW_WHEN is less or equal than `i`.
fn KW_WHEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WHEN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_THEN in current rule
fn KW_THEN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_THEN, starting from 0.
/// Returns `None` if number of children corresponding to token KW_THEN is less or equal than `i`.
fn KW_THEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_THEN, i)
}
/// Retrieves first TerminalNode corresponding to token KW_ELSE
/// Returns `None` if there is no child corresponding to token KW_ELSE
fn KW_ELSE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ELSE, 0)
}

}

impl<'input> CaseExpressionContextAttrs<'input> for CaseExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn caseExpression(&mut self,)
	-> Result<Rc<CaseExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CaseExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 770, RULE_caseExpression);
        let mut _localctx: Rc<CaseExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4576);
			recog.base.match_token(KW_CASE,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(4577);
			recog.expression()?;

			recog.base.set_state(4583); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				recog.base.set_state(4578);
				recog.base.match_token(KW_WHEN,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(4579);
				recog.expression()?;

				recog.base.set_state(4580);
				recog.base.match_token(KW_THEN,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(4581);
				recog.expression()?;

				}
				}
				recog.base.set_state(4585); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==KW_WHEN) {break}
			}
			recog.base.set_state(4589);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ELSE {
				{
				recog.base.set_state(4587);
				recog.base.match_token(KW_ELSE,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(4588);
				recog.expression()?;

				}
			}

			recog.base.set_state(4591);
			recog.base.match_token(KW_END,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whenExpression ----------------
pub type WhenExpressionContextAll<'input> = WhenExpressionContext<'input>;


pub type WhenExpressionContext<'input> = BaseParserRuleContext<'input,WhenExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct WhenExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for WhenExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for WhenExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whenExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_whenExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for WhenExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whenExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whenExpression }
}
crate::tid!{WhenExpressionContextExt<'a>}

impl<'input> WhenExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhenExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhenExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WhenExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<WhenExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CASE
/// Returns `None` if there is no child corresponding to token KW_CASE
fn KW_CASE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CASE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_END
/// Returns `None` if there is no child corresponding to token KW_END
fn KW_END(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_END, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_WHEN in current rule
fn KW_WHEN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_WHEN, starting from 0.
/// Returns `None` if number of children corresponding to token KW_WHEN is less or equal than `i`.
fn KW_WHEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WHEN, i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_THEN in current rule
fn KW_THEN_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_THEN, starting from 0.
/// Returns `None` if number of children corresponding to token KW_THEN is less or equal than `i`.
fn KW_THEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_THEN, i)
}
/// Retrieves first TerminalNode corresponding to token KW_ELSE
/// Returns `None` if there is no child corresponding to token KW_ELSE
fn KW_ELSE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ELSE, 0)
}

}

impl<'input> WhenExpressionContextAttrs<'input> for WhenExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whenExpression(&mut self,)
	-> Result<Rc<WhenExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhenExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 772, RULE_whenExpression);
        let mut _localctx: Rc<WhenExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4593);
			recog.base.match_token(KW_CASE,&mut recog.err_handler)?;

			recog.base.set_state(4599); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				recog.base.set_state(4594);
				recog.base.match_token(KW_WHEN,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(4595);
				recog.expression()?;

				recog.base.set_state(4596);
				recog.base.match_token(KW_THEN,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(4597);
				recog.expression()?;

				}
				}
				recog.base.set_state(4601); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==KW_WHEN) {break}
			}
			recog.base.set_state(4605);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_ELSE {
				{
				recog.base.set_state(4603);
				recog.base.match_token(KW_ELSE,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(4604);
				recog.expression()?;

				}
			}

			recog.base.set_state(4607);
			recog.base.match_token(KW_END,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- floorExpression ----------------
pub type FloorExpressionContextAll<'input> = FloorExpressionContext<'input>;


pub type FloorExpressionContext<'input> = BaseParserRuleContext<'input,FloorExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct FloorExpressionContextExt<'input>{
	pub floorUnit: Option<Rc<FloorDateQualifiersContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for FloorExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for FloorExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_floorExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_floorExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for FloorExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_floorExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_floorExpression }
}
crate::tid!{FloorExpressionContextExt<'a>}

impl<'input> FloorExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FloorExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FloorExpressionContextExt{
				floorUnit: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FloorExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<FloorExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_FLOOR
/// Returns `None` if there is no child corresponding to token KW_FLOOR
fn KW_FLOOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FLOOR, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
fn floorDateQualifiers(&self) -> Option<Rc<FloorDateQualifiersContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FloorExpressionContextAttrs<'input> for FloorExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn floorExpression(&mut self,)
	-> Result<Rc<FloorExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FloorExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 774, RULE_floorExpression);
        let mut _localctx: Rc<FloorExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4609);
			recog.base.match_token(KW_FLOOR,&mut recog.err_handler)?;

			recog.base.set_state(4610);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(4611);
			recog.expression()?;

			recog.base.set_state(4614);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_TO {
				{
				recog.base.set_state(4612);
				recog.base.match_token(KW_TO,&mut recog.err_handler)?;

				/*InvokeRule floorDateQualifiers*/
				recog.base.set_state(4613);
				let tmp = recog.floorDateQualifiers()?;
				 cast_mut::<_,FloorExpressionContext >(&mut _localctx).floorUnit = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(4616);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- floorDateQualifiers ----------------
pub type FloorDateQualifiersContextAll<'input> = FloorDateQualifiersContext<'input>;


pub type FloorDateQualifiersContext<'input> = BaseParserRuleContext<'input,FloorDateQualifiersContextExt<'input>>;

#[derive(Clone)]
pub struct FloorDateQualifiersContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for FloorDateQualifiersContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for FloorDateQualifiersContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_floorDateQualifiers(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_floorDateQualifiers(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for FloorDateQualifiersContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_floorDateQualifiers }
	//fn type_rule_index() -> usize where Self: Sized { RULE_floorDateQualifiers }
}
crate::tid!{FloorDateQualifiersContextExt<'a>}

impl<'input> FloorDateQualifiersContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FloorDateQualifiersContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FloorDateQualifiersContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FloorDateQualifiersContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<FloorDateQualifiersContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_YEAR
/// Returns `None` if there is no child corresponding to token KW_YEAR
fn KW_YEAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_QUARTER
/// Returns `None` if there is no child corresponding to token KW_QUARTER
fn KW_QUARTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUARTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MONTH
/// Returns `None` if there is no child corresponding to token KW_MONTH
fn KW_MONTH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WEEK
/// Returns `None` if there is no child corresponding to token KW_WEEK
fn KW_WEEK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DAY
/// Returns `None` if there is no child corresponding to token KW_DAY
fn KW_DAY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_HOUR
/// Returns `None` if there is no child corresponding to token KW_HOUR
fn KW_HOUR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MINUTE
/// Returns `None` if there is no child corresponding to token KW_MINUTE
fn KW_MINUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SECOND
/// Returns `None` if there is no child corresponding to token KW_SECOND
fn KW_SECOND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SECOND, 0)
}

}

impl<'input> FloorDateQualifiersContextAttrs<'input> for FloorDateQualifiersContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn floorDateQualifiers(&mut self,)
	-> Result<Rc<FloorDateQualifiersContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FloorDateQualifiersContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 776, RULE_floorDateQualifiers);
        let mut _localctx: Rc<FloorDateQualifiersContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4618);
			_la = recog.base.input.la(1);
			if { !(_la==KW_DAY || _la==KW_HOUR || _la==KW_MINUTE || _la==KW_MONTH || _la==KW_QUARTER || _la==KW_SECOND || _la==KW_WEEK || _la==KW_YEAR) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- extractExpression ----------------
pub type ExtractExpressionContextAll<'input> = ExtractExpressionContext<'input>;


pub type ExtractExpressionContext<'input> = BaseParserRuleContext<'input,ExtractExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ExtractExpressionContextExt<'input>{
	pub timeUnit: Option<Rc<TimeQualifiersContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExtractExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExtractExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_extractExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_extractExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExtractExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_extractExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_extractExpression }
}
crate::tid!{ExtractExpressionContextExt<'a>}

impl<'input> ExtractExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExtractExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExtractExpressionContextExt{
				timeUnit: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExtractExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExtractExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_EXTRACT
/// Returns `None` if there is no child corresponding to token KW_EXTRACT
fn KW_EXTRACT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXTRACT, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn timeQualifiers(&self) -> Option<Rc<TimeQualifiersContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExtractExpressionContextAttrs<'input> for ExtractExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn extractExpression(&mut self,)
	-> Result<Rc<ExtractExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExtractExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 778, RULE_extractExpression);
        let mut _localctx: Rc<ExtractExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4620);
			recog.base.match_token(KW_EXTRACT,&mut recog.err_handler)?;

			recog.base.set_state(4621);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule timeQualifiers*/
			recog.base.set_state(4622);
			let tmp = recog.timeQualifiers()?;
			 cast_mut::<_,ExtractExpressionContext >(&mut _localctx).timeUnit = Some(tmp.clone());
			  

			recog.base.set_state(4623);
			recog.base.match_token(KW_FROM,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(4624);
			recog.expression()?;

			recog.base.set_state(4625);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- timeQualifiers ----------------
pub type TimeQualifiersContextAll<'input> = TimeQualifiersContext<'input>;


pub type TimeQualifiersContext<'input> = BaseParserRuleContext<'input,TimeQualifiersContextExt<'input>>;

#[derive(Clone)]
pub struct TimeQualifiersContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TimeQualifiersContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TimeQualifiersContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_timeQualifiers(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_timeQualifiers(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TimeQualifiersContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_timeQualifiers }
	//fn type_rule_index() -> usize where Self: Sized { RULE_timeQualifiers }
}
crate::tid!{TimeQualifiersContextExt<'a>}

impl<'input> TimeQualifiersContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TimeQualifiersContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TimeQualifiersContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TimeQualifiersContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TimeQualifiersContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_YEAR
/// Returns `None` if there is no child corresponding to token KW_YEAR
fn KW_YEAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_QUARTER
/// Returns `None` if there is no child corresponding to token KW_QUARTER
fn KW_QUARTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUARTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MONTH
/// Returns `None` if there is no child corresponding to token KW_MONTH
fn KW_MONTH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WEEK
/// Returns `None` if there is no child corresponding to token KW_WEEK
fn KW_WEEK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DAY
/// Returns `None` if there is no child corresponding to token KW_DAY
fn KW_DAY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_HOUR
/// Returns `None` if there is no child corresponding to token KW_HOUR
fn KW_HOUR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MINUTE
/// Returns `None` if there is no child corresponding to token KW_MINUTE
fn KW_MINUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SECOND
/// Returns `None` if there is no child corresponding to token KW_SECOND
fn KW_SECOND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SECOND, 0)
}

}

impl<'input> TimeQualifiersContextAttrs<'input> for TimeQualifiersContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn timeQualifiers(&mut self,)
	-> Result<Rc<TimeQualifiersContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TimeQualifiersContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 780, RULE_timeQualifiers);
        let mut _localctx: Rc<TimeQualifiersContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4627);
			_la = recog.base.input.la(1);
			if { !(_la==KW_DAY || _la==KW_HOUR || _la==KW_MINUTE || _la==KW_MONTH || _la==KW_QUARTER || _la==KW_SECOND || _la==KW_WEEK || _la==KW_YEAR) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- constant ----------------
pub type ConstantContextAll<'input> = ConstantContext<'input>;


pub type ConstantContext<'input> = BaseParserRuleContext<'input,ConstantContextExt<'input>>;

#[derive(Clone)]
pub struct ConstantContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ConstantContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ConstantContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_constant(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_constant(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ConstantContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}
crate::tid!{ConstantContextExt<'a>}

impl<'input> ConstantContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConstantContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConstantContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ConstantContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ConstantContextExt<'input>>{

fn intervalLiteral(&self) -> Option<Rc<IntervalLiteralContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}
fn dateLiteral(&self) -> Option<Rc<DateLiteralContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn timestampLiteral(&self) -> Option<Rc<TimestampLiteralContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn timestampLocalTZLiteral(&self) -> Option<Rc<TimestampLocalTZLiteralContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn stringLiteralSequence(&self) -> Option<Rc<StringLiteralSequenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token IntegralLiteral
/// Returns `None` if there is no child corresponding to token IntegralLiteral
fn IntegralLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(IntegralLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token NumberLiteral
/// Returns `None` if there is no child corresponding to token NumberLiteral
fn NumberLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(NumberLiteral, 0)
}
fn charSetStringLiteral(&self) -> Option<Rc<CharSetStringLiteralContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn booleanValue(&self) -> Option<Rc<BooleanValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_NULL
/// Returns `None` if there is no child corresponding to token KW_NULL
fn KW_NULL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NULL, 0)
}
fn prepareStmtParam(&self) -> Option<Rc<PrepareStmtParamContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ConstantContextAttrs<'input> for ConstantContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn constant(&mut self,)
	-> Result<Rc<ConstantContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConstantContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 782, RULE_constant);
        let mut _localctx: Rc<ConstantContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4642);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(557,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule intervalLiteral*/
					recog.base.set_state(4629);
					recog.intervalLiteral()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4630);
					recog.base.match_token(Number,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule dateLiteral*/
					recog.base.set_state(4631);
					recog.dateLiteral()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule timestampLiteral*/
					recog.base.set_state(4632);
					recog.timestampLiteral()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule timestampLocalTZLiteral*/
					recog.base.set_state(4633);
					recog.timestampLocalTZLiteral()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(4634);
					recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule stringLiteralSequence*/
					recog.base.set_state(4635);
					recog.stringLiteralSequence()?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(4636);
					recog.base.match_token(IntegralLiteral,&mut recog.err_handler)?;

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					recog.base.set_state(4637);
					recog.base.match_token(NumberLiteral,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule charSetStringLiteral*/
					recog.base.set_state(4638);
					recog.charSetStringLiteral()?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule booleanValue*/
					recog.base.set_state(4639);
					recog.booleanValue()?;

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					recog.base.set_state(4640);
					recog.base.match_token(KW_NULL,&mut recog.err_handler)?;

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					/*InvokeRule prepareStmtParam*/
					recog.base.set_state(4641);
					recog.prepareStmtParam()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- prepareStmtParam ----------------
pub type PrepareStmtParamContextAll<'input> = PrepareStmtParamContext<'input>;


pub type PrepareStmtParamContext<'input> = BaseParserRuleContext<'input,PrepareStmtParamContextExt<'input>>;

#[derive(Clone)]
pub struct PrepareStmtParamContextExt<'input>{
	pub p: Option<Rc<ParameterIdxContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrepareStmtParamContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrepareStmtParamContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_prepareStmtParam(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_prepareStmtParam(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrepareStmtParamContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_prepareStmtParam }
	//fn type_rule_index() -> usize where Self: Sized { RULE_prepareStmtParam }
}
crate::tid!{PrepareStmtParamContextExt<'a>}

impl<'input> PrepareStmtParamContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrepareStmtParamContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrepareStmtParamContextExt{
				p: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrepareStmtParamContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrepareStmtParamContextExt<'input>>{

fn parameterIdx(&self) -> Option<Rc<ParameterIdxContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrepareStmtParamContextAttrs<'input> for PrepareStmtParamContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn prepareStmtParam(&mut self,)
	-> Result<Rc<PrepareStmtParamContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrepareStmtParamContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 784, RULE_prepareStmtParam);
        let mut _localctx: Rc<PrepareStmtParamContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule parameterIdx*/
			recog.base.set_state(4644);
			let tmp = recog.parameterIdx()?;
			 cast_mut::<_,PrepareStmtParamContext >(&mut _localctx).p = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parameterIdx ----------------
pub type ParameterIdxContextAll<'input> = ParameterIdxContext<'input>;


pub type ParameterIdxContext<'input> = BaseParserRuleContext<'input,ParameterIdxContextExt<'input>>;

#[derive(Clone)]
pub struct ParameterIdxContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ParameterIdxContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ParameterIdxContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parameterIdx(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_parameterIdx(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ParameterIdxContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parameterIdx }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parameterIdx }
}
crate::tid!{ParameterIdxContextExt<'a>}

impl<'input> ParameterIdxContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParameterIdxContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParameterIdxContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ParameterIdxContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ParameterIdxContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token QUESTION
/// Returns `None` if there is no child corresponding to token QUESTION
fn QUESTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(QUESTION, 0)
}

}

impl<'input> ParameterIdxContextAttrs<'input> for ParameterIdxContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parameterIdx(&mut self,)
	-> Result<Rc<ParameterIdxContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParameterIdxContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 786, RULE_parameterIdx);
        let mut _localctx: Rc<ParameterIdxContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4646);
			recog.base.match_token(QUESTION,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- stringLiteralSequence ----------------
pub type StringLiteralSequenceContextAll<'input> = StringLiteralSequenceContext<'input>;


pub type StringLiteralSequenceContext<'input> = BaseParserRuleContext<'input,StringLiteralSequenceContextExt<'input>>;

#[derive(Clone)]
pub struct StringLiteralSequenceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for StringLiteralSequenceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for StringLiteralSequenceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_stringLiteralSequence(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_stringLiteralSequence(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for StringLiteralSequenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_stringLiteralSequence }
	//fn type_rule_index() -> usize where Self: Sized { RULE_stringLiteralSequence }
}
crate::tid!{StringLiteralSequenceContextExt<'a>}

impl<'input> StringLiteralSequenceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StringLiteralSequenceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StringLiteralSequenceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StringLiteralSequenceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<StringLiteralSequenceContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token StringLiteral in current rule
fn StringLiteral_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token StringLiteral, starting from 0.
/// Returns `None` if number of children corresponding to token StringLiteral is less or equal than `i`.
fn StringLiteral(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, i)
}

}

impl<'input> StringLiteralSequenceContextAttrs<'input> for StringLiteralSequenceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn stringLiteralSequence(&mut self,)
	-> Result<Rc<StringLiteralSequenceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StringLiteralSequenceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 788, RULE_stringLiteralSequence);
        let mut _localctx: Rc<StringLiteralSequenceContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4648);
			recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

			recog.base.set_state(4650); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				recog.base.set_state(4649);
				recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

				}
				}
				recog.base.set_state(4652); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==StringLiteral) {break}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- charSetStringLiteral ----------------
pub type CharSetStringLiteralContextAll<'input> = CharSetStringLiteralContext<'input>;


pub type CharSetStringLiteralContext<'input> = BaseParserRuleContext<'input,CharSetStringLiteralContextExt<'input>>;

#[derive(Clone)]
pub struct CharSetStringLiteralContextExt<'input>{
	pub csName: Option<TokenType<'input>>,
	pub csLiteral: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CharSetStringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CharSetStringLiteralContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_charSetStringLiteral(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_charSetStringLiteral(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CharSetStringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_charSetStringLiteral }
	//fn type_rule_index() -> usize where Self: Sized { RULE_charSetStringLiteral }
}
crate::tid!{CharSetStringLiteralContextExt<'a>}

impl<'input> CharSetStringLiteralContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CharSetStringLiteralContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CharSetStringLiteralContextExt{
				csName: None, csLiteral: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CharSetStringLiteralContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CharSetStringLiteralContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CharSetName
/// Returns `None` if there is no child corresponding to token CharSetName
fn CharSetName(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(CharSetName, 0)
}
/// Retrieves first TerminalNode corresponding to token CharSetLiteral
/// Returns `None` if there is no child corresponding to token CharSetLiteral
fn CharSetLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(CharSetLiteral, 0)
}

}

impl<'input> CharSetStringLiteralContextAttrs<'input> for CharSetStringLiteralContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn charSetStringLiteral(&mut self,)
	-> Result<Rc<CharSetStringLiteralContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CharSetStringLiteralContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 790, RULE_charSetStringLiteral);
        let mut _localctx: Rc<CharSetStringLiteralContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4654);
			let tmp = recog.base.match_token(CharSetName,&mut recog.err_handler)?;
			 cast_mut::<_,CharSetStringLiteralContext >(&mut _localctx).csName = Some(tmp.clone());
			  

			recog.base.set_state(4655);
			let tmp = recog.base.match_token(CharSetLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,CharSetStringLiteralContext >(&mut _localctx).csLiteral = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dateLiteral ----------------
pub type DateLiteralContextAll<'input> = DateLiteralContext<'input>;


pub type DateLiteralContext<'input> = BaseParserRuleContext<'input,DateLiteralContextExt<'input>>;

#[derive(Clone)]
pub struct DateLiteralContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DateLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DateLiteralContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dateLiteral(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dateLiteral(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DateLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dateLiteral }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dateLiteral }
}
crate::tid!{DateLiteralContextExt<'a>}

impl<'input> DateLiteralContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DateLiteralContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DateLiteralContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DateLiteralContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DateLiteralContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DATE
/// Returns `None` if there is no child corresponding to token KW_DATE
fn KW_DATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CURRENT_DATE
/// Returns `None` if there is no child corresponding to token KW_CURRENT_DATE
fn KW_CURRENT_DATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CURRENT_DATE, 0)
}

}

impl<'input> DateLiteralContextAttrs<'input> for DateLiteralContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dateLiteral(&mut self,)
	-> Result<Rc<DateLiteralContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DateLiteralContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 792, RULE_dateLiteral);
        let mut _localctx: Rc<DateLiteralContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4660);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_DATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4657);
					recog.base.match_token(KW_DATE,&mut recog.err_handler)?;

					recog.base.set_state(4658);
					recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

					}
				}

			 KW_CURRENT_DATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4659);
					recog.base.match_token(KW_CURRENT_DATE,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- timestampLiteral ----------------
pub type TimestampLiteralContextAll<'input> = TimestampLiteralContext<'input>;


pub type TimestampLiteralContext<'input> = BaseParserRuleContext<'input,TimestampLiteralContextExt<'input>>;

#[derive(Clone)]
pub struct TimestampLiteralContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TimestampLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TimestampLiteralContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_timestampLiteral(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_timestampLiteral(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TimestampLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_timestampLiteral }
	//fn type_rule_index() -> usize where Self: Sized { RULE_timestampLiteral }
}
crate::tid!{TimestampLiteralContextExt<'a>}

impl<'input> TimestampLiteralContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TimestampLiteralContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TimestampLiteralContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TimestampLiteralContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TimestampLiteralContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TIMESTAMP
/// Returns `None` if there is no child corresponding to token KW_TIMESTAMP
fn KW_TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CURRENT_TIMESTAMP
/// Returns `None` if there is no child corresponding to token KW_CURRENT_TIMESTAMP
fn KW_CURRENT_TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CURRENT_TIMESTAMP, 0)
}

}

impl<'input> TimestampLiteralContextAttrs<'input> for TimestampLiteralContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn timestampLiteral(&mut self,)
	-> Result<Rc<TimestampLiteralContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TimestampLiteralContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 794, RULE_timestampLiteral);
        let mut _localctx: Rc<TimestampLiteralContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4665);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_TIMESTAMP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4662);
					recog.base.match_token(KW_TIMESTAMP,&mut recog.err_handler)?;

					recog.base.set_state(4663);
					recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

					}
				}

			 KW_CURRENT_TIMESTAMP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4664);
					recog.base.match_token(KW_CURRENT_TIMESTAMP,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- timestampLocalTZLiteral ----------------
pub type TimestampLocalTZLiteralContextAll<'input> = TimestampLocalTZLiteralContext<'input>;


pub type TimestampLocalTZLiteralContext<'input> = BaseParserRuleContext<'input,TimestampLocalTZLiteralContextExt<'input>>;

#[derive(Clone)]
pub struct TimestampLocalTZLiteralContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TimestampLocalTZLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TimestampLocalTZLiteralContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_timestampLocalTZLiteral(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_timestampLocalTZLiteral(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TimestampLocalTZLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_timestampLocalTZLiteral }
	//fn type_rule_index() -> usize where Self: Sized { RULE_timestampLocalTZLiteral }
}
crate::tid!{TimestampLocalTZLiteralContextExt<'a>}

impl<'input> TimestampLocalTZLiteralContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TimestampLocalTZLiteralContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TimestampLocalTZLiteralContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TimestampLocalTZLiteralContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TimestampLocalTZLiteralContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TIMESTAMPLOCALTZ
/// Returns `None` if there is no child corresponding to token KW_TIMESTAMPLOCALTZ
fn KW_TIMESTAMPLOCALTZ(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TIMESTAMPLOCALTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> TimestampLocalTZLiteralContextAttrs<'input> for TimestampLocalTZLiteralContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn timestampLocalTZLiteral(&mut self,)
	-> Result<Rc<TimestampLocalTZLiteralContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TimestampLocalTZLiteralContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 796, RULE_timestampLocalTZLiteral);
        let mut _localctx: Rc<TimestampLocalTZLiteralContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4667);
			recog.base.match_token(KW_TIMESTAMPLOCALTZ,&mut recog.err_handler)?;

			recog.base.set_state(4668);
			recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- intervalValue ----------------
pub type IntervalValueContextAll<'input> = IntervalValueContext<'input>;


pub type IntervalValueContext<'input> = BaseParserRuleContext<'input,IntervalValueContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for IntervalValueContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for IntervalValueContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_intervalValue(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_intervalValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for IntervalValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_intervalValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_intervalValue }
}
crate::tid!{IntervalValueContextExt<'a>}

impl<'input> IntervalValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalValueContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<IntervalValueContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}

}

impl<'input> IntervalValueContextAttrs<'input> for IntervalValueContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn intervalValue(&mut self,)
	-> Result<Rc<IntervalValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 798, RULE_intervalValue);
        let mut _localctx: Rc<IntervalValueContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4670);
			_la = recog.base.input.la(1);
			if { !(_la==StringLiteral || _la==Number) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- intervalLiteral ----------------
pub type IntervalLiteralContextAll<'input> = IntervalLiteralContext<'input>;


pub type IntervalLiteralContext<'input> = BaseParserRuleContext<'input,IntervalLiteralContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalLiteralContextExt<'input>{
	pub value: Option<Rc<IntervalValueContextAll<'input>>>,
	pub qualifiers: Option<Rc<IntervalQualifiersContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for IntervalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for IntervalLiteralContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_intervalLiteral(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_intervalLiteral(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for IntervalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_intervalLiteral }
	//fn type_rule_index() -> usize where Self: Sized { RULE_intervalLiteral }
}
crate::tid!{IntervalLiteralContextExt<'a>}

impl<'input> IntervalLiteralContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalLiteralContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalLiteralContextExt{
				value: None, qualifiers: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalLiteralContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<IntervalLiteralContextExt<'input>>{

fn intervalValue(&self) -> Option<Rc<IntervalValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn intervalQualifiers(&self) -> Option<Rc<IntervalQualifiersContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IntervalLiteralContextAttrs<'input> for IntervalLiteralContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn intervalLiteral(&mut self,)
	-> Result<Rc<IntervalLiteralContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalLiteralContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 800, RULE_intervalLiteral);
        let mut _localctx: Rc<IntervalLiteralContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule intervalValue*/
			recog.base.set_state(4672);
			let tmp = recog.intervalValue()?;
			 cast_mut::<_,IntervalLiteralContext >(&mut _localctx).value = Some(tmp.clone());
			  

			/*InvokeRule intervalQualifiers*/
			recog.base.set_state(4673);
			let tmp = recog.intervalQualifiers()?;
			 cast_mut::<_,IntervalLiteralContext >(&mut _localctx).qualifiers = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- intervalExpression ----------------
pub type IntervalExpressionContextAll<'input> = IntervalExpressionContext<'input>;


pub type IntervalExpressionContext<'input> = BaseParserRuleContext<'input,IntervalExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalExpressionContextExt<'input>{
	pub value: Option<Rc<IntervalValueContextAll<'input>>>,
	pub qualifiers: Option<Rc<IntervalQualifiersContextAll<'input>>>,
	pub expr: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for IntervalExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for IntervalExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_intervalExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_intervalExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for IntervalExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_intervalExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_intervalExpression }
}
crate::tid!{IntervalExpressionContextExt<'a>}

impl<'input> IntervalExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalExpressionContextExt{
				value: None, qualifiers: None, expr: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<IntervalExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
fn intervalValue(&self) -> Option<Rc<IntervalValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn intervalQualifiers(&self) -> Option<Rc<IntervalQualifiersContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_INTERVAL
/// Returns `None` if there is no child corresponding to token KW_INTERVAL
fn KW_INTERVAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INTERVAL, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IntervalExpressionContextAttrs<'input> for IntervalExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn intervalExpression(&mut self,)
	-> Result<Rc<IntervalExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 802, RULE_intervalExpression);
        let mut _localctx: Rc<IntervalExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4690);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 LPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4675);
					recog.base.match_token(LPAREN,&mut recog.err_handler)?;

					/*InvokeRule intervalValue*/
					recog.base.set_state(4676);
					let tmp = recog.intervalValue()?;
					 cast_mut::<_,IntervalExpressionContext >(&mut _localctx).value = Some(tmp.clone());
					  

					recog.base.set_state(4677);
					recog.base.match_token(RPAREN,&mut recog.err_handler)?;

					/*InvokeRule intervalQualifiers*/
					recog.base.set_state(4678);
					let tmp = recog.intervalQualifiers()?;
					 cast_mut::<_,IntervalExpressionContext >(&mut _localctx).qualifiers = Some(tmp.clone());
					  

					}
				}

			 KW_INTERVAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4680);
					recog.base.match_token(KW_INTERVAL,&mut recog.err_handler)?;

					recog.base.set_state(4686);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 StringLiteral | Number 
						=> {
							{
							/*InvokeRule intervalValue*/
							recog.base.set_state(4681);
							let tmp = recog.intervalValue()?;
							 cast_mut::<_,IntervalExpressionContext >(&mut _localctx).value = Some(tmp.clone());
							  

							}
						}

					 LPAREN 
						=> {
							{
							recog.base.set_state(4682);
							recog.base.match_token(LPAREN,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(4683);
							let tmp = recog.expression()?;
							 cast_mut::<_,IntervalExpressionContext >(&mut _localctx).expr = Some(tmp.clone());
							  

							recog.base.set_state(4684);
							recog.base.match_token(RPAREN,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					/*InvokeRule intervalQualifiers*/
					recog.base.set_state(4688);
					let tmp = recog.intervalQualifiers()?;
					 cast_mut::<_,IntervalExpressionContext >(&mut _localctx).qualifiers = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- intervalQualifiers ----------------
pub type IntervalQualifiersContextAll<'input> = IntervalQualifiersContext<'input>;


pub type IntervalQualifiersContext<'input> = BaseParserRuleContext<'input,IntervalQualifiersContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalQualifiersContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for IntervalQualifiersContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for IntervalQualifiersContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_intervalQualifiers(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_intervalQualifiers(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for IntervalQualifiersContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_intervalQualifiers }
	//fn type_rule_index() -> usize where Self: Sized { RULE_intervalQualifiers }
}
crate::tid!{IntervalQualifiersContextExt<'a>}

impl<'input> IntervalQualifiersContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalQualifiersContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalQualifiersContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalQualifiersContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<IntervalQualifiersContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_YEAR
/// Returns `None` if there is no child corresponding to token KW_YEAR
fn KW_YEAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MONTH
/// Returns `None` if there is no child corresponding to token KW_MONTH
fn KW_MONTH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DAY
/// Returns `None` if there is no child corresponding to token KW_DAY
fn KW_DAY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SECOND
/// Returns `None` if there is no child corresponding to token KW_SECOND
fn KW_SECOND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_HOUR
/// Returns `None` if there is no child corresponding to token KW_HOUR
fn KW_HOUR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MINUTE
/// Returns `None` if there is no child corresponding to token KW_MINUTE
fn KW_MINUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MINUTE, 0)
}

}

impl<'input> IntervalQualifiersContextAttrs<'input> for IntervalQualifiersContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn intervalQualifiers(&mut self,)
	-> Result<Rc<IntervalQualifiersContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalQualifiersContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 804, RULE_intervalQualifiers);
        let mut _localctx: Rc<IntervalQualifiersContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4704);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(563,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4692);
					recog.base.match_token(KW_YEAR,&mut recog.err_handler)?;

					recog.base.set_state(4693);
					recog.base.match_token(KW_TO,&mut recog.err_handler)?;

					recog.base.set_state(4694);
					recog.base.match_token(KW_MONTH,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4695);
					recog.base.match_token(KW_DAY,&mut recog.err_handler)?;

					recog.base.set_state(4696);
					recog.base.match_token(KW_TO,&mut recog.err_handler)?;

					recog.base.set_state(4697);
					recog.base.match_token(KW_SECOND,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4698);
					recog.base.match_token(KW_YEAR,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4699);
					recog.base.match_token(KW_MONTH,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(4700);
					recog.base.match_token(KW_DAY,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(4701);
					recog.base.match_token(KW_HOUR,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(4702);
					recog.base.match_token(KW_MINUTE,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(4703);
					recog.base.match_token(KW_SECOND,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expression ----------------
pub type ExpressionContextAll<'input> = ExpressionContext<'input>;


pub type ExpressionContext<'input> = BaseParserRuleContext<'input,ExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_expression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expression }
}
crate::tid!{ExpressionContextExt<'a>}

impl<'input> ExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExpressionContextExt<'input>>{

fn precedenceOrExpression(&self) -> Option<Rc<PrecedenceOrExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExpressionContextAttrs<'input> for ExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expression(&mut self,)
	-> Result<Rc<ExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 806, RULE_expression);
        let mut _localctx: Rc<ExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedenceOrExpression*/
			recog.base.set_state(4706);
			recog.precedenceOrExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- atomExpression ----------------
pub type AtomExpressionContextAll<'input> = AtomExpressionContext<'input>;


pub type AtomExpressionContext<'input> = BaseParserRuleContext<'input,AtomExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct AtomExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AtomExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AtomExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_atomExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_atomExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AtomExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_atomExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_atomExpression }
}
crate::tid!{AtomExpressionContextExt<'a>}

impl<'input> AtomExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AtomExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AtomExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AtomExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AtomExpressionContextExt<'input>>{

fn constant(&self) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn intervalExpression(&self) -> Option<Rc<IntervalExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn castExpression(&self) -> Option<Rc<CastExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn extractExpression(&self) -> Option<Rc<ExtractExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn floorExpression(&self) -> Option<Rc<FloorExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn caseExpression(&self) -> Option<Rc<CaseExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whenExpression(&self) -> Option<Rc<WhenExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn subQueryExpression(&self) -> Option<Rc<SubQueryExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn function_(&self) -> Option<Rc<Function_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableOrColumn(&self) -> Option<Rc<TableOrColumnContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expressionsInParenthesis(&self) -> Option<Rc<ExpressionsInParenthesisContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AtomExpressionContextAttrs<'input> for AtomExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn atomExpression(&mut self,)
	-> Result<Rc<AtomExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AtomExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 808, RULE_atomExpression);
        let mut _localctx: Rc<AtomExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4719);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(564,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule constant*/
					recog.base.set_state(4708);
					recog.constant()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule intervalExpression*/
					recog.base.set_state(4709);
					recog.intervalExpression()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule castExpression*/
					recog.base.set_state(4710);
					recog.castExpression()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule extractExpression*/
					recog.base.set_state(4711);
					recog.extractExpression()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule floorExpression*/
					recog.base.set_state(4712);
					recog.floorExpression()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule caseExpression*/
					recog.base.set_state(4713);
					recog.caseExpression()?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule whenExpression*/
					recog.base.set_state(4714);
					recog.whenExpression()?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule subQueryExpression*/
					recog.base.set_state(4715);
					recog.subQueryExpression()?;

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule function_*/
					recog.base.set_state(4716);
					recog.function_()?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule tableOrColumn*/
					recog.base.set_state(4717);
					recog.tableOrColumn()?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule expressionsInParenthesis*/
					recog.base.set_state(4718);
					recog.expressionsInParenthesis()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceFieldExpression ----------------
pub type PrecedenceFieldExpressionContextAll<'input> = PrecedenceFieldExpressionContext<'input>;


pub type PrecedenceFieldExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceFieldExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceFieldExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceFieldExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceFieldExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceFieldExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceFieldExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceFieldExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceFieldExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceFieldExpression }
}
crate::tid!{PrecedenceFieldExpressionContextExt<'a>}

impl<'input> PrecedenceFieldExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceFieldExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceFieldExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceFieldExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceFieldExpressionContextExt<'input>>{

fn atomExpression(&self) -> Option<Rc<AtomExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token LSQUARE in current rule
fn LSQUARE_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LSQUARE, starting from 0.
/// Returns `None` if number of children corresponding to token LSQUARE is less or equal than `i`.
fn LSQUARE(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LSQUARE, i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token RSQUARE in current rule
fn RSQUARE_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RSQUARE, starting from 0.
/// Returns `None` if number of children corresponding to token RSQUARE is less or equal than `i`.
fn RSQUARE(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RSQUARE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, i)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedenceFieldExpressionContextAttrs<'input> for PrecedenceFieldExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceFieldExpression(&mut self,)
	-> Result<Rc<PrecedenceFieldExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceFieldExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 810, RULE_precedenceFieldExpression);
        let mut _localctx: Rc<PrecedenceFieldExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule atomExpression*/
			recog.base.set_state(4721);
			recog.atomExpression()?;

			recog.base.set_state(4730);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==DOT || _la==LSQUARE {
				{
				recog.base.set_state(4728);
				recog.err_handler.sync(&mut recog.base)?;
				match recog.base.input.la(1) {
				 LSQUARE 
					=> {
						{
						recog.base.set_state(4722);
						recog.base.match_token(LSQUARE,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(4723);
						recog.expression()?;

						recog.base.set_state(4724);
						recog.base.match_token(RSQUARE,&mut recog.err_handler)?;

						}
					}

				 DOT 
					=> {
						{
						recog.base.set_state(4726);
						recog.base.match_token(DOT,&mut recog.err_handler)?;

						/*InvokeRule id_*/
						recog.base.set_state(4727);
						recog.id_()?;

						}
					}

					_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				}
				recog.base.set_state(4732);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceUnaryOperator ----------------
pub type PrecedenceUnaryOperatorContextAll<'input> = PrecedenceUnaryOperatorContext<'input>;


pub type PrecedenceUnaryOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceUnaryOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceUnaryOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceUnaryOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceUnaryOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceUnaryOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceUnaryOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceUnaryOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceUnaryOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceUnaryOperator }
}
crate::tid!{PrecedenceUnaryOperatorContextExt<'a>}

impl<'input> PrecedenceUnaryOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceUnaryOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceUnaryOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceUnaryOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceUnaryOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PLUS
/// Returns `None` if there is no child corresponding to token PLUS
fn PLUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS
/// Returns `None` if there is no child corresponding to token MINUS
fn MINUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(MINUS, 0)
}
/// Retrieves first TerminalNode corresponding to token TILDE
/// Returns `None` if there is no child corresponding to token TILDE
fn TILDE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(TILDE, 0)
}

}

impl<'input> PrecedenceUnaryOperatorContextAttrs<'input> for PrecedenceUnaryOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceUnaryOperator(&mut self,)
	-> Result<Rc<PrecedenceUnaryOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceUnaryOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 812, RULE_precedenceUnaryOperator);
        let mut _localctx: Rc<PrecedenceUnaryOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4733);
			_la = recog.base.input.la(1);
			if { !(((((_la - 399)) & !0x3f) == 0 && ((1usize << (_la - 399)) & ((1usize << (PLUS - 399)) | (1usize << (MINUS - 399)) | (1usize << (TILDE - 399)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceUnaryPrefixExpression ----------------
pub type PrecedenceUnaryPrefixExpressionContextAll<'input> = PrecedenceUnaryPrefixExpressionContext<'input>;


pub type PrecedenceUnaryPrefixExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceUnaryPrefixExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceUnaryPrefixExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceUnaryPrefixExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceUnaryPrefixExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceUnaryPrefixExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceUnaryPrefixExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceUnaryPrefixExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceUnaryPrefixExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceUnaryPrefixExpression }
}
crate::tid!{PrecedenceUnaryPrefixExpressionContextExt<'a>}

impl<'input> PrecedenceUnaryPrefixExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceUnaryPrefixExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceUnaryPrefixExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceUnaryPrefixExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceUnaryPrefixExpressionContextExt<'input>>{

fn precedenceFieldExpression(&self) -> Option<Rc<PrecedenceFieldExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn precedenceUnaryOperator_all(&self) ->  Vec<Rc<PrecedenceUnaryOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceUnaryOperator(&self, i: usize) -> Option<Rc<PrecedenceUnaryOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedenceUnaryPrefixExpressionContextAttrs<'input> for PrecedenceUnaryPrefixExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceUnaryPrefixExpression(&mut self,)
	-> Result<Rc<PrecedenceUnaryPrefixExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceUnaryPrefixExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 814, RULE_precedenceUnaryPrefixExpression);
        let mut _localctx: Rc<PrecedenceUnaryPrefixExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4738);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 399)) & !0x3f) == 0 && ((1usize << (_la - 399)) & ((1usize << (PLUS - 399)) | (1usize << (MINUS - 399)) | (1usize << (TILDE - 399)))) != 0) {
				{
				{
				/*InvokeRule precedenceUnaryOperator*/
				recog.base.set_state(4735);
				recog.precedenceUnaryOperator()?;

				}
				}
				recog.base.set_state(4740);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule precedenceFieldExpression*/
			recog.base.set_state(4741);
			recog.precedenceFieldExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceBitwiseXorOperator ----------------
pub type PrecedenceBitwiseXorOperatorContextAll<'input> = PrecedenceBitwiseXorOperatorContext<'input>;


pub type PrecedenceBitwiseXorOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceBitwiseXorOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceBitwiseXorOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceBitwiseXorOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceBitwiseXorOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceBitwiseXorOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceBitwiseXorOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceBitwiseXorOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceBitwiseXorOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceBitwiseXorOperator }
}
crate::tid!{PrecedenceBitwiseXorOperatorContextExt<'a>}

impl<'input> PrecedenceBitwiseXorOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceBitwiseXorOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceBitwiseXorOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceBitwiseXorOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceBitwiseXorOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BITWISEXOR
/// Returns `None` if there is no child corresponding to token BITWISEXOR
fn BITWISEXOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(BITWISEXOR, 0)
}

}

impl<'input> PrecedenceBitwiseXorOperatorContextAttrs<'input> for PrecedenceBitwiseXorOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceBitwiseXorOperator(&mut self,)
	-> Result<Rc<PrecedenceBitwiseXorOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceBitwiseXorOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 816, RULE_precedenceBitwiseXorOperator);
        let mut _localctx: Rc<PrecedenceBitwiseXorOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4743);
			recog.base.match_token(BITWISEXOR,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceBitwiseXorExpression ----------------
pub type PrecedenceBitwiseXorExpressionContextAll<'input> = PrecedenceBitwiseXorExpressionContext<'input>;


pub type PrecedenceBitwiseXorExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceBitwiseXorExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceBitwiseXorExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceBitwiseXorExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceBitwiseXorExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceBitwiseXorExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceBitwiseXorExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceBitwiseXorExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceBitwiseXorExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceBitwiseXorExpression }
}
crate::tid!{PrecedenceBitwiseXorExpressionContextExt<'a>}

impl<'input> PrecedenceBitwiseXorExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceBitwiseXorExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceBitwiseXorExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceBitwiseXorExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceBitwiseXorExpressionContextExt<'input>>{

fn precedenceUnaryPrefixExpression_all(&self) ->  Vec<Rc<PrecedenceUnaryPrefixExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceUnaryPrefixExpression(&self, i: usize) -> Option<Rc<PrecedenceUnaryPrefixExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn precedenceBitwiseXorOperator_all(&self) ->  Vec<Rc<PrecedenceBitwiseXorOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceBitwiseXorOperator(&self, i: usize) -> Option<Rc<PrecedenceBitwiseXorOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedenceBitwiseXorExpressionContextAttrs<'input> for PrecedenceBitwiseXorExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceBitwiseXorExpression(&mut self,)
	-> Result<Rc<PrecedenceBitwiseXorExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceBitwiseXorExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 818, RULE_precedenceBitwiseXorExpression);
        let mut _localctx: Rc<PrecedenceBitwiseXorExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedenceUnaryPrefixExpression*/
			recog.base.set_state(4745);
			recog.precedenceUnaryPrefixExpression()?;

			recog.base.set_state(4751);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==BITWISEXOR {
				{
				{
				/*InvokeRule precedenceBitwiseXorOperator*/
				recog.base.set_state(4746);
				recog.precedenceBitwiseXorOperator()?;

				/*InvokeRule precedenceUnaryPrefixExpression*/
				recog.base.set_state(4747);
				recog.precedenceUnaryPrefixExpression()?;

				}
				}
				recog.base.set_state(4753);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceStarOperator ----------------
pub type PrecedenceStarOperatorContextAll<'input> = PrecedenceStarOperatorContext<'input>;


pub type PrecedenceStarOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceStarOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceStarOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceStarOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceStarOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceStarOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceStarOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceStarOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceStarOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceStarOperator }
}
crate::tid!{PrecedenceStarOperatorContextExt<'a>}

impl<'input> PrecedenceStarOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceStarOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceStarOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceStarOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceStarOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token STAR
/// Returns `None` if there is no child corresponding to token STAR
fn STAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(STAR, 0)
}
/// Retrieves first TerminalNode corresponding to token DIVIDE
/// Returns `None` if there is no child corresponding to token DIVIDE
fn DIVIDE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DIVIDE, 0)
}
/// Retrieves first TerminalNode corresponding to token MOD
/// Returns `None` if there is no child corresponding to token MOD
fn MOD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(MOD, 0)
}
/// Retrieves first TerminalNode corresponding to token DIV
/// Returns `None` if there is no child corresponding to token DIV
fn DIV(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DIV, 0)
}

}

impl<'input> PrecedenceStarOperatorContextAttrs<'input> for PrecedenceStarOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceStarOperator(&mut self,)
	-> Result<Rc<PrecedenceStarOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceStarOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 820, RULE_precedenceStarOperator);
        let mut _localctx: Rc<PrecedenceStarOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4754);
			_la = recog.base.input.la(1);
			if { !(((((_la - 398)) & !0x3f) == 0 && ((1usize << (_la - 398)) & ((1usize << (DIVIDE - 398)) | (1usize << (STAR - 398)) | (1usize << (MOD - 398)) | (1usize << (DIV - 398)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceStarExpression ----------------
pub type PrecedenceStarExpressionContextAll<'input> = PrecedenceStarExpressionContext<'input>;


pub type PrecedenceStarExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceStarExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceStarExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceStarExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceStarExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceStarExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceStarExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceStarExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceStarExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceStarExpression }
}
crate::tid!{PrecedenceStarExpressionContextExt<'a>}

impl<'input> PrecedenceStarExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceStarExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceStarExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceStarExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceStarExpressionContextExt<'input>>{

fn precedenceBitwiseXorExpression_all(&self) ->  Vec<Rc<PrecedenceBitwiseXorExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceBitwiseXorExpression(&self, i: usize) -> Option<Rc<PrecedenceBitwiseXorExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn precedenceStarOperator_all(&self) ->  Vec<Rc<PrecedenceStarOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceStarOperator(&self, i: usize) -> Option<Rc<PrecedenceStarOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedenceStarExpressionContextAttrs<'input> for PrecedenceStarExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceStarExpression(&mut self,)
	-> Result<Rc<PrecedenceStarExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceStarExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 822, RULE_precedenceStarExpression);
        let mut _localctx: Rc<PrecedenceStarExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedenceBitwiseXorExpression*/
			recog.base.set_state(4756);
			recog.precedenceBitwiseXorExpression()?;

			recog.base.set_state(4762);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 398)) & !0x3f) == 0 && ((1usize << (_la - 398)) & ((1usize << (DIVIDE - 398)) | (1usize << (STAR - 398)) | (1usize << (MOD - 398)) | (1usize << (DIV - 398)))) != 0) {
				{
				{
				/*InvokeRule precedenceStarOperator*/
				recog.base.set_state(4757);
				recog.precedenceStarOperator()?;

				/*InvokeRule precedenceBitwiseXorExpression*/
				recog.base.set_state(4758);
				recog.precedenceBitwiseXorExpression()?;

				}
				}
				recog.base.set_state(4764);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedencePlusOperator ----------------
pub type PrecedencePlusOperatorContextAll<'input> = PrecedencePlusOperatorContext<'input>;


pub type PrecedencePlusOperatorContext<'input> = BaseParserRuleContext<'input,PrecedencePlusOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedencePlusOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedencePlusOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedencePlusOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedencePlusOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedencePlusOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedencePlusOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedencePlusOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedencePlusOperator }
}
crate::tid!{PrecedencePlusOperatorContextExt<'a>}

impl<'input> PrecedencePlusOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedencePlusOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedencePlusOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedencePlusOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedencePlusOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PLUS
/// Returns `None` if there is no child corresponding to token PLUS
fn PLUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS
/// Returns `None` if there is no child corresponding to token MINUS
fn MINUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(MINUS, 0)
}

}

impl<'input> PrecedencePlusOperatorContextAttrs<'input> for PrecedencePlusOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedencePlusOperator(&mut self,)
	-> Result<Rc<PrecedencePlusOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedencePlusOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 824, RULE_precedencePlusOperator);
        let mut _localctx: Rc<PrecedencePlusOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4765);
			_la = recog.base.input.la(1);
			if { !(_la==PLUS || _la==MINUS) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedencePlusExpression ----------------
pub type PrecedencePlusExpressionContextAll<'input> = PrecedencePlusExpressionContext<'input>;


pub type PrecedencePlusExpressionContext<'input> = BaseParserRuleContext<'input,PrecedencePlusExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedencePlusExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedencePlusExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedencePlusExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedencePlusExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedencePlusExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedencePlusExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedencePlusExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedencePlusExpression }
}
crate::tid!{PrecedencePlusExpressionContextExt<'a>}

impl<'input> PrecedencePlusExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedencePlusExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedencePlusExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedencePlusExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedencePlusExpressionContextExt<'input>>{

fn precedenceStarExpression_all(&self) ->  Vec<Rc<PrecedenceStarExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceStarExpression(&self, i: usize) -> Option<Rc<PrecedenceStarExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn precedencePlusOperator_all(&self) ->  Vec<Rc<PrecedencePlusOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedencePlusOperator(&self, i: usize) -> Option<Rc<PrecedencePlusOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedencePlusExpressionContextAttrs<'input> for PrecedencePlusExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedencePlusExpression(&mut self,)
	-> Result<Rc<PrecedencePlusExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedencePlusExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 826, RULE_precedencePlusExpression);
        let mut _localctx: Rc<PrecedencePlusExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedenceStarExpression*/
			recog.base.set_state(4767);
			recog.precedenceStarExpression()?;

			recog.base.set_state(4773);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==PLUS || _la==MINUS {
				{
				{
				/*InvokeRule precedencePlusOperator*/
				recog.base.set_state(4768);
				recog.precedencePlusOperator()?;

				/*InvokeRule precedenceStarExpression*/
				recog.base.set_state(4769);
				recog.precedenceStarExpression()?;

				}
				}
				recog.base.set_state(4775);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceConcatenateOperator ----------------
pub type PrecedenceConcatenateOperatorContextAll<'input> = PrecedenceConcatenateOperatorContext<'input>;


pub type PrecedenceConcatenateOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceConcatenateOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceConcatenateOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceConcatenateOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceConcatenateOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceConcatenateOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceConcatenateOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceConcatenateOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceConcatenateOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceConcatenateOperator }
}
crate::tid!{PrecedenceConcatenateOperatorContextExt<'a>}

impl<'input> PrecedenceConcatenateOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceConcatenateOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceConcatenateOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceConcatenateOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceConcatenateOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CONCATENATE
/// Returns `None` if there is no child corresponding to token CONCATENATE
fn CONCATENATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(CONCATENATE, 0)
}

}

impl<'input> PrecedenceConcatenateOperatorContextAttrs<'input> for PrecedenceConcatenateOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceConcatenateOperator(&mut self,)
	-> Result<Rc<PrecedenceConcatenateOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceConcatenateOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 828, RULE_precedenceConcatenateOperator);
        let mut _localctx: Rc<PrecedenceConcatenateOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4776);
			recog.base.match_token(CONCATENATE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceConcatenateExpression ----------------
pub type PrecedenceConcatenateExpressionContextAll<'input> = PrecedenceConcatenateExpressionContext<'input>;


pub type PrecedenceConcatenateExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceConcatenateExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceConcatenateExpressionContextExt<'input>{
	pub plus: Option<Rc<PrecedencePlusExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceConcatenateExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceConcatenateExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceConcatenateExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceConcatenateExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceConcatenateExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceConcatenateExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceConcatenateExpression }
}
crate::tid!{PrecedenceConcatenateExpressionContextExt<'a>}

impl<'input> PrecedenceConcatenateExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceConcatenateExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceConcatenateExpressionContextExt{
				plus: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceConcatenateExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceConcatenateExpressionContextExt<'input>>{

fn precedencePlusExpression_all(&self) ->  Vec<Rc<PrecedencePlusExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedencePlusExpression(&self, i: usize) -> Option<Rc<PrecedencePlusExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn precedenceConcatenateOperator_all(&self) ->  Vec<Rc<PrecedenceConcatenateOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceConcatenateOperator(&self, i: usize) -> Option<Rc<PrecedenceConcatenateOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedenceConcatenateExpressionContextAttrs<'input> for PrecedenceConcatenateExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceConcatenateExpression(&mut self,)
	-> Result<Rc<PrecedenceConcatenateExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceConcatenateExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 830, RULE_precedenceConcatenateExpression);
        let mut _localctx: Rc<PrecedenceConcatenateExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedencePlusExpression*/
			recog.base.set_state(4778);
			recog.precedencePlusExpression()?;

			recog.base.set_state(4784);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==CONCATENATE {
				{
				{
				/*InvokeRule precedenceConcatenateOperator*/
				recog.base.set_state(4779);
				recog.precedenceConcatenateOperator()?;

				/*InvokeRule precedencePlusExpression*/
				recog.base.set_state(4780);
				let tmp = recog.precedencePlusExpression()?;
				 cast_mut::<_,PrecedenceConcatenateExpressionContext >(&mut _localctx).plus = Some(tmp.clone());
				  

				}
				}
				recog.base.set_state(4786);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceAmpersandOperator ----------------
pub type PrecedenceAmpersandOperatorContextAll<'input> = PrecedenceAmpersandOperatorContext<'input>;


pub type PrecedenceAmpersandOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceAmpersandOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceAmpersandOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceAmpersandOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceAmpersandOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceAmpersandOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceAmpersandOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceAmpersandOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceAmpersandOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceAmpersandOperator }
}
crate::tid!{PrecedenceAmpersandOperatorContextExt<'a>}

impl<'input> PrecedenceAmpersandOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceAmpersandOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceAmpersandOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceAmpersandOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceAmpersandOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AMPERSAND
/// Returns `None` if there is no child corresponding to token AMPERSAND
fn AMPERSAND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(AMPERSAND, 0)
}

}

impl<'input> PrecedenceAmpersandOperatorContextAttrs<'input> for PrecedenceAmpersandOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceAmpersandOperator(&mut self,)
	-> Result<Rc<PrecedenceAmpersandOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceAmpersandOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 832, RULE_precedenceAmpersandOperator);
        let mut _localctx: Rc<PrecedenceAmpersandOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4787);
			recog.base.match_token(AMPERSAND,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceAmpersandExpression ----------------
pub type PrecedenceAmpersandExpressionContextAll<'input> = PrecedenceAmpersandExpressionContext<'input>;


pub type PrecedenceAmpersandExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceAmpersandExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceAmpersandExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceAmpersandExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceAmpersandExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceAmpersandExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceAmpersandExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceAmpersandExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceAmpersandExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceAmpersandExpression }
}
crate::tid!{PrecedenceAmpersandExpressionContextExt<'a>}

impl<'input> PrecedenceAmpersandExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceAmpersandExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceAmpersandExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceAmpersandExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceAmpersandExpressionContextExt<'input>>{

fn precedenceConcatenateExpression_all(&self) ->  Vec<Rc<PrecedenceConcatenateExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceConcatenateExpression(&self, i: usize) -> Option<Rc<PrecedenceConcatenateExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn precedenceAmpersandOperator_all(&self) ->  Vec<Rc<PrecedenceAmpersandOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceAmpersandOperator(&self, i: usize) -> Option<Rc<PrecedenceAmpersandOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedenceAmpersandExpressionContextAttrs<'input> for PrecedenceAmpersandExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceAmpersandExpression(&mut self,)
	-> Result<Rc<PrecedenceAmpersandExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceAmpersandExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 834, RULE_precedenceAmpersandExpression);
        let mut _localctx: Rc<PrecedenceAmpersandExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedenceConcatenateExpression*/
			recog.base.set_state(4789);
			recog.precedenceConcatenateExpression()?;

			recog.base.set_state(4795);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==AMPERSAND {
				{
				{
				/*InvokeRule precedenceAmpersandOperator*/
				recog.base.set_state(4790);
				recog.precedenceAmpersandOperator()?;

				/*InvokeRule precedenceConcatenateExpression*/
				recog.base.set_state(4791);
				recog.precedenceConcatenateExpression()?;

				}
				}
				recog.base.set_state(4797);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceBitwiseOrOperator ----------------
pub type PrecedenceBitwiseOrOperatorContextAll<'input> = PrecedenceBitwiseOrOperatorContext<'input>;


pub type PrecedenceBitwiseOrOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceBitwiseOrOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceBitwiseOrOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceBitwiseOrOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceBitwiseOrOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceBitwiseOrOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceBitwiseOrOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceBitwiseOrOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceBitwiseOrOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceBitwiseOrOperator }
}
crate::tid!{PrecedenceBitwiseOrOperatorContextExt<'a>}

impl<'input> PrecedenceBitwiseOrOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceBitwiseOrOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceBitwiseOrOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceBitwiseOrOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceBitwiseOrOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BITWISEOR
/// Returns `None` if there is no child corresponding to token BITWISEOR
fn BITWISEOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(BITWISEOR, 0)
}

}

impl<'input> PrecedenceBitwiseOrOperatorContextAttrs<'input> for PrecedenceBitwiseOrOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceBitwiseOrOperator(&mut self,)
	-> Result<Rc<PrecedenceBitwiseOrOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceBitwiseOrOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 836, RULE_precedenceBitwiseOrOperator);
        let mut _localctx: Rc<PrecedenceBitwiseOrOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4798);
			recog.base.match_token(BITWISEOR,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceBitwiseOrExpression ----------------
pub type PrecedenceBitwiseOrExpressionContextAll<'input> = PrecedenceBitwiseOrExpressionContext<'input>;


pub type PrecedenceBitwiseOrExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceBitwiseOrExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceBitwiseOrExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceBitwiseOrExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceBitwiseOrExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceBitwiseOrExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceBitwiseOrExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceBitwiseOrExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceBitwiseOrExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceBitwiseOrExpression }
}
crate::tid!{PrecedenceBitwiseOrExpressionContextExt<'a>}

impl<'input> PrecedenceBitwiseOrExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceBitwiseOrExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceBitwiseOrExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceBitwiseOrExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceBitwiseOrExpressionContextExt<'input>>{

fn precedenceAmpersandExpression_all(&self) ->  Vec<Rc<PrecedenceAmpersandExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceAmpersandExpression(&self, i: usize) -> Option<Rc<PrecedenceAmpersandExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn precedenceBitwiseOrOperator_all(&self) ->  Vec<Rc<PrecedenceBitwiseOrOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceBitwiseOrOperator(&self, i: usize) -> Option<Rc<PrecedenceBitwiseOrOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedenceBitwiseOrExpressionContextAttrs<'input> for PrecedenceBitwiseOrExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceBitwiseOrExpression(&mut self,)
	-> Result<Rc<PrecedenceBitwiseOrExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceBitwiseOrExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 838, RULE_precedenceBitwiseOrExpression);
        let mut _localctx: Rc<PrecedenceBitwiseOrExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedenceAmpersandExpression*/
			recog.base.set_state(4800);
			recog.precedenceAmpersandExpression()?;

			recog.base.set_state(4806);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==BITWISEOR {
				{
				{
				/*InvokeRule precedenceBitwiseOrOperator*/
				recog.base.set_state(4801);
				recog.precedenceBitwiseOrOperator()?;

				/*InvokeRule precedenceAmpersandExpression*/
				recog.base.set_state(4802);
				recog.precedenceAmpersandExpression()?;

				}
				}
				recog.base.set_state(4808);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceRegexpOperator ----------------
pub type PrecedenceRegexpOperatorContextAll<'input> = PrecedenceRegexpOperatorContext<'input>;


pub type PrecedenceRegexpOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceRegexpOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceRegexpOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceRegexpOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceRegexpOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceRegexpOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceRegexpOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceRegexpOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceRegexpOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceRegexpOperator }
}
crate::tid!{PrecedenceRegexpOperatorContextExt<'a>}

impl<'input> PrecedenceRegexpOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceRegexpOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceRegexpOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceRegexpOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceRegexpOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LIKE
/// Returns `None` if there is no child corresponding to token KW_LIKE
fn KW_LIKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RLIKE
/// Returns `None` if there is no child corresponding to token KW_RLIKE
fn KW_RLIKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RLIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REGEXP
/// Returns `None` if there is no child corresponding to token KW_REGEXP
fn KW_REGEXP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REGEXP, 0)
}

}

impl<'input> PrecedenceRegexpOperatorContextAttrs<'input> for PrecedenceRegexpOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceRegexpOperator(&mut self,)
	-> Result<Rc<PrecedenceRegexpOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceRegexpOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 840, RULE_precedenceRegexpOperator);
        let mut _localctx: Rc<PrecedenceRegexpOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4809);
			_la = recog.base.input.la(1);
			if { !(_la==KW_LIKE || _la==KW_REGEXP || _la==KW_RLIKE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceSimilarOperator ----------------
pub type PrecedenceSimilarOperatorContextAll<'input> = PrecedenceSimilarOperatorContext<'input>;


pub type PrecedenceSimilarOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceSimilarOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceSimilarOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceSimilarOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceSimilarOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceSimilarOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceSimilarOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceSimilarOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceSimilarOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceSimilarOperator }
}
crate::tid!{PrecedenceSimilarOperatorContextExt<'a>}

impl<'input> PrecedenceSimilarOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceSimilarOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceSimilarOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceSimilarOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceSimilarOperatorContextExt<'input>>{

fn precedenceRegexpOperator(&self) -> Option<Rc<PrecedenceRegexpOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHANOREQUALTO
/// Returns `None` if there is no child corresponding to token LESSTHANOREQUALTO
fn LESSTHANOREQUALTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHANOREQUALTO, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN
/// Returns `None` if there is no child corresponding to token LESSTHAN
fn LESSTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN, 0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHANOREQUALTO
/// Returns `None` if there is no child corresponding to token GREATERTHANOREQUALTO
fn GREATERTHANOREQUALTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHANOREQUALTO, 0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHAN
/// Returns `None` if there is no child corresponding to token GREATERTHAN
fn GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHAN, 0)
}

}

impl<'input> PrecedenceSimilarOperatorContextAttrs<'input> for PrecedenceSimilarOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceSimilarOperator(&mut self,)
	-> Result<Rc<PrecedenceSimilarOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceSimilarOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 842, RULE_precedenceSimilarOperator);
        let mut _localctx: Rc<PrecedenceSimilarOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4816);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_LIKE | KW_REGEXP | KW_RLIKE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule precedenceRegexpOperator*/
					recog.base.set_state(4811);
					recog.precedenceRegexpOperator()?;

					}
				}

			 LESSTHANOREQUALTO 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4812);
					recog.base.match_token(LESSTHANOREQUALTO,&mut recog.err_handler)?;

					}
				}

			 LESSTHAN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4813);
					recog.base.match_token(LESSTHAN,&mut recog.err_handler)?;

					}
				}

			 GREATERTHANOREQUALTO 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4814);
					recog.base.match_token(GREATERTHANOREQUALTO,&mut recog.err_handler)?;

					}
				}

			 GREATERTHAN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(4815);
					recog.base.match_token(GREATERTHAN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- subQueryExpression ----------------
pub type SubQueryExpressionContextAll<'input> = SubQueryExpressionContext<'input>;


pub type SubQueryExpressionContext<'input> = BaseParserRuleContext<'input,SubQueryExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct SubQueryExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SubQueryExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SubQueryExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_subQueryExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_subQueryExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SubQueryExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_subQueryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_subQueryExpression }
}
crate::tid!{SubQueryExpressionContextExt<'a>}

impl<'input> SubQueryExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SubQueryExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SubQueryExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SubQueryExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SubQueryExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn selectStatement(&self) -> Option<Rc<SelectStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> SubQueryExpressionContextAttrs<'input> for SubQueryExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn subQueryExpression(&mut self,)
	-> Result<Rc<SubQueryExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SubQueryExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 844, RULE_subQueryExpression);
        let mut _localctx: Rc<SubQueryExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4818);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule selectStatement*/
			recog.base.set_state(4819);
			recog.selectStatement()?;

			recog.base.set_state(4820);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceSimilarExpression ----------------
pub type PrecedenceSimilarExpressionContextAll<'input> = PrecedenceSimilarExpressionContext<'input>;


pub type PrecedenceSimilarExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceSimilarExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceSimilarExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceSimilarExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceSimilarExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceSimilarExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceSimilarExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceSimilarExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceSimilarExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceSimilarExpression }
}
crate::tid!{PrecedenceSimilarExpressionContextExt<'a>}

impl<'input> PrecedenceSimilarExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceSimilarExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceSimilarExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceSimilarExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceSimilarExpressionContextExt<'input>>{

fn precedenceSimilarExpressionMain(&self) -> Option<Rc<PrecedenceSimilarExpressionMainContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXISTS
/// Returns `None` if there is no child corresponding to token KW_EXISTS
fn KW_EXISTS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXISTS, 0)
}
fn subQueryExpression(&self) -> Option<Rc<SubQueryExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrecedenceSimilarExpressionContextAttrs<'input> for PrecedenceSimilarExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceSimilarExpression(&mut self,)
	-> Result<Rc<PrecedenceSimilarExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceSimilarExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 846, RULE_precedenceSimilarExpression);
        let mut _localctx: Rc<PrecedenceSimilarExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4825);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ARRAY | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT |
			 KW_BATCH | KW_BEFORE | KW_BIGINT | KW_BINARY | KW_BOOLEAN | KW_BUCKET |
			 KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CASE | KW_CAST | KW_CBO | KW_CHANGE |
			 KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS | KW_COLLECTION |
			 KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS | KW_COMPUTE |
			 KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_CURRENT_DATE |
			 KW_CURRENT_TIMESTAMP | KW_DATA | KW_DATABASES | KW_DATE | KW_DATETIME |
			 KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES | KW_DCPROPERTIES | KW_DEBUG |
			 KW_DEFAULT | KW_DEFERRED | KW_DEFINED | KW_DELIMITED | KW_DEPENDENCY |
			 KW_DESC | KW_DETAIL | KW_DIRECTORIES | KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE |
			 KW_DISTRIBUTED | KW_DO | KW_DOUBLE | KW_DUMP | KW_ELEM_TYPE | KW_ENABLE |
			 KW_ENFORCED | KW_ESCAPED | KW_EVERY | KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED |
			 KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN | KW_EXPORT | KW_EXPRESSION | KW_EXTRACT |
			 KW_FALSE | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST | KW_FLOAT |
			 KW_FLOOR | KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_GROUPING | KW_HOLD_DDLTIME |
			 KW_HOUR | KW_IDXPROPERTIES | KW_IF | KW_IGNORE | KW_INDEX | KW_INDEXES |
			 KW_INPATH | KW_INPUTDRIVER | KW_INPUTFORMAT | KW_INT | KW_INTERVAL |
			 KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY | KW_KEYS | KW_KEY_TYPE |
			 KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES | KW_LOAD | KW_LOCATION |
			 KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED | KW_MANAGEDLOCATION |
			 KW_MANAGEMENT | KW_MAP | KW_MAPJOIN | KW_MAPPING | KW_MATCHED | KW_MATERIALIZED |
			 KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK | KW_NORELY |
			 KW_NOSCAN | KW_NOVALIDATE | KW_NO_DROP | KW_NULL | KW_NULLS | KW_OFFLINE |
			 KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT |
			 KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH |
			 KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION |
			 KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY |
			 KW_REAL | KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD |
			 KW_RELY | KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL |
			 KW_REPLACE | KW_REPLICATION | KW_RESOURCE | KW_RESPECT | KW_RESTRICT |
			 KW_REWRITE | KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY |
			 KW_SCHEMA | KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES |
			 KW_SERVER | KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW |
			 KW_SHOW_DATABASE | KW_SKEWED | KW_SMALLINT | KW_SNAPSHOT | KW_SORT |
			 KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS | KW_STATUS | KW_STORED |
			 KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY | KW_SYSTEM_TIME |
			 KW_SYSTEM_VERSION | KW_TABLES | KW_TBLPROPERTIES | KW_TEMPORARY | KW_TERMINATED |
			 KW_TIMESTAMP | KW_TIMESTAMPLOCALTZ | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH |
			 KW_TRANSACTION | KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TRUE |
			 KW_TYPE | KW_UNARCHIVE | KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK |
			 KW_UNMANAGED | KW_UNSET | KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC |
			 KW_UTCTIMESTAMP | KW_VALIDATE | KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW |
			 KW_VIEWS | KW_WAIT | KW_WEEK | KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD |
			 KW_WRITE | KW_YEAR | KW_ZONE | LPAREN | PLUS | MINUS | TILDE | QUESTION |
			 StringLiteral | IntegralLiteral | NumberLiteral | Number | Identifier |
			 CharSetName 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule precedenceSimilarExpressionMain*/
					recog.base.set_state(4822);
					recog.precedenceSimilarExpressionMain()?;

					}
				}

			 KW_EXISTS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4823);
					recog.base.match_token(KW_EXISTS,&mut recog.err_handler)?;

					/*InvokeRule subQueryExpression*/
					recog.base.set_state(4824);
					recog.subQueryExpression()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceSimilarExpressionMain ----------------
pub type PrecedenceSimilarExpressionMainContextAll<'input> = PrecedenceSimilarExpressionMainContext<'input>;


pub type PrecedenceSimilarExpressionMainContext<'input> = BaseParserRuleContext<'input,PrecedenceSimilarExpressionMainContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceSimilarExpressionMainContextExt<'input>{
	pub a: Option<Rc<PrecedenceBitwiseOrExpressionContextAll<'input>>>,
	pub part: Option<Rc<PrecedenceSimilarExpressionPartContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceSimilarExpressionMainContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceSimilarExpressionMainContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceSimilarExpressionMain(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceSimilarExpressionMain(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceSimilarExpressionMainContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceSimilarExpressionMain }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceSimilarExpressionMain }
}
crate::tid!{PrecedenceSimilarExpressionMainContextExt<'a>}

impl<'input> PrecedenceSimilarExpressionMainContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceSimilarExpressionMainContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceSimilarExpressionMainContextExt{
				a: None, part: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceSimilarExpressionMainContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceSimilarExpressionMainContextExt<'input>>{

fn precedenceBitwiseOrExpression(&self) -> Option<Rc<PrecedenceBitwiseOrExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn precedenceSimilarExpressionPart(&self) -> Option<Rc<PrecedenceSimilarExpressionPartContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrecedenceSimilarExpressionMainContextAttrs<'input> for PrecedenceSimilarExpressionMainContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceSimilarExpressionMain(&mut self,)
	-> Result<Rc<PrecedenceSimilarExpressionMainContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceSimilarExpressionMainContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 848, RULE_precedenceSimilarExpressionMain);
        let mut _localctx: Rc<PrecedenceSimilarExpressionMainContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedenceBitwiseOrExpression*/
			recog.base.set_state(4827);
			let tmp = recog.precedenceBitwiseOrExpression()?;
			 cast_mut::<_,PrecedenceSimilarExpressionMainContext >(&mut _localctx).a = Some(tmp.clone());
			  

			recog.base.set_state(4829);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(576,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule precedenceSimilarExpressionPart*/
					recog.base.set_state(4828);
					let tmp = recog.precedenceSimilarExpressionPart()?;
					 cast_mut::<_,PrecedenceSimilarExpressionMainContext >(&mut _localctx).part = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceSimilarExpressionPart ----------------
pub type PrecedenceSimilarExpressionPartContextAll<'input> = PrecedenceSimilarExpressionPartContext<'input>;


pub type PrecedenceSimilarExpressionPartContext<'input> = BaseParserRuleContext<'input,PrecedenceSimilarExpressionPartContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceSimilarExpressionPartContextExt<'input>{
	pub equalExpr: Option<Rc<PrecedenceBitwiseOrExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceSimilarExpressionPartContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceSimilarExpressionPartContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceSimilarExpressionPart(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceSimilarExpressionPart(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceSimilarExpressionPartContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceSimilarExpressionPart }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceSimilarExpressionPart }
}
crate::tid!{PrecedenceSimilarExpressionPartContextExt<'a>}

impl<'input> PrecedenceSimilarExpressionPartContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceSimilarExpressionPartContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceSimilarExpressionPartContextExt{
				equalExpr: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceSimilarExpressionPartContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceSimilarExpressionPartContextExt<'input>>{

fn precedenceSimilarOperator(&self) -> Option<Rc<PrecedenceSimilarOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn precedenceBitwiseOrExpression(&self) -> Option<Rc<PrecedenceBitwiseOrExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn precedenceSimilarExpressionAtom(&self) -> Option<Rc<PrecedenceSimilarExpressionAtomContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOT
/// Returns `None` if there is no child corresponding to token KW_NOT
fn KW_NOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOT, 0)
}
fn precedenceSimilarExpressionPartNot(&self) -> Option<Rc<PrecedenceSimilarExpressionPartNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrecedenceSimilarExpressionPartContextAttrs<'input> for PrecedenceSimilarExpressionPartContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceSimilarExpressionPart(&mut self,)
	-> Result<Rc<PrecedenceSimilarExpressionPartContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceSimilarExpressionPartContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 850, RULE_precedenceSimilarExpressionPart);
        let mut _localctx: Rc<PrecedenceSimilarExpressionPartContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4837);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(577,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule precedenceSimilarOperator*/
					recog.base.set_state(4831);
					recog.precedenceSimilarOperator()?;

					/*InvokeRule precedenceBitwiseOrExpression*/
					recog.base.set_state(4832);
					let tmp = recog.precedenceBitwiseOrExpression()?;
					 cast_mut::<_,PrecedenceSimilarExpressionPartContext >(&mut _localctx).equalExpr = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule precedenceSimilarExpressionAtom*/
					recog.base.set_state(4834);
					recog.precedenceSimilarExpressionAtom()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4835);
					recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

					/*InvokeRule precedenceSimilarExpressionPartNot*/
					recog.base.set_state(4836);
					recog.precedenceSimilarExpressionPartNot()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceSimilarExpressionAtom ----------------
pub type PrecedenceSimilarExpressionAtomContextAll<'input> = PrecedenceSimilarExpressionAtomContext<'input>;


pub type PrecedenceSimilarExpressionAtomContext<'input> = BaseParserRuleContext<'input,PrecedenceSimilarExpressionAtomContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceSimilarExpressionAtomContextExt<'input>{
	pub min: Option<Rc<PrecedenceBitwiseOrExpressionContextAll<'input>>>,
	pub max: Option<Rc<PrecedenceBitwiseOrExpressionContextAll<'input>>>,
	pub expr: Option<Rc<ExpressionsInParenthesisContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceSimilarExpressionAtomContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceSimilarExpressionAtomContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceSimilarExpressionAtom(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceSimilarExpressionAtom(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceSimilarExpressionAtomContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceSimilarExpressionAtom }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceSimilarExpressionAtom }
}
crate::tid!{PrecedenceSimilarExpressionAtomContextExt<'a>}

impl<'input> PrecedenceSimilarExpressionAtomContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceSimilarExpressionAtomContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceSimilarExpressionAtomContextExt{
				min: None, max: None, expr: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceSimilarExpressionAtomContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceSimilarExpressionAtomContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_IN
/// Returns `None` if there is no child corresponding to token KW_IN
fn KW_IN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IN, 0)
}
fn precedenceSimilarExpressionIn(&self) -> Option<Rc<PrecedenceSimilarExpressionInContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_BETWEEN
/// Returns `None` if there is no child corresponding to token KW_BETWEEN
fn KW_BETWEEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BETWEEN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AND
/// Returns `None` if there is no child corresponding to token KW_AND
fn KW_AND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AND, 0)
}
fn precedenceBitwiseOrExpression_all(&self) ->  Vec<Rc<PrecedenceBitwiseOrExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceBitwiseOrExpression(&self, i: usize) -> Option<Rc<PrecedenceBitwiseOrExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_LIKE
/// Returns `None` if there is no child corresponding to token KW_LIKE
fn KW_LIKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ANY
/// Returns `None` if there is no child corresponding to token KW_ANY
fn KW_ANY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ANY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ALL
/// Returns `None` if there is no child corresponding to token KW_ALL
fn KW_ALL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALL, 0)
}
fn expressionsInParenthesis(&self) -> Option<Rc<ExpressionsInParenthesisContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn precedenceSimilarExpressionQuantifierPredicate(&self) -> Option<Rc<PrecedenceSimilarExpressionQuantifierPredicateContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrecedenceSimilarExpressionAtomContextAttrs<'input> for PrecedenceSimilarExpressionAtomContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceSimilarExpressionAtom(&mut self,)
	-> Result<Rc<PrecedenceSimilarExpressionAtomContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceSimilarExpressionAtomContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 852, RULE_precedenceSimilarExpressionAtom);
        let mut _localctx: Rc<PrecedenceSimilarExpressionAtomContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4850);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_IN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4839);
					recog.base.match_token(KW_IN,&mut recog.err_handler)?;

					/*InvokeRule precedenceSimilarExpressionIn*/
					recog.base.set_state(4840);
					recog.precedenceSimilarExpressionIn()?;

					}
				}

			 KW_BETWEEN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4841);
					recog.base.match_token(KW_BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule precedenceBitwiseOrExpression*/
					recog.base.set_state(4842);
					let tmp = recog.precedenceBitwiseOrExpression()?;
					 cast_mut::<_,PrecedenceSimilarExpressionAtomContext >(&mut _localctx).min = Some(tmp.clone());
					  

					recog.base.set_state(4843);
					recog.base.match_token(KW_AND,&mut recog.err_handler)?;

					/*InvokeRule precedenceBitwiseOrExpression*/
					recog.base.set_state(4844);
					let tmp = recog.precedenceBitwiseOrExpression()?;
					 cast_mut::<_,PrecedenceSimilarExpressionAtomContext >(&mut _localctx).max = Some(tmp.clone());
					  

					}
				}

			 KW_LIKE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4846);
					recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

					recog.base.set_state(4847);
					_la = recog.base.input.la(1);
					if { !(_la==KW_ALL || _la==KW_ANY) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule expressionsInParenthesis*/
					recog.base.set_state(4848);
					let tmp = recog.expressionsInParenthesis()?;
					 cast_mut::<_,PrecedenceSimilarExpressionAtomContext >(&mut _localctx).expr = Some(tmp.clone());
					  

					}
				}

			 EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO |
			 GREATERTHAN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule precedenceSimilarExpressionQuantifierPredicate*/
					recog.base.set_state(4849);
					recog.precedenceSimilarExpressionQuantifierPredicate()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceSimilarExpressionQuantifierPredicate ----------------
pub type PrecedenceSimilarExpressionQuantifierPredicateContextAll<'input> = PrecedenceSimilarExpressionQuantifierPredicateContext<'input>;


pub type PrecedenceSimilarExpressionQuantifierPredicateContext<'input> = BaseParserRuleContext<'input,PrecedenceSimilarExpressionQuantifierPredicateContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceSimilarExpressionQuantifierPredicateContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceSimilarExpressionQuantifierPredicateContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceSimilarExpressionQuantifierPredicateContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceSimilarExpressionQuantifierPredicate(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceSimilarExpressionQuantifierPredicate(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceSimilarExpressionQuantifierPredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceSimilarExpressionQuantifierPredicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceSimilarExpressionQuantifierPredicate }
}
crate::tid!{PrecedenceSimilarExpressionQuantifierPredicateContextExt<'a>}

impl<'input> PrecedenceSimilarExpressionQuantifierPredicateContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceSimilarExpressionQuantifierPredicateContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceSimilarExpressionQuantifierPredicateContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceSimilarExpressionQuantifierPredicateContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceSimilarExpressionQuantifierPredicateContextExt<'input>>{

fn subQuerySelectorOperator(&self) -> Option<Rc<SubQuerySelectorOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn quantifierType(&self) -> Option<Rc<QuantifierTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn subQueryExpression(&self) -> Option<Rc<SubQueryExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrecedenceSimilarExpressionQuantifierPredicateContextAttrs<'input> for PrecedenceSimilarExpressionQuantifierPredicateContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceSimilarExpressionQuantifierPredicate(&mut self,)
	-> Result<Rc<PrecedenceSimilarExpressionQuantifierPredicateContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceSimilarExpressionQuantifierPredicateContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 854, RULE_precedenceSimilarExpressionQuantifierPredicate);
        let mut _localctx: Rc<PrecedenceSimilarExpressionQuantifierPredicateContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule subQuerySelectorOperator*/
			recog.base.set_state(4852);
			recog.subQuerySelectorOperator()?;

			/*InvokeRule quantifierType*/
			recog.base.set_state(4853);
			recog.quantifierType()?;

			/*InvokeRule subQueryExpression*/
			recog.base.set_state(4854);
			recog.subQueryExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- quantifierType ----------------
pub type QuantifierTypeContextAll<'input> = QuantifierTypeContext<'input>;


pub type QuantifierTypeContext<'input> = BaseParserRuleContext<'input,QuantifierTypeContextExt<'input>>;

#[derive(Clone)]
pub struct QuantifierTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for QuantifierTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for QuantifierTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_quantifierType(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_quantifierType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for QuantifierTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_quantifierType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_quantifierType }
}
crate::tid!{QuantifierTypeContextExt<'a>}

impl<'input> QuantifierTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QuantifierTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QuantifierTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QuantifierTypeContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<QuantifierTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ANY
/// Returns `None` if there is no child corresponding to token KW_ANY
fn KW_ANY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ANY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SOME
/// Returns `None` if there is no child corresponding to token KW_SOME
fn KW_SOME(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SOME, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ALL
/// Returns `None` if there is no child corresponding to token KW_ALL
fn KW_ALL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALL, 0)
}

}

impl<'input> QuantifierTypeContextAttrs<'input> for QuantifierTypeContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn quantifierType(&mut self,)
	-> Result<Rc<QuantifierTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QuantifierTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 856, RULE_quantifierType);
        let mut _localctx: Rc<QuantifierTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4856);
			_la = recog.base.input.la(1);
			if { !(_la==KW_ALL || _la==KW_ANY || _la==KW_SOME) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceSimilarExpressionIn ----------------
pub type PrecedenceSimilarExpressionInContextAll<'input> = PrecedenceSimilarExpressionInContext<'input>;


pub type PrecedenceSimilarExpressionInContext<'input> = BaseParserRuleContext<'input,PrecedenceSimilarExpressionInContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceSimilarExpressionInContextExt<'input>{
	pub expr: Option<Rc<ExpressionsInParenthesisContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceSimilarExpressionInContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceSimilarExpressionInContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceSimilarExpressionIn(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceSimilarExpressionIn(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceSimilarExpressionInContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceSimilarExpressionIn }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceSimilarExpressionIn }
}
crate::tid!{PrecedenceSimilarExpressionInContextExt<'a>}

impl<'input> PrecedenceSimilarExpressionInContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceSimilarExpressionInContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceSimilarExpressionInContextExt{
				expr: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceSimilarExpressionInContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceSimilarExpressionInContextExt<'input>>{

fn subQueryExpression(&self) -> Option<Rc<SubQueryExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expressionsInParenthesis(&self) -> Option<Rc<ExpressionsInParenthesisContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrecedenceSimilarExpressionInContextAttrs<'input> for PrecedenceSimilarExpressionInContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceSimilarExpressionIn(&mut self,)
	-> Result<Rc<PrecedenceSimilarExpressionInContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceSimilarExpressionInContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 858, RULE_precedenceSimilarExpressionIn);
        let mut _localctx: Rc<PrecedenceSimilarExpressionInContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4860);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(579,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule subQueryExpression*/
					recog.base.set_state(4858);
					recog.subQueryExpression()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule expressionsInParenthesis*/
					recog.base.set_state(4859);
					let tmp = recog.expressionsInParenthesis()?;
					 cast_mut::<_,PrecedenceSimilarExpressionInContext >(&mut _localctx).expr = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceSimilarExpressionPartNot ----------------
pub type PrecedenceSimilarExpressionPartNotContextAll<'input> = PrecedenceSimilarExpressionPartNotContext<'input>;


pub type PrecedenceSimilarExpressionPartNotContext<'input> = BaseParserRuleContext<'input,PrecedenceSimilarExpressionPartNotContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceSimilarExpressionPartNotContextExt<'input>{
	pub notExpr: Option<Rc<PrecedenceBitwiseOrExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceSimilarExpressionPartNotContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceSimilarExpressionPartNotContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceSimilarExpressionPartNot(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceSimilarExpressionPartNot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceSimilarExpressionPartNotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceSimilarExpressionPartNot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceSimilarExpressionPartNot }
}
crate::tid!{PrecedenceSimilarExpressionPartNotContextExt<'a>}

impl<'input> PrecedenceSimilarExpressionPartNotContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceSimilarExpressionPartNotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceSimilarExpressionPartNotContextExt{
				notExpr: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceSimilarExpressionPartNotContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceSimilarExpressionPartNotContextExt<'input>>{

fn precedenceRegexpOperator(&self) -> Option<Rc<PrecedenceRegexpOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn precedenceBitwiseOrExpression(&self) -> Option<Rc<PrecedenceBitwiseOrExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn precedenceSimilarExpressionAtom(&self) -> Option<Rc<PrecedenceSimilarExpressionAtomContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrecedenceSimilarExpressionPartNotContextAttrs<'input> for PrecedenceSimilarExpressionPartNotContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceSimilarExpressionPartNot(&mut self,)
	-> Result<Rc<PrecedenceSimilarExpressionPartNotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceSimilarExpressionPartNotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 860, RULE_precedenceSimilarExpressionPartNot);
        let mut _localctx: Rc<PrecedenceSimilarExpressionPartNotContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4866);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(580,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule precedenceRegexpOperator*/
					recog.base.set_state(4862);
					recog.precedenceRegexpOperator()?;

					/*InvokeRule precedenceBitwiseOrExpression*/
					recog.base.set_state(4863);
					let tmp = recog.precedenceBitwiseOrExpression()?;
					 cast_mut::<_,PrecedenceSimilarExpressionPartNotContext >(&mut _localctx).notExpr = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule precedenceSimilarExpressionAtom*/
					recog.base.set_state(4865);
					recog.precedenceSimilarExpressionAtom()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceDistinctOperator ----------------
pub type PrecedenceDistinctOperatorContextAll<'input> = PrecedenceDistinctOperatorContext<'input>;


pub type PrecedenceDistinctOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceDistinctOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceDistinctOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceDistinctOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceDistinctOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceDistinctOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceDistinctOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceDistinctOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceDistinctOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceDistinctOperator }
}
crate::tid!{PrecedenceDistinctOperatorContextExt<'a>}

impl<'input> PrecedenceDistinctOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceDistinctOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceDistinctOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceDistinctOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceDistinctOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_IS
/// Returns `None` if there is no child corresponding to token KW_IS
fn KW_IS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DISTINCT
/// Returns `None` if there is no child corresponding to token KW_DISTINCT
fn KW_DISTINCT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}

}

impl<'input> PrecedenceDistinctOperatorContextAttrs<'input> for PrecedenceDistinctOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceDistinctOperator(&mut self,)
	-> Result<Rc<PrecedenceDistinctOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceDistinctOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 862, RULE_precedenceDistinctOperator);
        let mut _localctx: Rc<PrecedenceDistinctOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4868);
			recog.base.match_token(KW_IS,&mut recog.err_handler)?;

			recog.base.set_state(4869);
			recog.base.match_token(KW_DISTINCT,&mut recog.err_handler)?;

			recog.base.set_state(4870);
			recog.base.match_token(KW_FROM,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceEqualOperator ----------------
pub type PrecedenceEqualOperatorContextAll<'input> = PrecedenceEqualOperatorContext<'input>;


pub type PrecedenceEqualOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceEqualOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceEqualOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceEqualOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceEqualOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceEqualOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceEqualOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceEqualOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceEqualOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceEqualOperator }
}
crate::tid!{PrecedenceEqualOperatorContextExt<'a>}

impl<'input> PrecedenceEqualOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceEqualOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceEqualOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceEqualOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceEqualOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL_NS
/// Returns `None` if there is no child corresponding to token EQUAL_NS
fn EQUAL_NS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL_NS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOTEQUAL
/// Returns `None` if there is no child corresponding to token NOTEQUAL
fn NOTEQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(NOTEQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IS
/// Returns `None` if there is no child corresponding to token KW_IS
fn KW_IS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOT
/// Returns `None` if there is no child corresponding to token KW_NOT
fn KW_NOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DISTINCT
/// Returns `None` if there is no child corresponding to token KW_DISTINCT
fn KW_DISTINCT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}

}

impl<'input> PrecedenceEqualOperatorContextAttrs<'input> for PrecedenceEqualOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceEqualOperator(&mut self,)
	-> Result<Rc<PrecedenceEqualOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceEqualOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 864, RULE_precedenceEqualOperator);
        let mut _localctx: Rc<PrecedenceEqualOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4879);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 EQUAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4872);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					}
				}

			 EQUAL_NS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4873);
					recog.base.match_token(EQUAL_NS,&mut recog.err_handler)?;

					}
				}

			 NOTEQUAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4874);
					recog.base.match_token(NOTEQUAL,&mut recog.err_handler)?;

					}
				}

			 KW_IS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4875);
					recog.base.match_token(KW_IS,&mut recog.err_handler)?;

					recog.base.set_state(4876);
					recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

					recog.base.set_state(4877);
					recog.base.match_token(KW_DISTINCT,&mut recog.err_handler)?;

					recog.base.set_state(4878);
					recog.base.match_token(KW_FROM,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceEqualExpression ----------------
pub type PrecedenceEqualExpressionContextAll<'input> = PrecedenceEqualExpressionContext<'input>;


pub type PrecedenceEqualExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceEqualExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceEqualExpressionContextExt<'input>{
	pub precedenceEqualOperator: Option<Rc<PrecedenceEqualOperatorContextAll<'input>>>,
	pub equal:Vec<Rc<PrecedenceEqualOperatorContextAll<'input>>>,
	pub precedenceSimilarExpression: Option<Rc<PrecedenceSimilarExpressionContextAll<'input>>>,
	pub p:Vec<Rc<PrecedenceSimilarExpressionContextAll<'input>>>,
	pub precedenceDistinctOperator: Option<Rc<PrecedenceDistinctOperatorContextAll<'input>>>,
	pub dist:Vec<Rc<PrecedenceDistinctOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceEqualExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceEqualExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceEqualExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceEqualExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceEqualExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceEqualExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceEqualExpression }
}
crate::tid!{PrecedenceEqualExpressionContextExt<'a>}

impl<'input> PrecedenceEqualExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceEqualExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceEqualExpressionContextExt{
				precedenceEqualOperator: None, precedenceSimilarExpression: None, precedenceDistinctOperator: None, 
				equal: Vec::new(), p: Vec::new(), dist: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceEqualExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceEqualExpressionContextExt<'input>>{

fn precedenceSimilarExpression_all(&self) ->  Vec<Rc<PrecedenceSimilarExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceSimilarExpression(&self, i: usize) -> Option<Rc<PrecedenceSimilarExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn precedenceEqualOperator_all(&self) ->  Vec<Rc<PrecedenceEqualOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceEqualOperator(&self, i: usize) -> Option<Rc<PrecedenceEqualOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn precedenceDistinctOperator_all(&self) ->  Vec<Rc<PrecedenceDistinctOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceDistinctOperator(&self, i: usize) -> Option<Rc<PrecedenceDistinctOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedenceEqualExpressionContextAttrs<'input> for PrecedenceEqualExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceEqualExpression(&mut self,)
	-> Result<Rc<PrecedenceEqualExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceEqualExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 866, RULE_precedenceEqualExpression);
        let mut _localctx: Rc<PrecedenceEqualExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedenceSimilarExpression*/
			recog.base.set_state(4881);
			recog.precedenceSimilarExpression()?;

			recog.base.set_state(4890);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(583,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					recog.base.set_state(4888);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(582,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule precedenceEqualOperator*/
							recog.base.set_state(4882);
							let tmp = recog.precedenceEqualOperator()?;
							 cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).precedenceEqualOperator = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).precedenceEqualOperator.clone().unwrap()
							 ;
							 cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).equal.push(temp);
							  
							/*InvokeRule precedenceSimilarExpression*/
							recog.base.set_state(4883);
							let tmp = recog.precedenceSimilarExpression()?;
							 cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).precedenceSimilarExpression = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).precedenceSimilarExpression.clone().unwrap()
							 ;
							 cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).p.push(temp);
							  
							}
						}
					,
						2 =>{
							{
							/*InvokeRule precedenceDistinctOperator*/
							recog.base.set_state(4885);
							let tmp = recog.precedenceDistinctOperator()?;
							 cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).precedenceDistinctOperator = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).precedenceDistinctOperator.clone().unwrap()
							 ;
							 cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).dist.push(temp);
							  
							/*InvokeRule precedenceSimilarExpression*/
							recog.base.set_state(4886);
							let tmp = recog.precedenceSimilarExpression()?;
							 cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).precedenceSimilarExpression = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).precedenceSimilarExpression.clone().unwrap()
							 ;
							 cast_mut::<_,PrecedenceEqualExpressionContext >(&mut _localctx).p.push(temp);
							  
							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(4892);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(583,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- isCondition ----------------
pub type IsConditionContextAll<'input> = IsConditionContext<'input>;


pub type IsConditionContext<'input> = BaseParserRuleContext<'input,IsConditionContextExt<'input>>;

#[derive(Clone)]
pub struct IsConditionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for IsConditionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for IsConditionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_isCondition(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_isCondition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for IsConditionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_isCondition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_isCondition }
}
crate::tid!{IsConditionContextExt<'a>}

impl<'input> IsConditionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IsConditionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IsConditionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IsConditionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<IsConditionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_NULL
/// Returns `None` if there is no child corresponding to token KW_NULL
fn KW_NULL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRUE
/// Returns `None` if there is no child corresponding to token KW_TRUE
fn KW_TRUE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FALSE
/// Returns `None` if there is no child corresponding to token KW_FALSE
fn KW_FALSE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FALSE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNKNOWN
/// Returns `None` if there is no child corresponding to token KW_UNKNOWN
fn KW_UNKNOWN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNKNOWN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOT
/// Returns `None` if there is no child corresponding to token KW_NOT
fn KW_NOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOT, 0)
}

}

impl<'input> IsConditionContextAttrs<'input> for IsConditionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn isCondition(&mut self,)
	-> Result<Rc<IsConditionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IsConditionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 868, RULE_isCondition);
        let mut _localctx: Rc<IsConditionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4905);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(584,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4893);
					recog.base.match_token(KW_NULL,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4894);
					recog.base.match_token(KW_TRUE,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4895);
					recog.base.match_token(KW_FALSE,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4896);
					recog.base.match_token(KW_UNKNOWN,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(4897);
					recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

					recog.base.set_state(4898);
					recog.base.match_token(KW_NULL,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(4899);
					recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

					recog.base.set_state(4900);
					recog.base.match_token(KW_TRUE,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(4901);
					recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

					recog.base.set_state(4902);
					recog.base.match_token(KW_FALSE,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(4903);
					recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

					recog.base.set_state(4904);
					recog.base.match_token(KW_UNKNOWN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceUnarySuffixExpression ----------------
pub type PrecedenceUnarySuffixExpressionContextAll<'input> = PrecedenceUnarySuffixExpressionContext<'input>;


pub type PrecedenceUnarySuffixExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceUnarySuffixExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceUnarySuffixExpressionContextExt<'input>{
	pub a: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceUnarySuffixExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceUnarySuffixExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceUnarySuffixExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceUnarySuffixExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceUnarySuffixExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceUnarySuffixExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceUnarySuffixExpression }
}
crate::tid!{PrecedenceUnarySuffixExpressionContextExt<'a>}

impl<'input> PrecedenceUnarySuffixExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceUnarySuffixExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceUnarySuffixExpressionContextExt{
				a: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceUnarySuffixExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceUnarySuffixExpressionContextExt<'input>>{

fn precedenceEqualExpression(&self) -> Option<Rc<PrecedenceEqualExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn isCondition(&self) -> Option<Rc<IsConditionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_IS
/// Returns `None` if there is no child corresponding to token KW_IS
fn KW_IS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IS, 0)
}

}

impl<'input> PrecedenceUnarySuffixExpressionContextAttrs<'input> for PrecedenceUnarySuffixExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceUnarySuffixExpression(&mut self,)
	-> Result<Rc<PrecedenceUnarySuffixExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceUnarySuffixExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 870, RULE_precedenceUnarySuffixExpression);
        let mut _localctx: Rc<PrecedenceUnarySuffixExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedenceEqualExpression*/
			recog.base.set_state(4907);
			recog.precedenceEqualExpression()?;

			recog.base.set_state(4910);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IS {
				{
				recog.base.set_state(4908);
				let tmp = recog.base.match_token(KW_IS,&mut recog.err_handler)?;
				 cast_mut::<_,PrecedenceUnarySuffixExpressionContext >(&mut _localctx).a = Some(tmp.clone());
				  

				/*InvokeRule isCondition*/
				recog.base.set_state(4909);
				recog.isCondition()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceNotOperator ----------------
pub type PrecedenceNotOperatorContextAll<'input> = PrecedenceNotOperatorContext<'input>;


pub type PrecedenceNotOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceNotOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceNotOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceNotOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceNotOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceNotOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceNotOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceNotOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceNotOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceNotOperator }
}
crate::tid!{PrecedenceNotOperatorContextExt<'a>}

impl<'input> PrecedenceNotOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceNotOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceNotOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceNotOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceNotOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_NOT
/// Returns `None` if there is no child corresponding to token KW_NOT
fn KW_NOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOT, 0)
}

}

impl<'input> PrecedenceNotOperatorContextAttrs<'input> for PrecedenceNotOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceNotOperator(&mut self,)
	-> Result<Rc<PrecedenceNotOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceNotOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 872, RULE_precedenceNotOperator);
        let mut _localctx: Rc<PrecedenceNotOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4912);
			recog.base.match_token(KW_NOT,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceNotExpression ----------------
pub type PrecedenceNotExpressionContextAll<'input> = PrecedenceNotExpressionContext<'input>;


pub type PrecedenceNotExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceNotExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceNotExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceNotExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceNotExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceNotExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceNotExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceNotExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceNotExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceNotExpression }
}
crate::tid!{PrecedenceNotExpressionContextExt<'a>}

impl<'input> PrecedenceNotExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceNotExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceNotExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceNotExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceNotExpressionContextExt<'input>>{

fn precedenceUnarySuffixExpression(&self) -> Option<Rc<PrecedenceUnarySuffixExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn precedenceNotOperator_all(&self) ->  Vec<Rc<PrecedenceNotOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceNotOperator(&self, i: usize) -> Option<Rc<PrecedenceNotOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedenceNotExpressionContextAttrs<'input> for PrecedenceNotExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceNotExpression(&mut self,)
	-> Result<Rc<PrecedenceNotExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceNotExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 874, RULE_precedenceNotExpression);
        let mut _localctx: Rc<PrecedenceNotExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4917);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==KW_NOT {
				{
				{
				/*InvokeRule precedenceNotOperator*/
				recog.base.set_state(4914);
				recog.precedenceNotOperator()?;

				}
				}
				recog.base.set_state(4919);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule precedenceUnarySuffixExpression*/
			recog.base.set_state(4920);
			recog.precedenceUnarySuffixExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceAndOperator ----------------
pub type PrecedenceAndOperatorContextAll<'input> = PrecedenceAndOperatorContext<'input>;


pub type PrecedenceAndOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceAndOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceAndOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceAndOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceAndOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceAndOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceAndOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceAndOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceAndOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceAndOperator }
}
crate::tid!{PrecedenceAndOperatorContextExt<'a>}

impl<'input> PrecedenceAndOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceAndOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceAndOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceAndOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceAndOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_AND
/// Returns `None` if there is no child corresponding to token KW_AND
fn KW_AND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AND, 0)
}

}

impl<'input> PrecedenceAndOperatorContextAttrs<'input> for PrecedenceAndOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceAndOperator(&mut self,)
	-> Result<Rc<PrecedenceAndOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceAndOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 876, RULE_precedenceAndOperator);
        let mut _localctx: Rc<PrecedenceAndOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4922);
			recog.base.match_token(KW_AND,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceAndExpression ----------------
pub type PrecedenceAndExpressionContextAll<'input> = PrecedenceAndExpressionContext<'input>;


pub type PrecedenceAndExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceAndExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceAndExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceAndExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceAndExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceAndExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceAndExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceAndExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceAndExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceAndExpression }
}
crate::tid!{PrecedenceAndExpressionContextExt<'a>}

impl<'input> PrecedenceAndExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceAndExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceAndExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceAndExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceAndExpressionContextExt<'input>>{

fn precedenceNotExpression_all(&self) ->  Vec<Rc<PrecedenceNotExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceNotExpression(&self, i: usize) -> Option<Rc<PrecedenceNotExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn precedenceAndOperator_all(&self) ->  Vec<Rc<PrecedenceAndOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceAndOperator(&self, i: usize) -> Option<Rc<PrecedenceAndOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedenceAndExpressionContextAttrs<'input> for PrecedenceAndExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceAndExpression(&mut self,)
	-> Result<Rc<PrecedenceAndExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceAndExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 878, RULE_precedenceAndExpression);
        let mut _localctx: Rc<PrecedenceAndExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedenceNotExpression*/
			recog.base.set_state(4924);
			recog.precedenceNotExpression()?;

			recog.base.set_state(4930);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==KW_AND {
				{
				{
				/*InvokeRule precedenceAndOperator*/
				recog.base.set_state(4925);
				recog.precedenceAndOperator()?;

				/*InvokeRule precedenceNotExpression*/
				recog.base.set_state(4926);
				recog.precedenceNotExpression()?;

				}
				}
				recog.base.set_state(4932);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceOrOperator ----------------
pub type PrecedenceOrOperatorContextAll<'input> = PrecedenceOrOperatorContext<'input>;


pub type PrecedenceOrOperatorContext<'input> = BaseParserRuleContext<'input,PrecedenceOrOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceOrOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceOrOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceOrOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceOrOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceOrOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceOrOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceOrOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceOrOperator }
}
crate::tid!{PrecedenceOrOperatorContextExt<'a>}

impl<'input> PrecedenceOrOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceOrOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceOrOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceOrOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceOrOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_OR
/// Returns `None` if there is no child corresponding to token KW_OR
fn KW_OR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OR, 0)
}

}

impl<'input> PrecedenceOrOperatorContextAttrs<'input> for PrecedenceOrOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceOrOperator(&mut self,)
	-> Result<Rc<PrecedenceOrOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceOrOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 880, RULE_precedenceOrOperator);
        let mut _localctx: Rc<PrecedenceOrOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4933);
			recog.base.match_token(KW_OR,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- precedenceOrExpression ----------------
pub type PrecedenceOrExpressionContextAll<'input> = PrecedenceOrExpressionContext<'input>;


pub type PrecedenceOrExpressionContext<'input> = BaseParserRuleContext<'input,PrecedenceOrExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrecedenceOrExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrecedenceOrExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrecedenceOrExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_precedenceOrExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_precedenceOrExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrecedenceOrExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_precedenceOrExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_precedenceOrExpression }
}
crate::tid!{PrecedenceOrExpressionContextExt<'a>}

impl<'input> PrecedenceOrExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrecedenceOrExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrecedenceOrExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrecedenceOrExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrecedenceOrExpressionContextExt<'input>>{

fn precedenceAndExpression_all(&self) ->  Vec<Rc<PrecedenceAndExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceAndExpression(&self, i: usize) -> Option<Rc<PrecedenceAndExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn precedenceOrOperator_all(&self) ->  Vec<Rc<PrecedenceOrOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn precedenceOrOperator(&self, i: usize) -> Option<Rc<PrecedenceOrOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PrecedenceOrExpressionContextAttrs<'input> for PrecedenceOrExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn precedenceOrExpression(&mut self,)
	-> Result<Rc<PrecedenceOrExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrecedenceOrExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 882, RULE_precedenceOrExpression);
        let mut _localctx: Rc<PrecedenceOrExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule precedenceAndExpression*/
			recog.base.set_state(4935);
			recog.precedenceAndExpression()?;

			recog.base.set_state(4941);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==KW_OR {
				{
				{
				/*InvokeRule precedenceOrOperator*/
				recog.base.set_state(4936);
				recog.precedenceOrOperator()?;

				/*InvokeRule precedenceAndExpression*/
				recog.base.set_state(4937);
				recog.precedenceAndExpression()?;

				}
				}
				recog.base.set_state(4943);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- booleanValue ----------------
pub type BooleanValueContextAll<'input> = BooleanValueContext<'input>;


pub type BooleanValueContext<'input> = BaseParserRuleContext<'input,BooleanValueContextExt<'input>>;

#[derive(Clone)]
pub struct BooleanValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for BooleanValueContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for BooleanValueContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_booleanValue(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_booleanValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for BooleanValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanValue }
}
crate::tid!{BooleanValueContextExt<'a>}

impl<'input> BooleanValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BooleanValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BooleanValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BooleanValueContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<BooleanValueContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TRUE
/// Returns `None` if there is no child corresponding to token KW_TRUE
fn KW_TRUE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FALSE
/// Returns `None` if there is no child corresponding to token KW_FALSE
fn KW_FALSE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FALSE, 0)
}

}

impl<'input> BooleanValueContextAttrs<'input> for BooleanValueContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn booleanValue(&mut self,)
	-> Result<Rc<BooleanValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BooleanValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 884, RULE_booleanValue);
        let mut _localctx: Rc<BooleanValueContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4944);
			_la = recog.base.input.la(1);
			if { !(_la==KW_FALSE || _la==KW_TRUE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- booleanValueTok ----------------
pub type BooleanValueTokContextAll<'input> = BooleanValueTokContext<'input>;


pub type BooleanValueTokContext<'input> = BaseParserRuleContext<'input,BooleanValueTokContextExt<'input>>;

#[derive(Clone)]
pub struct BooleanValueTokContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for BooleanValueTokContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for BooleanValueTokContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_booleanValueTok(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_booleanValueTok(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for BooleanValueTokContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanValueTok }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanValueTok }
}
crate::tid!{BooleanValueTokContextExt<'a>}

impl<'input> BooleanValueTokContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BooleanValueTokContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BooleanValueTokContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BooleanValueTokContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<BooleanValueTokContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_TRUE
/// Returns `None` if there is no child corresponding to token KW_TRUE
fn KW_TRUE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FALSE
/// Returns `None` if there is no child corresponding to token KW_FALSE
fn KW_FALSE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FALSE, 0)
}

}

impl<'input> BooleanValueTokContextAttrs<'input> for BooleanValueTokContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn booleanValueTok(&mut self,)
	-> Result<Rc<BooleanValueTokContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BooleanValueTokContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 886, RULE_booleanValueTok);
        let mut _localctx: Rc<BooleanValueTokContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4946);
			_la = recog.base.input.la(1);
			if { !(_la==KW_FALSE || _la==KW_TRUE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableOrPartition ----------------
pub type TableOrPartitionContextAll<'input> = TableOrPartitionContext<'input>;


pub type TableOrPartitionContext<'input> = BaseParserRuleContext<'input,TableOrPartitionContextExt<'input>>;

#[derive(Clone)]
pub struct TableOrPartitionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TableOrPartitionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TableOrPartitionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableOrPartition(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_tableOrPartition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TableOrPartitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableOrPartition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableOrPartition }
}
crate::tid!{TableOrPartitionContextExt<'a>}

impl<'input> TableOrPartitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableOrPartitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableOrPartitionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableOrPartitionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TableOrPartitionContextExt<'input>>{

fn tableName(&self) -> Option<Rc<TableNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableOrPartitionContextAttrs<'input> for TableOrPartitionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableOrPartition(&mut self,)
	-> Result<Rc<TableOrPartitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableOrPartitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 888, RULE_tableOrPartition);
        let mut _localctx: Rc<TableOrPartitionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableName*/
			recog.base.set_state(4948);
			recog.tableName()?;

			recog.base.set_state(4950);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_PARTITION {
				{
				/*InvokeRule partitionSpec*/
				recog.base.set_state(4949);
				recog.partitionSpec()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionSpec ----------------
pub type PartitionSpecContextAll<'input> = PartitionSpecContext<'input>;


pub type PartitionSpecContext<'input> = BaseParserRuleContext<'input,PartitionSpecContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitionSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitionSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitionSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitionSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionSpec }
}
crate::tid!{PartitionSpecContextExt<'a>}

impl<'input> PartitionSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitionSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_PARTITION
/// Returns `None` if there is no child corresponding to token KW_PARTITION
fn KW_PARTITION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn partitionVal_all(&self) ->  Vec<Rc<PartitionValContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionVal(&self, i: usize) -> Option<Rc<PartitionValContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PartitionSpecContextAttrs<'input> for PartitionSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionSpec(&mut self,)
	-> Result<Rc<PartitionSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 890, RULE_partitionSpec);
        let mut _localctx: Rc<PartitionSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4952);
			recog.base.match_token(KW_PARTITION,&mut recog.err_handler)?;

			recog.base.set_state(4953);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule partitionVal*/
			recog.base.set_state(4954);
			recog.partitionVal()?;

			recog.base.set_state(4959);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4955);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule partitionVal*/
				recog.base.set_state(4956);
				recog.partitionVal()?;

				}
				}
				recog.base.set_state(4961);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(4962);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionVal ----------------
pub type PartitionValContextAll<'input> = PartitionValContext<'input>;


pub type PartitionValContext<'input> = BaseParserRuleContext<'input,PartitionValContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionValContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitionValContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitionValContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionVal(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitionVal(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitionValContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionVal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionVal }
}
crate::tid!{PartitionValContextExt<'a>}

impl<'input> PartitionValContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionValContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionValContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionValContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitionValContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn constant(&self) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionValContextAttrs<'input> for PartitionValContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionVal(&mut self,)
	-> Result<Rc<PartitionValContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionValContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 892, RULE_partitionVal);
        let mut _localctx: Rc<PartitionValContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(4964);
			recog.id_()?;

			recog.base.set_state(4967);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==EQUAL {
				{
				recog.base.set_state(4965);
				recog.base.match_token(EQUAL,&mut recog.err_handler)?;

				/*InvokeRule constant*/
				recog.base.set_state(4966);
				recog.constant()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionSelectorSpec ----------------
pub type PartitionSelectorSpecContextAll<'input> = PartitionSelectorSpecContext<'input>;


pub type PartitionSelectorSpecContext<'input> = BaseParserRuleContext<'input,PartitionSelectorSpecContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionSelectorSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitionSelectorSpecContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitionSelectorSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionSelectorSpec(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitionSelectorSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitionSelectorSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionSelectorSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionSelectorSpec }
}
crate::tid!{PartitionSelectorSpecContextExt<'a>}

impl<'input> PartitionSelectorSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionSelectorSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionSelectorSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionSelectorSpecContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitionSelectorSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn partitionSelectorVal_all(&self) ->  Vec<Rc<PartitionSelectorValContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionSelectorVal(&self, i: usize) -> Option<Rc<PartitionSelectorValContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PartitionSelectorSpecContextAttrs<'input> for PartitionSelectorSpecContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionSelectorSpec(&mut self,)
	-> Result<Rc<PartitionSelectorSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionSelectorSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 894, RULE_partitionSelectorSpec);
        let mut _localctx: Rc<PartitionSelectorSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4969);
			recog.base.match_token(LPAREN,&mut recog.err_handler)?;

			/*InvokeRule partitionSelectorVal*/
			recog.base.set_state(4970);
			recog.partitionSelectorVal()?;

			recog.base.set_state(4975);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4971);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule partitionSelectorVal*/
				recog.base.set_state(4972);
				recog.partitionSelectorVal()?;

				}
				}
				recog.base.set_state(4977);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(4978);
			recog.base.match_token(RPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionSelectorVal ----------------
pub type PartitionSelectorValContextAll<'input> = PartitionSelectorValContext<'input>;


pub type PartitionSelectorValContext<'input> = BaseParserRuleContext<'input,PartitionSelectorValContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionSelectorValContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitionSelectorValContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitionSelectorValContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionSelectorVal(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitionSelectorVal(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitionSelectorValContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionSelectorVal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionSelectorVal }
}
crate::tid!{PartitionSelectorValContextExt<'a>}

impl<'input> PartitionSelectorValContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionSelectorValContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionSelectorValContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionSelectorValContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitionSelectorValContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionSelectorOperator(&self) -> Option<Rc<PartitionSelectorOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn constant(&self) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionSelectorValContextAttrs<'input> for PartitionSelectorValContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionSelectorVal(&mut self,)
	-> Result<Rc<PartitionSelectorValContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionSelectorValContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 896, RULE_partitionSelectorVal);
        let mut _localctx: Rc<PartitionSelectorValContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(4980);
			recog.id_()?;

			/*InvokeRule partitionSelectorOperator*/
			recog.base.set_state(4981);
			recog.partitionSelectorOperator()?;

			/*InvokeRule constant*/
			recog.base.set_state(4982);
			recog.constant()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionSelectorOperator ----------------
pub type PartitionSelectorOperatorContextAll<'input> = PartitionSelectorOperatorContext<'input>;


pub type PartitionSelectorOperatorContext<'input> = BaseParserRuleContext<'input,PartitionSelectorOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionSelectorOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PartitionSelectorOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PartitionSelectorOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionSelectorOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_partitionSelectorOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PartitionSelectorOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionSelectorOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionSelectorOperator }
}
crate::tid!{PartitionSelectorOperatorContextExt<'a>}

impl<'input> PartitionSelectorOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionSelectorOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionSelectorOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionSelectorOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PartitionSelectorOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_LIKE
/// Returns `None` if there is no child corresponding to token KW_LIKE
fn KW_LIKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LIKE, 0)
}
fn subQuerySelectorOperator(&self) -> Option<Rc<SubQuerySelectorOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionSelectorOperatorContextAttrs<'input> for PartitionSelectorOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionSelectorOperator(&mut self,)
	-> Result<Rc<PartitionSelectorOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionSelectorOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 898, RULE_partitionSelectorOperator);
        let mut _localctx: Rc<PartitionSelectorOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4986);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_LIKE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4984);
					recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

					}
				}

			 EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO |
			 GREATERTHAN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule subQuerySelectorOperator*/
					recog.base.set_state(4985);
					recog.subQuerySelectorOperator()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- subQuerySelectorOperator ----------------
pub type SubQuerySelectorOperatorContextAll<'input> = SubQuerySelectorOperatorContext<'input>;


pub type SubQuerySelectorOperatorContext<'input> = BaseParserRuleContext<'input,SubQuerySelectorOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SubQuerySelectorOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SubQuerySelectorOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SubQuerySelectorOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_subQuerySelectorOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_subQuerySelectorOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SubQuerySelectorOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_subQuerySelectorOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_subQuerySelectorOperator }
}
crate::tid!{SubQuerySelectorOperatorContextExt<'a>}

impl<'input> SubQuerySelectorOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SubQuerySelectorOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SubQuerySelectorOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SubQuerySelectorOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SubQuerySelectorOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token NOTEQUAL
/// Returns `None` if there is no child corresponding to token NOTEQUAL
fn NOTEQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(NOTEQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHANOREQUALTO
/// Returns `None` if there is no child corresponding to token LESSTHANOREQUALTO
fn LESSTHANOREQUALTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHANOREQUALTO, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN
/// Returns `None` if there is no child corresponding to token LESSTHAN
fn LESSTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN, 0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHANOREQUALTO
/// Returns `None` if there is no child corresponding to token GREATERTHANOREQUALTO
fn GREATERTHANOREQUALTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHANOREQUALTO, 0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHAN
/// Returns `None` if there is no child corresponding to token GREATERTHAN
fn GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHAN, 0)
}

}

impl<'input> SubQuerySelectorOperatorContextAttrs<'input> for SubQuerySelectorOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn subQuerySelectorOperator(&mut self,)
	-> Result<Rc<SubQuerySelectorOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SubQuerySelectorOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 900, RULE_subQuerySelectorOperator);
        let mut _localctx: Rc<SubQuerySelectorOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4988);
			_la = recog.base.input.la(1);
			if { !(((((_la - 391)) & !0x3f) == 0 && ((1usize << (_la - 391)) & ((1usize << (EQUAL - 391)) | (1usize << (NOTEQUAL - 391)) | (1usize << (LESSTHANOREQUALTO - 391)) | (1usize << (LESSTHAN - 391)) | (1usize << (GREATERTHANOREQUALTO - 391)) | (1usize << (GREATERTHAN - 391)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sysFuncNames ----------------
pub type SysFuncNamesContextAll<'input> = SysFuncNamesContext<'input>;


pub type SysFuncNamesContext<'input> = BaseParserRuleContext<'input,SysFuncNamesContextExt<'input>>;

#[derive(Clone)]
pub struct SysFuncNamesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for SysFuncNamesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for SysFuncNamesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sysFuncNames(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_sysFuncNames(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for SysFuncNamesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sysFuncNames }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sysFuncNames }
}
crate::tid!{SysFuncNamesContextExt<'a>}

impl<'input> SysFuncNamesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SysFuncNamesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SysFuncNamesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SysFuncNamesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<SysFuncNamesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_AND
/// Returns `None` if there is no child corresponding to token KW_AND
fn KW_AND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AND, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OR
/// Returns `None` if there is no child corresponding to token KW_OR
fn KW_OR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOT
/// Returns `None` if there is no child corresponding to token KW_NOT
fn KW_NOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LIKE
/// Returns `None` if there is no child corresponding to token KW_LIKE
fn KW_LIKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IF
/// Returns `None` if there is no child corresponding to token KW_IF
fn KW_IF(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IF, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CASE
/// Returns `None` if there is no child corresponding to token KW_CASE
fn KW_CASE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CASE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WHEN
/// Returns `None` if there is no child corresponding to token KW_WHEN
fn KW_WHEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FLOOR
/// Returns `None` if there is no child corresponding to token KW_FLOOR
fn KW_FLOOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FLOOR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TINYINT
/// Returns `None` if there is no child corresponding to token KW_TINYINT
fn KW_TINYINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TINYINT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SMALLINT
/// Returns `None` if there is no child corresponding to token KW_SMALLINT
fn KW_SMALLINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SMALLINT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INT
/// Returns `None` if there is no child corresponding to token KW_INT
fn KW_INT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BIGINT
/// Returns `None` if there is no child corresponding to token KW_BIGINT
fn KW_BIGINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BIGINT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FLOAT
/// Returns `None` if there is no child corresponding to token KW_FLOAT
fn KW_FLOAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FLOAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REAL
/// Returns `None` if there is no child corresponding to token KW_REAL
fn KW_REAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DOUBLE
/// Returns `None` if there is no child corresponding to token KW_DOUBLE
fn KW_DOUBLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BOOLEAN
/// Returns `None` if there is no child corresponding to token KW_BOOLEAN
fn KW_BOOLEAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BOOLEAN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STRING
/// Returns `None` if there is no child corresponding to token KW_STRING
fn KW_STRING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STRING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BINARY
/// Returns `None` if there is no child corresponding to token KW_BINARY
fn KW_BINARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BINARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ARRAY
/// Returns `None` if there is no child corresponding to token KW_ARRAY
fn KW_ARRAY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MAP
/// Returns `None` if there is no child corresponding to token KW_MAP
fn KW_MAP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STRUCT
/// Returns `None` if there is no child corresponding to token KW_STRUCT
fn KW_STRUCT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNIONTYPE
/// Returns `None` if there is no child corresponding to token KW_UNIONTYPE
fn KW_UNIONTYPE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNIONTYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL_NS
/// Returns `None` if there is no child corresponding to token EQUAL_NS
fn EQUAL_NS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL_NS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOTEQUAL
/// Returns `None` if there is no child corresponding to token NOTEQUAL
fn NOTEQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(NOTEQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHANOREQUALTO
/// Returns `None` if there is no child corresponding to token LESSTHANOREQUALTO
fn LESSTHANOREQUALTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHANOREQUALTO, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN
/// Returns `None` if there is no child corresponding to token LESSTHAN
fn LESSTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN, 0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHANOREQUALTO
/// Returns `None` if there is no child corresponding to token GREATERTHANOREQUALTO
fn GREATERTHANOREQUALTO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHANOREQUALTO, 0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHAN
/// Returns `None` if there is no child corresponding to token GREATERTHAN
fn GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHAN, 0)
}
/// Retrieves first TerminalNode corresponding to token DIVIDE
/// Returns `None` if there is no child corresponding to token DIVIDE
fn DIVIDE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DIVIDE, 0)
}
/// Retrieves first TerminalNode corresponding to token PLUS
/// Returns `None` if there is no child corresponding to token PLUS
fn PLUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS
/// Returns `None` if there is no child corresponding to token MINUS
fn MINUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(MINUS, 0)
}
/// Retrieves first TerminalNode corresponding to token STAR
/// Returns `None` if there is no child corresponding to token STAR
fn STAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(STAR, 0)
}
/// Retrieves first TerminalNode corresponding to token MOD
/// Returns `None` if there is no child corresponding to token MOD
fn MOD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(MOD, 0)
}
/// Retrieves first TerminalNode corresponding to token DIV
/// Returns `None` if there is no child corresponding to token DIV
fn DIV(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DIV, 0)
}
/// Retrieves first TerminalNode corresponding to token AMPERSAND
/// Returns `None` if there is no child corresponding to token AMPERSAND
fn AMPERSAND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(AMPERSAND, 0)
}
/// Retrieves first TerminalNode corresponding to token TILDE
/// Returns `None` if there is no child corresponding to token TILDE
fn TILDE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(TILDE, 0)
}
/// Retrieves first TerminalNode corresponding to token BITWISEOR
/// Returns `None` if there is no child corresponding to token BITWISEOR
fn BITWISEOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(BITWISEOR, 0)
}
/// Retrieves first TerminalNode corresponding to token BITWISEXOR
/// Returns `None` if there is no child corresponding to token BITWISEXOR
fn BITWISEXOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(BITWISEXOR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RLIKE
/// Returns `None` if there is no child corresponding to token KW_RLIKE
fn KW_RLIKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RLIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REGEXP
/// Returns `None` if there is no child corresponding to token KW_REGEXP
fn KW_REGEXP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REGEXP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IN
/// Returns `None` if there is no child corresponding to token KW_IN
fn KW_IN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BETWEEN
/// Returns `None` if there is no child corresponding to token KW_BETWEEN
fn KW_BETWEEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BETWEEN, 0)
}

}

impl<'input> SysFuncNamesContextAttrs<'input> for SysFuncNamesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sysFuncNames(&mut self,)
	-> Result<Rc<SysFuncNamesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SysFuncNamesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 902, RULE_sysFuncNames);
        let mut _localctx: Rc<SysFuncNamesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4990);
			_la = recog.base.input.la(1);
			if { !(((((_la - 11)) & !0x3f) == 0 && ((1usize << (_la - 11)) & ((1usize << (KW_AND - 11)) | (1usize << (KW_ARRAY - 11)) | (1usize << (KW_BETWEEN - 11)) | (1usize << (KW_BIGINT - 11)) | (1usize << (KW_BINARY - 11)) | (1usize << (KW_BOOLEAN - 11)) | (1usize << (KW_CASE - 11)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (KW_DOUBLE - 96)) | (1usize << (KW_FLOAT - 96)) | (1usize << (KW_FLOOR - 96)))) != 0) || ((((_la - 144)) & !0x3f) == 0 && ((1usize << (_la - 144)) & ((1usize << (KW_IF - 144)) | (1usize << (KW_IN - 144)) | (1usize << (KW_INT - 144)) | (1usize << (KW_LIKE - 144)))) != 0) || ((((_la - 189)) & !0x3f) == 0 && ((1usize << (_la - 189)) & ((1usize << (KW_MAP - 189)) | (1usize << (KW_NOT - 189)) | (1usize << (KW_OR - 189)))) != 0) || ((((_la - 253)) & !0x3f) == 0 && ((1usize << (_la - 253)) & ((1usize << (KW_REAL - 253)) | (1usize << (KW_REGEXP - 253)) | (1usize << (KW_RLIKE - 253)))) != 0) || ((((_la - 299)) & !0x3f) == 0 && ((1usize << (_la - 299)) & ((1usize << (KW_SMALLINT - 299)) | (1usize << (KW_STRING - 299)) | (1usize << (KW_STRUCT - 299)) | (1usize << (KW_TINYINT - 299)))) != 0) || _la==KW_UNIONTYPE || _la==KW_WHEN || ((((_la - 391)) & !0x3f) == 0 && ((1usize << (_la - 391)) & ((1usize << (EQUAL - 391)) | (1usize << (EQUAL_NS - 391)) | (1usize << (NOTEQUAL - 391)) | (1usize << (LESSTHANOREQUALTO - 391)) | (1usize << (LESSTHAN - 391)) | (1usize << (GREATERTHANOREQUALTO - 391)) | (1usize << (GREATERTHAN - 391)) | (1usize << (DIVIDE - 391)) | (1usize << (PLUS - 391)) | (1usize << (MINUS - 391)) | (1usize << (STAR - 391)) | (1usize << (MOD - 391)) | (1usize << (DIV - 391)) | (1usize << (AMPERSAND - 391)) | (1usize << (TILDE - 391)) | (1usize << (BITWISEOR - 391)) | (1usize << (BITWISEXOR - 391)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- descFuncNames ----------------
pub type DescFuncNamesContextAll<'input> = DescFuncNamesContext<'input>;


pub type DescFuncNamesContext<'input> = BaseParserRuleContext<'input,DescFuncNamesContextExt<'input>>;

#[derive(Clone)]
pub struct DescFuncNamesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DescFuncNamesContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DescFuncNamesContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_descFuncNames(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_descFuncNames(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DescFuncNamesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_descFuncNames }
	//fn type_rule_index() -> usize where Self: Sized { RULE_descFuncNames }
}
crate::tid!{DescFuncNamesContextExt<'a>}

impl<'input> DescFuncNamesContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DescFuncNamesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DescFuncNamesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DescFuncNamesContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DescFuncNamesContextExt<'input>>{

fn sysFuncNames(&self) -> Option<Rc<SysFuncNamesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn functionIdentifier(&self) -> Option<Rc<FunctionIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DescFuncNamesContextAttrs<'input> for DescFuncNamesContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn descFuncNames(&mut self,)
	-> Result<Rc<DescFuncNamesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DescFuncNamesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 904, RULE_descFuncNames);
        let mut _localctx: Rc<DescFuncNamesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4995);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(594,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule sysFuncNames*/
					recog.base.set_state(4992);
					recog.sysFuncNames()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4993);
					recog.base.match_token(StringLiteral,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule functionIdentifier*/
					recog.base.set_state(4994);
					recog.functionIdentifier()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- id_ ----------------
pub type Id_ContextAll<'input> = Id_Context<'input>;


pub type Id_Context<'input> = BaseParserRuleContext<'input,Id_ContextExt<'input>>;

#[derive(Clone)]
pub struct Id_ContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Id_Context<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Id_Context<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_id_(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_id_(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Id_ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_id_ }
	//fn type_rule_index() -> usize where Self: Sized { RULE_id_ }
}
crate::tid!{Id_ContextExt<'a>}

impl<'input> Id_ContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Id_ContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Id_ContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Id_ContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Id_ContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token Identifier
/// Returns `None` if there is no child corresponding to token Identifier
fn Identifier(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Identifier, 0)
}
fn nonReserved(&self) -> Option<Rc<NonReservedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> Id_ContextAttrs<'input> for Id_Context<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn id_(&mut self,)
	-> Result<Rc<Id_ContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Id_ContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 906, RULE_id_);
        let mut _localctx: Rc<Id_ContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4999);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 Identifier 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4997);
					recog.base.match_token(Identifier,&mut recog.err_handler)?;

					}
				}

			 KW_ABORT | KW_ACTIVATE | KW_ACTIVE | KW_ADD | KW_ADMIN | KW_AFTER | KW_ALLOC_FRACTION |
			 KW_ANALYZE | KW_ARCHIVE | KW_ASC | KW_AST | KW_AT | KW_AUTOCOMMIT | KW_BATCH |
			 KW_BEFORE | KW_BUCKET | KW_BUCKETS | KW_CACHE | KW_CASCADE | KW_CBO |
			 KW_CHANGE | KW_CHECK | KW_CLUSTER | KW_CLUSTERED | KW_CLUSTERSTATUS |
			 KW_COLLECTION | KW_COLUMNS | KW_COMMENT | KW_COMPACT | KW_COMPACTIONS |
			 KW_COMPUTE | KW_CONCATENATE | KW_CONTINUE | KW_COST | KW_CRON | KW_DATA |
			 KW_DATABASES | KW_DATETIME | KW_DAY | KW_DAYOFWEEK | KW_DBPROPERTIES |
			 KW_DCPROPERTIES | KW_DEBUG | KW_DEFAULT | KW_DEFERRED | KW_DEFINED |
			 KW_DELIMITED | KW_DEPENDENCY | KW_DESC | KW_DETAIL | KW_DIRECTORIES |
			 KW_DIRECTORY | KW_DISABLE | KW_DISTRIBUTE | KW_DISTRIBUTED | KW_DO |
			 KW_DUMP | KW_ELEM_TYPE | KW_ENABLE | KW_ENFORCED | KW_ESCAPED | KW_EVERY |
			 KW_EXCLUSIVE | KW_EXECUTE | KW_EXECUTED | KW_EXPIRE_SNAPSHOTS | KW_EXPLAIN |
			 KW_EXPORT | KW_EXPRESSION | KW_FIELDS | KW_FILE | KW_FILEFORMAT | KW_FIRST |
			 KW_FORMAT | KW_FORMATTED | KW_FUNCTIONS | KW_HOLD_DDLTIME | KW_HOUR |
			 KW_IDXPROPERTIES | KW_IGNORE | KW_INDEX | KW_INDEXES | KW_INPATH | KW_INPUTDRIVER |
			 KW_INPUTFORMAT | KW_ISOLATION | KW_ITEMS | KW_JAR | KW_JOINCOST | KW_KEY |
			 KW_KEYS | KW_KEY_TYPE | KW_KILL | KW_LAST | KW_LEVEL | KW_LIMIT | KW_LINES |
			 KW_LOAD | KW_LOCATION | KW_LOCK | KW_LOCKS | KW_LOGICAL | KW_LONG | KW_MANAGED |
			 KW_MANAGEDLOCATION | KW_MANAGEMENT | KW_MAPJOIN | KW_MAPPING | KW_MATCHED |
			 KW_MATERIALIZED | KW_METADATA | KW_MINUTE | KW_MONTH | KW_MOVE | KW_MSCK |
			 KW_NORELY | KW_NOSCAN | KW_NOVALIDATE | KW_NO_DROP | KW_NULLS | KW_OFFLINE |
			 KW_OFFSET | KW_OPERATOR | KW_OPTION | KW_OUTPUTDRIVER | KW_OUTPUTFORMAT |
			 KW_OVERWRITE | KW_OWNER | KW_PARTITIONED | KW_PARTITIONS | KW_PATH |
			 KW_PLAN | KW_PLANS | KW_PLUS | KW_POOL | KW_PRINCIPALS | KW_PROTECTION |
			 KW_PURGE | KW_QUARTER | KW_QUERY | KW_QUERY_PARALLELISM | KW_READ | KW_READONLY |
			 KW_REBUILD | KW_RECORDREADER | KW_RECORDWRITER | KW_RELOAD | KW_RELY |
			 KW_REMOTE | KW_RENAME | KW_REOPTIMIZATION | KW_REPAIR | KW_REPL | KW_REPLACE |
			 KW_REPLICATION | KW_RESOURCE | KW_RESPECT | KW_RESTRICT | KW_REWRITE |
			 KW_ROLE | KW_ROLES | KW_SCHEDULED | KW_SCHEDULING_POLICY | KW_SCHEMA |
			 KW_SCHEMAS | KW_SECOND | KW_SEMI | KW_SERDE | KW_SERDEPROPERTIES | KW_SERVER |
			 KW_SETS | KW_SET_CURRENT_SNAPSHOT | KW_SHARED | KW_SHOW | KW_SHOW_DATABASE |
			 KW_SKEWED | KW_SNAPSHOT | KW_SORT | KW_SORTED | KW_SPEC | KW_SSL | KW_STATISTICS |
			 KW_STATUS | KW_STORED | KW_STREAMTABLE | KW_STRING | KW_STRUCT | KW_SUMMARY |
			 KW_SYSTEM_TIME | KW_SYSTEM_VERSION | KW_TABLES | KW_TBLPROPERTIES | KW_TEMPORARY |
			 KW_TERMINATED | KW_TIMESTAMPTZ | KW_TINYINT | KW_TOUCH | KW_TRANSACTION |
			 KW_TRANSACTIONAL | KW_TRANSACTIONS | KW_TRIM | KW_TYPE | KW_UNARCHIVE |
			 KW_UNDO | KW_UNIONTYPE | KW_UNKNOWN | KW_UNLOCK | KW_UNMANAGED | KW_UNSET |
			 KW_UNSIGNED | KW_URI | KW_URL | KW_USE | KW_UTC | KW_UTCTIMESTAMP | KW_VALIDATE |
			 KW_VALUE_TYPE | KW_VECTORIZATION | KW_VIEW | KW_VIEWS | KW_WAIT | KW_WEEK |
			 KW_WHILE | KW_WITHIN | KW_WORK | KW_WORKLOAD | KW_WRITE | KW_YEAR | KW_ZONE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule nonReserved*/
					recog.base.set_state(4998);
					recog.nonReserved()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionIdentifier ----------------
pub type FunctionIdentifierContextAll<'input> = FunctionIdentifierContext<'input>;


pub type FunctionIdentifierContext<'input> = BaseParserRuleContext<'input,FunctionIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionIdentifierContextExt<'input>{
	pub r#fn: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for FunctionIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for FunctionIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionIdentifier(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_functionIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for FunctionIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionIdentifier }
}
crate::tid!{FunctionIdentifierContextExt<'a>}

impl<'input> FunctionIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionIdentifierContextExt{
				r#fn: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionIdentifierContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<FunctionIdentifierContextExt<'input>>{

fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}

}

impl<'input> FunctionIdentifierContextAttrs<'input> for FunctionIdentifierContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionIdentifier(&mut self,)
	-> Result<Rc<FunctionIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 908, RULE_functionIdentifier);
        let mut _localctx: Rc<FunctionIdentifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(5001);
			recog.id_()?;

			recog.base.set_state(5004);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DOT {
				{
				recog.base.set_state(5002);
				recog.base.match_token(DOT,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(5003);
				let tmp = recog.id_()?;
				 cast_mut::<_,FunctionIdentifierContext >(&mut _localctx).r#fn = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- principalIdentifier ----------------
pub type PrincipalIdentifierContextAll<'input> = PrincipalIdentifierContext<'input>;


pub type PrincipalIdentifierContext<'input> = BaseParserRuleContext<'input,PrincipalIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct PrincipalIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrincipalIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrincipalIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_principalIdentifier(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_principalIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrincipalIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_principalIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_principalIdentifier }
}
crate::tid!{PrincipalIdentifierContextExt<'a>}

impl<'input> PrincipalIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrincipalIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrincipalIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrincipalIdentifierContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrincipalIdentifierContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrincipalIdentifierContextAttrs<'input> for PrincipalIdentifierContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn principalIdentifier(&mut self,)
	-> Result<Rc<PrincipalIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrincipalIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 910, RULE_principalIdentifier);
        let mut _localctx: Rc<PrincipalIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(5006);
			recog.id_()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nonReserved ----------------
pub type NonReservedContextAll<'input> = NonReservedContext<'input>;


pub type NonReservedContext<'input> = BaseParserRuleContext<'input,NonReservedContextExt<'input>>;

#[derive(Clone)]
pub struct NonReservedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for NonReservedContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for NonReservedContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nonReserved(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_nonReserved(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for NonReservedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonReserved }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonReserved }
}
crate::tid!{NonReservedContextExt<'a>}

impl<'input> NonReservedContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NonReservedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NonReservedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NonReservedContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<NonReservedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ABORT
/// Returns `None` if there is no child corresponding to token KW_ABORT
fn KW_ABORT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ABORT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ACTIVATE
/// Returns `None` if there is no child corresponding to token KW_ACTIVATE
fn KW_ACTIVATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ACTIVATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ACTIVE
/// Returns `None` if there is no child corresponding to token KW_ACTIVE
fn KW_ACTIVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ACTIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ADD
/// Returns `None` if there is no child corresponding to token KW_ADD
fn KW_ADD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ADMIN
/// Returns `None` if there is no child corresponding to token KW_ADMIN
fn KW_ADMIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ADMIN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AFTER
/// Returns `None` if there is no child corresponding to token KW_AFTER
fn KW_AFTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AFTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ALLOC_FRACTION
/// Returns `None` if there is no child corresponding to token KW_ALLOC_FRACTION
fn KW_ALLOC_FRACTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALLOC_FRACTION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ANALYZE
/// Returns `None` if there is no child corresponding to token KW_ANALYZE
fn KW_ANALYZE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ANALYZE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ARCHIVE
/// Returns `None` if there is no child corresponding to token KW_ARCHIVE
fn KW_ARCHIVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ARCHIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ASC
/// Returns `None` if there is no child corresponding to token KW_ASC
fn KW_ASC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AST
/// Returns `None` if there is no child corresponding to token KW_AST
fn KW_AST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AST, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AT
/// Returns `None` if there is no child corresponding to token KW_AT
fn KW_AT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_AUTOCOMMIT
/// Returns `None` if there is no child corresponding to token KW_AUTOCOMMIT
fn KW_AUTOCOMMIT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AUTOCOMMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BATCH
/// Returns `None` if there is no child corresponding to token KW_BATCH
fn KW_BATCH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BATCH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BEFORE
/// Returns `None` if there is no child corresponding to token KW_BEFORE
fn KW_BEFORE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BEFORE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BUCKET
/// Returns `None` if there is no child corresponding to token KW_BUCKET
fn KW_BUCKET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BUCKET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BUCKETS
/// Returns `None` if there is no child corresponding to token KW_BUCKETS
fn KW_BUCKETS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BUCKETS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CACHE
/// Returns `None` if there is no child corresponding to token KW_CACHE
fn KW_CACHE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CACHE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CASCADE
/// Returns `None` if there is no child corresponding to token KW_CASCADE
fn KW_CASCADE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CASCADE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CBO
/// Returns `None` if there is no child corresponding to token KW_CBO
fn KW_CBO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CBO, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CHANGE
/// Returns `None` if there is no child corresponding to token KW_CHANGE
fn KW_CHANGE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CHANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CHECK
/// Returns `None` if there is no child corresponding to token KW_CHECK
fn KW_CHECK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CHECK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CLUSTER
/// Returns `None` if there is no child corresponding to token KW_CLUSTER
fn KW_CLUSTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CLUSTERED
/// Returns `None` if there is no child corresponding to token KW_CLUSTERED
fn KW_CLUSTERED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CLUSTERED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CLUSTERSTATUS
/// Returns `None` if there is no child corresponding to token KW_CLUSTERSTATUS
fn KW_CLUSTERSTATUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CLUSTERSTATUS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COLLECTION
/// Returns `None` if there is no child corresponding to token KW_COLLECTION
fn KW_COLLECTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLLECTION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COLUMNS
/// Returns `None` if there is no child corresponding to token KW_COLUMNS
fn KW_COLUMNS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMMENT
/// Returns `None` if there is no child corresponding to token KW_COMMENT
fn KW_COMMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMPACT
/// Returns `None` if there is no child corresponding to token KW_COMPACT
fn KW_COMPACT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMPACT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMPACTIONS
/// Returns `None` if there is no child corresponding to token KW_COMPACTIONS
fn KW_COMPACTIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMPACTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COMPUTE
/// Returns `None` if there is no child corresponding to token KW_COMPUTE
fn KW_COMPUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COMPUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CONCATENATE
/// Returns `None` if there is no child corresponding to token KW_CONCATENATE
fn KW_CONCATENATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONCATENATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CONTINUE
/// Returns `None` if there is no child corresponding to token KW_CONTINUE
fn KW_CONTINUE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CONTINUE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_COST
/// Returns `None` if there is no child corresponding to token KW_COST
fn KW_COST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_COST, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CRON
/// Returns `None` if there is no child corresponding to token KW_CRON
fn KW_CRON(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CRON, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATA
/// Returns `None` if there is no child corresponding to token KW_DATA
fn KW_DATA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATA, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATABASES
/// Returns `None` if there is no child corresponding to token KW_DATABASES
fn KW_DATABASES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATABASES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATETIME
/// Returns `None` if there is no child corresponding to token KW_DATETIME
fn KW_DATETIME(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATETIME, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DAY
/// Returns `None` if there is no child corresponding to token KW_DAY
fn KW_DAY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DAYOFWEEK
/// Returns `None` if there is no child corresponding to token KW_DAYOFWEEK
fn KW_DAYOFWEEK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DAYOFWEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DBPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_DBPROPERTIES
fn KW_DBPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DBPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DCPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_DCPROPERTIES
fn KW_DCPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DCPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEBUG
/// Returns `None` if there is no child corresponding to token KW_DEBUG
fn KW_DEBUG(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEBUG, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEFAULT
/// Returns `None` if there is no child corresponding to token KW_DEFAULT
fn KW_DEFAULT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEFERRED
/// Returns `None` if there is no child corresponding to token KW_DEFERRED
fn KW_DEFERRED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEFERRED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEFINED
/// Returns `None` if there is no child corresponding to token KW_DEFINED
fn KW_DEFINED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEFINED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DELIMITED
/// Returns `None` if there is no child corresponding to token KW_DELIMITED
fn KW_DELIMITED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DELIMITED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEPENDENCY
/// Returns `None` if there is no child corresponding to token KW_DEPENDENCY
fn KW_DEPENDENCY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEPENDENCY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DESC
/// Returns `None` if there is no child corresponding to token KW_DESC
fn KW_DESC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DETAIL
/// Returns `None` if there is no child corresponding to token KW_DETAIL
fn KW_DETAIL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DETAIL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DIRECTORIES
/// Returns `None` if there is no child corresponding to token KW_DIRECTORIES
fn KW_DIRECTORIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DIRECTORIES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DIRECTORY
/// Returns `None` if there is no child corresponding to token KW_DIRECTORY
fn KW_DIRECTORY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DIRECTORY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DISABLE
/// Returns `None` if there is no child corresponding to token KW_DISABLE
fn KW_DISABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DISTRIBUTE
/// Returns `None` if there is no child corresponding to token KW_DISTRIBUTE
fn KW_DISTRIBUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISTRIBUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DISTRIBUTED
/// Returns `None` if there is no child corresponding to token KW_DISTRIBUTED
fn KW_DISTRIBUTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISTRIBUTED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DO
/// Returns `None` if there is no child corresponding to token KW_DO
fn KW_DO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DO, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DUMP
/// Returns `None` if there is no child corresponding to token KW_DUMP
fn KW_DUMP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DUMP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ELEM_TYPE
/// Returns `None` if there is no child corresponding to token KW_ELEM_TYPE
fn KW_ELEM_TYPE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ELEM_TYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ENABLE
/// Returns `None` if there is no child corresponding to token KW_ENABLE
fn KW_ENABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ENABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ENFORCED
/// Returns `None` if there is no child corresponding to token KW_ENFORCED
fn KW_ENFORCED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ENFORCED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ESCAPED
/// Returns `None` if there is no child corresponding to token KW_ESCAPED
fn KW_ESCAPED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ESCAPED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EVERY
/// Returns `None` if there is no child corresponding to token KW_EVERY
fn KW_EVERY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EVERY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXCLUSIVE
/// Returns `None` if there is no child corresponding to token KW_EXCLUSIVE
fn KW_EXCLUSIVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXCLUSIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXECUTE
/// Returns `None` if there is no child corresponding to token KW_EXECUTE
fn KW_EXECUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXECUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXECUTED
/// Returns `None` if there is no child corresponding to token KW_EXECUTED
fn KW_EXECUTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXECUTED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXPIRE_SNAPSHOTS
/// Returns `None` if there is no child corresponding to token KW_EXPIRE_SNAPSHOTS
fn KW_EXPIRE_SNAPSHOTS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXPIRE_SNAPSHOTS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXPLAIN
/// Returns `None` if there is no child corresponding to token KW_EXPLAIN
fn KW_EXPLAIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXPLAIN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXPORT
/// Returns `None` if there is no child corresponding to token KW_EXPORT
fn KW_EXPORT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXPORT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_EXPRESSION
/// Returns `None` if there is no child corresponding to token KW_EXPRESSION
fn KW_EXPRESSION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXPRESSION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FIELDS
/// Returns `None` if there is no child corresponding to token KW_FIELDS
fn KW_FIELDS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FIELDS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FILE
/// Returns `None` if there is no child corresponding to token KW_FILE
fn KW_FILE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FILE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FILEFORMAT
/// Returns `None` if there is no child corresponding to token KW_FILEFORMAT
fn KW_FILEFORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FILEFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FIRST
/// Returns `None` if there is no child corresponding to token KW_FIRST
fn KW_FIRST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FORMAT
/// Returns `None` if there is no child corresponding to token KW_FORMAT
fn KW_FORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FORMATTED
/// Returns `None` if there is no child corresponding to token KW_FORMATTED
fn KW_FORMATTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FORMATTED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FUNCTIONS
/// Returns `None` if there is no child corresponding to token KW_FUNCTIONS
fn KW_FUNCTIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FUNCTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_HOLD_DDLTIME
/// Returns `None` if there is no child corresponding to token KW_HOLD_DDLTIME
fn KW_HOLD_DDLTIME(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_HOLD_DDLTIME, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_HOUR
/// Returns `None` if there is no child corresponding to token KW_HOUR
fn KW_HOUR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IDXPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_IDXPROPERTIES
fn KW_IDXPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IDXPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IGNORE
/// Returns `None` if there is no child corresponding to token KW_IGNORE
fn KW_IGNORE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IGNORE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INDEX
/// Returns `None` if there is no child corresponding to token KW_INDEX
fn KW_INDEX(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INDEX, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INDEXES
/// Returns `None` if there is no child corresponding to token KW_INDEXES
fn KW_INDEXES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INDEXES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INPATH
/// Returns `None` if there is no child corresponding to token KW_INPATH
fn KW_INPATH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INPATH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INPUTDRIVER
/// Returns `None` if there is no child corresponding to token KW_INPUTDRIVER
fn KW_INPUTDRIVER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INPUTDRIVER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INPUTFORMAT
/// Returns `None` if there is no child corresponding to token KW_INPUTFORMAT
fn KW_INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ISOLATION
/// Returns `None` if there is no child corresponding to token KW_ISOLATION
fn KW_ISOLATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ISOLATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ITEMS
/// Returns `None` if there is no child corresponding to token KW_ITEMS
fn KW_ITEMS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ITEMS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_JAR
/// Returns `None` if there is no child corresponding to token KW_JAR
fn KW_JAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_JAR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_JOINCOST
/// Returns `None` if there is no child corresponding to token KW_JOINCOST
fn KW_JOINCOST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_JOINCOST, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_KEY
/// Returns `None` if there is no child corresponding to token KW_KEY
fn KW_KEY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KEY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_KEYS
/// Returns `None` if there is no child corresponding to token KW_KEYS
fn KW_KEYS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KEYS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_KEY_TYPE
/// Returns `None` if there is no child corresponding to token KW_KEY_TYPE
fn KW_KEY_TYPE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KEY_TYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_KILL
/// Returns `None` if there is no child corresponding to token KW_KILL
fn KW_KILL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KILL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LAST
/// Returns `None` if there is no child corresponding to token KW_LAST
fn KW_LAST(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LAST, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LEVEL
/// Returns `None` if there is no child corresponding to token KW_LEVEL
fn KW_LEVEL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LEVEL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LIMIT
/// Returns `None` if there is no child corresponding to token KW_LIMIT
fn KW_LIMIT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LINES
/// Returns `None` if there is no child corresponding to token KW_LINES
fn KW_LINES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LINES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOAD
/// Returns `None` if there is no child corresponding to token KW_LOAD
fn KW_LOAD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOAD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCATION
/// Returns `None` if there is no child corresponding to token KW_LOCATION
fn KW_LOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCK
/// Returns `None` if there is no child corresponding to token KW_LOCK
fn KW_LOCK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOCKS
/// Returns `None` if there is no child corresponding to token KW_LOCKS
fn KW_LOCKS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOCKS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LOGICAL
/// Returns `None` if there is no child corresponding to token KW_LOGICAL
fn KW_LOGICAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LOGICAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LONG
/// Returns `None` if there is no child corresponding to token KW_LONG
fn KW_LONG(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LONG, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MANAGED
/// Returns `None` if there is no child corresponding to token KW_MANAGED
fn KW_MANAGED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MANAGED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MANAGEDLOCATION
/// Returns `None` if there is no child corresponding to token KW_MANAGEDLOCATION
fn KW_MANAGEDLOCATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MANAGEDLOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MANAGEMENT
/// Returns `None` if there is no child corresponding to token KW_MANAGEMENT
fn KW_MANAGEMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MANAGEMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MAPJOIN
/// Returns `None` if there is no child corresponding to token KW_MAPJOIN
fn KW_MAPJOIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MAPJOIN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MAPPING
/// Returns `None` if there is no child corresponding to token KW_MAPPING
fn KW_MAPPING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MAPPING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MATCHED
/// Returns `None` if there is no child corresponding to token KW_MATCHED
fn KW_MATCHED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MATERIALIZED
/// Returns `None` if there is no child corresponding to token KW_MATERIALIZED
fn KW_MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_METADATA
/// Returns `None` if there is no child corresponding to token KW_METADATA
fn KW_METADATA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_METADATA, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MINUTE
/// Returns `None` if there is no child corresponding to token KW_MINUTE
fn KW_MINUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MONTH
/// Returns `None` if there is no child corresponding to token KW_MONTH
fn KW_MONTH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MOVE
/// Returns `None` if there is no child corresponding to token KW_MOVE
fn KW_MOVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MOVE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MSCK
/// Returns `None` if there is no child corresponding to token KW_MSCK
fn KW_MSCK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MSCK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NORELY
/// Returns `None` if there is no child corresponding to token KW_NORELY
fn KW_NORELY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NORELY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOSCAN
/// Returns `None` if there is no child corresponding to token KW_NOSCAN
fn KW_NOSCAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOSCAN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NOVALIDATE
/// Returns `None` if there is no child corresponding to token KW_NOVALIDATE
fn KW_NOVALIDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NOVALIDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NO_DROP
/// Returns `None` if there is no child corresponding to token KW_NO_DROP
fn KW_NO_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NO_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NULLS
/// Returns `None` if there is no child corresponding to token KW_NULLS
fn KW_NULLS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OFFLINE
/// Returns `None` if there is no child corresponding to token KW_OFFLINE
fn KW_OFFLINE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OFFLINE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OFFSET
/// Returns `None` if there is no child corresponding to token KW_OFFSET
fn KW_OFFSET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OFFSET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OPERATOR
/// Returns `None` if there is no child corresponding to token KW_OPERATOR
fn KW_OPERATOR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OPERATOR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OPTION
/// Returns `None` if there is no child corresponding to token KW_OPTION
fn KW_OPTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OUTPUTDRIVER
/// Returns `None` if there is no child corresponding to token KW_OUTPUTDRIVER
fn KW_OUTPUTDRIVER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OUTPUTDRIVER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OUTPUTFORMAT
/// Returns `None` if there is no child corresponding to token KW_OUTPUTFORMAT
fn KW_OUTPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OUTPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OVERWRITE
/// Returns `None` if there is no child corresponding to token KW_OVERWRITE
fn KW_OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OVERWRITE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_OWNER
/// Returns `None` if there is no child corresponding to token KW_OWNER
fn KW_OWNER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OWNER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PARTITIONED
/// Returns `None` if there is no child corresponding to token KW_PARTITIONED
fn KW_PARTITIONED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITIONED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PARTITIONS
/// Returns `None` if there is no child corresponding to token KW_PARTITIONS
fn KW_PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PARTITIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PATH
/// Returns `None` if there is no child corresponding to token KW_PATH
fn KW_PATH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PATH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PLAN
/// Returns `None` if there is no child corresponding to token KW_PLAN
fn KW_PLAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PLAN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PLANS
/// Returns `None` if there is no child corresponding to token KW_PLANS
fn KW_PLANS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PLANS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PLUS
/// Returns `None` if there is no child corresponding to token KW_PLUS
fn KW_PLUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_POOL
/// Returns `None` if there is no child corresponding to token KW_POOL
fn KW_POOL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_POOL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PRINCIPALS
/// Returns `None` if there is no child corresponding to token KW_PRINCIPALS
fn KW_PRINCIPALS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PRINCIPALS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PROTECTION
/// Returns `None` if there is no child corresponding to token KW_PROTECTION
fn KW_PROTECTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PROTECTION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PURGE
/// Returns `None` if there is no child corresponding to token KW_PURGE
fn KW_PURGE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PURGE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_QUARTER
/// Returns `None` if there is no child corresponding to token KW_QUARTER
fn KW_QUARTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUARTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_QUERY
/// Returns `None` if there is no child corresponding to token KW_QUERY
fn KW_QUERY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUERY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_QUERY_PARALLELISM
/// Returns `None` if there is no child corresponding to token KW_QUERY_PARALLELISM
fn KW_QUERY_PARALLELISM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUERY_PARALLELISM, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_READ
/// Returns `None` if there is no child corresponding to token KW_READ
fn KW_READ(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_READ, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_READONLY
/// Returns `None` if there is no child corresponding to token KW_READONLY
fn KW_READONLY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_READONLY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REBUILD
/// Returns `None` if there is no child corresponding to token KW_REBUILD
fn KW_REBUILD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REBUILD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RECORDREADER
/// Returns `None` if there is no child corresponding to token KW_RECORDREADER
fn KW_RECORDREADER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RECORDREADER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RECORDWRITER
/// Returns `None` if there is no child corresponding to token KW_RECORDWRITER
fn KW_RECORDWRITER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RECORDWRITER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RELOAD
/// Returns `None` if there is no child corresponding to token KW_RELOAD
fn KW_RELOAD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RELOAD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RELY
/// Returns `None` if there is no child corresponding to token KW_RELY
fn KW_RELY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RELY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REMOTE
/// Returns `None` if there is no child corresponding to token KW_REMOTE
fn KW_REMOTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REMOTE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RENAME
/// Returns `None` if there is no child corresponding to token KW_RENAME
fn KW_RENAME(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RENAME, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REOPTIMIZATION
/// Returns `None` if there is no child corresponding to token KW_REOPTIMIZATION
fn KW_REOPTIMIZATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REOPTIMIZATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REPAIR
/// Returns `None` if there is no child corresponding to token KW_REPAIR
fn KW_REPAIR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPAIR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REPL
/// Returns `None` if there is no child corresponding to token KW_REPL
fn KW_REPL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REPLACE
/// Returns `None` if there is no child corresponding to token KW_REPLACE
fn KW_REPLACE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REPLICATION
/// Returns `None` if there is no child corresponding to token KW_REPLICATION
fn KW_REPLICATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPLICATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RESOURCE
/// Returns `None` if there is no child corresponding to token KW_RESOURCE
fn KW_RESOURCE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RESOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RESPECT
/// Returns `None` if there is no child corresponding to token KW_RESPECT
fn KW_RESPECT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RESPECT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RESTRICT
/// Returns `None` if there is no child corresponding to token KW_RESTRICT
fn KW_RESTRICT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RESTRICT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REWRITE
/// Returns `None` if there is no child corresponding to token KW_REWRITE
fn KW_REWRITE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REWRITE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLE
/// Returns `None` if there is no child corresponding to token KW_ROLE
fn KW_ROLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ROLES
/// Returns `None` if there is no child corresponding to token KW_ROLES
fn KW_ROLES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ROLES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SCHEDULED
/// Returns `None` if there is no child corresponding to token KW_SCHEDULED
fn KW_SCHEDULED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SCHEDULED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SCHEDULING_POLICY
/// Returns `None` if there is no child corresponding to token KW_SCHEDULING_POLICY
fn KW_SCHEDULING_POLICY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SCHEDULING_POLICY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SCHEMA
/// Returns `None` if there is no child corresponding to token KW_SCHEMA
fn KW_SCHEMA(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SCHEMA, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SCHEMAS
/// Returns `None` if there is no child corresponding to token KW_SCHEMAS
fn KW_SCHEMAS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SCHEMAS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SECOND
/// Returns `None` if there is no child corresponding to token KW_SECOND
fn KW_SECOND(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SEMI
/// Returns `None` if there is no child corresponding to token KW_SEMI
fn KW_SEMI(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SEMI, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERDE
/// Returns `None` if there is no child corresponding to token KW_SERDE
fn KW_SERDE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERDE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_SERDEPROPERTIES
fn KW_SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERDEPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SERVER
/// Returns `None` if there is no child corresponding to token KW_SERVER
fn KW_SERVER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SERVER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SETS
/// Returns `None` if there is no child corresponding to token KW_SETS
fn KW_SETS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SETS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SET_CURRENT_SNAPSHOT
/// Returns `None` if there is no child corresponding to token KW_SET_CURRENT_SNAPSHOT
fn KW_SET_CURRENT_SNAPSHOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET_CURRENT_SNAPSHOT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SHARED
/// Returns `None` if there is no child corresponding to token KW_SHARED
fn KW_SHARED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SHARED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SHOW
/// Returns `None` if there is no child corresponding to token KW_SHOW
fn KW_SHOW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SHOW_DATABASE
/// Returns `None` if there is no child corresponding to token KW_SHOW_DATABASE
fn KW_SHOW_DATABASE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SHOW_DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SKEWED
/// Returns `None` if there is no child corresponding to token KW_SKEWED
fn KW_SKEWED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SKEWED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SNAPSHOT
/// Returns `None` if there is no child corresponding to token KW_SNAPSHOT
fn KW_SNAPSHOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SNAPSHOT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SORT
/// Returns `None` if there is no child corresponding to token KW_SORT
fn KW_SORT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SORT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SORTED
/// Returns `None` if there is no child corresponding to token KW_SORTED
fn KW_SORTED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SORTED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SPEC
/// Returns `None` if there is no child corresponding to token KW_SPEC
fn KW_SPEC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SPEC, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SSL
/// Returns `None` if there is no child corresponding to token KW_SSL
fn KW_SSL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SSL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STATISTICS
/// Returns `None` if there is no child corresponding to token KW_STATISTICS
fn KW_STATISTICS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STATISTICS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STATUS
/// Returns `None` if there is no child corresponding to token KW_STATUS
fn KW_STATUS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STATUS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STORED
/// Returns `None` if there is no child corresponding to token KW_STORED
fn KW_STORED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STREAMTABLE
/// Returns `None` if there is no child corresponding to token KW_STREAMTABLE
fn KW_STREAMTABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STREAMTABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STRING
/// Returns `None` if there is no child corresponding to token KW_STRING
fn KW_STRING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STRING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STRUCT
/// Returns `None` if there is no child corresponding to token KW_STRUCT
fn KW_STRUCT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SUMMARY
/// Returns `None` if there is no child corresponding to token KW_SUMMARY
fn KW_SUMMARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SUMMARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SYSTEM_TIME
/// Returns `None` if there is no child corresponding to token KW_SYSTEM_TIME
fn KW_SYSTEM_TIME(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SYSTEM_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SYSTEM_VERSION
/// Returns `None` if there is no child corresponding to token KW_SYSTEM_VERSION
fn KW_SYSTEM_VERSION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SYSTEM_VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TABLES
/// Returns `None` if there is no child corresponding to token KW_TABLES
fn KW_TABLES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TABLES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TBLPROPERTIES
/// Returns `None` if there is no child corresponding to token KW_TBLPROPERTIES
fn KW_TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TBLPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TEMPORARY
/// Returns `None` if there is no child corresponding to token KW_TEMPORARY
fn KW_TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TEMPORARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TERMINATED
/// Returns `None` if there is no child corresponding to token KW_TERMINATED
fn KW_TERMINATED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TERMINATED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TIMESTAMPTZ
/// Returns `None` if there is no child corresponding to token KW_TIMESTAMPTZ
fn KW_TIMESTAMPTZ(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TIMESTAMPTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TINYINT
/// Returns `None` if there is no child corresponding to token KW_TINYINT
fn KW_TINYINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TINYINT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TOUCH
/// Returns `None` if there is no child corresponding to token KW_TOUCH
fn KW_TOUCH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TOUCH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRANSACTION
/// Returns `None` if there is no child corresponding to token KW_TRANSACTION
fn KW_TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRANSACTION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRANSACTIONAL
/// Returns `None` if there is no child corresponding to token KW_TRANSACTIONAL
fn KW_TRANSACTIONAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRANSACTIONAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRANSACTIONS
/// Returns `None` if there is no child corresponding to token KW_TRANSACTIONS
fn KW_TRANSACTIONS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRANSACTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRIM
/// Returns `None` if there is no child corresponding to token KW_TRIM
fn KW_TRIM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRIM, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TYPE
/// Returns `None` if there is no child corresponding to token KW_TYPE
fn KW_TYPE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNARCHIVE
/// Returns `None` if there is no child corresponding to token KW_UNARCHIVE
fn KW_UNARCHIVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNARCHIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNDO
/// Returns `None` if there is no child corresponding to token KW_UNDO
fn KW_UNDO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNDO, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNIONTYPE
/// Returns `None` if there is no child corresponding to token KW_UNIONTYPE
fn KW_UNIONTYPE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNIONTYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNKNOWN
/// Returns `None` if there is no child corresponding to token KW_UNKNOWN
fn KW_UNKNOWN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNKNOWN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNLOCK
/// Returns `None` if there is no child corresponding to token KW_UNLOCK
fn KW_UNLOCK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNLOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNMANAGED
/// Returns `None` if there is no child corresponding to token KW_UNMANAGED
fn KW_UNMANAGED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNMANAGED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNSET
/// Returns `None` if there is no child corresponding to token KW_UNSET
fn KW_UNSET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNSET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNSIGNED
/// Returns `None` if there is no child corresponding to token KW_UNSIGNED
fn KW_UNSIGNED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNSIGNED, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_URI
/// Returns `None` if there is no child corresponding to token KW_URI
fn KW_URI(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_URI, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_URL
/// Returns `None` if there is no child corresponding to token KW_URL
fn KW_URL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_URL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_USE
/// Returns `None` if there is no child corresponding to token KW_USE
fn KW_USE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UTC
/// Returns `None` if there is no child corresponding to token KW_UTC
fn KW_UTC(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UTC, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UTCTIMESTAMP
/// Returns `None` if there is no child corresponding to token KW_UTCTIMESTAMP
fn KW_UTCTIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UTCTIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VALIDATE
/// Returns `None` if there is no child corresponding to token KW_VALIDATE
fn KW_VALIDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VALIDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VALUE_TYPE
/// Returns `None` if there is no child corresponding to token KW_VALUE_TYPE
fn KW_VALUE_TYPE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VALUE_TYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VECTORIZATION
/// Returns `None` if there is no child corresponding to token KW_VECTORIZATION
fn KW_VECTORIZATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VECTORIZATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VIEW
/// Returns `None` if there is no child corresponding to token KW_VIEW
fn KW_VIEW(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VIEW, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_VIEWS
/// Returns `None` if there is no child corresponding to token KW_VIEWS
fn KW_VIEWS(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VIEWS, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WAIT
/// Returns `None` if there is no child corresponding to token KW_WAIT
fn KW_WAIT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WAIT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WEEK
/// Returns `None` if there is no child corresponding to token KW_WEEK
fn KW_WEEK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WHILE
/// Returns `None` if there is no child corresponding to token KW_WHILE
fn KW_WHILE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WHILE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITHIN
/// Returns `None` if there is no child corresponding to token KW_WITHIN
fn KW_WITHIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITHIN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WORK
/// Returns `None` if there is no child corresponding to token KW_WORK
fn KW_WORK(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WORK, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WORKLOAD
/// Returns `None` if there is no child corresponding to token KW_WORKLOAD
fn KW_WORKLOAD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WORKLOAD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WRITE
/// Returns `None` if there is no child corresponding to token KW_WRITE
fn KW_WRITE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WRITE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_YEAR
/// Returns `None` if there is no child corresponding to token KW_YEAR
fn KW_YEAR(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ZONE
/// Returns `None` if there is no child corresponding to token KW_ZONE
fn KW_ZONE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ZONE, 0)
}

}

impl<'input> NonReservedContextAttrs<'input> for NonReservedContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nonReserved(&mut self,)
	-> Result<Rc<NonReservedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NonReservedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 912, RULE_nonReserved);
        let mut _localctx: Rc<NonReservedContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5008);
			_la = recog.base.input.la(1);
			if { !((((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << KW_ABORT) | (1usize << KW_ACTIVATE) | (1usize << KW_ACTIVE) | (1usize << KW_ADD) | (1usize << KW_ADMIN) | (1usize << KW_AFTER) | (1usize << KW_ALLOC_FRACTION) | (1usize << KW_ANALYZE) | (1usize << KW_ARCHIVE) | (1usize << KW_ASC) | (1usize << KW_AST) | (1usize << KW_AT) | (1usize << KW_AUTOCOMMIT) | (1usize << KW_BATCH) | (1usize << KW_BEFORE) | (1usize << KW_BUCKET) | (1usize << KW_BUCKETS))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (KW_CACHE - 33)) | (1usize << (KW_CASCADE - 33)) | (1usize << (KW_CBO - 33)) | (1usize << (KW_CHANGE - 33)) | (1usize << (KW_CHECK - 33)) | (1usize << (KW_CLUSTER - 33)) | (1usize << (KW_CLUSTERED - 33)) | (1usize << (KW_CLUSTERSTATUS - 33)) | (1usize << (KW_COLLECTION - 33)) | (1usize << (KW_COLUMNS - 33)) | (1usize << (KW_COMMENT - 33)) | (1usize << (KW_COMPACT - 33)) | (1usize << (KW_COMPACTIONS - 33)) | (1usize << (KW_COMPUTE - 33)) | (1usize << (KW_CONCATENATE - 33)) | (1usize << (KW_CONTINUE - 33)) | (1usize << (KW_COST - 33)) | (1usize << (KW_CRON - 33)))) != 0) || ((((_la - 66)) & !0x3f) == 0 && ((1usize << (_la - 66)) & ((1usize << (KW_DATA - 66)) | (1usize << (KW_DATABASES - 66)) | (1usize << (KW_DATETIME - 66)) | (1usize << (KW_DAY - 66)) | (1usize << (KW_DAYOFWEEK - 66)) | (1usize << (KW_DBPROPERTIES - 66)) | (1usize << (KW_DCPROPERTIES - 66)) | (1usize << (KW_DEBUG - 66)) | (1usize << (KW_DEFAULT - 66)) | (1usize << (KW_DEFERRED - 66)) | (1usize << (KW_DEFINED - 66)) | (1usize << (KW_DELIMITED - 66)) | (1usize << (KW_DEPENDENCY - 66)) | (1usize << (KW_DESC - 66)) | (1usize << (KW_DETAIL - 66)) | (1usize << (KW_DIRECTORIES - 66)) | (1usize << (KW_DIRECTORY - 66)) | (1usize << (KW_DISABLE - 66)) | (1usize << (KW_DISTRIBUTE - 66)) | (1usize << (KW_DISTRIBUTED - 66)) | (1usize << (KW_DO - 66)))) != 0) || ((((_la - 98)) & !0x3f) == 0 && ((1usize << (_la - 98)) & ((1usize << (KW_DUMP - 98)) | (1usize << (KW_ELEM_TYPE - 98)) | (1usize << (KW_ENABLE - 98)) | (1usize << (KW_ENFORCED - 98)) | (1usize << (KW_ESCAPED - 98)) | (1usize << (KW_EVERY - 98)) | (1usize << (KW_EXCLUSIVE - 98)) | (1usize << (KW_EXECUTE - 98)) | (1usize << (KW_EXECUTED - 98)) | (1usize << (KW_EXPIRE_SNAPSHOTS - 98)) | (1usize << (KW_EXPLAIN - 98)) | (1usize << (KW_EXPORT - 98)) | (1usize << (KW_EXPRESSION - 98)) | (1usize << (KW_FIELDS - 98)) | (1usize << (KW_FILE - 98)) | (1usize << (KW_FILEFORMAT - 98)) | (1usize << (KW_FIRST - 98)))) != 0) || ((((_la - 131)) & !0x3f) == 0 && ((1usize << (_la - 131)) & ((1usize << (KW_FORMAT - 131)) | (1usize << (KW_FORMATTED - 131)) | (1usize << (KW_FUNCTIONS - 131)) | (1usize << (KW_HOLD_DDLTIME - 131)) | (1usize << (KW_HOUR - 131)) | (1usize << (KW_IDXPROPERTIES - 131)) | (1usize << (KW_IGNORE - 131)) | (1usize << (KW_INDEX - 131)) | (1usize << (KW_INDEXES - 131)) | (1usize << (KW_INPATH - 131)) | (1usize << (KW_INPUTDRIVER - 131)) | (1usize << (KW_INPUTFORMAT - 131)) | (1usize << (KW_ISOLATION - 131)) | (1usize << (KW_ITEMS - 131)) | (1usize << (KW_JAR - 131)))) != 0) || ((((_la - 164)) & !0x3f) == 0 && ((1usize << (_la - 164)) & ((1usize << (KW_JOINCOST - 164)) | (1usize << (KW_KEY - 164)) | (1usize << (KW_KEYS - 164)) | (1usize << (KW_KEY_TYPE - 164)) | (1usize << (KW_KILL - 164)) | (1usize << (KW_LAST - 164)) | (1usize << (KW_LEVEL - 164)) | (1usize << (KW_LIMIT - 164)) | (1usize << (KW_LINES - 164)) | (1usize << (KW_LOAD - 164)) | (1usize << (KW_LOCATION - 164)) | (1usize << (KW_LOCK - 164)) | (1usize << (KW_LOCKS - 164)) | (1usize << (KW_LOGICAL - 164)) | (1usize << (KW_LONG - 164)) | (1usize << (KW_MANAGED - 164)) | (1usize << (KW_MANAGEDLOCATION - 164)) | (1usize << (KW_MANAGEMENT - 164)) | (1usize << (KW_MAPJOIN - 164)) | (1usize << (KW_MAPPING - 164)) | (1usize << (KW_MATCHED - 164)) | (1usize << (KW_MATERIALIZED - 164)) | (1usize << (KW_METADATA - 164)))) != 0) || ((((_la - 197)) & !0x3f) == 0 && ((1usize << (_la - 197)) & ((1usize << (KW_MINUTE - 197)) | (1usize << (KW_MONTH - 197)) | (1usize << (KW_MOVE - 197)) | (1usize << (KW_MSCK - 197)) | (1usize << (KW_NORELY - 197)) | (1usize << (KW_NOSCAN - 197)) | (1usize << (KW_NOVALIDATE - 197)) | (1usize << (KW_NO_DROP - 197)) | (1usize << (KW_NULLS - 197)) | (1usize << (KW_OFFLINE - 197)) | (1usize << (KW_OFFSET - 197)) | (1usize << (KW_OPERATOR - 197)) | (1usize << (KW_OPTION - 197)) | (1usize << (KW_OUTPUTDRIVER - 197)) | (1usize << (KW_OUTPUTFORMAT - 197)) | (1usize << (KW_OVERWRITE - 197)) | (1usize << (KW_OWNER - 197)) | (1usize << (KW_PARTITIONED - 197)) | (1usize << (KW_PARTITIONS - 197)))) != 0) || ((((_la - 229)) & !0x3f) == 0 && ((1usize << (_la - 229)) & ((1usize << (KW_PATH - 229)) | (1usize << (KW_PLAN - 229)) | (1usize << (KW_PLANS - 229)) | (1usize << (KW_PLUS - 229)) | (1usize << (KW_POOL - 229)) | (1usize << (KW_PRINCIPALS - 229)) | (1usize << (KW_PROTECTION - 229)) | (1usize << (KW_PURGE - 229)) | (1usize << (KW_QUARTER - 229)) | (1usize << (KW_QUERY - 229)) | (1usize << (KW_QUERY_PARALLELISM - 229)) | (1usize << (KW_READ - 229)) | (1usize << (KW_READONLY - 229)) | (1usize << (KW_REBUILD - 229)) | (1usize << (KW_RECORDREADER - 229)) | (1usize << (KW_RECORDWRITER - 229)) | (1usize << (KW_RELOAD - 229)))) != 0) || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (KW_RELY - 261)) | (1usize << (KW_REMOTE - 261)) | (1usize << (KW_RENAME - 261)) | (1usize << (KW_REOPTIMIZATION - 261)) | (1usize << (KW_REPAIR - 261)) | (1usize << (KW_REPL - 261)) | (1usize << (KW_REPLACE - 261)) | (1usize << (KW_REPLICATION - 261)) | (1usize << (KW_RESOURCE - 261)) | (1usize << (KW_RESPECT - 261)) | (1usize << (KW_RESTRICT - 261)) | (1usize << (KW_REWRITE - 261)) | (1usize << (KW_ROLE - 261)) | (1usize << (KW_ROLES - 261)) | (1usize << (KW_SCHEDULED - 261)) | (1usize << (KW_SCHEDULING_POLICY - 261)) | (1usize << (KW_SCHEMA - 261)) | (1usize << (KW_SCHEMAS - 261)) | (1usize << (KW_SECOND - 261)) | (1usize << (KW_SEMI - 261)) | (1usize << (KW_SERDE - 261)) | (1usize << (KW_SERDEPROPERTIES - 261)) | (1usize << (KW_SERVER - 261)))) != 0) || ((((_la - 293)) & !0x3f) == 0 && ((1usize << (_la - 293)) & ((1usize << (KW_SETS - 293)) | (1usize << (KW_SET_CURRENT_SNAPSHOT - 293)) | (1usize << (KW_SHARED - 293)) | (1usize << (KW_SHOW - 293)) | (1usize << (KW_SHOW_DATABASE - 293)) | (1usize << (KW_SKEWED - 293)) | (1usize << (KW_SNAPSHOT - 293)) | (1usize << (KW_SORT - 293)) | (1usize << (KW_SORTED - 293)) | (1usize << (KW_SPEC - 293)) | (1usize << (KW_SSL - 293)) | (1usize << (KW_STATISTICS - 293)) | (1usize << (KW_STATUS - 293)) | (1usize << (KW_STORED - 293)) | (1usize << (KW_STREAMTABLE - 293)) | (1usize << (KW_STRING - 293)) | (1usize << (KW_STRUCT - 293)) | (1usize << (KW_SUMMARY - 293)) | (1usize << (KW_SYSTEM_TIME - 293)) | (1usize << (KW_SYSTEM_VERSION - 293)) | (1usize << (KW_TABLES - 293)) | (1usize << (KW_TBLPROPERTIES - 293)) | (1usize << (KW_TEMPORARY - 293)) | (1usize << (KW_TERMINATED - 293)))) != 0) || ((((_la - 327)) & !0x3f) == 0 && ((1usize << (_la - 327)) & ((1usize << (KW_TIMESTAMPTZ - 327)) | (1usize << (KW_TINYINT - 327)) | (1usize << (KW_TOUCH - 327)) | (1usize << (KW_TRANSACTION - 327)) | (1usize << (KW_TRANSACTIONAL - 327)) | (1usize << (KW_TRANSACTIONS - 327)) | (1usize << (KW_TRIM - 327)) | (1usize << (KW_TYPE - 327)) | (1usize << (KW_UNARCHIVE - 327)) | (1usize << (KW_UNDO - 327)) | (1usize << (KW_UNIONTYPE - 327)) | (1usize << (KW_UNKNOWN - 327)) | (1usize << (KW_UNLOCK - 327)) | (1usize << (KW_UNMANAGED - 327)) | (1usize << (KW_UNSET - 327)) | (1usize << (KW_UNSIGNED - 327)) | (1usize << (KW_URI - 327)) | (1usize << (KW_URL - 327)) | (1usize << (KW_USE - 327)))) != 0) || ((((_la - 359)) & !0x3f) == 0 && ((1usize << (_la - 359)) & ((1usize << (KW_UTC - 359)) | (1usize << (KW_UTCTIMESTAMP - 359)) | (1usize << (KW_VALIDATE - 359)) | (1usize << (KW_VALUE_TYPE - 359)) | (1usize << (KW_VECTORIZATION - 359)) | (1usize << (KW_VIEW - 359)) | (1usize << (KW_VIEWS - 359)) | (1usize << (KW_WAIT - 359)) | (1usize << (KW_WEEK - 359)) | (1usize << (KW_WHILE - 359)) | (1usize << (KW_WITHIN - 359)) | (1usize << (KW_WORK - 359)) | (1usize << (KW_WORKLOAD - 359)) | (1usize << (KW_WRITE - 359)) | (1usize << (KW_YEAR - 359)) | (1usize << (KW_ZONE - 359)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sql11ReservedKeywordsUsedAsFunctionName ----------------
pub type Sql11ReservedKeywordsUsedAsFunctionNameContextAll<'input> = Sql11ReservedKeywordsUsedAsFunctionNameContext<'input>;


pub type Sql11ReservedKeywordsUsedAsFunctionNameContext<'input> = BaseParserRuleContext<'input,Sql11ReservedKeywordsUsedAsFunctionNameContextExt<'input>>;

#[derive(Clone)]
pub struct Sql11ReservedKeywordsUsedAsFunctionNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for Sql11ReservedKeywordsUsedAsFunctionNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for Sql11ReservedKeywordsUsedAsFunctionNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sql11ReservedKeywordsUsedAsFunctionName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_sql11ReservedKeywordsUsedAsFunctionName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for Sql11ReservedKeywordsUsedAsFunctionNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sql11ReservedKeywordsUsedAsFunctionName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sql11ReservedKeywordsUsedAsFunctionName }
}
crate::tid!{Sql11ReservedKeywordsUsedAsFunctionNameContextExt<'a>}

impl<'input> Sql11ReservedKeywordsUsedAsFunctionNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<Sql11ReservedKeywordsUsedAsFunctionNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,Sql11ReservedKeywordsUsedAsFunctionNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait Sql11ReservedKeywordsUsedAsFunctionNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<Sql11ReservedKeywordsUsedAsFunctionNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ARRAY
/// Returns `None` if there is no child corresponding to token KW_ARRAY
fn KW_ARRAY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BIGINT
/// Returns `None` if there is no child corresponding to token KW_BIGINT
fn KW_BIGINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BIGINT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BINARY
/// Returns `None` if there is no child corresponding to token KW_BINARY
fn KW_BINARY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BINARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_BOOLEAN
/// Returns `None` if there is no child corresponding to token KW_BOOLEAN
fn KW_BOOLEAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_BOOLEAN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CURRENT_DATE
/// Returns `None` if there is no child corresponding to token KW_CURRENT_DATE
fn KW_CURRENT_DATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CURRENT_DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_CURRENT_TIMESTAMP
/// Returns `None` if there is no child corresponding to token KW_CURRENT_TIMESTAMP
fn KW_CURRENT_TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CURRENT_TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DATE
/// Returns `None` if there is no child corresponding to token KW_DATE
fn KW_DATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DOUBLE
/// Returns `None` if there is no child corresponding to token KW_DOUBLE
fn KW_DOUBLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FLOAT
/// Returns `None` if there is no child corresponding to token KW_FLOAT
fn KW_FLOAT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FLOAT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_GROUPING
/// Returns `None` if there is no child corresponding to token KW_GROUPING
fn KW_GROUPING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GROUPING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IF
/// Returns `None` if there is no child corresponding to token KW_IF
fn KW_IF(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IF, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_INT
/// Returns `None` if there is no child corresponding to token KW_INT
fn KW_INT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_INT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MAP
/// Returns `None` if there is no child corresponding to token KW_MAP
fn KW_MAP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REAL
/// Returns `None` if there is no child corresponding to token KW_REAL
fn KW_REAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SMALLINT
/// Returns `None` if there is no child corresponding to token KW_SMALLINT
fn KW_SMALLINT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SMALLINT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TIMESTAMP
/// Returns `None` if there is no child corresponding to token KW_TIMESTAMP
fn KW_TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TIMESTAMP, 0)
}

}

impl<'input> Sql11ReservedKeywordsUsedAsFunctionNameContextAttrs<'input> for Sql11ReservedKeywordsUsedAsFunctionNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sql11ReservedKeywordsUsedAsFunctionName(&mut self,)
	-> Result<Rc<Sql11ReservedKeywordsUsedAsFunctionNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = Sql11ReservedKeywordsUsedAsFunctionNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 914, RULE_sql11ReservedKeywordsUsedAsFunctionName);
        let mut _localctx: Rc<Sql11ReservedKeywordsUsedAsFunctionNameContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5010);
			_la = recog.base.input.la(1);
			if { !((((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << KW_ARRAY) | (1usize << KW_BIGINT) | (1usize << KW_BINARY) | (1usize << KW_BOOLEAN))) != 0) || ((((_la - 63)) & !0x3f) == 0 && ((1usize << (_la - 63)) & ((1usize << (KW_CURRENT_DATE - 63)) | (1usize << (KW_CURRENT_TIMESTAMP - 63)) | (1usize << (KW_DATE - 63)))) != 0) || _la==KW_DOUBLE || _la==KW_FLOAT || ((((_la - 139)) & !0x3f) == 0 && ((1usize << (_la - 139)) & ((1usize << (KW_GROUPING - 139)) | (1usize << (KW_IF - 139)) | (1usize << (KW_INT - 139)))) != 0) || _la==KW_MAP || _la==KW_REAL || _la==KW_SMALLINT || _la==KW_TIMESTAMP) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- hint ----------------
pub type HintContextAll<'input> = HintContext<'input>;


pub type HintContext<'input> = BaseParserRuleContext<'input,HintContextExt<'input>>;

#[derive(Clone)]
pub struct HintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for HintContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for HintContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_hint(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_hint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for HintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_hint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_hint }
}
crate::tid!{HintContextExt<'a>}

impl<'input> HintContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait HintContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<HintContextExt<'input>>{

fn hintList(&self) -> Option<Rc<HintListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> HintContextAttrs<'input> for HintContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn hint(&mut self,)
	-> Result<Rc<HintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 916, RULE_hint);
        let mut _localctx: Rc<HintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule hintList*/
			recog.base.set_state(5012);
			recog.hintList()?;

			recog.base.set_state(5013);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- hintList ----------------
pub type HintListContextAll<'input> = HintListContext<'input>;


pub type HintListContext<'input> = BaseParserRuleContext<'input,HintListContextExt<'input>>;

#[derive(Clone)]
pub struct HintListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for HintListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for HintListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_hintList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_hintList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for HintListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_hintList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_hintList }
}
crate::tid!{HintListContextExt<'a>}

impl<'input> HintListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HintListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HintListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait HintListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<HintListContextExt<'input>>{

fn hintItem_all(&self) ->  Vec<Rc<HintItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn hintItem(&self, i: usize) -> Option<Rc<HintItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> HintListContextAttrs<'input> for HintListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn hintList(&mut self,)
	-> Result<Rc<HintListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HintListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 918, RULE_hintList);
        let mut _localctx: Rc<HintListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule hintItem*/
			recog.base.set_state(5015);
			recog.hintItem()?;

			recog.base.set_state(5020);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(5016);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule hintItem*/
				recog.base.set_state(5017);
				recog.hintItem()?;

				}
				}
				recog.base.set_state(5022);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- hintItem ----------------
pub type HintItemContextAll<'input> = HintItemContext<'input>;


pub type HintItemContext<'input> = BaseParserRuleContext<'input,HintItemContextExt<'input>>;

#[derive(Clone)]
pub struct HintItemContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for HintItemContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for HintItemContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_hintItem(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_hintItem(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for HintItemContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_hintItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_hintItem }
}
crate::tid!{HintItemContextExt<'a>}

impl<'input> HintItemContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HintItemContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HintItemContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait HintItemContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<HintItemContextExt<'input>>{

fn hintName(&self) -> Option<Rc<HintNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LPAREN
/// Returns `None` if there is no child corresponding to token LPAREN
fn LPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(LPAREN, 0)
}
fn hintArgs(&self) -> Option<Rc<HintArgsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RPAREN
/// Returns `None` if there is no child corresponding to token RPAREN
fn RPAREN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(RPAREN, 0)
}

}

impl<'input> HintItemContextAttrs<'input> for HintItemContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn hintItem(&mut self,)
	-> Result<Rc<HintItemContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HintItemContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 920, RULE_hintItem);
        let mut _localctx: Rc<HintItemContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule hintName*/
			recog.base.set_state(5023);
			recog.hintName()?;

			recog.base.set_state(5028);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LPAREN {
				{
				recog.base.set_state(5024);
				recog.base.match_token(LPAREN,&mut recog.err_handler)?;

				/*InvokeRule hintArgs*/
				recog.base.set_state(5025);
				recog.hintArgs()?;

				recog.base.set_state(5026);
				recog.base.match_token(RPAREN,&mut recog.err_handler)?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- hintName ----------------
pub type HintNameContextAll<'input> = HintNameContext<'input>;


pub type HintNameContext<'input> = BaseParserRuleContext<'input,HintNameContextExt<'input>>;

#[derive(Clone)]
pub struct HintNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for HintNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for HintNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_hintName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_hintName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for HintNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_hintName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_hintName }
}
crate::tid!{HintNameContextExt<'a>}

impl<'input> HintNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HintNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HintNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait HintNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<HintNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_MAPJOIN
/// Returns `None` if there is no child corresponding to token KW_MAPJOIN
fn KW_MAPJOIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MAPJOIN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SEMI
/// Returns `None` if there is no child corresponding to token KW_SEMI
fn KW_SEMI(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SEMI, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_STREAMTABLE
/// Returns `None` if there is no child corresponding to token KW_STREAMTABLE
fn KW_STREAMTABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_STREAMTABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PKFK_JOIN
/// Returns `None` if there is no child corresponding to token KW_PKFK_JOIN
fn KW_PKFK_JOIN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PKFK_JOIN, 0)
}

}

impl<'input> HintNameContextAttrs<'input> for HintNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn hintName(&mut self,)
	-> Result<Rc<HintNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HintNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 922, RULE_hintName);
        let mut _localctx: Rc<HintNameContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5030);
			_la = recog.base.input.la(1);
			if { !(_la==KW_MAPJOIN || _la==KW_PKFK_JOIN || _la==KW_SEMI || _la==KW_STREAMTABLE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- hintArgs ----------------
pub type HintArgsContextAll<'input> = HintArgsContext<'input>;


pub type HintArgsContext<'input> = BaseParserRuleContext<'input,HintArgsContextExt<'input>>;

#[derive(Clone)]
pub struct HintArgsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for HintArgsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for HintArgsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_hintArgs(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_hintArgs(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for HintArgsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_hintArgs }
	//fn type_rule_index() -> usize where Self: Sized { RULE_hintArgs }
}
crate::tid!{HintArgsContextExt<'a>}

impl<'input> HintArgsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HintArgsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HintArgsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait HintArgsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<HintArgsContextExt<'input>>{

fn hintArgName_all(&self) ->  Vec<Rc<HintArgNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn hintArgName(&self, i: usize) -> Option<Rc<HintArgNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> HintArgsContextAttrs<'input> for HintArgsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn hintArgs(&mut self,)
	-> Result<Rc<HintArgsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HintArgsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 924, RULE_hintArgs);
        let mut _localctx: Rc<HintArgsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule hintArgName*/
			recog.base.set_state(5032);
			recog.hintArgName()?;

			recog.base.set_state(5037);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(5033);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule hintArgName*/
				recog.base.set_state(5034);
				recog.hintArgName()?;

				}
				}
				recog.base.set_state(5039);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- hintArgName ----------------
pub type HintArgNameContextAll<'input> = HintArgNameContext<'input>;


pub type HintArgNameContext<'input> = BaseParserRuleContext<'input,HintArgNameContextExt<'input>>;

#[derive(Clone)]
pub struct HintArgNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for HintArgNameContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for HintArgNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_hintArgName(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_hintArgName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for HintArgNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_hintArgName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_hintArgName }
}
crate::tid!{HintArgNameContextExt<'a>}

impl<'input> HintArgNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HintArgNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HintArgNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait HintArgNameContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<HintArgNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token Identifier
/// Returns `None` if there is no child corresponding to token Identifier
fn Identifier(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Identifier, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_NONE
/// Returns `None` if there is no child corresponding to token KW_NONE
fn KW_NONE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_NONE, 0)
}

}

impl<'input> HintArgNameContextAttrs<'input> for HintArgNameContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn hintArgName(&mut self,)
	-> Result<Rc<HintArgNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HintArgNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 926, RULE_hintArgName);
        let mut _localctx: Rc<HintArgNameContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5040);
			_la = recog.base.input.la(1);
			if { !(_la==KW_NONE || _la==Number || _la==Identifier) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- prepareStatement ----------------
pub type PrepareStatementContextAll<'input> = PrepareStatementContext<'input>;


pub type PrepareStatementContext<'input> = BaseParserRuleContext<'input,PrepareStatementContextExt<'input>>;

#[derive(Clone)]
pub struct PrepareStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PrepareStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PrepareStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_prepareStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_prepareStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PrepareStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_prepareStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_prepareStatement }
}
crate::tid!{PrepareStatementContextExt<'a>}

impl<'input> PrepareStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrepareStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrepareStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrepareStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PrepareStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_PREPARE
/// Returns `None` if there is no child corresponding to token KW_PREPARE
fn KW_PREPARE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PREPARE, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}
fn queryStatementExpression(&self) -> Option<Rc<QueryStatementExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrepareStatementContextAttrs<'input> for PrepareStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn prepareStatement(&mut self,)
	-> Result<Rc<PrepareStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrepareStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 928, RULE_prepareStatement);
        let mut _localctx: Rc<PrepareStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5042);
			recog.base.match_token(KW_PREPARE,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5043);
			recog.id_()?;

			recog.base.set_state(5044);
			recog.base.match_token(KW_FROM,&mut recog.err_handler)?;

			/*InvokeRule queryStatementExpression*/
			recog.base.set_state(5045);
			recog.queryStatementExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- executeStatement ----------------
pub type ExecuteStatementContextAll<'input> = ExecuteStatementContext<'input>;


pub type ExecuteStatementContext<'input> = BaseParserRuleContext<'input,ExecuteStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ExecuteStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExecuteStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExecuteStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_executeStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_executeStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExecuteStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_executeStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_executeStatement }
}
crate::tid!{ExecuteStatementContextExt<'a>}

impl<'input> ExecuteStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExecuteStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExecuteStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExecuteStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExecuteStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_EXECUTE
/// Returns `None` if there is no child corresponding to token KW_EXECUTE
fn KW_EXECUTE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_EXECUTE, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_USING
/// Returns `None` if there is no child corresponding to token KW_USING
fn KW_USING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USING, 0)
}
fn executeParamList(&self) -> Option<Rc<ExecuteParamListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExecuteStatementContextAttrs<'input> for ExecuteStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn executeStatement(&mut self,)
	-> Result<Rc<ExecuteStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExecuteStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 930, RULE_executeStatement);
        let mut _localctx: Rc<ExecuteStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5047);
			recog.base.match_token(KW_EXECUTE,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5048);
			recog.id_()?;

			recog.base.set_state(5049);
			recog.base.match_token(KW_USING,&mut recog.err_handler)?;

			/*InvokeRule executeParamList*/
			recog.base.set_state(5050);
			recog.executeParamList()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- executeParamList ----------------
pub type ExecuteParamListContextAll<'input> = ExecuteParamListContext<'input>;


pub type ExecuteParamListContext<'input> = BaseParserRuleContext<'input,ExecuteParamListContextExt<'input>>;

#[derive(Clone)]
pub struct ExecuteParamListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ExecuteParamListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ExecuteParamListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_executeParamList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_executeParamList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ExecuteParamListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_executeParamList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_executeParamList }
}
crate::tid!{ExecuteParamListContextExt<'a>}

impl<'input> ExecuteParamListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExecuteParamListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExecuteParamListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExecuteParamListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ExecuteParamListContextExt<'input>>{

fn constant_all(&self) ->  Vec<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn constant(&self, i: usize) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ExecuteParamListContextAttrs<'input> for ExecuteParamListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn executeParamList(&mut self,)
	-> Result<Rc<ExecuteParamListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExecuteParamListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 932, RULE_executeParamList);
        let mut _localctx: Rc<ExecuteParamListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule constant*/
			recog.base.set_state(5052);
			recog.constant()?;

			recog.base.set_state(5057);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(5053);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule constant*/
				recog.base.set_state(5054);
				recog.constant()?;

				}
				}
				recog.base.set_state(5059);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- resourcePlanDdlStatements ----------------
pub type ResourcePlanDdlStatementsContextAll<'input> = ResourcePlanDdlStatementsContext<'input>;


pub type ResourcePlanDdlStatementsContext<'input> = BaseParserRuleContext<'input,ResourcePlanDdlStatementsContextExt<'input>>;

#[derive(Clone)]
pub struct ResourcePlanDdlStatementsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ResourcePlanDdlStatementsContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ResourcePlanDdlStatementsContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_resourcePlanDdlStatements(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_resourcePlanDdlStatements(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ResourcePlanDdlStatementsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_resourcePlanDdlStatements }
	//fn type_rule_index() -> usize where Self: Sized { RULE_resourcePlanDdlStatements }
}
crate::tid!{ResourcePlanDdlStatementsContextExt<'a>}

impl<'input> ResourcePlanDdlStatementsContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ResourcePlanDdlStatementsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ResourcePlanDdlStatementsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ResourcePlanDdlStatementsContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ResourcePlanDdlStatementsContextExt<'input>>{

fn createResourcePlanStatement(&self) -> Option<Rc<CreateResourcePlanStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterResourcePlanStatement(&self) -> Option<Rc<AlterResourcePlanStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropResourcePlanStatement(&self) -> Option<Rc<DropResourcePlanStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn globalWmStatement(&self) -> Option<Rc<GlobalWmStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn replaceResourcePlanStatement(&self) -> Option<Rc<ReplaceResourcePlanStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createTriggerStatement(&self) -> Option<Rc<CreateTriggerStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterTriggerStatement(&self) -> Option<Rc<AlterTriggerStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropTriggerStatement(&self) -> Option<Rc<DropTriggerStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createPoolStatement(&self) -> Option<Rc<CreatePoolStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterPoolStatement(&self) -> Option<Rc<AlterPoolStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropPoolStatement(&self) -> Option<Rc<DropPoolStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn createMappingStatement(&self) -> Option<Rc<CreateMappingStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterMappingStatement(&self) -> Option<Rc<AlterMappingStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dropMappingStatement(&self) -> Option<Rc<DropMappingStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ResourcePlanDdlStatementsContextAttrs<'input> for ResourcePlanDdlStatementsContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn resourcePlanDdlStatements(&mut self,)
	-> Result<Rc<ResourcePlanDdlStatementsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ResourcePlanDdlStatementsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 934, RULE_resourcePlanDdlStatements);
        let mut _localctx: Rc<ResourcePlanDdlStatementsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(5074);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(601,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule createResourcePlanStatement*/
					recog.base.set_state(5060);
					recog.createResourcePlanStatement()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule alterResourcePlanStatement*/
					recog.base.set_state(5061);
					recog.alterResourcePlanStatement()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule dropResourcePlanStatement*/
					recog.base.set_state(5062);
					recog.dropResourcePlanStatement()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule globalWmStatement*/
					recog.base.set_state(5063);
					recog.globalWmStatement()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule replaceResourcePlanStatement*/
					recog.base.set_state(5064);
					recog.replaceResourcePlanStatement()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule createTriggerStatement*/
					recog.base.set_state(5065);
					recog.createTriggerStatement()?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule alterTriggerStatement*/
					recog.base.set_state(5066);
					recog.alterTriggerStatement()?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule dropTriggerStatement*/
					recog.base.set_state(5067);
					recog.dropTriggerStatement()?;

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule createPoolStatement*/
					recog.base.set_state(5068);
					recog.createPoolStatement()?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule alterPoolStatement*/
					recog.base.set_state(5069);
					recog.alterPoolStatement()?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule dropPoolStatement*/
					recog.base.set_state(5070);
					recog.dropPoolStatement()?;

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					/*InvokeRule createMappingStatement*/
					recog.base.set_state(5071);
					recog.createMappingStatement()?;

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					/*InvokeRule alterMappingStatement*/
					recog.base.set_state(5072);
					recog.alterMappingStatement()?;

					}
				}
			,
				14 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					/*InvokeRule dropMappingStatement*/
					recog.base.set_state(5073);
					recog.dropMappingStatement()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rpAssign ----------------
pub type RpAssignContextAll<'input> = RpAssignContext<'input>;


pub type RpAssignContext<'input> = BaseParserRuleContext<'input,RpAssignContextExt<'input>>;

#[derive(Clone)]
pub struct RpAssignContextExt<'input>{
	pub parallelism: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RpAssignContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RpAssignContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rpAssign(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rpAssign(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RpAssignContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rpAssign }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rpAssign }
}
crate::tid!{RpAssignContextExt<'a>}

impl<'input> RpAssignContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RpAssignContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RpAssignContextExt{
				parallelism: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RpAssignContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RpAssignContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_QUERY_PARALLELISM
/// Returns `None` if there is no child corresponding to token KW_QUERY_PARALLELISM
fn KW_QUERY_PARALLELISM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUERY_PARALLELISM, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEFAULT
/// Returns `None` if there is no child corresponding to token KW_DEFAULT
fn KW_DEFAULT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_POOL
/// Returns `None` if there is no child corresponding to token KW_POOL
fn KW_POOL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_POOL, 0)
}
fn poolPath(&self) -> Option<Rc<PoolPathContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RpAssignContextAttrs<'input> for RpAssignContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rpAssign(&mut self,)
	-> Result<Rc<RpAssignContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RpAssignContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 936, RULE_rpAssign);
        let mut _localctx: Rc<RpAssignContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(5083);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_QUERY_PARALLELISM 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(5076);
					recog.base.match_token(KW_QUERY_PARALLELISM,&mut recog.err_handler)?;

					recog.base.set_state(5077);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(5078);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,RpAssignContext >(&mut _localctx).parallelism = Some(tmp.clone());
					  

					}
				}

			 KW_DEFAULT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(5079);
					recog.base.match_token(KW_DEFAULT,&mut recog.err_handler)?;

					recog.base.set_state(5080);
					recog.base.match_token(KW_POOL,&mut recog.err_handler)?;

					recog.base.set_state(5081);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule poolPath*/
					recog.base.set_state(5082);
					recog.poolPath()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rpAssignList ----------------
pub type RpAssignListContextAll<'input> = RpAssignListContext<'input>;


pub type RpAssignListContext<'input> = BaseParserRuleContext<'input,RpAssignListContextExt<'input>>;

#[derive(Clone)]
pub struct RpAssignListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RpAssignListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RpAssignListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rpAssignList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rpAssignList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RpAssignListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rpAssignList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rpAssignList }
}
crate::tid!{RpAssignListContextExt<'a>}

impl<'input> RpAssignListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RpAssignListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RpAssignListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RpAssignListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RpAssignListContextExt<'input>>{

fn rpAssign_all(&self) ->  Vec<Rc<RpAssignContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rpAssign(&self, i: usize) -> Option<Rc<RpAssignContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> RpAssignListContextAttrs<'input> for RpAssignListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rpAssignList(&mut self,)
	-> Result<Rc<RpAssignListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RpAssignListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 938, RULE_rpAssignList);
        let mut _localctx: Rc<RpAssignListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule rpAssign*/
			recog.base.set_state(5085);
			recog.rpAssign()?;

			recog.base.set_state(5090);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(5086);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule rpAssign*/
				recog.base.set_state(5087);
				recog.rpAssign()?;

				}
				}
				recog.base.set_state(5092);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rpUnassign ----------------
pub type RpUnassignContextAll<'input> = RpUnassignContext<'input>;


pub type RpUnassignContext<'input> = BaseParserRuleContext<'input,RpUnassignContextExt<'input>>;

#[derive(Clone)]
pub struct RpUnassignContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RpUnassignContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RpUnassignContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rpUnassign(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rpUnassign(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RpUnassignContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rpUnassign }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rpUnassign }
}
crate::tid!{RpUnassignContextExt<'a>}

impl<'input> RpUnassignContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RpUnassignContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RpUnassignContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RpUnassignContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RpUnassignContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_QUERY_PARALLELISM
/// Returns `None` if there is no child corresponding to token KW_QUERY_PARALLELISM
fn KW_QUERY_PARALLELISM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUERY_PARALLELISM, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DEFAULT
/// Returns `None` if there is no child corresponding to token KW_DEFAULT
fn KW_DEFAULT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_POOL
/// Returns `None` if there is no child corresponding to token KW_POOL
fn KW_POOL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_POOL, 0)
}

}

impl<'input> RpUnassignContextAttrs<'input> for RpUnassignContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rpUnassign(&mut self,)
	-> Result<Rc<RpUnassignContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RpUnassignContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 940, RULE_rpUnassign);
        let mut _localctx: Rc<RpUnassignContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(5096);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_QUERY_PARALLELISM 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(5093);
					recog.base.match_token(KW_QUERY_PARALLELISM,&mut recog.err_handler)?;

					}
				}

			 KW_DEFAULT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(5094);
					recog.base.match_token(KW_DEFAULT,&mut recog.err_handler)?;

					recog.base.set_state(5095);
					recog.base.match_token(KW_POOL,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rpUnassignList ----------------
pub type RpUnassignListContextAll<'input> = RpUnassignListContext<'input>;


pub type RpUnassignListContext<'input> = BaseParserRuleContext<'input,RpUnassignListContextExt<'input>>;

#[derive(Clone)]
pub struct RpUnassignListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for RpUnassignListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for RpUnassignListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rpUnassignList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_rpUnassignList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for RpUnassignListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rpUnassignList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rpUnassignList }
}
crate::tid!{RpUnassignListContextExt<'a>}

impl<'input> RpUnassignListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RpUnassignListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RpUnassignListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RpUnassignListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<RpUnassignListContextExt<'input>>{

fn rpUnassign_all(&self) ->  Vec<Rc<RpUnassignContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rpUnassign(&self, i: usize) -> Option<Rc<RpUnassignContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> RpUnassignListContextAttrs<'input> for RpUnassignListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rpUnassignList(&mut self,)
	-> Result<Rc<RpUnassignListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RpUnassignListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 942, RULE_rpUnassignList);
        let mut _localctx: Rc<RpUnassignListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule rpUnassign*/
			recog.base.set_state(5098);
			recog.rpUnassign()?;

			recog.base.set_state(5103);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(5099);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule rpUnassign*/
				recog.base.set_state(5100);
				recog.rpUnassign()?;

				}
				}
				recog.base.set_state(5105);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createResourcePlanStatement ----------------
pub type CreateResourcePlanStatementContextAll<'input> = CreateResourcePlanStatementContext<'input>;


pub type CreateResourcePlanStatementContext<'input> = BaseParserRuleContext<'input,CreateResourcePlanStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateResourcePlanStatementContextExt<'input>{
	pub name: Option<Rc<Id_ContextAll<'input>>>,
	pub likeName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateResourcePlanStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateResourcePlanStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createResourcePlanStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createResourcePlanStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateResourcePlanStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createResourcePlanStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createResourcePlanStatement }
}
crate::tid!{CreateResourcePlanStatementContextExt<'a>}

impl<'input> CreateResourcePlanStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateResourcePlanStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateResourcePlanStatementContextExt{
				name: None, likeName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateResourcePlanStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateResourcePlanStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RESOURCE
/// Returns `None` if there is no child corresponding to token KW_RESOURCE
fn KW_RESOURCE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RESOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PLAN
/// Returns `None` if there is no child corresponding to token KW_PLAN
fn KW_PLAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PLAN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_LIKE
/// Returns `None` if there is no child corresponding to token KW_LIKE
fn KW_LIKE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_LIKE, 0)
}
fn ifNotExists(&self) -> Option<Rc<IfNotExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
fn rpAssignList(&self) -> Option<Rc<RpAssignListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateResourcePlanStatementContextAttrs<'input> for CreateResourcePlanStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createResourcePlanStatement(&mut self,)
	-> Result<Rc<CreateResourcePlanStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateResourcePlanStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 944, RULE_createResourcePlanStatement);
        let mut _localctx: Rc<CreateResourcePlanStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5106);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(5107);
			recog.base.match_token(KW_RESOURCE,&mut recog.err_handler)?;

			recog.base.set_state(5108);
			recog.base.match_token(KW_PLAN,&mut recog.err_handler)?;

			recog.base.set_state(5110);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifNotExists*/
				recog.base.set_state(5109);
				recog.ifNotExists()?;

				}
			}

			recog.base.set_state(5121);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(608,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule id_*/
					recog.base.set_state(5112);
					let tmp = recog.id_()?;
					 cast_mut::<_,CreateResourcePlanStatementContext >(&mut _localctx).name = Some(tmp.clone());
					  

					recog.base.set_state(5113);
					recog.base.match_token(KW_LIKE,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(5114);
					let tmp = recog.id_()?;
					 cast_mut::<_,CreateResourcePlanStatementContext >(&mut _localctx).likeName = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					{
					/*InvokeRule id_*/
					recog.base.set_state(5116);
					let tmp = recog.id_()?;
					 cast_mut::<_,CreateResourcePlanStatementContext >(&mut _localctx).name = Some(tmp.clone());
					  

					recog.base.set_state(5119);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(607,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(5117);
							recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

							/*InvokeRule rpAssignList*/
							recog.base.set_state(5118);
							recog.rpAssignList()?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- withReplace ----------------
pub type WithReplaceContextAll<'input> = WithReplaceContext<'input>;


pub type WithReplaceContext<'input> = BaseParserRuleContext<'input,WithReplaceContextExt<'input>>;

#[derive(Clone)]
pub struct WithReplaceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for WithReplaceContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for WithReplaceContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_withReplace(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_withReplace(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for WithReplaceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_withReplace }
	//fn type_rule_index() -> usize where Self: Sized { RULE_withReplace }
}
crate::tid!{WithReplaceContextExt<'a>}

impl<'input> WithReplaceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WithReplaceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WithReplaceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WithReplaceContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<WithReplaceContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_REPLACE
/// Returns `None` if there is no child corresponding to token KW_REPLACE
fn KW_REPLACE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPLACE, 0)
}

}

impl<'input> WithReplaceContextAttrs<'input> for WithReplaceContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn withReplace(&mut self,)
	-> Result<Rc<WithReplaceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WithReplaceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 946, RULE_withReplace);
        let mut _localctx: Rc<WithReplaceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5123);
			recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

			recog.base.set_state(5124);
			recog.base.match_token(KW_REPLACE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- activate ----------------
pub type ActivateContextAll<'input> = ActivateContext<'input>;


pub type ActivateContext<'input> = BaseParserRuleContext<'input,ActivateContextExt<'input>>;

#[derive(Clone)]
pub struct ActivateContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ActivateContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ActivateContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_activate(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_activate(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ActivateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_activate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_activate }
}
crate::tid!{ActivateContextExt<'a>}

impl<'input> ActivateContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ActivateContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ActivateContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ActivateContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ActivateContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ACTIVATE
/// Returns `None` if there is no child corresponding to token KW_ACTIVATE
fn KW_ACTIVATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ACTIVATE, 0)
}
fn withReplace(&self) -> Option<Rc<WithReplaceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ActivateContextAttrs<'input> for ActivateContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn activate(&mut self,)
	-> Result<Rc<ActivateContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ActivateContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 948, RULE_activate);
        let mut _localctx: Rc<ActivateContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5126);
			recog.base.match_token(KW_ACTIVATE,&mut recog.err_handler)?;

			recog.base.set_state(5128);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(609,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule withReplace*/
					recog.base.set_state(5127);
					recog.withReplace()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- enable ----------------
pub type EnableContextAll<'input> = EnableContext<'input>;


pub type EnableContext<'input> = BaseParserRuleContext<'input,EnableContextExt<'input>>;

#[derive(Clone)]
pub struct EnableContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for EnableContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for EnableContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_enable(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_enable(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for EnableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_enable }
	//fn type_rule_index() -> usize where Self: Sized { RULE_enable }
}
crate::tid!{EnableContextExt<'a>}

impl<'input> EnableContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EnableContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EnableContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait EnableContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<EnableContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ENABLE
/// Returns `None` if there is no child corresponding to token KW_ENABLE
fn KW_ENABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ENABLE, 0)
}

}

impl<'input> EnableContextAttrs<'input> for EnableContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn enable(&mut self,)
	-> Result<Rc<EnableContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EnableContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 950, RULE_enable);
        let mut _localctx: Rc<EnableContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5130);
			recog.base.match_token(KW_ENABLE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- disable ----------------
pub type DisableContextAll<'input> = DisableContext<'input>;


pub type DisableContext<'input> = BaseParserRuleContext<'input,DisableContextExt<'input>>;

#[derive(Clone)]
pub struct DisableContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DisableContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DisableContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_disable(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_disable(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DisableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_disable }
	//fn type_rule_index() -> usize where Self: Sized { RULE_disable }
}
crate::tid!{DisableContextExt<'a>}

impl<'input> DisableContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DisableContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DisableContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DisableContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DisableContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DISABLE
/// Returns `None` if there is no child corresponding to token KW_DISABLE
fn KW_DISABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISABLE, 0)
}

}

impl<'input> DisableContextAttrs<'input> for DisableContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn disable(&mut self,)
	-> Result<Rc<DisableContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DisableContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 952, RULE_disable);
        let mut _localctx: Rc<DisableContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5132);
			recog.base.match_token(KW_DISABLE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unmanaged ----------------
pub type UnmanagedContextAll<'input> = UnmanagedContext<'input>;


pub type UnmanagedContext<'input> = BaseParserRuleContext<'input,UnmanagedContextExt<'input>>;

#[derive(Clone)]
pub struct UnmanagedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for UnmanagedContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for UnmanagedContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unmanaged(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_unmanaged(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for UnmanagedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unmanaged }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unmanaged }
}
crate::tid!{UnmanagedContextExt<'a>}

impl<'input> UnmanagedContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnmanagedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnmanagedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnmanagedContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<UnmanagedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_UNMANAGED
/// Returns `None` if there is no child corresponding to token KW_UNMANAGED
fn KW_UNMANAGED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNMANAGED, 0)
}

}

impl<'input> UnmanagedContextAttrs<'input> for UnmanagedContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unmanaged(&mut self,)
	-> Result<Rc<UnmanagedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnmanagedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 954, RULE_unmanaged);
        let mut _localctx: Rc<UnmanagedContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5134);
			recog.base.match_token(KW_UNMANAGED,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterResourcePlanStatement ----------------
pub type AlterResourcePlanStatementContextAll<'input> = AlterResourcePlanStatementContext<'input>;


pub type AlterResourcePlanStatementContext<'input> = BaseParserRuleContext<'input,AlterResourcePlanStatementContextExt<'input>>;

#[derive(Clone)]
pub struct AlterResourcePlanStatementContextExt<'input>{
	pub name: Option<Rc<Id_ContextAll<'input>>>,
	pub newName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterResourcePlanStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterResourcePlanStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterResourcePlanStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterResourcePlanStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterResourcePlanStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterResourcePlanStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterResourcePlanStatement }
}
crate::tid!{AlterResourcePlanStatementContextExt<'a>}

impl<'input> AlterResourcePlanStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterResourcePlanStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterResourcePlanStatementContextExt{
				name: None, newName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterResourcePlanStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterResourcePlanStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ALTER
/// Returns `None` if there is no child corresponding to token KW_ALTER
fn KW_ALTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RESOURCE
/// Returns `None` if there is no child corresponding to token KW_RESOURCE
fn KW_RESOURCE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RESOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PLAN
/// Returns `None` if there is no child corresponding to token KW_PLAN
fn KW_PLAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PLAN, 0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_VALIDATE
/// Returns `None` if there is no child corresponding to token KW_VALIDATE
fn KW_VALIDATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_VALIDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DISABLE
/// Returns `None` if there is no child corresponding to token KW_DISABLE
fn KW_DISABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
fn rpAssignList(&self) -> Option<Rc<RpAssignListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNSET
/// Returns `None` if there is no child corresponding to token KW_UNSET
fn KW_UNSET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNSET, 0)
}
fn rpUnassignList(&self) -> Option<Rc<RpUnassignListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_RENAME
/// Returns `None` if there is no child corresponding to token KW_RENAME
fn KW_RENAME(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RENAME, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
fn activate(&self) -> Option<Rc<ActivateContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn enable(&self) -> Option<Rc<EnableContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterResourcePlanStatementContextAttrs<'input> for AlterResourcePlanStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterResourcePlanStatement(&mut self,)
	-> Result<Rc<AlterResourcePlanStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterResourcePlanStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 956, RULE_alterResourcePlanStatement);
        let mut _localctx: Rc<AlterResourcePlanStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5136);
			recog.base.match_token(KW_ALTER,&mut recog.err_handler)?;

			recog.base.set_state(5137);
			recog.base.match_token(KW_RESOURCE,&mut recog.err_handler)?;

			recog.base.set_state(5138);
			recog.base.match_token(KW_PLAN,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5139);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterResourcePlanStatementContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(5157);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_VALIDATE 
				=> {
					{
					recog.base.set_state(5140);
					recog.base.match_token(KW_VALIDATE,&mut recog.err_handler)?;

					}
				}

			 KW_DISABLE 
				=> {
					{
					recog.base.set_state(5141);
					recog.base.match_token(KW_DISABLE,&mut recog.err_handler)?;

					}
				}

			 KW_SET 
				=> {
					{
					recog.base.set_state(5142);
					recog.base.match_token(KW_SET,&mut recog.err_handler)?;

					/*InvokeRule rpAssignList*/
					recog.base.set_state(5143);
					recog.rpAssignList()?;

					}
				}

			 KW_UNSET 
				=> {
					{
					recog.base.set_state(5144);
					recog.base.match_token(KW_UNSET,&mut recog.err_handler)?;

					/*InvokeRule rpUnassignList*/
					recog.base.set_state(5145);
					recog.rpUnassignList()?;

					}
				}

			 KW_RENAME 
				=> {
					{
					recog.base.set_state(5146);
					recog.base.match_token(KW_RENAME,&mut recog.err_handler)?;

					recog.base.set_state(5147);
					recog.base.match_token(KW_TO,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(5148);
					let tmp = recog.id_()?;
					 cast_mut::<_,AlterResourcePlanStatementContext >(&mut _localctx).newName = Some(tmp.clone());
					  

					}
				}

			 KW_ACTIVATE 
				=> {
					{
					/*InvokeRule activate*/
					recog.base.set_state(5149);
					recog.activate()?;

					recog.base.set_state(5151);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(610,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule enable*/
							recog.base.set_state(5150);
							recog.enable()?;

							}
						}

						_ => {}
					}
					}
				}

			 KW_ENABLE 
				=> {
					{
					/*InvokeRule enable*/
					recog.base.set_state(5153);
					recog.enable()?;

					recog.base.set_state(5155);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==KW_ACTIVATE {
						{
						/*InvokeRule activate*/
						recog.base.set_state(5154);
						recog.activate()?;

						}
					}

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- globalWmStatement ----------------
pub type GlobalWmStatementContextAll<'input> = GlobalWmStatementContext<'input>;


pub type GlobalWmStatementContext<'input> = BaseParserRuleContext<'input,GlobalWmStatementContextExt<'input>>;

#[derive(Clone)]
pub struct GlobalWmStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for GlobalWmStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for GlobalWmStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_globalWmStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_globalWmStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for GlobalWmStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_globalWmStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_globalWmStatement }
}
crate::tid!{GlobalWmStatementContextExt<'a>}

impl<'input> GlobalWmStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GlobalWmStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GlobalWmStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GlobalWmStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<GlobalWmStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_WORKLOAD
/// Returns `None` if there is no child corresponding to token KW_WORKLOAD
fn KW_WORKLOAD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WORKLOAD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MANAGEMENT
/// Returns `None` if there is no child corresponding to token KW_MANAGEMENT
fn KW_MANAGEMENT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MANAGEMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ENABLE
/// Returns `None` if there is no child corresponding to token KW_ENABLE
fn KW_ENABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ENABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DISABLE
/// Returns `None` if there is no child corresponding to token KW_DISABLE
fn KW_DISABLE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DISABLE, 0)
}

}

impl<'input> GlobalWmStatementContextAttrs<'input> for GlobalWmStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn globalWmStatement(&mut self,)
	-> Result<Rc<GlobalWmStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GlobalWmStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 958, RULE_globalWmStatement);
        let mut _localctx: Rc<GlobalWmStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5159);
			_la = recog.base.input.la(1);
			if { !(_la==KW_DISABLE || _la==KW_ENABLE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(5160);
			recog.base.match_token(KW_WORKLOAD,&mut recog.err_handler)?;

			recog.base.set_state(5161);
			recog.base.match_token(KW_MANAGEMENT,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- replaceResourcePlanStatement ----------------
pub type ReplaceResourcePlanStatementContextAll<'input> = ReplaceResourcePlanStatementContext<'input>;


pub type ReplaceResourcePlanStatementContext<'input> = BaseParserRuleContext<'input,ReplaceResourcePlanStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ReplaceResourcePlanStatementContextExt<'input>{
	pub src: Option<Rc<Id_ContextAll<'input>>>,
	pub dest: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ReplaceResourcePlanStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ReplaceResourcePlanStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_replaceResourcePlanStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_replaceResourcePlanStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ReplaceResourcePlanStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_replaceResourcePlanStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_replaceResourcePlanStatement }
}
crate::tid!{ReplaceResourcePlanStatementContextExt<'a>}

impl<'input> ReplaceResourcePlanStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReplaceResourcePlanStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReplaceResourcePlanStatementContextExt{
				src: None, dest: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ReplaceResourcePlanStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ReplaceResourcePlanStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_REPLACE
/// Returns `None` if there is no child corresponding to token KW_REPLACE
fn KW_REPLACE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ACTIVE
/// Returns `None` if there is no child corresponding to token KW_ACTIVE
fn KW_ACTIVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ACTIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RESOURCE
/// Returns `None` if there is no child corresponding to token KW_RESOURCE
fn KW_RESOURCE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RESOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PLAN
/// Returns `None` if there is no child corresponding to token KW_PLAN
fn KW_PLAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PLAN, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ReplaceResourcePlanStatementContextAttrs<'input> for ReplaceResourcePlanStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn replaceResourcePlanStatement(&mut self,)
	-> Result<Rc<ReplaceResourcePlanStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReplaceResourcePlanStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 960, RULE_replaceResourcePlanStatement);
        let mut _localctx: Rc<ReplaceResourcePlanStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5163);
			recog.base.match_token(KW_REPLACE,&mut recog.err_handler)?;

			recog.base.set_state(5175);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ACTIVE 
				=> {
					{
					recog.base.set_state(5164);
					recog.base.match_token(KW_ACTIVE,&mut recog.err_handler)?;

					recog.base.set_state(5165);
					recog.base.match_token(KW_RESOURCE,&mut recog.err_handler)?;

					recog.base.set_state(5166);
					recog.base.match_token(KW_PLAN,&mut recog.err_handler)?;

					recog.base.set_state(5167);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(5168);
					let tmp = recog.id_()?;
					 cast_mut::<_,ReplaceResourcePlanStatementContext >(&mut _localctx).src = Some(tmp.clone());
					  

					}
				}

			 KW_RESOURCE 
				=> {
					{
					recog.base.set_state(5169);
					recog.base.match_token(KW_RESOURCE,&mut recog.err_handler)?;

					recog.base.set_state(5170);
					recog.base.match_token(KW_PLAN,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(5171);
					let tmp = recog.id_()?;
					 cast_mut::<_,ReplaceResourcePlanStatementContext >(&mut _localctx).dest = Some(tmp.clone());
					  

					recog.base.set_state(5172);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(5173);
					let tmp = recog.id_()?;
					 cast_mut::<_,ReplaceResourcePlanStatementContext >(&mut _localctx).src = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropResourcePlanStatement ----------------
pub type DropResourcePlanStatementContextAll<'input> = DropResourcePlanStatementContext<'input>;


pub type DropResourcePlanStatementContext<'input> = BaseParserRuleContext<'input,DropResourcePlanStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropResourcePlanStatementContextExt<'input>{
	pub name: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropResourcePlanStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropResourcePlanStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropResourcePlanStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropResourcePlanStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropResourcePlanStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropResourcePlanStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropResourcePlanStatement }
}
crate::tid!{DropResourcePlanStatementContextExt<'a>}

impl<'input> DropResourcePlanStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropResourcePlanStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropResourcePlanStatementContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DropResourcePlanStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropResourcePlanStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_RESOURCE
/// Returns `None` if there is no child corresponding to token KW_RESOURCE
fn KW_RESOURCE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_RESOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PLAN
/// Returns `None` if there is no child corresponding to token KW_PLAN
fn KW_PLAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PLAN, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifExists(&self) -> Option<Rc<IfExistsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DropResourcePlanStatementContextAttrs<'input> for DropResourcePlanStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropResourcePlanStatement(&mut self,)
	-> Result<Rc<DropResourcePlanStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropResourcePlanStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 962, RULE_dropResourcePlanStatement);
        let mut _localctx: Rc<DropResourcePlanStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5177);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(5178);
			recog.base.match_token(KW_RESOURCE,&mut recog.err_handler)?;

			recog.base.set_state(5179);
			recog.base.match_token(KW_PLAN,&mut recog.err_handler)?;

			recog.base.set_state(5181);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KW_IF {
				{
				/*InvokeRule ifExists*/
				recog.base.set_state(5180);
				recog.ifExists()?;

				}
			}

			/*InvokeRule id_*/
			recog.base.set_state(5183);
			let tmp = recog.id_()?;
			 cast_mut::<_,DropResourcePlanStatementContext >(&mut _localctx).name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- poolPath ----------------
pub type PoolPathContextAll<'input> = PoolPathContext<'input>;


pub type PoolPathContext<'input> = BaseParserRuleContext<'input,PoolPathContextExt<'input>>;

#[derive(Clone)]
pub struct PoolPathContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PoolPathContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PoolPathContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_poolPath(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_poolPath(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PoolPathContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_poolPath }
	//fn type_rule_index() -> usize where Self: Sized { RULE_poolPath }
}
crate::tid!{PoolPathContextExt<'a>}

impl<'input> PoolPathContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PoolPathContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PoolPathContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PoolPathContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PoolPathContextExt<'input>>{

fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, i)
}

}

impl<'input> PoolPathContextAttrs<'input> for PoolPathContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn poolPath(&mut self,)
	-> Result<Rc<PoolPathContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PoolPathContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 964, RULE_poolPath);
        let mut _localctx: Rc<PoolPathContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(5185);
			recog.id_()?;

			recog.base.set_state(5190);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==DOT {
				{
				{
				recog.base.set_state(5186);
				recog.base.match_token(DOT,&mut recog.err_handler)?;

				/*InvokeRule id_*/
				recog.base.set_state(5187);
				recog.id_()?;

				}
				}
				recog.base.set_state(5192);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- triggerExpression ----------------
pub type TriggerExpressionContextAll<'input> = TriggerExpressionContext<'input>;


pub type TriggerExpressionContext<'input> = BaseParserRuleContext<'input,TriggerExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct TriggerExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TriggerExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TriggerExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_triggerExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_triggerExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TriggerExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_triggerExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_triggerExpression }
}
crate::tid!{TriggerExpressionContextExt<'a>}

impl<'input> TriggerExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TriggerExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TriggerExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TriggerExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TriggerExpressionContextExt<'input>>{

fn triggerAtomExpression(&self) -> Option<Rc<TriggerAtomExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TriggerExpressionContextAttrs<'input> for TriggerExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn triggerExpression(&mut self,)
	-> Result<Rc<TriggerExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TriggerExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 966, RULE_triggerExpression);
        let mut _localctx: Rc<TriggerExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule triggerAtomExpression*/
			recog.base.set_state(5193);
			recog.triggerAtomExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- triggerExpressionStandalone ----------------
pub type TriggerExpressionStandaloneContextAll<'input> = TriggerExpressionStandaloneContext<'input>;


pub type TriggerExpressionStandaloneContext<'input> = BaseParserRuleContext<'input,TriggerExpressionStandaloneContextExt<'input>>;

#[derive(Clone)]
pub struct TriggerExpressionStandaloneContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TriggerExpressionStandaloneContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TriggerExpressionStandaloneContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_triggerExpressionStandalone(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_triggerExpressionStandalone(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TriggerExpressionStandaloneContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_triggerExpressionStandalone }
	//fn type_rule_index() -> usize where Self: Sized { RULE_triggerExpressionStandalone }
}
crate::tid!{TriggerExpressionStandaloneContextExt<'a>}

impl<'input> TriggerExpressionStandaloneContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TriggerExpressionStandaloneContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TriggerExpressionStandaloneContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TriggerExpressionStandaloneContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TriggerExpressionStandaloneContextExt<'input>>{

fn triggerExpression(&self) -> Option<Rc<TriggerExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> TriggerExpressionStandaloneContextAttrs<'input> for TriggerExpressionStandaloneContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn triggerExpressionStandalone(&mut self,)
	-> Result<Rc<TriggerExpressionStandaloneContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TriggerExpressionStandaloneContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 968, RULE_triggerExpressionStandalone);
        let mut _localctx: Rc<TriggerExpressionStandaloneContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule triggerExpression*/
			recog.base.set_state(5195);
			recog.triggerExpression()?;

			recog.base.set_state(5196);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- triggerOrExpression ----------------
pub type TriggerOrExpressionContextAll<'input> = TriggerOrExpressionContext<'input>;


pub type TriggerOrExpressionContext<'input> = BaseParserRuleContext<'input,TriggerOrExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct TriggerOrExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TriggerOrExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TriggerOrExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_triggerOrExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_triggerOrExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TriggerOrExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_triggerOrExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_triggerOrExpression }
}
crate::tid!{TriggerOrExpressionContextExt<'a>}

impl<'input> TriggerOrExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TriggerOrExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TriggerOrExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TriggerOrExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TriggerOrExpressionContextExt<'input>>{

fn triggerAndExpression_all(&self) ->  Vec<Rc<TriggerAndExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn triggerAndExpression(&self, i: usize) -> Option<Rc<TriggerAndExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_OR in current rule
fn KW_OR_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_OR, starting from 0.
/// Returns `None` if number of children corresponding to token KW_OR is less or equal than `i`.
fn KW_OR(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_OR, i)
}

}

impl<'input> TriggerOrExpressionContextAttrs<'input> for TriggerOrExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn triggerOrExpression(&mut self,)
	-> Result<Rc<TriggerOrExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TriggerOrExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 970, RULE_triggerOrExpression);
        let mut _localctx: Rc<TriggerOrExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule triggerAndExpression*/
			recog.base.set_state(5198);
			recog.triggerAndExpression()?;

			recog.base.set_state(5203);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==KW_OR {
				{
				{
				recog.base.set_state(5199);
				recog.base.match_token(KW_OR,&mut recog.err_handler)?;

				/*InvokeRule triggerAndExpression*/
				recog.base.set_state(5200);
				recog.triggerAndExpression()?;

				}
				}
				recog.base.set_state(5205);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- triggerAndExpression ----------------
pub type TriggerAndExpressionContextAll<'input> = TriggerAndExpressionContext<'input>;


pub type TriggerAndExpressionContext<'input> = BaseParserRuleContext<'input,TriggerAndExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct TriggerAndExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TriggerAndExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TriggerAndExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_triggerAndExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_triggerAndExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TriggerAndExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_triggerAndExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_triggerAndExpression }
}
crate::tid!{TriggerAndExpressionContextExt<'a>}

impl<'input> TriggerAndExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TriggerAndExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TriggerAndExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TriggerAndExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TriggerAndExpressionContextExt<'input>>{

fn triggerAtomExpression_all(&self) ->  Vec<Rc<TriggerAtomExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn triggerAtomExpression(&self, i: usize) -> Option<Rc<TriggerAtomExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token KW_AND in current rule
fn KW_AND_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token KW_AND, starting from 0.
/// Returns `None` if number of children corresponding to token KW_AND is less or equal than `i`.
fn KW_AND(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_AND, i)
}

}

impl<'input> TriggerAndExpressionContextAttrs<'input> for TriggerAndExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn triggerAndExpression(&mut self,)
	-> Result<Rc<TriggerAndExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TriggerAndExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 972, RULE_triggerAndExpression);
        let mut _localctx: Rc<TriggerAndExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule triggerAtomExpression*/
			recog.base.set_state(5206);
			recog.triggerAtomExpression()?;

			recog.base.set_state(5211);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==KW_AND {
				{
				{
				recog.base.set_state(5207);
				recog.base.match_token(KW_AND,&mut recog.err_handler)?;

				/*InvokeRule triggerAtomExpression*/
				recog.base.set_state(5208);
				recog.triggerAtomExpression()?;

				}
				}
				recog.base.set_state(5213);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- triggerAtomExpression ----------------
pub type TriggerAtomExpressionContextAll<'input> = TriggerAtomExpressionContext<'input>;


pub type TriggerAtomExpressionContext<'input> = BaseParserRuleContext<'input,TriggerAtomExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct TriggerAtomExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TriggerAtomExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TriggerAtomExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_triggerAtomExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_triggerAtomExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TriggerAtomExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_triggerAtomExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_triggerAtomExpression }
}
crate::tid!{TriggerAtomExpressionContextExt<'a>}

impl<'input> TriggerAtomExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TriggerAtomExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TriggerAtomExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TriggerAtomExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TriggerAtomExpressionContextExt<'input>>{

fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn comparisionOperator(&self) -> Option<Rc<ComparisionOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn triggerLiteral(&self) -> Option<Rc<TriggerLiteralContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TriggerAtomExpressionContextAttrs<'input> for TriggerAtomExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn triggerAtomExpression(&mut self,)
	-> Result<Rc<TriggerAtomExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TriggerAtomExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 974, RULE_triggerAtomExpression);
        let mut _localctx: Rc<TriggerAtomExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule id_*/
			recog.base.set_state(5214);
			recog.id_()?;

			/*InvokeRule comparisionOperator*/
			recog.base.set_state(5215);
			recog.comparisionOperator()?;

			/*InvokeRule triggerLiteral*/
			recog.base.set_state(5216);
			recog.triggerLiteral()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- triggerLiteral ----------------
pub type TriggerLiteralContextAll<'input> = TriggerLiteralContext<'input>;


pub type TriggerLiteralContext<'input> = BaseParserRuleContext<'input,TriggerLiteralContextExt<'input>>;

#[derive(Clone)]
pub struct TriggerLiteralContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TriggerLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TriggerLiteralContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_triggerLiteral(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_triggerLiteral(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TriggerLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_triggerLiteral }
	//fn type_rule_index() -> usize where Self: Sized { RULE_triggerLiteral }
}
crate::tid!{TriggerLiteralContextExt<'a>}

impl<'input> TriggerLiteralContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TriggerLiteralContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TriggerLiteralContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TriggerLiteralContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TriggerLiteralContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}

}

impl<'input> TriggerLiteralContextAttrs<'input> for TriggerLiteralContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn triggerLiteral(&mut self,)
	-> Result<Rc<TriggerLiteralContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TriggerLiteralContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 976, RULE_triggerLiteral);
        let mut _localctx: Rc<TriggerLiteralContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5218);
			_la = recog.base.input.la(1);
			if { !(_la==StringLiteral || _la==Number) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- comparisionOperator ----------------
pub type ComparisionOperatorContextAll<'input> = ComparisionOperatorContext<'input>;


pub type ComparisionOperatorContext<'input> = BaseParserRuleContext<'input,ComparisionOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ComparisionOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for ComparisionOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for ComparisionOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_comparisionOperator(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_comparisionOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for ComparisionOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisionOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisionOperator }
}
crate::tid!{ComparisionOperatorContextExt<'a>}

impl<'input> ComparisionOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComparisionOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComparisionOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ComparisionOperatorContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<ComparisionOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GREATERTHAN
/// Returns `None` if there is no child corresponding to token GREATERTHAN
fn GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHAN, 0)
}

}

impl<'input> ComparisionOperatorContextAttrs<'input> for ComparisionOperatorContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn comparisionOperator(&mut self,)
	-> Result<Rc<ComparisionOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComparisionOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 978, RULE_comparisionOperator);
        let mut _localctx: Rc<ComparisionOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5220);
			recog.base.match_token(GREATERTHAN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- triggerActionExpression ----------------
pub type TriggerActionExpressionContextAll<'input> = TriggerActionExpressionContext<'input>;


pub type TriggerActionExpressionContext<'input> = BaseParserRuleContext<'input,TriggerActionExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct TriggerActionExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TriggerActionExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TriggerActionExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_triggerActionExpression(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_triggerActionExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TriggerActionExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_triggerActionExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_triggerActionExpression }
}
crate::tid!{TriggerActionExpressionContextExt<'a>}

impl<'input> TriggerActionExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TriggerActionExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TriggerActionExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TriggerActionExpressionContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TriggerActionExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_KILL
/// Returns `None` if there is no child corresponding to token KW_KILL
fn KW_KILL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_KILL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MOVE
/// Returns `None` if there is no child corresponding to token KW_MOVE
fn KW_MOVE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MOVE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
fn poolPath(&self) -> Option<Rc<PoolPathContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TriggerActionExpressionContextAttrs<'input> for TriggerActionExpressionContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn triggerActionExpression(&mut self,)
	-> Result<Rc<TriggerActionExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TriggerActionExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 980, RULE_triggerActionExpression);
        let mut _localctx: Rc<TriggerActionExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(5226);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_KILL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(5222);
					recog.base.match_token(KW_KILL,&mut recog.err_handler)?;

					}
				}

			 KW_MOVE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(5223);
					recog.base.match_token(KW_MOVE,&mut recog.err_handler)?;

					recog.base.set_state(5224);
					recog.base.match_token(KW_TO,&mut recog.err_handler)?;

					/*InvokeRule poolPath*/
					recog.base.set_state(5225);
					recog.poolPath()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- triggerActionExpressionStandalone ----------------
pub type TriggerActionExpressionStandaloneContextAll<'input> = TriggerActionExpressionStandaloneContext<'input>;


pub type TriggerActionExpressionStandaloneContext<'input> = BaseParserRuleContext<'input,TriggerActionExpressionStandaloneContextExt<'input>>;

#[derive(Clone)]
pub struct TriggerActionExpressionStandaloneContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for TriggerActionExpressionStandaloneContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for TriggerActionExpressionStandaloneContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_triggerActionExpressionStandalone(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_triggerActionExpressionStandalone(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for TriggerActionExpressionStandaloneContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_triggerActionExpressionStandalone }
	//fn type_rule_index() -> usize where Self: Sized { RULE_triggerActionExpressionStandalone }
}
crate::tid!{TriggerActionExpressionStandaloneContextExt<'a>}

impl<'input> TriggerActionExpressionStandaloneContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TriggerActionExpressionStandaloneContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TriggerActionExpressionStandaloneContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TriggerActionExpressionStandaloneContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<TriggerActionExpressionStandaloneContextExt<'input>>{

fn triggerActionExpression(&self) -> Option<Rc<TriggerActionExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> TriggerActionExpressionStandaloneContextAttrs<'input> for TriggerActionExpressionStandaloneContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn triggerActionExpressionStandalone(&mut self,)
	-> Result<Rc<TriggerActionExpressionStandaloneContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TriggerActionExpressionStandaloneContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 982, RULE_triggerActionExpressionStandalone);
        let mut _localctx: Rc<TriggerActionExpressionStandaloneContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule triggerActionExpression*/
			recog.base.set_state(5228);
			recog.triggerActionExpression()?;

			recog.base.set_state(5229);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createTriggerStatement ----------------
pub type CreateTriggerStatementContextAll<'input> = CreateTriggerStatementContext<'input>;


pub type CreateTriggerStatementContext<'input> = BaseParserRuleContext<'input,CreateTriggerStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateTriggerStatementContextExt<'input>{
	pub rpName: Option<Rc<Id_ContextAll<'input>>>,
	pub triggerName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateTriggerStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateTriggerStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createTriggerStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createTriggerStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateTriggerStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createTriggerStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createTriggerStatement }
}
crate::tid!{CreateTriggerStatementContextExt<'a>}

impl<'input> CreateTriggerStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateTriggerStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateTriggerStatementContextExt{
				rpName: None, triggerName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateTriggerStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateTriggerStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRIGGER
/// Returns `None` if there is no child corresponding to token KW_TRIGGER
fn KW_TRIGGER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRIGGER, 0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_WHEN
/// Returns `None` if there is no child corresponding to token KW_WHEN
fn KW_WHEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WHEN, 0)
}
fn triggerExpression(&self) -> Option<Rc<TriggerExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_DO
/// Returns `None` if there is no child corresponding to token KW_DO
fn KW_DO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DO, 0)
}
fn triggerActionExpression(&self) -> Option<Rc<TriggerActionExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> CreateTriggerStatementContextAttrs<'input> for CreateTriggerStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createTriggerStatement(&mut self,)
	-> Result<Rc<CreateTriggerStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateTriggerStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 984, RULE_createTriggerStatement);
        let mut _localctx: Rc<CreateTriggerStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5231);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(5232);
			recog.base.match_token(KW_TRIGGER,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5233);
			let tmp = recog.id_()?;
			 cast_mut::<_,CreateTriggerStatementContext >(&mut _localctx).rpName = Some(tmp.clone());
			  

			recog.base.set_state(5234);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5235);
			let tmp = recog.id_()?;
			 cast_mut::<_,CreateTriggerStatementContext >(&mut _localctx).triggerName = Some(tmp.clone());
			  

			recog.base.set_state(5236);
			recog.base.match_token(KW_WHEN,&mut recog.err_handler)?;

			/*InvokeRule triggerExpression*/
			recog.base.set_state(5237);
			recog.triggerExpression()?;

			recog.base.set_state(5238);
			recog.base.match_token(KW_DO,&mut recog.err_handler)?;

			/*InvokeRule triggerActionExpression*/
			recog.base.set_state(5239);
			recog.triggerActionExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterTriggerStatement ----------------
pub type AlterTriggerStatementContextAll<'input> = AlterTriggerStatementContext<'input>;


pub type AlterTriggerStatementContext<'input> = BaseParserRuleContext<'input,AlterTriggerStatementContextExt<'input>>;

#[derive(Clone)]
pub struct AlterTriggerStatementContextExt<'input>{
	pub rpName: Option<Rc<Id_ContextAll<'input>>>,
	pub triggerName: Option<Rc<Id_ContextAll<'input>>>,
	pub poolName: Option<Rc<PoolPathContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterTriggerStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterTriggerStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterTriggerStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterTriggerStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterTriggerStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterTriggerStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterTriggerStatement }
}
crate::tid!{AlterTriggerStatementContextExt<'a>}

impl<'input> AlterTriggerStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterTriggerStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterTriggerStatementContextExt{
				rpName: None, triggerName: None, poolName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterTriggerStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterTriggerStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ALTER
/// Returns `None` if there is no child corresponding to token KW_ALTER
fn KW_ALTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRIGGER
/// Returns `None` if there is no child corresponding to token KW_TRIGGER
fn KW_TRIGGER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRIGGER, 0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_WHEN
/// Returns `None` if there is no child corresponding to token KW_WHEN
fn KW_WHEN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WHEN, 0)
}
fn triggerExpression(&self) -> Option<Rc<TriggerExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_DO
/// Returns `None` if there is no child corresponding to token KW_DO
fn KW_DO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DO, 0)
}
fn triggerActionExpression(&self) -> Option<Rc<TriggerActionExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_ADD
/// Returns `None` if there is no child corresponding to token KW_ADD
fn KW_ADD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_FROM
/// Returns `None` if there is no child corresponding to token KW_FROM
fn KW_FROM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_POOL
/// Returns `None` if there is no child corresponding to token KW_POOL
fn KW_POOL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_POOL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNMANAGED
/// Returns `None` if there is no child corresponding to token KW_UNMANAGED
fn KW_UNMANAGED(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNMANAGED, 0)
}
fn poolPath(&self) -> Option<Rc<PoolPathContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterTriggerStatementContextAttrs<'input> for AlterTriggerStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterTriggerStatement(&mut self,)
	-> Result<Rc<AlterTriggerStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterTriggerStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 986, RULE_alterTriggerStatement);
        let mut _localctx: Rc<AlterTriggerStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5241);
			recog.base.match_token(KW_ALTER,&mut recog.err_handler)?;

			recog.base.set_state(5242);
			recog.base.match_token(KW_TRIGGER,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5243);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterTriggerStatementContext >(&mut _localctx).rpName = Some(tmp.clone());
			  

			recog.base.set_state(5244);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5245);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterTriggerStatementContext >(&mut _localctx).triggerName = Some(tmp.clone());
			  

			recog.base.set_state(5262);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_WHEN 
				=> {
					{
					recog.base.set_state(5246);
					recog.base.match_token(KW_WHEN,&mut recog.err_handler)?;

					/*InvokeRule triggerExpression*/
					recog.base.set_state(5247);
					recog.triggerExpression()?;

					recog.base.set_state(5248);
					recog.base.match_token(KW_DO,&mut recog.err_handler)?;

					/*InvokeRule triggerActionExpression*/
					recog.base.set_state(5249);
					recog.triggerActionExpression()?;

					}
				}

			 KW_ADD | KW_DROP 
				=> {
					{
					recog.base.set_state(5255);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_ADD 
						=> {
							{
							recog.base.set_state(5251);
							recog.base.match_token(KW_ADD,&mut recog.err_handler)?;

							recog.base.set_state(5252);
							recog.base.match_token(KW_TO,&mut recog.err_handler)?;

							}
						}

					 KW_DROP 
						=> {
							{
							recog.base.set_state(5253);
							recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

							recog.base.set_state(5254);
							recog.base.match_token(KW_FROM,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					recog.base.set_state(5260);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 KW_POOL 
						=> {
							{
							recog.base.set_state(5257);
							recog.base.match_token(KW_POOL,&mut recog.err_handler)?;

							/*InvokeRule poolPath*/
							recog.base.set_state(5258);
							let tmp = recog.poolPath()?;
							 cast_mut::<_,AlterTriggerStatementContext >(&mut _localctx).poolName = Some(tmp.clone());
							  

							}
						}

					 KW_UNMANAGED 
						=> {
							{
							recog.base.set_state(5259);
							recog.base.match_token(KW_UNMANAGED,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropTriggerStatement ----------------
pub type DropTriggerStatementContextAll<'input> = DropTriggerStatementContext<'input>;


pub type DropTriggerStatementContext<'input> = BaseParserRuleContext<'input,DropTriggerStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropTriggerStatementContextExt<'input>{
	pub rpName: Option<Rc<Id_ContextAll<'input>>>,
	pub triggerName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropTriggerStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropTriggerStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropTriggerStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropTriggerStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropTriggerStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropTriggerStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropTriggerStatement }
}
crate::tid!{DropTriggerStatementContextExt<'a>}

impl<'input> DropTriggerStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropTriggerStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropTriggerStatementContextExt{
				rpName: None, triggerName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DropTriggerStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropTriggerStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRIGGER
/// Returns `None` if there is no child corresponding to token KW_TRIGGER
fn KW_TRIGGER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRIGGER, 0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> DropTriggerStatementContextAttrs<'input> for DropTriggerStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropTriggerStatement(&mut self,)
	-> Result<Rc<DropTriggerStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropTriggerStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 988, RULE_dropTriggerStatement);
        let mut _localctx: Rc<DropTriggerStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5264);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(5265);
			recog.base.match_token(KW_TRIGGER,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5266);
			let tmp = recog.id_()?;
			 cast_mut::<_,DropTriggerStatementContext >(&mut _localctx).rpName = Some(tmp.clone());
			  

			recog.base.set_state(5267);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5268);
			let tmp = recog.id_()?;
			 cast_mut::<_,DropTriggerStatementContext >(&mut _localctx).triggerName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- poolAssign ----------------
pub type PoolAssignContextAll<'input> = PoolAssignContext<'input>;


pub type PoolAssignContext<'input> = BaseParserRuleContext<'input,PoolAssignContextExt<'input>>;

#[derive(Clone)]
pub struct PoolAssignContextExt<'input>{
	pub allocFraction: Option<TokenType<'input>>,
	pub parallelism: Option<TokenType<'input>>,
	pub policy: Option<TokenType<'input>>,
	pub path: Option<Rc<PoolPathContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PoolAssignContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PoolAssignContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_poolAssign(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_poolAssign(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PoolAssignContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_poolAssign }
	//fn type_rule_index() -> usize where Self: Sized { RULE_poolAssign }
}
crate::tid!{PoolAssignContextExt<'a>}

impl<'input> PoolAssignContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PoolAssignContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PoolAssignContextExt{
				allocFraction: None, parallelism: None, policy: None, 
				path: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PoolAssignContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PoolAssignContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ALLOC_FRACTION
/// Returns `None` if there is no child corresponding to token KW_ALLOC_FRACTION
fn KW_ALLOC_FRACTION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALLOC_FRACTION, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_QUERY_PARALLELISM
/// Returns `None` if there is no child corresponding to token KW_QUERY_PARALLELISM
fn KW_QUERY_PARALLELISM(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_QUERY_PARALLELISM, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SCHEDULING_POLICY
/// Returns `None` if there is no child corresponding to token KW_SCHEDULING_POLICY
fn KW_SCHEDULING_POLICY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SCHEDULING_POLICY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_PATH
/// Returns `None` if there is no child corresponding to token KW_PATH
fn KW_PATH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_PATH, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn poolPath(&self) -> Option<Rc<PoolPathContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PoolAssignContextAttrs<'input> for PoolAssignContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn poolAssign(&mut self,)
	-> Result<Rc<PoolAssignContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PoolAssignContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 990, RULE_poolAssign);
        let mut _localctx: Rc<PoolAssignContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5282);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_ALLOC_FRACTION 
				=> {
					{
					recog.base.set_state(5270);
					recog.base.match_token(KW_ALLOC_FRACTION,&mut recog.err_handler)?;

					recog.base.set_state(5271);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(5272);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,PoolAssignContext >(&mut _localctx).allocFraction = Some(tmp.clone());
					  

					}
				}

			 KW_QUERY_PARALLELISM 
				=> {
					{
					recog.base.set_state(5273);
					recog.base.match_token(KW_QUERY_PARALLELISM,&mut recog.err_handler)?;

					recog.base.set_state(5274);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(5275);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,PoolAssignContext >(&mut _localctx).parallelism = Some(tmp.clone());
					  

					}
				}

			 KW_SCHEDULING_POLICY 
				=> {
					{
					recog.base.set_state(5276);
					recog.base.match_token(KW_SCHEDULING_POLICY,&mut recog.err_handler)?;

					recog.base.set_state(5277);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(5278);
					let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
					 cast_mut::<_,PoolAssignContext >(&mut _localctx).policy = Some(tmp.clone());
					  

					}
				}

			 KW_PATH 
				=> {
					{
					recog.base.set_state(5279);
					recog.base.match_token(KW_PATH,&mut recog.err_handler)?;

					recog.base.set_state(5280);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule poolPath*/
					recog.base.set_state(5281);
					let tmp = recog.poolPath()?;
					 cast_mut::<_,PoolAssignContext >(&mut _localctx).path = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- poolAssignList ----------------
pub type PoolAssignListContextAll<'input> = PoolAssignListContext<'input>;


pub type PoolAssignListContext<'input> = BaseParserRuleContext<'input,PoolAssignListContextExt<'input>>;

#[derive(Clone)]
pub struct PoolAssignListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for PoolAssignListContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for PoolAssignListContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_poolAssignList(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_poolAssignList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for PoolAssignListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_poolAssignList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_poolAssignList }
}
crate::tid!{PoolAssignListContextExt<'a>}

impl<'input> PoolAssignListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PoolAssignListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PoolAssignListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PoolAssignListContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<PoolAssignListContextExt<'input>>{

fn poolAssign_all(&self) ->  Vec<Rc<PoolAssignContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn poolAssign(&self, i: usize) -> Option<Rc<PoolAssignContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HiveSqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PoolAssignListContextAttrs<'input> for PoolAssignListContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn poolAssignList(&mut self,)
	-> Result<Rc<PoolAssignListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PoolAssignListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 992, RULE_poolAssignList);
        let mut _localctx: Rc<PoolAssignListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule poolAssign*/
			recog.base.set_state(5284);
			recog.poolAssign()?;

			recog.base.set_state(5289);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(5285);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule poolAssign*/
				recog.base.set_state(5286);
				recog.poolAssign()?;

				}
				}
				recog.base.set_state(5291);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createPoolStatement ----------------
pub type CreatePoolStatementContextAll<'input> = CreatePoolStatementContext<'input>;


pub type CreatePoolStatementContext<'input> = BaseParserRuleContext<'input,CreatePoolStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreatePoolStatementContextExt<'input>{
	pub rpName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreatePoolStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreatePoolStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createPoolStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createPoolStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreatePoolStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createPoolStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createPoolStatement }
}
crate::tid!{CreatePoolStatementContextExt<'a>}

impl<'input> CreatePoolStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreatePoolStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreatePoolStatementContextExt{
				rpName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreatePoolStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreatePoolStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_POOL
/// Returns `None` if there is no child corresponding to token KW_POOL
fn KW_POOL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_POOL, 0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn poolPath(&self) -> Option<Rc<PoolPathContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
fn poolAssignList(&self) -> Option<Rc<PoolAssignListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreatePoolStatementContextAttrs<'input> for CreatePoolStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createPoolStatement(&mut self,)
	-> Result<Rc<CreatePoolStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreatePoolStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 994, RULE_createPoolStatement);
        let mut _localctx: Rc<CreatePoolStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5292);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(5293);
			recog.base.match_token(KW_POOL,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5294);
			let tmp = recog.id_()?;
			 cast_mut::<_,CreatePoolStatementContext >(&mut _localctx).rpName = Some(tmp.clone());
			  

			recog.base.set_state(5295);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			/*InvokeRule poolPath*/
			recog.base.set_state(5296);
			recog.poolPath()?;

			recog.base.set_state(5297);
			recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

			/*InvokeRule poolAssignList*/
			recog.base.set_state(5298);
			recog.poolAssignList()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterPoolStatement ----------------
pub type AlterPoolStatementContextAll<'input> = AlterPoolStatementContext<'input>;


pub type AlterPoolStatementContext<'input> = BaseParserRuleContext<'input,AlterPoolStatementContextExt<'input>>;

#[derive(Clone)]
pub struct AlterPoolStatementContextExt<'input>{
	pub rpName: Option<Rc<Id_ContextAll<'input>>>,
	pub triggerName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterPoolStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterPoolStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterPoolStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterPoolStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterPoolStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterPoolStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterPoolStatement }
}
crate::tid!{AlterPoolStatementContextExt<'a>}

impl<'input> AlterPoolStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterPoolStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterPoolStatementContextExt{
				rpName: None, triggerName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterPoolStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterPoolStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ALTER
/// Returns `None` if there is no child corresponding to token KW_ALTER
fn KW_ALTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_POOL
/// Returns `None` if there is no child corresponding to token KW_POOL
fn KW_POOL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_POOL, 0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn poolPath(&self) -> Option<Rc<PoolPathContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id__all(&self) ->  Vec<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn id_(&self, i: usize) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token KW_SET
/// Returns `None` if there is no child corresponding to token KW_SET
fn KW_SET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SET, 0)
}
fn poolAssignList(&self) -> Option<Rc<PoolAssignListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_UNSET
/// Returns `None` if there is no child corresponding to token KW_UNSET
fn KW_UNSET(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_UNSET, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_SCHEDULING_POLICY
/// Returns `None` if there is no child corresponding to token KW_SCHEDULING_POLICY
fn KW_SCHEDULING_POLICY(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_SCHEDULING_POLICY, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TRIGGER
/// Returns `None` if there is no child corresponding to token KW_TRIGGER
fn KW_TRIGGER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TRIGGER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ADD
/// Returns `None` if there is no child corresponding to token KW_ADD
fn KW_ADD(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}

}

impl<'input> AlterPoolStatementContextAttrs<'input> for AlterPoolStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterPoolStatement(&mut self,)
	-> Result<Rc<AlterPoolStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterPoolStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 996, RULE_alterPoolStatement);
        let mut _localctx: Rc<AlterPoolStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5300);
			recog.base.match_token(KW_ALTER,&mut recog.err_handler)?;

			recog.base.set_state(5301);
			recog.base.match_token(KW_POOL,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5302);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterPoolStatementContext >(&mut _localctx).rpName = Some(tmp.clone());
			  

			recog.base.set_state(5303);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			/*InvokeRule poolPath*/
			recog.base.set_state(5304);
			recog.poolPath()?;

			recog.base.set_state(5312);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_SET 
				=> {
					{
					recog.base.set_state(5305);
					recog.base.match_token(KW_SET,&mut recog.err_handler)?;

					/*InvokeRule poolAssignList*/
					recog.base.set_state(5306);
					recog.poolAssignList()?;

					}
				}

			 KW_UNSET 
				=> {
					{
					recog.base.set_state(5307);
					recog.base.match_token(KW_UNSET,&mut recog.err_handler)?;

					recog.base.set_state(5308);
					recog.base.match_token(KW_SCHEDULING_POLICY,&mut recog.err_handler)?;

					}
				}

			 KW_ADD | KW_DROP 
				=> {
					{
					recog.base.set_state(5309);
					_la = recog.base.input.la(1);
					if { !(_la==KW_ADD || _la==KW_DROP) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(5310);
					recog.base.match_token(KW_TRIGGER,&mut recog.err_handler)?;

					/*InvokeRule id_*/
					recog.base.set_state(5311);
					let tmp = recog.id_()?;
					 cast_mut::<_,AlterPoolStatementContext >(&mut _localctx).triggerName = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropPoolStatement ----------------
pub type DropPoolStatementContextAll<'input> = DropPoolStatementContext<'input>;


pub type DropPoolStatementContext<'input> = BaseParserRuleContext<'input,DropPoolStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropPoolStatementContextExt<'input>{
	pub rpName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropPoolStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropPoolStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropPoolStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropPoolStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropPoolStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropPoolStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropPoolStatement }
}
crate::tid!{DropPoolStatementContextExt<'a>}

impl<'input> DropPoolStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropPoolStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropPoolStatementContextExt{
				rpName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DropPoolStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropPoolStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_POOL
/// Returns `None` if there is no child corresponding to token KW_POOL
fn KW_POOL(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_POOL, 0)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn poolPath(&self) -> Option<Rc<PoolPathContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DropPoolStatementContextAttrs<'input> for DropPoolStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropPoolStatement(&mut self,)
	-> Result<Rc<DropPoolStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropPoolStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 998, RULE_dropPoolStatement);
        let mut _localctx: Rc<DropPoolStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5314);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(5315);
			recog.base.match_token(KW_POOL,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5316);
			let tmp = recog.id_()?;
			 cast_mut::<_,DropPoolStatementContext >(&mut _localctx).rpName = Some(tmp.clone());
			  

			recog.base.set_state(5317);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			/*InvokeRule poolPath*/
			recog.base.set_state(5318);
			recog.poolPath()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createMappingStatement ----------------
pub type CreateMappingStatementContextAll<'input> = CreateMappingStatementContext<'input>;


pub type CreateMappingStatementContext<'input> = BaseParserRuleContext<'input,CreateMappingStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CreateMappingStatementContextExt<'input>{
	pub mappingType: Option<TokenType<'input>>,
	pub name: Option<TokenType<'input>>,
	pub rpName: Option<Rc<Id_ContextAll<'input>>>,
	pub path: Option<Rc<PoolPathContextAll<'input>>>,
	pub order: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for CreateMappingStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for CreateMappingStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createMappingStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_createMappingStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for CreateMappingStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createMappingStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createMappingStatement }
}
crate::tid!{CreateMappingStatementContextExt<'a>}

impl<'input> CreateMappingStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateMappingStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateMappingStatementContextExt{
				mappingType: None, name: None, order: None, 
				rpName: None, path: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateMappingStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<CreateMappingStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_CREATE
/// Returns `None` if there is no child corresponding to token KW_CREATE
fn KW_CREATE(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MAPPING
/// Returns `None` if there is no child corresponding to token KW_MAPPING
fn KW_MAPPING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MAPPING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IN
/// Returns `None` if there is no child corresponding to token KW_IN
fn KW_IN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IN, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_USER
/// Returns `None` if there is no child corresponding to token KW_USER
fn KW_USER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_GROUP
/// Returns `None` if there is no child corresponding to token KW_GROUP
fn KW_GROUP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_APPLICATION
/// Returns `None` if there is no child corresponding to token KW_APPLICATION
fn KW_APPLICATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_APPLICATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
fn unmanaged(&self) -> Option<Rc<UnmanagedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn poolPath(&self) -> Option<Rc<PoolPathContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ORDER
/// Returns `None` if there is no child corresponding to token KW_ORDER
fn KW_ORDER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}

}

impl<'input> CreateMappingStatementContextAttrs<'input> for CreateMappingStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createMappingStatement(&mut self,)
	-> Result<Rc<CreateMappingStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateMappingStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 1000, RULE_createMappingStatement);
        let mut _localctx: Rc<CreateMappingStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5320);
			recog.base.match_token(KW_CREATE,&mut recog.err_handler)?;

			recog.base.set_state(5321);
			 cast_mut::<_,CreateMappingStatementContext >(&mut _localctx).mappingType = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==KW_APPLICATION || _la==KW_GROUP || _la==KW_USER) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,CreateMappingStatementContext >(&mut _localctx).mappingType = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(5322);
			recog.base.match_token(KW_MAPPING,&mut recog.err_handler)?;

			recog.base.set_state(5323);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,CreateMappingStatementContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(5324);
			recog.base.match_token(KW_IN,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5325);
			let tmp = recog.id_()?;
			 cast_mut::<_,CreateMappingStatementContext >(&mut _localctx).rpName = Some(tmp.clone());
			  

			recog.base.set_state(5329);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_TO 
				=> {
					{
					recog.base.set_state(5326);
					recog.base.match_token(KW_TO,&mut recog.err_handler)?;

					/*InvokeRule poolPath*/
					recog.base.set_state(5327);
					let tmp = recog.poolPath()?;
					 cast_mut::<_,CreateMappingStatementContext >(&mut _localctx).path = Some(tmp.clone());
					  

					}
				}

			 KW_UNMANAGED 
				=> {
					{
					/*InvokeRule unmanaged*/
					recog.base.set_state(5328);
					recog.unmanaged()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(5334);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(626,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(5331);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					recog.base.set_state(5332);
					recog.base.match_token(KW_ORDER,&mut recog.err_handler)?;

					recog.base.set_state(5333);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,CreateMappingStatementContext >(&mut _localctx).order = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterMappingStatement ----------------
pub type AlterMappingStatementContextAll<'input> = AlterMappingStatementContext<'input>;


pub type AlterMappingStatementContext<'input> = BaseParserRuleContext<'input,AlterMappingStatementContextExt<'input>>;

#[derive(Clone)]
pub struct AlterMappingStatementContextExt<'input>{
	pub mappingType: Option<TokenType<'input>>,
	pub name: Option<TokenType<'input>>,
	pub rpName: Option<Rc<Id_ContextAll<'input>>>,
	pub path: Option<Rc<PoolPathContextAll<'input>>>,
	pub order: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for AlterMappingStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for AlterMappingStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterMappingStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_alterMappingStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for AlterMappingStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterMappingStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterMappingStatement }
}
crate::tid!{AlterMappingStatementContextExt<'a>}

impl<'input> AlterMappingStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterMappingStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterMappingStatementContextExt{
				mappingType: None, name: None, order: None, 
				rpName: None, path: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterMappingStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<AlterMappingStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_ALTER
/// Returns `None` if there is no child corresponding to token KW_ALTER
fn KW_ALTER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MAPPING
/// Returns `None` if there is no child corresponding to token KW_MAPPING
fn KW_MAPPING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MAPPING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IN
/// Returns `None` if there is no child corresponding to token KW_IN
fn KW_IN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IN, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_USER
/// Returns `None` if there is no child corresponding to token KW_USER
fn KW_USER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_GROUP
/// Returns `None` if there is no child corresponding to token KW_GROUP
fn KW_GROUP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_APPLICATION
/// Returns `None` if there is no child corresponding to token KW_APPLICATION
fn KW_APPLICATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_APPLICATION, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_TO
/// Returns `None` if there is no child corresponding to token KW_TO
fn KW_TO(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_TO, 0)
}
fn unmanaged(&self) -> Option<Rc<UnmanagedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn poolPath(&self) -> Option<Rc<PoolPathContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_WITH
/// Returns `None` if there is no child corresponding to token KW_WITH
fn KW_WITH(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_ORDER
/// Returns `None` if there is no child corresponding to token KW_ORDER
fn KW_ORDER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token Number
/// Returns `None` if there is no child corresponding to token Number
fn Number(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(Number, 0)
}

}

impl<'input> AlterMappingStatementContextAttrs<'input> for AlterMappingStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterMappingStatement(&mut self,)
	-> Result<Rc<AlterMappingStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterMappingStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 1002, RULE_alterMappingStatement);
        let mut _localctx: Rc<AlterMappingStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5336);
			recog.base.match_token(KW_ALTER,&mut recog.err_handler)?;

			recog.base.set_state(5337);
			 cast_mut::<_,AlterMappingStatementContext >(&mut _localctx).mappingType = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==KW_APPLICATION || _la==KW_GROUP || _la==KW_USER) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,AlterMappingStatementContext >(&mut _localctx).mappingType = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(5338);
			recog.base.match_token(KW_MAPPING,&mut recog.err_handler)?;

			recog.base.set_state(5339);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,AlterMappingStatementContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(5340);
			recog.base.match_token(KW_IN,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5341);
			let tmp = recog.id_()?;
			 cast_mut::<_,AlterMappingStatementContext >(&mut _localctx).rpName = Some(tmp.clone());
			  

			recog.base.set_state(5345);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 KW_TO 
				=> {
					{
					recog.base.set_state(5342);
					recog.base.match_token(KW_TO,&mut recog.err_handler)?;

					/*InvokeRule poolPath*/
					recog.base.set_state(5343);
					let tmp = recog.poolPath()?;
					 cast_mut::<_,AlterMappingStatementContext >(&mut _localctx).path = Some(tmp.clone());
					  

					}
				}

			 KW_UNMANAGED 
				=> {
					{
					/*InvokeRule unmanaged*/
					recog.base.set_state(5344);
					recog.unmanaged()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(5350);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(628,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(5347);
					recog.base.match_token(KW_WITH,&mut recog.err_handler)?;

					recog.base.set_state(5348);
					recog.base.match_token(KW_ORDER,&mut recog.err_handler)?;

					recog.base.set_state(5349);
					let tmp = recog.base.match_token(Number,&mut recog.err_handler)?;
					 cast_mut::<_,AlterMappingStatementContext >(&mut _localctx).order = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dropMappingStatement ----------------
pub type DropMappingStatementContextAll<'input> = DropMappingStatementContext<'input>;


pub type DropMappingStatementContext<'input> = BaseParserRuleContext<'input,DropMappingStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DropMappingStatementContextExt<'input>{
	pub mappingType: Option<TokenType<'input>>,
	pub name: Option<TokenType<'input>>,
	pub rpName: Option<Rc<Id_ContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HiveSqlParserContext<'input> for DropMappingStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HiveSqlParserListener<'input> + 'a> for DropMappingStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dropMappingStatement(self);
		}fn exit(&self,listener: &mut (dyn HiveSqlParserListener<'input> + 'a)) {
			listener.exit_dropMappingStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input> CustomRuleContext<'input> for DropMappingStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HiveSqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dropMappingStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dropMappingStatement }
}
crate::tid!{DropMappingStatementContextExt<'a>}

impl<'input> DropMappingStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HiveSqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DropMappingStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DropMappingStatementContextExt{
				mappingType: None, name: None, 
				rpName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DropMappingStatementContextAttrs<'input>: HiveSqlParserContext<'input> + BorrowMut<DropMappingStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KW_DROP
/// Returns `None` if there is no child corresponding to token KW_DROP
fn KW_DROP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_MAPPING
/// Returns `None` if there is no child corresponding to token KW_MAPPING
fn KW_MAPPING(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_MAPPING, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_IN
/// Returns `None` if there is no child corresponding to token KW_IN
fn KW_IN(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_IN, 0)
}
/// Retrieves first TerminalNode corresponding to token StringLiteral
/// Returns `None` if there is no child corresponding to token StringLiteral
fn StringLiteral(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(StringLiteral, 0)
}
fn id_(&self) -> Option<Rc<Id_ContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KW_USER
/// Returns `None` if there is no child corresponding to token KW_USER
fn KW_USER(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_USER, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_GROUP
/// Returns `None` if there is no child corresponding to token KW_GROUP
fn KW_GROUP(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token KW_APPLICATION
/// Returns `None` if there is no child corresponding to token KW_APPLICATION
fn KW_APPLICATION(&self) -> Option<Rc<TerminalNode<'input,HiveSqlParserContextType>>> where Self:Sized{
	self.get_token(KW_APPLICATION, 0)
}

}

impl<'input> DropMappingStatementContextAttrs<'input> for DropMappingStatementContext<'input>{}

impl<'input, I, H> HiveSqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dropMappingStatement(&mut self,)
	-> Result<Rc<DropMappingStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DropMappingStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 1004, RULE_dropMappingStatement);
        let mut _localctx: Rc<DropMappingStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5352);
			recog.base.match_token(KW_DROP,&mut recog.err_handler)?;

			recog.base.set_state(5353);
			 cast_mut::<_,DropMappingStatementContext >(&mut _localctx).mappingType = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==KW_APPLICATION || _la==KW_GROUP || _la==KW_USER) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,DropMappingStatementContext >(&mut _localctx).mappingType = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(5354);
			recog.base.match_token(KW_MAPPING,&mut recog.err_handler)?;

			recog.base.set_state(5355);
			let tmp = recog.base.match_token(StringLiteral,&mut recog.err_handler)?;
			 cast_mut::<_,DropMappingStatementContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(5356);
			recog.base.match_token(KW_IN,&mut recog.err_handler)?;

			/*InvokeRule id_*/
			recog.base.set_state(5357);
			let tmp = recog.id_()?;
			 cast_mut::<_,DropMappingStatementContext >(&mut _localctx).rpName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}

lazy_static! {
    static ref _ATN: Arc<ATN> =
        Arc::new(ATNDeserializer::new(None).deserialize(_serializedATN.chars()));
    static ref _decision_to_DFA: Arc<Vec<crate::RwLock<DFA>>> = {
        let mut dfa = Vec::new();
        let size = _ATN.decision_to_state.len();
        for i in 0..size {
            dfa.push(DFA::new(
                _ATN.clone(),
                _ATN.get_decision_state(i),
                i as isize,
            ).into())
        }
        Arc::new(dfa)
    };
}



const _serializedATN:&'static str =
	"\x03\u{608b}\u{a72a}\u{8133}\u{b9ed}\u{417c}\u{3be7}\u{7786}\u{5964}\x03\
	\u{1a9}\u{14f2}\x04\x02\x09\x02\x04\x03\x09\x03\x04\x04\x09\x04\x04\x05\
	\x09\x05\x04\x06\x09\x06\x04\x07\x09\x07\x04\x08\x09\x08\x04\x09\x09\x09\
	\x04\x0a\x09\x0a\x04\x0b\x09\x0b\x04\x0c\x09\x0c\x04\x0d\x09\x0d\x04\x0e\
	\x09\x0e\x04\x0f\x09\x0f\x04\x10\x09\x10\x04\x11\x09\x11\x04\x12\x09\x12\
	\x04\x13\x09\x13\x04\x14\x09\x14\x04\x15\x09\x15\x04\x16\x09\x16\x04\x17\
	\x09\x17\x04\x18\x09\x18\x04\x19\x09\x19\x04\x1a\x09\x1a\x04\x1b\x09\x1b\
	\x04\x1c\x09\x1c\x04\x1d\x09\x1d\x04\x1e\x09\x1e\x04\x1f\x09\x1f\x04\x20\
	\x09\x20\x04\x21\x09\x21\x04\x22\x09\x22\x04\x23\x09\x23\x04\x24\x09\x24\
	\x04\x25\x09\x25\x04\x26\x09\x26\x04\x27\x09\x27\x04\x28\x09\x28\x04\x29\
	\x09\x29\x04\x2a\x09\x2a\x04\x2b\x09\x2b\x04\x2c\x09\x2c\x04\x2d\x09\x2d\
	\x04\x2e\x09\x2e\x04\x2f\x09\x2f\x04\x30\x09\x30\x04\x31\x09\x31\x04\x32\
	\x09\x32\x04\x33\x09\x33\x04\x34\x09\x34\x04\x35\x09\x35\x04\x36\x09\x36\
	\x04\x37\x09\x37\x04\x38\x09\x38\x04\x39\x09\x39\x04\x3a\x09\x3a\x04\x3b\
	\x09\x3b\x04\x3c\x09\x3c\x04\x3d\x09\x3d\x04\x3e\x09\x3e\x04\x3f\x09\x3f\
	\x04\x40\x09\x40\x04\x41\x09\x41\x04\x42\x09\x42\x04\x43\x09\x43\x04\x44\
	\x09\x44\x04\x45\x09\x45\x04\x46\x09\x46\x04\x47\x09\x47\x04\x48\x09\x48\
	\x04\x49\x09\x49\x04\x4a\x09\x4a\x04\x4b\x09\x4b\x04\x4c\x09\x4c\x04\x4d\
	\x09\x4d\x04\x4e\x09\x4e\x04\x4f\x09\x4f\x04\x50\x09\x50\x04\x51\x09\x51\
	\x04\x52\x09\x52\x04\x53\x09\x53\x04\x54\x09\x54\x04\x55\x09\x55\x04\x56\
	\x09\x56\x04\x57\x09\x57\x04\x58\x09\x58\x04\x59\x09\x59\x04\x5a\x09\x5a\
	\x04\x5b\x09\x5b\x04\x5c\x09\x5c\x04\x5d\x09\x5d\x04\x5e\x09\x5e\x04\x5f\
	\x09\x5f\x04\x60\x09\x60\x04\x61\x09\x61\x04\x62\x09\x62\x04\x63\x09\x63\
	\x04\x64\x09\x64\x04\x65\x09\x65\x04\x66\x09\x66\x04\x67\x09\x67\x04\x68\
	\x09\x68\x04\x69\x09\x69\x04\x6a\x09\x6a\x04\x6b\x09\x6b\x04\x6c\x09\x6c\
	\x04\x6d\x09\x6d\x04\x6e\x09\x6e\x04\x6f\x09\x6f\x04\x70\x09\x70\x04\x71\
	\x09\x71\x04\x72\x09\x72\x04\x73\x09\x73\x04\x74\x09\x74\x04\x75\x09\x75\
	\x04\x76\x09\x76\x04\x77\x09\x77\x04\x78\x09\x78\x04\x79\x09\x79\x04\x7a\
	\x09\x7a\x04\x7b\x09\x7b\x04\x7c\x09\x7c\x04\x7d\x09\x7d\x04\x7e\x09\x7e\
	\x04\x7f\x09\x7f\x04\u{80}\x09\u{80}\x04\u{81}\x09\u{81}\x04\u{82}\x09\u{82}\
	\x04\u{83}\x09\u{83}\x04\u{84}\x09\u{84}\x04\u{85}\x09\u{85}\x04\u{86}\x09\
	\u{86}\x04\u{87}\x09\u{87}\x04\u{88}\x09\u{88}\x04\u{89}\x09\u{89}\x04\u{8a}\
	\x09\u{8a}\x04\u{8b}\x09\u{8b}\x04\u{8c}\x09\u{8c}\x04\u{8d}\x09\u{8d}\x04\
	\u{8e}\x09\u{8e}\x04\u{8f}\x09\u{8f}\x04\u{90}\x09\u{90}\x04\u{91}\x09\u{91}\
	\x04\u{92}\x09\u{92}\x04\u{93}\x09\u{93}\x04\u{94}\x09\u{94}\x04\u{95}\x09\
	\u{95}\x04\u{96}\x09\u{96}\x04\u{97}\x09\u{97}\x04\u{98}\x09\u{98}\x04\u{99}\
	\x09\u{99}\x04\u{9a}\x09\u{9a}\x04\u{9b}\x09\u{9b}\x04\u{9c}\x09\u{9c}\x04\
	\u{9d}\x09\u{9d}\x04\u{9e}\x09\u{9e}\x04\u{9f}\x09\u{9f}\x04\u{a0}\x09\u{a0}\
	\x04\u{a1}\x09\u{a1}\x04\u{a2}\x09\u{a2}\x04\u{a3}\x09\u{a3}\x04\u{a4}\x09\
	\u{a4}\x04\u{a5}\x09\u{a5}\x04\u{a6}\x09\u{a6}\x04\u{a7}\x09\u{a7}\x04\u{a8}\
	\x09\u{a8}\x04\u{a9}\x09\u{a9}\x04\u{aa}\x09\u{aa}\x04\u{ab}\x09\u{ab}\x04\
	\u{ac}\x09\u{ac}\x04\u{ad}\x09\u{ad}\x04\u{ae}\x09\u{ae}\x04\u{af}\x09\u{af}\
	\x04\u{b0}\x09\u{b0}\x04\u{b1}\x09\u{b1}\x04\u{b2}\x09\u{b2}\x04\u{b3}\x09\
	\u{b3}\x04\u{b4}\x09\u{b4}\x04\u{b5}\x09\u{b5}\x04\u{b6}\x09\u{b6}\x04\u{b7}\
	\x09\u{b7}\x04\u{b8}\x09\u{b8}\x04\u{b9}\x09\u{b9}\x04\u{ba}\x09\u{ba}\x04\
	\u{bb}\x09\u{bb}\x04\u{bc}\x09\u{bc}\x04\u{bd}\x09\u{bd}\x04\u{be}\x09\u{be}\
	\x04\u{bf}\x09\u{bf}\x04\u{c0}\x09\u{c0}\x04\u{c1}\x09\u{c1}\x04\u{c2}\x09\
	\u{c2}\x04\u{c3}\x09\u{c3}\x04\u{c4}\x09\u{c4}\x04\u{c5}\x09\u{c5}\x04\u{c6}\
	\x09\u{c6}\x04\u{c7}\x09\u{c7}\x04\u{c8}\x09\u{c8}\x04\u{c9}\x09\u{c9}\x04\
	\u{ca}\x09\u{ca}\x04\u{cb}\x09\u{cb}\x04\u{cc}\x09\u{cc}\x04\u{cd}\x09\u{cd}\
	\x04\u{ce}\x09\u{ce}\x04\u{cf}\x09\u{cf}\x04\u{d0}\x09\u{d0}\x04\u{d1}\x09\
	\u{d1}\x04\u{d2}\x09\u{d2}\x04\u{d3}\x09\u{d3}\x04\u{d4}\x09\u{d4}\x04\u{d5}\
	\x09\u{d5}\x04\u{d6}\x09\u{d6}\x04\u{d7}\x09\u{d7}\x04\u{d8}\x09\u{d8}\x04\
	\u{d9}\x09\u{d9}\x04\u{da}\x09\u{da}\x04\u{db}\x09\u{db}\x04\u{dc}\x09\u{dc}\
	\x04\u{dd}\x09\u{dd}\x04\u{de}\x09\u{de}\x04\u{df}\x09\u{df}\x04\u{e0}\x09\
	\u{e0}\x04\u{e1}\x09\u{e1}\x04\u{e2}\x09\u{e2}\x04\u{e3}\x09\u{e3}\x04\u{e4}\
	\x09\u{e4}\x04\u{e5}\x09\u{e5}\x04\u{e6}\x09\u{e6}\x04\u{e7}\x09\u{e7}\x04\
	\u{e8}\x09\u{e8}\x04\u{e9}\x09\u{e9}\x04\u{ea}\x09\u{ea}\x04\u{eb}\x09\u{eb}\
	\x04\u{ec}\x09\u{ec}\x04\u{ed}\x09\u{ed}\x04\u{ee}\x09\u{ee}\x04\u{ef}\x09\
	\u{ef}\x04\u{f0}\x09\u{f0}\x04\u{f1}\x09\u{f1}\x04\u{f2}\x09\u{f2}\x04\u{f3}\
	\x09\u{f3}\x04\u{f4}\x09\u{f4}\x04\u{f5}\x09\u{f5}\x04\u{f6}\x09\u{f6}\x04\
	\u{f7}\x09\u{f7}\x04\u{f8}\x09\u{f8}\x04\u{f9}\x09\u{f9}\x04\u{fa}\x09\u{fa}\
	\x04\u{fb}\x09\u{fb}\x04\u{fc}\x09\u{fc}\x04\u{fd}\x09\u{fd}\x04\u{fe}\x09\
	\u{fe}\x04\u{ff}\x09\u{ff}\x04\u{100}\x09\u{100}\x04\u{101}\x09\u{101}\x04\
	\u{102}\x09\u{102}\x04\u{103}\x09\u{103}\x04\u{104}\x09\u{104}\x04\u{105}\
	\x09\u{105}\x04\u{106}\x09\u{106}\x04\u{107}\x09\u{107}\x04\u{108}\x09\u{108}\
	\x04\u{109}\x09\u{109}\x04\u{10a}\x09\u{10a}\x04\u{10b}\x09\u{10b}\x04\u{10c}\
	\x09\u{10c}\x04\u{10d}\x09\u{10d}\x04\u{10e}\x09\u{10e}\x04\u{10f}\x09\u{10f}\
	\x04\u{110}\x09\u{110}\x04\u{111}\x09\u{111}\x04\u{112}\x09\u{112}\x04\u{113}\
	\x09\u{113}\x04\u{114}\x09\u{114}\x04\u{115}\x09\u{115}\x04\u{116}\x09\u{116}\
	\x04\u{117}\x09\u{117}\x04\u{118}\x09\u{118}\x04\u{119}\x09\u{119}\x04\u{11a}\
	\x09\u{11a}\x04\u{11b}\x09\u{11b}\x04\u{11c}\x09\u{11c}\x04\u{11d}\x09\u{11d}\
	\x04\u{11e}\x09\u{11e}\x04\u{11f}\x09\u{11f}\x04\u{120}\x09\u{120}\x04\u{121}\
	\x09\u{121}\x04\u{122}\x09\u{122}\x04\u{123}\x09\u{123}\x04\u{124}\x09\u{124}\
	\x04\u{125}\x09\u{125}\x04\u{126}\x09\u{126}\x04\u{127}\x09\u{127}\x04\u{128}\
	\x09\u{128}\x04\u{129}\x09\u{129}\x04\u{12a}\x09\u{12a}\x04\u{12b}\x09\u{12b}\
	\x04\u{12c}\x09\u{12c}\x04\u{12d}\x09\u{12d}\x04\u{12e}\x09\u{12e}\x04\u{12f}\
	\x09\u{12f}\x04\u{130}\x09\u{130}\x04\u{131}\x09\u{131}\x04\u{132}\x09\u{132}\
	\x04\u{133}\x09\u{133}\x04\u{134}\x09\u{134}\x04\u{135}\x09\u{135}\x04\u{136}\
	\x09\u{136}\x04\u{137}\x09\u{137}\x04\u{138}\x09\u{138}\x04\u{139}\x09\u{139}\
	\x04\u{13a}\x09\u{13a}\x04\u{13b}\x09\u{13b}\x04\u{13c}\x09\u{13c}\x04\u{13d}\
	\x09\u{13d}\x04\u{13e}\x09\u{13e}\x04\u{13f}\x09\u{13f}\x04\u{140}\x09\u{140}\
	\x04\u{141}\x09\u{141}\x04\u{142}\x09\u{142}\x04\u{143}\x09\u{143}\x04\u{144}\
	\x09\u{144}\x04\u{145}\x09\u{145}\x04\u{146}\x09\u{146}\x04\u{147}\x09\u{147}\
	\x04\u{148}\x09\u{148}\x04\u{149}\x09\u{149}\x04\u{14a}\x09\u{14a}\x04\u{14b}\
	\x09\u{14b}\x04\u{14c}\x09\u{14c}\x04\u{14d}\x09\u{14d}\x04\u{14e}\x09\u{14e}\
	\x04\u{14f}\x09\u{14f}\x04\u{150}\x09\u{150}\x04\u{151}\x09\u{151}\x04\u{152}\
	\x09\u{152}\x04\u{153}\x09\u{153}\x04\u{154}\x09\u{154}\x04\u{155}\x09\u{155}\
	\x04\u{156}\x09\u{156}\x04\u{157}\x09\u{157}\x04\u{158}\x09\u{158}\x04\u{159}\
	\x09\u{159}\x04\u{15a}\x09\u{15a}\x04\u{15b}\x09\u{15b}\x04\u{15c}\x09\u{15c}\
	\x04\u{15d}\x09\u{15d}\x04\u{15e}\x09\u{15e}\x04\u{15f}\x09\u{15f}\x04\u{160}\
	\x09\u{160}\x04\u{161}\x09\u{161}\x04\u{162}\x09\u{162}\x04\u{163}\x09\u{163}\
	\x04\u{164}\x09\u{164}\x04\u{165}\x09\u{165}\x04\u{166}\x09\u{166}\x04\u{167}\
	\x09\u{167}\x04\u{168}\x09\u{168}\x04\u{169}\x09\u{169}\x04\u{16a}\x09\u{16a}\
	\x04\u{16b}\x09\u{16b}\x04\u{16c}\x09\u{16c}\x04\u{16d}\x09\u{16d}\x04\u{16e}\
	\x09\u{16e}\x04\u{16f}\x09\u{16f}\x04\u{170}\x09\u{170}\x04\u{171}\x09\u{171}\
	\x04\u{172}\x09\u{172}\x04\u{173}\x09\u{173}\x04\u{174}\x09\u{174}\x04\u{175}\
	\x09\u{175}\x04\u{176}\x09\u{176}\x04\u{177}\x09\u{177}\x04\u{178}\x09\u{178}\
	\x04\u{179}\x09\u{179}\x04\u{17a}\x09\u{17a}\x04\u{17b}\x09\u{17b}\x04\u{17c}\
	\x09\u{17c}\x04\u{17d}\x09\u{17d}\x04\u{17e}\x09\u{17e}\x04\u{17f}\x09\u{17f}\
	\x04\u{180}\x09\u{180}\x04\u{181}\x09\u{181}\x04\u{182}\x09\u{182}\x04\u{183}\
	\x09\u{183}\x04\u{184}\x09\u{184}\x04\u{185}\x09\u{185}\x04\u{186}\x09\u{186}\
	\x04\u{187}\x09\u{187}\x04\u{188}\x09\u{188}\x04\u{189}\x09\u{189}\x04\u{18a}\
	\x09\u{18a}\x04\u{18b}\x09\u{18b}\x04\u{18c}\x09\u{18c}\x04\u{18d}\x09\u{18d}\
	\x04\u{18e}\x09\u{18e}\x04\u{18f}\x09\u{18f}\x04\u{190}\x09\u{190}\x04\u{191}\
	\x09\u{191}\x04\u{192}\x09\u{192}\x04\u{193}\x09\u{193}\x04\u{194}\x09\u{194}\
	\x04\u{195}\x09\u{195}\x04\u{196}\x09\u{196}\x04\u{197}\x09\u{197}\x04\u{198}\
	\x09\u{198}\x04\u{199}\x09\u{199}\x04\u{19a}\x09\u{19a}\x04\u{19b}\x09\u{19b}\
	\x04\u{19c}\x09\u{19c}\x04\u{19d}\x09\u{19d}\x04\u{19e}\x09\u{19e}\x04\u{19f}\
	\x09\u{19f}\x04\u{1a0}\x09\u{1a0}\x04\u{1a1}\x09\u{1a1}\x04\u{1a2}\x09\u{1a2}\
	\x04\u{1a3}\x09\u{1a3}\x04\u{1a4}\x09\u{1a4}\x04\u{1a5}\x09\u{1a5}\x04\u{1a6}\
	\x09\u{1a6}\x04\u{1a7}\x09\u{1a7}\x04\u{1a8}\x09\u{1a8}\x04\u{1a9}\x09\u{1a9}\
	\x04\u{1aa}\x09\u{1aa}\x04\u{1ab}\x09\u{1ab}\x04\u{1ac}\x09\u{1ac}\x04\u{1ad}\
	\x09\u{1ad}\x04\u{1ae}\x09\u{1ae}\x04\u{1af}\x09\u{1af}\x04\u{1b0}\x09\u{1b0}\
	\x04\u{1b1}\x09\u{1b1}\x04\u{1b2}\x09\u{1b2}\x04\u{1b3}\x09\u{1b3}\x04\u{1b4}\
	\x09\u{1b4}\x04\u{1b5}\x09\u{1b5}\x04\u{1b6}\x09\u{1b6}\x04\u{1b7}\x09\u{1b7}\
	\x04\u{1b8}\x09\u{1b8}\x04\u{1b9}\x09\u{1b9}\x04\u{1ba}\x09\u{1ba}\x04\u{1bb}\
	\x09\u{1bb}\x04\u{1bc}\x09\u{1bc}\x04\u{1bd}\x09\u{1bd}\x04\u{1be}\x09\u{1be}\
	\x04\u{1bf}\x09\u{1bf}\x04\u{1c0}\x09\u{1c0}\x04\u{1c1}\x09\u{1c1}\x04\u{1c2}\
	\x09\u{1c2}\x04\u{1c3}\x09\u{1c3}\x04\u{1c4}\x09\u{1c4}\x04\u{1c5}\x09\u{1c5}\
	\x04\u{1c6}\x09\u{1c6}\x04\u{1c7}\x09\u{1c7}\x04\u{1c8}\x09\u{1c8}\x04\u{1c9}\
	\x09\u{1c9}\x04\u{1ca}\x09\u{1ca}\x04\u{1cb}\x09\u{1cb}\x04\u{1cc}\x09\u{1cc}\
	\x04\u{1cd}\x09\u{1cd}\x04\u{1ce}\x09\u{1ce}\x04\u{1cf}\x09\u{1cf}\x04\u{1d0}\
	\x09\u{1d0}\x04\u{1d1}\x09\u{1d1}\x04\u{1d2}\x09\u{1d2}\x04\u{1d3}\x09\u{1d3}\
	\x04\u{1d4}\x09\u{1d4}\x04\u{1d5}\x09\u{1d5}\x04\u{1d6}\x09\u{1d6}\x04\u{1d7}\
	\x09\u{1d7}\x04\u{1d8}\x09\u{1d8}\x04\u{1d9}\x09\u{1d9}\x04\u{1da}\x09\u{1da}\
	\x04\u{1db}\x09\u{1db}\x04\u{1dc}\x09\u{1dc}\x04\u{1dd}\x09\u{1dd}\x04\u{1de}\
	\x09\u{1de}\x04\u{1df}\x09\u{1df}\x04\u{1e0}\x09\u{1e0}\x04\u{1e1}\x09\u{1e1}\
	\x04\u{1e2}\x09\u{1e2}\x04\u{1e3}\x09\u{1e3}\x04\u{1e4}\x09\u{1e4}\x04\u{1e5}\
	\x09\u{1e5}\x04\u{1e6}\x09\u{1e6}\x04\u{1e7}\x09\u{1e7}\x04\u{1e8}\x09\u{1e8}\
	\x04\u{1e9}\x09\u{1e9}\x04\u{1ea}\x09\u{1ea}\x04\u{1eb}\x09\u{1eb}\x04\u{1ec}\
	\x09\u{1ec}\x04\u{1ed}\x09\u{1ed}\x04\u{1ee}\x09\u{1ee}\x04\u{1ef}\x09\u{1ef}\
	\x04\u{1f0}\x09\u{1f0}\x04\u{1f1}\x09\u{1f1}\x04\u{1f2}\x09\u{1f2}\x04\u{1f3}\
	\x09\u{1f3}\x04\u{1f4}\x09\u{1f4}\x04\u{1f5}\x09\u{1f5}\x04\u{1f6}\x09\u{1f6}\
	\x04\u{1f7}\x09\u{1f7}\x04\u{1f8}\x09\u{1f8}\x03\x02\x07\x02\u{3f2}\x0a\
	\x02\x0c\x02\x0e\x02\u{3f5}\x0b\x02\x03\x02\x03\x02\x03\x03\x03\x03\x05\
	\x03\u{3fb}\x0a\x03\x03\x03\x05\x03\u{3fe}\x0a\x03\x03\x04\x03\x04\x07\x04\
	\u{402}\x0a\x04\x0c\x04\x0e\x04\u{405}\x0b\x04\x03\x04\x03\x04\x03\x04\x05\
	\x04\u{40a}\x0a\x04\x03\x05\x03\x05\x03\x05\x03\x05\x03\x05\x05\x05\u{411}\
	\x0a\x05\x03\x05\x03\x05\x03\x05\x03\x05\x03\x05\x03\x05\x03\x05\x03\x05\
	\x05\x05\u{41b}\x0a\x05\x03\x05\x05\x05\u{41e}\x0a\x05\x03\x05\x03\x05\x05\
	\x05\u{422}\x0a\x05\x03\x06\x03\x06\x03\x07\x03\x07\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x03\
	\x08\x03\x08\x03\x08\x05\x08\u{436}\x0a\x08\x03\x09\x03\x09\x03\x09\x05\
	\x09\u{43b}\x0a\x09\x03\x09\x03\x09\x03\x09\x05\x09\u{440}\x0a\x09\x03\x09\
	\x03\x09\x03\x09\x03\x09\x05\x09\u{446}\x0a\x09\x03\x0a\x03\x0a\x05\x0a\
	\u{44a}\x0a\x0a\x03\x0a\x03\x0a\x03\x0a\x03\x0a\x03\x0a\x03\x0b\x03\x0b\
	\x03\x0b\x03\x0b\x03\x0b\x03\x0b\x05\x0b\u{457}\x0a\x0b\x03\x0c\x03\x0c\
	\x05\x0c\u{45b}\x0a\x0c\x03\x0c\x03\x0c\x05\x0c\u{45f}\x0a\x0c\x03\x0c\x03\
	\x0c\x03\x0c\x05\x0c\u{464}\x0a\x0c\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\
	\x0d\x05\x0d\u{46b}\x0a\x0d\x03\x0d\x03\x0d\x05\x0d\u{46f}\x0a\x0d\x03\x0e\
	\x03\x0e\x03\x0e\x05\x0e\u{474}\x0a\x0e\x03\x0f\x03\x0f\x03\x0f\x03\x0f\
	\x03\x0f\x05\x0f\u{47b}\x0a\x0f\x03\x0f\x03\x0f\x05\x0f\u{47f}\x0a\x0f\x03\
	\x10\x03\x10\x03\x10\x03\x10\x03\x11\x03\x11\x03\x11\x07\x11\u{488}\x0a\
	\x11\x0c\x11\x0e\x11\u{48b}\x0b\x11\x03\x12\x03\x12\x03\x12\x05\x12\u{490}\
	\x0a\x12\x03\x13\x03\x13\x03\x13\x03\x13\x03\x13\x05\x13\u{497}\x0a\x13\
	\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\
	\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\
	\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\
	\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\
	\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\
	\x03\x14\x03\x14\x05\x14\u{4c8}\x0a\x14\x03\x15\x03\x15\x03\x15\x03\x16\
	\x03\x16\x03\x17\x03\x17\x03\x17\x03\x17\x03\x18\x03\x18\x03\x19\x03\x19\
	\x03\x19\x03\x1a\x03\x1a\x03\x1a\x03\x1b\x03\x1b\x03\x1b\x03\x1b\x03\x1c\
	\x03\x1c\x03\x1c\x03\x1d\x03\x1d\x03\x1d\x05\x1d\u{4e5}\x0a\x1d\x03\x1d\
	\x03\x1d\x05\x1d\u{4e9}\x0a\x1d\x03\x1d\x05\x1d\u{4ec}\x0a\x1d\x03\x1d\x05\
	\x1d\u{4ef}\x0a\x1d\x03\x1d\x03\x1d\x03\x1d\x05\x1d\u{4f4}\x0a\x1d\x03\x1d\
	\x03\x1d\x03\x1d\x03\x1d\x05\x1d\u{4fa}\x0a\x1d\x03\x1d\x03\x1d\x05\x1d\
	\u{4fe}\x0a\x1d\x03\x1d\x03\x1d\x03\x1d\x03\x1d\x05\x1d\u{504}\x0a\x1d\x05\
	\x1d\u{506}\x0a\x1d\x03\x1e\x03\x1e\x03\x1e\x03\x1f\x03\x1f\x03\x1f\x03\
	\x20\x03\x20\x03\x20\x03\x20\x03\x21\x03\x21\x03\x21\x07\x21\u{515}\x0a\
	\x21\x0c\x21\x0e\x21\u{518}\x0b\x21\x03\x22\x03\x22\x03\x22\x03\x23\x03\
	\x23\x03\x23\x03\x24\x03\x24\x03\x24\x05\x24\u{523}\x0a\x24\x03\x24\x03\
	\x24\x05\x24\u{527}\x0a\x24\x03\x25\x03\x25\x03\x25\x03\x26\x03\x26\x05\
	\x26\u{52e}\x0a\x26\x03\x26\x03\x26\x03\x26\x03\x26\x03\x26\x03\x26\x05\
	\x26\u{536}\x0a\x26\x03\x26\x05\x26\u{539}\x0a\x26\x03\x27\x03\x27\x03\x27\
	\x05\x27\u{53e}\x0a\x27\x03\x27\x03\x27\x05\x27\u{542}\x0a\x27\x03\x27\x05\
	\x27\u{545}\x0a\x27\x03\x28\x03\x28\x03\x28\x03\x28\x03\x28\x03\x29\x03\
	\x29\x03\x29\x05\x29\u{54f}\x0a\x29\x03\x29\x03\x29\x03\x29\x03\x29\x03\
	\x29\x03\x29\x05\x29\u{557}\x0a\x29\x07\x29\u{559}\x0a\x29\x0c\x29\x0e\x29\
	\u{55c}\x0b\x29\x05\x29\u{55e}\x0a\x29\x03\x2a\x03\x2a\x05\x2a\u{562}\x0a\
	\x2a\x03\x2b\x03\x2b\x05\x2b\u{566}\x0a\x2b\x03\x2b\x05\x2b\u{569}\x0a\x2b\
	\x03\x2c\x03\x2c\x03\x2c\x05\x2c\u{56e}\x0a\x2c\x03\x2c\x03\x2c\x03\x2c\
	\x03\x2c\x05\x2c\u{574}\x0a\x2c\x03\x2c\x03\x2c\x03\x2c\x05\x2c\u{579}\x0a\
	\x2c\x03\x2c\x03\x2c\x03\x2c\x05\x2c\u{57e}\x0a\x2c\x03\x2c\x03\x2c\x05\
	\x2c\u{582}\x0a\x2c\x03\x2d\x03\x2d\x03\x2d\x03\x2d\x03\x2d\x03\x2d\x03\
	\x2d\x03\x2d\x03\x2d\x05\x2d\u{58d}\x0a\x2d\x05\x2d\u{58f}\x0a\x2d\x03\x2d\
	\x03\x2d\x05\x2d\u{593}\x0a\x2d\x03\x2e\x03\x2e\x03\x2f\x03\x2f\x03\x30\
	\x03\x30\x03\x30\x03\x30\x05\x30\u{59d}\x0a\x30\x03\x30\x03\x30\x05\x30\
	\u{5a1}\x0a\x30\x03\x30\x03\x30\x03\x30\x03\x30\x05\x30\u{5a7}\x0a\x30\x03\
	\x30\x05\x30\u{5aa}\x0a\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x05\
	\x30\u{5b1}\x0a\x30\x03\x30\x03\x30\x03\x30\x05\x30\u{5b6}\x0a\x30\x03\x30\
	\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x05\x30\u{5be}\x0a\x30\x03\x30\
	\x03\x30\x03\x30\x05\x30\u{5c3}\x0a\x30\x03\x30\x03\x30\x05\x30\u{5c7}\x0a\
	\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x05\x30\u{5cf}\x0a\
	\x30\x03\x30\x03\x30\x03\x30\x05\x30\u{5d4}\x0a\x30\x03\x30\x03\x30\x03\
	\x30\x03\x30\x05\x30\u{5da}\x0a\x30\x03\x30\x03\x30\x03\x30\x03\x30\x05\
	\x30\u{5e0}\x0a\x30\x03\x30\x05\x30\u{5e3}\x0a\x30\x03\x30\x05\x30\u{5e6}\
	\x0a\x30\x03\x30\x05\x30\u{5e9}\x0a\x30\x03\x30\x03\x30\x03\x30\x03\x30\
	\x03\x30\x03\x30\x03\x30\x05\x30\u{5f2}\x0a\x30\x03\x30\x03\x30\x03\x30\
	\x03\x30\x03\x30\x03\x30\x05\x30\u{5fa}\x0a\x30\x03\x30\x03\x30\x03\x30\
	\x05\x30\u{5ff}\x0a\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\
	\x05\x30\u{607}\x0a\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x05\x30\
	\u{60e}\x0a\x30\x03\x30\x05\x30\u{611}\x0a\x30\x03\x30\x05\x30\u{614}\x0a\
	\x30\x05\x30\u{616}\x0a\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\
	\x30\x05\x30\u{61e}\x0a\x30\x03\x30\x05\x30\u{621}\x0a\x30\x03\x30\x05\x30\
	\u{624}\x0a\x30\x03\x30\x05\x30\u{627}\x0a\x30\x03\x30\x05\x30\u{62a}\x0a\
	\x30\x03\x30\x05\x30\u{62d}\x0a\x30\x03\x30\x05\x30\u{630}\x0a\x30\x03\x30\
	\x05\x30\u{633}\x0a\x30\x03\x30\x05\x30\u{636}\x0a\x30\x03\x30\x05\x30\u{639}\
	\x0a\x30\x03\x30\x05\x30\u{63c}\x0a\x30\x05\x30\u{63e}\x0a\x30\x03\x30\x03\
	\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x03\x30\x05\
	\x30\u{64a}\x0a\x30\x03\x30\x03\x30\x05\x30\u{64e}\x0a\x30\x03\x31\x03\x31\
	\x03\x31\x03\x31\x03\x31\x03\x31\x03\x31\x03\x31\x05\x31\u{658}\x0a\x31\
	\x03\x32\x03\x32\x03\x32\x03\x32\x05\x32\u{65e}\x0a\x32\x03\x32\x03\x32\
	\x03\x33\x03\x33\x03\x33\x03\x33\x03\x33\x03\x34\x03\x34\x03\x35\x03\x35\
	\x03\x35\x03\x35\x05\x35\u{66d}\x0a\x35\x03\x36\x03\x36\x03\x36\x03\x36\
	\x03\x37\x03\x37\x03\x37\x03\x37\x03\x38\x03\x38\x03\x38\x03\x38\x03\x39\
	\x03\x39\x03\x39\x05\x39\u{67e}\x0a\x39\x03\x39\x03\x39\x03\x39\x05\x39\
	\u{683}\x0a\x39\x03\x3a\x03\x3a\x05\x3a\u{687}\x0a\x3a\x03\x3a\x03\x3a\x05\
	\x3a\u{68b}\x0a\x3a\x03\x3a\x03\x3a\x03\x3a\x03\x3b\x03\x3b\x05\x3b\u{692}\
	\x0a\x3b\x03\x3b\x03\x3b\x03\x3b\x07\x3b\u{697}\x0a\x3b\x0c\x3b\x0e\x3b\
	\u{69a}\x0b\x3b\x03\x3b\x03\x3b\x03\x3b\x05\x3b\u{69f}\x0a\x3b\x03\x3c\x03\
	\x3c\x05\x3c\u{6a3}\x0a\x3c\x03\x3c\x05\x3c\u{6a6}\x0a\x3c\x03\x3c\x03\x3c\
	\x03\x3c\x07\x3c\u{6ab}\x0a\x3c\x0c\x3c\x0e\x3c\u{6ae}\x0b\x3c\x03\x3c\x03\
	\x3c\x03\x3c\x03\x3d\x03\x3d\x03\x3d\x03\x3d\x03\x3d\x03\x3e\x03\x3e\x03\
	\x3e\x03\x3f\x03\x3f\x03\x3f\x03\x3f\x03\x40\x03\x40\x03\x40\x03\x40\x03\
	\x40\x05\x40\u{6c4}\x0a\x40\x03\x41\x03\x41\x03\x41\x05\x41\u{6c9}\x0a\x41\
	\x03\x41\x03\x41\x05\x41\u{6cd}\x0a\x41\x03\x42\x03\x42\x03\x42\x03\x42\
	\x03\x43\x03\x43\x05\x43\u{6d5}\x0a\x43\x03\x44\x03\x44\x03\x44\x03\x45\
	\x03\x45\x03\x45\x03\x45\x05\x45\u{6de}\x0a\x45\x03\x45\x03\x45\x05\x45\
	\u{6e2}\x0a\x45\x03\x45\x03\x45\x03\x45\x03\x45\x05\x45\u{6e8}\x0a\x45\x03\
	\x46\x03\x46\x03\x46\x03\x46\x05\x46\u{6ee}\x0a\x46\x03\x46\x03\x46\x03\
	\x46\x03\x46\x03\x46\x05\x46\u{6f5}\x0a\x46\x03\x46\x05\x46\u{6f8}\x0a\x46\
	\x03\x46\x03\x46\x03\x46\x03\x46\x05\x46\u{6fe}\x0a\x46\x03\x47\x03\x47\
	\x03\x47\x07\x47\u{703}\x0a\x47\x0c\x47\x0e\x47\u{706}\x0b\x47\x03\x48\x03\
	\x48\x03\x48\x03\x48\x03\x48\x05\x48\u{70d}\x0a\x48\x03\x49\x03\x49\x03\
	\x4a\x03\x4a\x03\x4a\x07\x4a\u{714}\x0a\x4a\x0c\x4a\x0e\x4a\u{717}\x0b\x4a\
	\x03\x4b\x03\x4b\x03\x4b\x03\x4b\x03\x4b\x03\x4b\x05\x4b\u{71f}\x0a\x4b\
	\x03\x4c\x03\x4c\x03\x4c\x03\x4c\x03\x4d\x03\x4d\x03\x4d\x03\x4d\x03\x4e\
	\x03\x4e\x03\x4e\x03\x4e\x03\x4f\x03\x4f\x03\x4f\x03\x4f\x03\x50\x03\x50\
	\x05\x50\u{733}\x0a\x50\x03\x50\x03\x50\x03\x50\x03\x50\x03\x50\x05\x50\
	\u{73a}\x0a\x50\x05\x50\u{73c}\x0a\x50\x03\x51\x03\x51\x03\x51\x07\x51\u{741}\
	\x0a\x51\x0c\x51\x0e\x51\u{744}\x0b\x51\x03\x52\x03\x52\x03\x52\x03\x53\
	\x03\x53\x03\x54\x03\x54\x05\x54\u{74d}\x0a\x54\x03\x54\x03\x54\x03\x54\
	\x03\x54\x03\x54\x03\x54\x05\x54\u{755}\x0a\x54\x03\x55\x03\x55\x05\x55\
	\u{759}\x0a\x55\x03\x55\x03\x55\x05\x55\u{75d}\x0a\x55\x03\x55\x03\x55\x03\
	\x56\x03\x56\x03\x56\x03\x57\x03\x57\x03\x57\x03\x57\x03\x57\x03\x57\x05\
	\x57\u{76a}\x0a\x57\x03\x57\x03\x57\x03\x57\x03\x58\x03\x58\x03\x58\x03\
	\x58\x05\x58\u{773}\x0a\x58\x03\x58\x03\x58\x03\x59\x03\x59\x03\x59\x03\
	\x59\x03\x59\x03\x59\x03\x59\x03\x59\x03\x59\x03\x59\x03\x59\x03\x59\x05\
	\x59\u{783}\x0a\x59\x03\x59\x03\x59\x05\x59\u{787}\x0a\x59\x03\x59\x03\x59\
	\x03\x59\x05\x59\u{78c}\x0a\x59\x03\x59\x03\x59\x03\x59\x05\x59\u{791}\x0a\
	\x59\x03\x59\x05\x59\u{794}\x0a\x59\x03\x59\x05\x59\u{797}\x0a\x59\x03\x59\
	\x03\x59\x05\x59\u{79b}\x0a\x59\x03\x59\x05\x59\u{79e}\x0a\x59\x03\x59\x05\
	\x59\u{7a1}\x0a\x59\x03\x5a\x03\x5a\x03\x5a\x05\x5a\u{7a6}\x0a\x5a\x03\x5a\
	\x03\x5a\x03\x5a\x03\x5a\x03\x5b\x03\x5b\x05\x5b\u{7ae}\x0a\x5b\x03\x5b\
	\x03\x5b\x05\x5b\u{7b2}\x0a\x5b\x03\x5b\x03\x5b\x03\x5b\x03\x5b\x03\x5b\
	\x05\x5b\u{7b9}\x0a\x5b\x03\x5b\x05\x5b\u{7bc}\x0a\x5b\x03\x5b\x05\x5b\u{7bf}\
	\x0a\x5b\x03\x5b\x05\x5b\u{7c2}\x0a\x5b\x03\x5b\x03\x5b\x03\x5b\x03\x5c\
	\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x05\x5c\u{7ce}\x0a\x5c\
	\x03\x5c\x03\x5c\x03\x5d\x03\x5d\x05\x5d\u{7d4}\x0a\x5d\x03\x5e\x03\x5e\
	\x03\x5e\x03\x5e\x03\x5e\x03\x5e\x03\x5f\x03\x5f\x03\x5f\x03\x60\x03\x60\
	\x03\x60\x03\x60\x03\x60\x03\x60\x03\x61\x03\x61\x03\x61\x03\x61\x03\x61\
	\x03\x61\x03\x62\x03\x62\x03\x62\x05\x62\u{7ee}\x0a\x62\x03\x62\x03\x62\
	\x03\x63\x03\x63\x03\x63\x03\x63\x05\x63\u{7f6}\x0a\x63\x03\x63\x03\x63\
	\x05\x63\u{7fa}\x0a\x63\x03\x63\x05\x63\u{7fd}\x0a\x63\x03\x63\x05\x63\u{800}\
	\x0a\x63\x03\x63\x05\x63\u{803}\x0a\x63\x03\x63\x05\x63\u{806}\x0a\x63\x03\
	\x63\x05\x63\u{809}\x0a\x63\x03\x63\x05\x63\u{80c}\x0a\x63\x03\x63\x05\x63\
	\u{80f}\x0a\x63\x03\x63\x03\x63\x03\x63\x03\x64\x03\x64\x03\x64\x03\x64\
	\x05\x64\u{818}\x0a\x64\x03\x64\x03\x64\x03\x65\x03\x65\x03\x65\x03\x65\
	\x03\x65\x03\x65\x05\x65\u{822}\x0a\x65\x03\x65\x05\x65\u{825}\x0a\x65\x03\
	\x65\x03\x65\x03\x66\x03\x66\x03\x66\x03\x66\x03\x66\x03\x67\x03\x67\x03\
	\x67\x03\x67\x03\x67\x03\x67\x03\x68\x03\x68\x03\x68\x03\x68\x03\x68\x05\
	\x68\u{839}\x0a\x68\x03\x69\x03\x69\x03\x69\x03\x69\x05\x69\u{83f}\x0a\x69\
	\x03\x69\x03\x69\x03\x69\x03\x69\x05\x69\u{845}\x0a\x69\x03\x69\x05\x69\
	\u{848}\x0a\x69\x05\x69\u{84a}\x0a\x69\x03\x6a\x03\x6a\x03\x6a\x03\x6a\x03\
	\x6b\x05\x6b\u{851}\x0a\x6b\x03\x6b\x03\x6b\x03\x6b\x03\x6c\x03\x6c\x05\
	\x6c\u{858}\x0a\x6c\x03\x6d\x03\x6d\x05\x6d\u{85c}\x0a\x6d\x03\x6e\x03\x6e\
	\x03\x6e\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{866}\x0a\x6f\
	\x03\x6f\x03\x6f\x03\x6f\x05\x6f\u{86b}\x0a\x6f\x03\x6f\x03\x6f\x03\x70\
	\x03\x70\x03\x70\x07\x70\u{872}\x0a\x70\x0c\x70\x0e\x70\u{875}\x0b\x70\x03\
	\x71\x03\x71\x03\x71\x07\x71\u{87a}\x0a\x71\x0c\x71\x0e\x71\u{87d}\x0b\x71\
	\x03\x72\x03\x72\x03\x72\x07\x72\u{882}\x0a\x72\x0c\x72\x0e\x72\u{885}\x0b\
	\x72\x03\x73\x03\x73\x03\x74\x03\x74\x03\x74\x03\x74\x03\x74\x03\x74\x03\
	\x74\x03\x74\x03\x74\x03\x74\x03\x74\x03\x74\x03\x74\x05\x74\u{896}\x0a\
	\x74\x03\x75\x03\x75\x03\x75\x03\x75\x03\x75\x03\x75\x03\x75\x03\x75\x03\
	\x75\x03\x75\x03\x75\x05\x75\u{8a3}\x0a\x75\x03\x75\x03\x75\x03\x75\x03\
	\x75\x03\x76\x03\x76\x03\x76\x03\x76\x03\x76\x03\x77\x03\x77\x03\x77\x03\
	\x77\x03\x77\x03\x77\x03\x77\x03\x77\x03\x77\x03\x77\x05\x77\u{8b8}\x0a\
	\x77\x03\x78\x03\x78\x05\x78\u{8bc}\x0a\x78\x03\x79\x03\x79\x03\x79\x03\
	\x7a\x03\x7a\x03\x7a\x03\x7b\x03\x7b\x03\x7b\x03\x7b\x03\x7b\x03\x7b\x03\
	\x7b\x05\x7b\u{8cb}\x0a\x7b\x03\x7c\x03\x7c\x03\x7c\x03\x7c\x05\x7c\u{8d1}\
	\x0a\x7c\x03\x7c\x05\x7c\u{8d4}\x0a\x7c\x03\x7c\x05\x7c\u{8d7}\x0a\x7c\x03\
	\x7c\x05\x7c\u{8da}\x0a\x7c\x03\x7c\x05\x7c\u{8dd}\x0a\x7c\x03\x7d\x03\x7d\
	\x05\x7d\u{8e1}\x0a\x7d\x03\x7e\x03\x7e\x03\x7e\x03\x7f\x03\x7f\x03\x7f\
	\x03\x7f\x03\u{80}\x03\u{80}\x03\u{80}\x07\u{80}\u{8ed}\x0a\u{80}\x0c\u{80}\
	\x0e\u{80}\u{8f0}\x0b\u{80}\x03\u{80}\x03\u{80}\x03\u{80}\x07\u{80}\u{8f5}\
	\x0a\u{80}\x0c\u{80}\x0e\u{80}\u{8f8}\x0b\u{80}\x05\u{80}\u{8fa}\x0a\u{80}\
	\x03\u{81}\x03\u{81}\x03\u{81}\x03\u{81}\x03\u{82}\x03\u{82}\x03\u{83}\x03\
	\u{83}\x03\u{83}\x03\u{83}\x03\u{83}\x03\u{83}\x03\u{83}\x05\u{83}\u{909}\
	\x0a\u{83}\x03\u{84}\x03\u{84}\x03\u{84}\x03\u{84}\x03\u{84}\x03\u{84}\x03\
	\u{85}\x03\u{85}\x03\u{85}\x03\u{85}\x03\u{85}\x03\u{85}\x03\u{86}\x03\u{86}\
	\x03\u{86}\x03\u{86}\x03\u{86}\x03\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x03\
	\u{87}\x03\u{88}\x03\u{88}\x03\u{88}\x03\u{88}\x03\u{88}\x03\u{88}\x03\u{88}\
	\x03\u{88}\x03\u{88}\x03\u{88}\x05\u{88}\u{92b}\x0a\u{88}\x03\u{88}\x03\
	\u{88}\x03\u{88}\x03\u{88}\x03\u{88}\x03\u{88}\x05\u{88}\u{933}\x0a\u{88}\
	\x03\u{88}\x03\u{88}\x03\u{88}\x05\u{88}\u{938}\x0a\u{88}\x03\u{88}\x03\
	\u{88}\x03\u{88}\x03\u{88}\x03\u{88}\x03\u{88}\x05\u{88}\u{940}\x0a\u{88}\
	\x03\u{88}\x03\u{88}\x03\u{88}\x05\u{88}\u{945}\x0a\u{88}\x03\u{88}\x03\
	\u{88}\x03\u{88}\x05\u{88}\u{94a}\x0a\u{88}\x03\u{89}\x03\u{89}\x03\u{89}\
	\x03\u{8a}\x03\u{8a}\x03\u{8a}\x07\u{8a}\u{952}\x0a\u{8a}\x0c\u{8a}\x0e\
	\u{8a}\u{955}\x0b\u{8a}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x07\u{8b}\u{95a}\x0a\
	\u{8b}\x0c\u{8b}\x0e\u{8b}\u{95d}\x0b\u{8b}\x03\u{8c}\x03\u{8c}\x03\u{8c}\
	\x07\u{8c}\u{962}\x0a\u{8c}\x0c\u{8c}\x0e\u{8c}\u{965}\x0b\u{8c}\x03\u{8d}\
	\x03\u{8d}\x03\u{8d}\x07\u{8d}\u{96a}\x0a\u{8d}\x0c\u{8d}\x0e\u{8d}\u{96d}\
	\x0b\u{8d}\x03\u{8e}\x03\u{8e}\x03\u{8f}\x03\u{8f}\x03\u{8f}\x03\u{8f}\x03\
	\u{8f}\x03\u{8f}\x05\u{8f}\u{977}\x0a\u{8f}\x07\u{8f}\u{979}\x0a\u{8f}\x0c\
	\u{8f}\x0e\u{8f}\u{97c}\x0b\u{8f}\x03\u{90}\x03\u{90}\x03\u{90}\x07\u{90}\
	\u{981}\x0a\u{90}\x0c\u{90}\x0e\u{90}\u{984}\x0b\u{90}\x03\u{91}\x03\u{91}\
	\x03\u{91}\x03\u{91}\x03\u{92}\x03\u{92}\x05\u{92}\u{98c}\x0a\u{92}\x03\
	\u{92}\x05\u{92}\u{98f}\x0a\u{92}\x03\u{93}\x03\u{93}\x03\u{94}\x03\u{94}\
	\x03\u{95}\x03\u{95}\x03\u{95}\x05\u{95}\u{998}\x0a\u{95}\x03\u{96}\x03\
	\u{96}\x03\u{97}\x03\u{97}\x05\u{97}\u{99e}\x0a\u{97}\x03\u{97}\x03\u{97}\
	\x05\u{97}\u{9a2}\x0a\u{97}\x03\u{98}\x03\u{98}\x03\u{98}\x03\u{98}\x05\
	\u{98}\u{9a8}\x0a\u{98}\x03\u{99}\x03\u{99}\x05\u{99}\u{9ac}\x0a\u{99}\x03\
	\u{9a}\x03\u{9a}\x03\u{9a}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\
	\x03\u{9c}\x03\u{9c}\x05\u{9c}\u{9b8}\x0a\u{9c}\x03\u{9c}\x03\u{9c}\x03\
	\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x05\u{9c}\u{9c1}\x0a\u{9c}\
	\x03\u{9d}\x03\u{9d}\x03\u{9d}\x03\u{9d}\x03\u{9d}\x03\u{9d}\x03\u{9d}\x03\
	\u{9d}\x03\u{9d}\x05\u{9d}\u{9cc}\x0a\u{9d}\x03\u{9e}\x03\u{9e}\x05\u{9e}\
	\u{9d0}\x0a\u{9e}\x03\u{9f}\x03\u{9f}\x03\u{9f}\x07\u{9f}\u{9d5}\x0a\u{9f}\
	\x0c\u{9f}\x0e\u{9f}\u{9d8}\x0b\u{9f}\x03\u{a0}\x03\u{a0}\x03\u{a0}\x03\
	\u{a0}\x03\u{a1}\x03\u{a1}\x03\u{a1}\x07\u{a1}\u{9e1}\x0a\u{a1}\x0c\u{a1}\
	\x0e\u{a1}\u{9e4}\x0b\u{a1}\x03\u{a2}\x03\u{a2}\x03\u{a3}\x03\u{a3}\x05\
	\u{a3}\u{9ea}\x0a\u{a3}\x03\u{a4}\x03\u{a4}\x03\u{a5}\x03\u{a5}\x03\u{a5}\
	\x03\u{a6}\x03\u{a6}\x05\u{a6}\u{9f3}\x0a\u{a6}\x03\u{a6}\x05\u{a6}\u{9f6}\
	\x0a\u{a6}\x03\u{a7}\x03\u{a7}\x03\u{a7}\x07\u{a7}\u{9fb}\x0a\u{a7}\x0c\
	\u{a7}\x0e\u{a7}\u{9fe}\x0b\u{a7}\x03\u{a8}\x03\u{a8}\x03\u{a8}\x05\u{a8}\
	\u{a03}\x0a\u{a8}\x03\u{a9}\x03\u{a9}\x03\u{aa}\x03\u{aa}\x05\u{aa}\u{a09}\
	\x0a\u{aa}\x03\u{aa}\x05\u{aa}\u{a0c}\x0a\u{aa}\x03\u{ab}\x03\u{ab}\x03\
	\u{ab}\x03\u{ab}\x05\u{ab}\u{a12}\x0a\u{ab}\x03\u{ac}\x03\u{ac}\x05\u{ac}\
	\u{a16}\x0a\u{ac}\x03\u{ad}\x03\u{ad}\x05\u{ad}\u{a1a}\x0a\u{ad}\x03\u{ae}\
	\x03\u{ae}\x03\u{ae}\x05\u{ae}\u{a1f}\x0a\u{ae}\x03\u{ae}\x03\u{ae}\x05\
	\u{ae}\u{a23}\x0a\u{ae}\x03\u{af}\x03\u{af}\x05\u{af}\u{a27}\x0a\u{af}\x03\
	\u{b0}\x03\u{b0}\x05\u{b0}\u{a2b}\x0a\u{b0}\x03\u{b0}\x03\u{b0}\x03\u{b0}\
	\x03\u{b0}\x03\u{b0}\x03\u{b0}\x05\u{b0}\u{a33}\x0a\u{b0}\x03\u{b1}\x03\
	\u{b1}\x05\u{b1}\u{a37}\x0a\u{b1}\x03\u{b1}\x03\u{b1}\x05\u{b1}\u{a3b}\x0a\
	\u{b1}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{a3f}\x0a\u{b2}\x03\u{b3}\x03\u{b3}\
	\x05\u{b3}\u{a43}\x0a\u{b3}\x03\u{b3}\x03\u{b3}\x03\u{b3}\x03\u{b3}\x03\
	\u{b3}\x03\u{b3}\x05\u{b3}\u{a4b}\x0a\u{b3}\x03\u{b4}\x03\u{b4}\x05\u{b4}\
	\u{a4f}\x0a\u{b4}\x03\u{b4}\x03\u{b4}\x05\u{b4}\u{a53}\x0a\u{b4}\x03\u{b5}\
	\x03\u{b5}\x03\u{b5}\x03\u{b5}\x03\u{b5}\x03\u{b5}\x05\u{b5}\u{a5b}\x0a\
	\u{b5}\x03\u{b6}\x03\u{b6}\x03\u{b6}\x05\u{b6}\u{a60}\x0a\u{b6}\x03\u{b7}\
	\x03\u{b7}\x03\u{b7}\x05\u{b7}\u{a65}\x0a\u{b7}\x03\u{b8}\x03\u{b8}\x05\
	\u{b8}\u{a69}\x0a\u{b8}\x03\u{b9}\x03\u{b9}\x05\u{b9}\u{a6d}\x0a\u{b9}\x03\
	\u{ba}\x03\u{ba}\x03\u{ba}\x03\u{ba}\x03\u{ba}\x05\u{ba}\u{a74}\x0a\u{ba}\
	\x03\u{bb}\x03\u{bb}\x03\u{bc}\x03\u{bc}\x03\u{bc}\x07\u{bc}\u{a7b}\x0a\
	\u{bc}\x0c\u{bc}\x0e\u{bc}\u{a7e}\x0b\u{bc}\x03\u{bd}\x03\u{bd}\x03\u{bd}\
	\x03\u{bd}\x03\u{bd}\x05\u{bd}\u{a85}\x0a\u{bd}\x03\u{be}\x03\u{be}\x03\
	\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x05\u{be}\
	\u{a90}\x0a\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x03\
	\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\
	\x03\u{be}\x03\u{be}\x03\u{be}\x05\u{be}\u{aa2}\x0a\u{be}\x03\u{be}\x05\
	\u{be}\u{aa5}\x0a\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x03\u{be}\x05\u{be}\
	\u{aab}\x0a\u{be}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\
	\u{c0}\x03\u{c0}\x03\u{c0}\x03\u{c0}\x03\u{c0}\x03\u{c1}\x03\u{c1}\x03\u{c1}\
	\x03\u{c1}\x03\u{c1}\x03\u{c1}\x03\u{c1}\x03\u{c2}\x03\u{c2}\x03\u{c2}\x03\
	\u{c2}\x03\u{c2}\x03\u{c3}\x03\u{c3}\x05\u{c3}\u{ac5}\x0a\u{c3}\x03\u{c4}\
	\x05\u{c4}\u{ac8}\x0a\u{c4}\x03\u{c4}\x03\u{c4}\x03\u{c5}\x03\u{c5}\x05\
	\u{c5}\u{ace}\x0a\u{c5}\x03\u{c6}\x03\u{c6}\x03\u{c6}\x03\u{c6}\x07\u{c6}\
	\u{ad4}\x0a\u{c6}\x0c\u{c6}\x0e\u{c6}\u{ad7}\x0b\u{c6}\x03\u{c7}\x03\u{c7}\
	\x03\u{c7}\x03\u{c7}\x03\u{c7}\x05\u{c7}\u{ade}\x0a\u{c7}\x03\u{c7}\x03\
	\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c8}\x03\u{c8}\x03\u{c8}\x03\u{c8}\
	\x07\u{c8}\u{ae9}\x0a\u{c8}\x0c\u{c8}\x0e\u{c8}\u{aec}\x0b\u{c8}\x03\u{c9}\
	\x03\u{c9}\x06\u{c9}\u{af0}\x0a\u{c9}\x0d\u{c9}\x0e\u{c9}\u{af1}\x03\u{ca}\
	\x03\u{ca}\x03\u{ca}\x03\u{ca}\x05\u{ca}\u{af8}\x0a\u{ca}\x03\u{cb}\x03\
	\u{cb}\x05\u{cb}\u{afc}\x0a\u{cb}\x03\u{cb}\x05\u{cb}\u{aff}\x0a\u{cb}\x03\
	\u{cb}\x05\u{cb}\u{b02}\x0a\u{cb}\x03\u{cb}\x05\u{cb}\u{b05}\x0a\u{cb}\x03\
	\u{cb}\x05\u{cb}\u{b08}\x0a\u{cb}\x03\u{cb}\x05\u{cb}\u{b0b}\x0a\u{cb}\x03\
	\u{cb}\x03\u{cb}\x03\u{cb}\x03\u{cb}\x03\u{cb}\x05\u{cb}\u{b12}\x0a\u{cb}\
	\x03\u{cc}\x03\u{cc}\x05\u{cc}\u{b16}\x0a\u{cc}\x03\u{cc}\x05\u{cc}\u{b19}\
	\x0a\u{cc}\x03\u{cc}\x05\u{cc}\u{b1c}\x0a\u{cc}\x03\u{cc}\x05\u{cc}\u{b1f}\
	\x0a\u{cc}\x03\u{cc}\x05\u{cc}\u{b22}\x0a\u{cc}\x03\u{cc}\x05\u{cc}\u{b25}\
	\x0a\u{cc}\x03\u{cd}\x03\u{cd}\x03\u{cd}\x06\u{cd}\u{b2a}\x0a\u{cd}\x0d\
	\u{cd}\x0e\u{cd}\u{b2b}\x03\u{ce}\x05\u{ce}\u{b2f}\x0a\u{ce}\x03\u{ce}\x03\
	\u{ce}\x03\u{cf}\x03\u{cf}\x03\u{cf}\x05\u{cf}\u{b36}\x0a\u{cf}\x03\u{cf}\
	\x05\u{cf}\u{b39}\x0a\u{cf}\x03\u{cf}\x05\u{cf}\u{b3c}\x0a\u{cf}\x03\u{cf}\
	\x05\u{cf}\u{b3f}\x0a\u{cf}\x03\u{cf}\x05\u{cf}\u{b42}\x0a\u{cf}\x03\u{cf}\
	\x05\u{cf}\u{b45}\x0a\u{cf}\x03\u{cf}\x05\u{cf}\u{b48}\x0a\u{cf}\x03\u{cf}\
	\x05\u{cf}\u{b4b}\x0a\u{cf}\x03\u{cf}\x05\u{cf}\u{b4e}\x0a\u{cf}\x03\u{cf}\
	\x05\u{cf}\u{b51}\x0a\u{cf}\x03\u{cf}\x05\u{cf}\u{b54}\x0a\u{cf}\x03\u{cf}\
	\x03\u{cf}\x05\u{cf}\u{b58}\x0a\u{cf}\x03\u{cf}\x05\u{cf}\u{b5b}\x0a\u{cf}\
	\x03\u{cf}\x05\u{cf}\u{b5e}\x0a\u{cf}\x03\u{cf}\x05\u{cf}\u{b61}\x0a\u{cf}\
	\x03\u{cf}\x05\u{cf}\u{b64}\x0a\u{cf}\x03\u{cf}\x05\u{cf}\u{b67}\x0a\u{cf}\
	\x03\u{cf}\x05\u{cf}\u{b6a}\x0a\u{cf}\x03\u{cf}\x05\u{cf}\u{b6d}\x0a\u{cf}\
	\x03\u{cf}\x05\u{cf}\u{b70}\x0a\u{cf}\x03\u{cf}\x05\u{cf}\u{b73}\x0a\u{cf}\
	\x03\u{cf}\x05\u{cf}\u{b76}\x0a\u{cf}\x05\u{cf}\u{b78}\x0a\u{cf}\x03\u{d0}\
	\x03\u{d0}\x03\u{d0}\x03\u{d0}\x05\u{d0}\u{b7e}\x0a\u{d0}\x03\u{d0}\x03\
	\u{d0}\x05\u{d0}\u{b82}\x0a\u{d0}\x03\u{d0}\x03\u{d0}\x03\u{d0}\x03\u{d0}\
	\x03\u{d0}\x05\u{d0}\u{b89}\x0a\u{d0}\x05\u{d0}\u{b8b}\x0a\u{d0}\x03\u{d1}\
	\x05\u{d1}\u{b8e}\x0a\u{d1}\x03\u{d1}\x03\u{d1}\x03\u{d1}\x05\u{d1}\u{b93}\
	\x0a\u{d1}\x03\u{d1}\x05\u{d1}\u{b96}\x0a\u{d1}\x03\u{d1}\x03\u{d1}\x05\
	\u{d1}\u{b9a}\x0a\u{d1}\x03\u{d2}\x03\u{d2}\x03\u{d2}\x05\u{d2}\u{b9f}\x0a\
	\u{d2}\x03\u{d2}\x03\u{d2}\x03\u{d2}\x03\u{d2}\x05\u{d2}\u{ba5}\x0a\u{d2}\
	\x03\u{d3}\x03\u{d3}\x03\u{d3}\x03\u{d3}\x05\u{d3}\u{bab}\x0a\u{d3}\x03\
	\u{d4}\x03\u{d4}\x03\u{d4}\x03\u{d4}\x03\u{d5}\x03\u{d5}\x05\u{d5}\u{bb3}\
	\x0a\u{d5}\x03\u{d6}\x03\u{d6}\x03\u{d6}\x03\u{d6}\x07\u{d6}\u{bb9}\x0a\
	\u{d6}\x0c\u{d6}\x0e\u{d6}\u{bbc}\x0b\u{d6}\x03\u{d7}\x03\u{d7}\x03\u{d7}\
	\x03\u{d7}\x05\u{d7}\u{bc2}\x0a\u{d7}\x03\u{d8}\x03\u{d8}\x03\u{d8}\x03\
	\u{d8}\x05\u{d8}\u{bc8}\x0a\u{d8}\x03\u{d9}\x03\u{d9}\x03\u{d9}\x03\u{d9}\
	\x03\u{d9}\x07\u{d9}\u{bcf}\x0a\u{d9}\x0c\u{d9}\x0e\u{d9}\u{bd2}\x0b\u{d9}\
	\x05\u{d9}\u{bd4}\x0a\u{d9}\x03\u{da}\x03\u{da}\x05\u{da}\u{bd8}\x0a\u{da}\
	\x03\u{db}\x03\u{db}\x03\u{db}\x03\u{dc}\x03\u{dc}\x03\u{dc}\x03\u{dc}\x03\
	\u{dd}\x03\u{dd}\x03\u{de}\x03\u{de}\x05\u{de}\u{be5}\x0a\u{de}\x03\u{df}\
	\x03\u{df}\x05\u{df}\u{be9}\x0a\u{df}\x03\u{e0}\x03\u{e0}\x03\u{e0}\x03\
	\u{e0}\x03\u{e1}\x03\u{e1}\x03\u{e1}\x06\u{e1}\u{bf2}\x0a\u{e1}\x0d\u{e1}\
	\x0e\u{e1}\u{bf3}\x03\u{e2}\x03\u{e2}\x03\u{e2}\x06\u{e2}\u{bf9}\x0a\u{e2}\
	\x0d\u{e2}\x0e\u{e2}\u{bfa}\x03\u{e3}\x03\u{e3}\x05\u{e3}\u{bff}\x0a\u{e3}\
	\x03\u{e3}\x03\u{e3}\x03\u{e3}\x05\u{e3}\u{c04}\x0a\u{e3}\x03\u{e3}\x05\
	\u{e3}\u{c07}\x0a\u{e3}\x03\u{e3}\x03\u{e3}\x03\u{e3}\x03\u{e3}\x03\u{e3}\
	\x03\u{e3}\x03\u{e4}\x03\u{e4}\x07\u{e4}\u{c11}\x0a\u{e4}\x0c\u{e4}\x0e\
	\u{e4}\u{c14}\x0b\u{e4}\x03\u{e4}\x05\u{e4}\u{c17}\x0a\u{e4}\x03\u{e5}\x03\
	\u{e5}\x03\u{e5}\x03\u{e5}\x03\u{e5}\x05\u{e5}\u{c1e}\x0a\u{e5}\x03\u{e5}\
	\x03\u{e5}\x03\u{e5}\x05\u{e5}\u{c23}\x0a\u{e5}\x03\u{e5}\x03\u{e5}\x03\
	\u{e5}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\u{e6}\
	\x03\u{e7}\x03\u{e7}\x03\u{e7}\x03\u{e7}\x03\u{e7}\x03\u{e8}\x03\u{e8}\x03\
	\u{e8}\x05\u{e8}\u{c37}\x0a\u{e8}\x03\u{e9}\x03\u{e9}\x03\u{e9}\x06\u{e9}\
	\u{c3c}\x0a\u{e9}\x0d\u{e9}\x0e\u{e9}\u{c3d}\x03\u{ea}\x03\u{ea}\x03\u{ea}\
	\x03\u{ea}\x03\u{eb}\x03\u{eb}\x03\u{eb}\x03\u{ec}\x03\u{ec}\x03\u{ec}\x03\
	\u{ed}\x03\u{ed}\x03\u{ed}\x03\u{ee}\x03\u{ee}\x03\u{ee}\x03\u{ee}\x03\u{ee}\
	\x03\u{ee}\x03\u{ee}\x03\u{ee}\x05\u{ee}\u{c55}\x0a\u{ee}\x03\u{ee}\x03\
	\u{ee}\x03\u{ee}\x03\u{ee}\x03\u{ee}\x03\u{ee}\x03\u{ee}\x03\u{ee}\x03\u{ee}\
	\x03\u{ee}\x03\u{ee}\x03\u{ee}\x03\u{ee}\x03\u{ee}\x05\u{ee}\u{c65}\x0a\
	\u{ee}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\
	\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\
	\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x05\u{ef}\u{c7a}\x0a\u{ef}\
	\x03\u{f0}\x03\u{f0}\x03\u{f0}\x03\u{f0}\x03\u{f0}\x03\u{f0}\x03\u{f0}\x03\
	\u{f0}\x03\u{f0}\x03\u{f0}\x03\u{f0}\x03\u{f0}\x03\u{f0}\x03\u{f0}\x03\u{f0}\
	\x05\u{f0}\u{c8b}\x0a\u{f0}\x03\u{f1}\x03\u{f1}\x03\u{f1}\x03\u{f1}\x03\
	\u{f1}\x03\u{f1}\x03\u{f2}\x03\u{f2}\x03\u{f2}\x03\u{f2}\x03\u{f2}\x05\u{f2}\
	\u{c98}\x0a\u{f2}\x03\u{f3}\x03\u{f3}\x05\u{f3}\u{c9c}\x0a\u{f3}\x03\u{f4}\
	\x03\u{f4}\x05\u{f4}\u{ca0}\x0a\u{f4}\x03\u{f5}\x03\u{f5}\x03\u{f6}\x03\
	\u{f6}\x03\u{f6}\x05\u{f6}\u{ca7}\x0a\u{f6}\x03\u{f7}\x03\u{f7}\x03\u{f7}\
	\x03\u{f7}\x03\u{f7}\x03\u{f8}\x03\u{f8}\x03\u{f8}\x03\u{f8}\x03\u{f8}\x03\
	\u{f9}\x03\u{f9}\x03\u{f9}\x03\u{f9}\x03\u{f9}\x03\u{fa}\x03\u{fa}\x03\u{fa}\
	\x03\u{fa}\x03\u{fa}\x03\u{fb}\x03\u{fb}\x03\u{fb}\x03\u{fb}\x03\u{fc}\x03\
	\u{fc}\x05\u{fc}\u{cc3}\x0a\u{fc}\x03\u{fc}\x03\u{fc}\x03\u{fc}\x03\u{fc}\
	\x03\u{fc}\x05\u{fc}\u{cca}\x0a\u{fc}\x03\u{fd}\x03\u{fd}\x03\u{fd}\x05\
	\u{fd}\u{ccf}\x0a\u{fd}\x03\u{fe}\x03\u{fe}\x03\u{fe}\x05\u{fe}\u{cd4}\x0a\
	\u{fe}\x03\u{ff}\x03\u{ff}\x03\u{ff}\x05\u{ff}\u{cd9}\x0a\u{ff}\x03\u{ff}\
	\x03\u{ff}\x03\u{ff}\x05\u{ff}\u{cde}\x0a\u{ff}\x03\u{100}\x03\u{100}\x03\
	\u{100}\x03\u{100}\x03\u{101}\x03\u{101}\x05\u{101}\u{ce6}\x0a\u{101}\x03\
	\u{101}\x03\u{101}\x03\u{101}\x03\u{101}\x05\u{101}\u{cec}\x0a\u{101}\x03\
	\u{101}\x03\u{101}\x05\u{101}\u{cf0}\x0a\u{101}\x03\u{101}\x05\u{101}\u{cf3}\
	\x0a\u{101}\x03\u{101}\x05\u{101}\u{cf6}\x0a\u{101}\x03\u{102}\x03\u{102}\
	\x03\u{102}\x03\u{102}\x05\u{102}\u{cfc}\x0a\u{102}\x03\u{102}\x03\u{102}\
	\x03\u{102}\x03\u{102}\x03\u{102}\x05\u{102}\u{d03}\x0a\u{102}\x03\u{103}\
	\x03\u{103}\x03\u{103}\x03\u{103}\x03\u{103}\x03\u{104}\x03\u{104}\x03\u{104}\
	\x05\u{104}\u{d0d}\x0a\u{104}\x03\u{105}\x03\u{105}\x05\u{105}\u{d11}\x0a\
	\u{105}\x03\u{105}\x06\u{105}\u{d14}\x0a\u{105}\x0d\u{105}\x0e\u{105}\u{d15}\
	\x03\u{106}\x03\u{106}\x05\u{106}\u{d1a}\x0a\u{106}\x03\u{107}\x03\u{107}\
	\x07\u{107}\u{d1e}\x0a\u{107}\x0c\u{107}\x0e\u{107}\u{d21}\x0b\u{107}\x03\
	\u{108}\x03\u{108}\x07\u{108}\u{d25}\x0a\u{108}\x0c\u{108}\x0e\u{108}\u{d28}\
	\x0b\u{108}\x03\u{109}\x03\u{109}\x07\u{109}\u{d2c}\x0a\u{109}\x0c\u{109}\
	\x0e\u{109}\u{d2f}\x0b\u{109}\x03\u{10a}\x03\u{10a}\x03\u{10a}\x03\u{10b}\
	\x03\u{10b}\x05\u{10b}\u{d36}\x0a\u{10b}\x03\u{10b}\x03\u{10b}\x03\u{10b}\
	\x03\u{10b}\x03\u{10b}\x07\u{10b}\u{d3d}\x0a\u{10b}\x0c\u{10b}\x0e\u{10b}\
	\u{d40}\x0b\u{10b}\x03\u{10b}\x05\u{10b}\u{d43}\x0a\u{10b}\x03\u{10b}\x05\
	\u{10b}\u{d46}\x0a\u{10b}\x03\u{10c}\x03\u{10c}\x03\u{10c}\x03\u{10c}\x03\
	\u{10c}\x03\u{10c}\x05\u{10c}\u{d4e}\x0a\u{10c}\x03\u{10c}\x05\u{10c}\u{d51}\
	\x0a\u{10c}\x03\u{10d}\x03\u{10d}\x03\u{10d}\x03\u{10d}\x03\u{10d}\x03\u{10d}\
	\x05\u{10d}\u{d59}\x0a\u{10d}\x03\u{10d}\x05\u{10d}\u{d5c}\x0a\u{10d}\x03\
	\u{10e}\x03\u{10e}\x03\u{10e}\x03\u{10e}\x03\u{10e}\x03\u{10e}\x05\u{10e}\
	\u{d64}\x0a\u{10e}\x03\u{10e}\x03\u{10e}\x05\u{10e}\u{d68}\x0a\u{10e}\x03\
	\u{10e}\x03\u{10e}\x03\u{10e}\x05\u{10e}\u{d6d}\x0a\u{10e}\x03\u{10f}\x03\
	\u{10f}\x05\u{10f}\u{d71}\x0a\u{10f}\x03\u{110}\x03\u{110}\x03\u{110}\x03\
	\u{110}\x03\u{111}\x03\u{111}\x03\u{111}\x05\u{111}\u{d7a}\x0a\u{111}\x03\
	\u{112}\x03\u{112}\x03\u{112}\x03\u{112}\x03\u{112}\x03\u{113}\x03\u{113}\
	\x03\u{113}\x03\u{113}\x03\u{114}\x03\u{114}\x03\u{114}\x07\u{114}\u{d88}\
	\x0a\u{114}\x0c\u{114}\x0e\u{114}\u{d8b}\x0b\u{114}\x03\u{115}\x03\u{115}\
	\x03\u{115}\x03\u{115}\x03\u{116}\x03\u{116}\x03\u{116}\x03\u{116}\x03\u{117}\
	\x03\u{117}\x03\u{117}\x03\u{117}\x05\u{117}\u{d99}\x0a\u{117}\x05\u{117}\
	\u{d9b}\x0a\u{117}\x03\u{118}\x03\u{118}\x03\u{118}\x03\u{118}\x03\u{118}\
	\x03\u{118}\x03\u{119}\x03\u{119}\x03\u{119}\x03\u{119}\x03\u{11a}\x03\u{11a}\
	\x03\u{11a}\x03\u{11a}\x05\u{11a}\u{dab}\x0a\u{11a}\x03\u{11a}\x03\u{11a}\
	\x03\u{11a}\x03\u{11a}\x03\u{11a}\x05\u{11a}\u{db2}\x0a\u{11a}\x03\u{11b}\
	\x03\u{11b}\x03\u{11c}\x03\u{11c}\x03\u{11c}\x03\u{11c}\x03\u{11d}\x03\u{11d}\
	\x03\u{11d}\x03\u{11e}\x03\u{11e}\x03\u{11e}\x03\u{11f}\x03\u{11f}\x03\u{11f}\
	\x05\u{11f}\u{dc3}\x0a\u{11f}\x03\u{11f}\x05\u{11f}\u{dc6}\x0a\u{11f}\x03\
	\u{11f}\x05\u{11f}\u{dc9}\x0a\u{11f}\x03\u{11f}\x05\u{11f}\u{dcc}\x0a\u{11f}\
	\x03\u{11f}\x03\u{11f}\x03\u{11f}\x03\u{11f}\x05\u{11f}\u{dd2}\x0a\u{11f}\
	\x03\u{120}\x03\u{120}\x03\u{120}\x03\u{120}\x03\u{121}\x03\u{121}\x03\u{121}\
	\x03\u{121}\x03\u{121}\x03\u{121}\x03\u{121}\x03\u{122}\x03\u{122}\x03\u{122}\
	\x03\u{122}\x03\u{122}\x03\u{122}\x03\u{122}\x03\u{122}\x03\u{122}\x03\u{122}\
	\x05\u{122}\u{de9}\x0a\u{122}\x03\u{122}\x03\u{122}\x03\u{123}\x03\u{123}\
	\x03\u{123}\x03\u{123}\x05\u{123}\u{df1}\x0a\u{123}\x03\u{123}\x03\u{123}\
	\x03\u{124}\x03\u{124}\x03\u{124}\x03\u{124}\x03\u{124}\x03\u{124}\x03\u{124}\
	\x03\u{124}\x03\u{124}\x03\u{124}\x05\u{124}\u{dff}\x0a\u{124}\x03\u{124}\
	\x05\u{124}\u{e02}\x0a\u{124}\x03\u{125}\x03\u{125}\x03\u{125}\x05\u{125}\
	\u{e07}\x0a\u{125}\x03\u{126}\x03\u{126}\x03\u{126}\x03\u{126}\x03\u{126}\
	\x03\u{127}\x03\u{127}\x03\u{127}\x03\u{127}\x03\u{127}\x03\u{128}\x03\u{128}\
	\x03\u{128}\x03\u{128}\x03\u{128}\x03\u{129}\x03\u{129}\x03\u{129}\x03\u{129}\
	\x03\u{129}\x03\u{129}\x03\u{129}\x03\u{129}\x03\u{129}\x05\u{129}\u{e21}\
	\x0a\u{129}\x03\u{12a}\x03\u{12a}\x05\u{12a}\u{e25}\x0a\u{12a}\x03\u{12a}\
	\x05\u{12a}\u{e28}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e2b}\x0a\u{12a}\x03\
	\u{12a}\x03\u{12a}\x05\u{12a}\u{e2f}\x0a\u{12a}\x03\u{12a}\x03\u{12a}\x03\
	\u{12a}\x05\u{12a}\u{e34}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e37}\x0a\u{12a}\
	\x03\u{12a}\x05\u{12a}\u{e3a}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e3d}\x0a\
	\u{12a}\x03\u{12a}\x05\u{12a}\u{e40}\x0a\u{12a}\x03\u{12a}\x03\u{12a}\x03\
	\u{12a}\x03\u{12a}\x05\u{12a}\u{e46}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e49}\
	\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e4c}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\
	\u{e4f}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e52}\x0a\u{12a}\x03\u{12a}\x05\
	\u{12a}\u{e55}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e58}\x0a\u{12a}\x03\u{12a}\
	\x05\u{12a}\u{e5b}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e5e}\x0a\u{12a}\x03\
	\u{12a}\x03\u{12a}\x05\u{12a}\u{e62}\x0a\u{12a}\x05\u{12a}\u{e64}\x0a\u{12a}\
	\x03\u{12a}\x03\u{12a}\x03\u{12a}\x03\u{12a}\x05\u{12a}\u{e6a}\x0a\u{12a}\
	\x03\u{12a}\x03\u{12a}\x03\u{12a}\x05\u{12a}\u{e6f}\x0a\u{12a}\x03\u{12a}\
	\x05\u{12a}\u{e72}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e75}\x0a\u{12a}\x03\
	\u{12a}\x05\u{12a}\u{e78}\x0a\u{12a}\x03\u{12a}\x03\u{12a}\x03\u{12a}\x03\
	\u{12a}\x05\u{12a}\u{e7e}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e81}\x0a\u{12a}\
	\x03\u{12a}\x05\u{12a}\u{e84}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e87}\x0a\
	\u{12a}\x03\u{12a}\x05\u{12a}\u{e8a}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e8d}\
	\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e90}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\
	\u{e93}\x0a\u{12a}\x03\u{12a}\x05\u{12a}\u{e96}\x0a\u{12a}\x03\u{12a}\x03\
	\u{12a}\x05\u{12a}\u{e9a}\x0a\u{12a}\x05\u{12a}\u{e9c}\x0a\u{12a}\x05\u{12a}\
	\u{e9e}\x0a\u{12a}\x03\u{12b}\x03\u{12b}\x03\u{12b}\x05\u{12b}\u{ea3}\x0a\
	\u{12b}\x03\u{12b}\x03\u{12b}\x03\u{12b}\x03\u{12b}\x05\u{12b}\u{ea9}\x0a\
	\u{12b}\x03\u{12b}\x03\u{12b}\x03\u{12b}\x05\u{12b}\u{eae}\x0a\u{12b}\x03\
	\u{12c}\x03\u{12c}\x03\u{12c}\x03\u{12d}\x03\u{12d}\x03\u{12d}\x03\u{12e}\
	\x03\u{12e}\x03\u{12e}\x03\u{12f}\x03\u{12f}\x03\u{12f}\x03\u{12f}\x03\u{130}\
	\x03\u{130}\x03\u{130}\x05\u{130}\u{ec0}\x0a\u{130}\x03\u{130}\x03\u{130}\
	\x03\u{131}\x03\u{131}\x03\u{131}\x03\u{131}\x03\u{131}\x05\u{131}\u{ec9}\
	\x0a\u{131}\x03\u{132}\x03\u{132}\x03\u{133}\x03\u{133}\x03\u{134}\x03\u{134}\
	\x03\u{134}\x07\u{134}\u{ed2}\x0a\u{134}\x0c\u{134}\x0e\u{134}\u{ed5}\x0b\
	\u{134}\x03\u{135}\x03\u{135}\x03\u{135}\x07\u{135}\u{eda}\x0a\u{135}\x0c\
	\u{135}\x0e\u{135}\u{edd}\x0b\u{135}\x03\u{136}\x03\u{136}\x03\u{136}\x03\
	\u{137}\x03\u{137}\x03\u{137}\x03\u{137}\x06\u{137}\u{ee6}\x0a\u{137}\x0d\
	\u{137}\x0e\u{137}\u{ee7}\x03\u{137}\x05\u{137}\u{eeb}\x0a\u{137}\x03\u{138}\
	\x03\u{138}\x07\u{138}\u{eef}\x0a\u{138}\x0c\u{138}\x0e\u{138}\u{ef2}\x0b\
	\u{138}\x03\u{138}\x03\u{138}\x07\u{138}\u{ef6}\x0a\u{138}\x0c\u{138}\x0e\
	\u{138}\u{ef9}\x0b\u{138}\x03\u{138}\x03\u{138}\x07\u{138}\u{efd}\x0a\u{138}\
	\x0c\u{138}\x0e\u{138}\u{f00}\x0b\u{138}\x03\u{138}\x03\u{138}\x07\u{138}\
	\u{f04}\x0a\u{138}\x0c\u{138}\x0e\u{138}\u{f07}\x0b\u{138}\x03\u{138}\x03\
	\u{138}\x03\u{138}\x03\u{138}\x05\u{138}\u{f0d}\x0a\u{138}\x03\u{139}\x03\
	\u{139}\x03\u{139}\x03\u{139}\x03\u{139}\x03\u{139}\x03\u{139}\x05\u{139}\
	\u{f16}\x0a\u{139}\x07\u{139}\u{f18}\x0a\u{139}\x0c\u{139}\x0e\u{139}\u{f1b}\
	\x0b\u{139}\x03\u{13a}\x03\u{13a}\x03\u{13a}\x03\u{13a}\x05\u{13a}\u{f21}\
	\x0a\u{13a}\x03\u{13a}\x07\u{13a}\u{f24}\x0a\u{13a}\x0c\u{13a}\x0e\u{13a}\
	\u{f27}\x0b\u{13a}\x03\u{13b}\x05\u{13b}\u{f2a}\x0a\u{13b}\x03\u{13b}\x03\
	\u{13b}\x03\u{13b}\x03\u{13c}\x03\u{13c}\x03\u{13c}\x03\u{13c}\x03\u{13d}\
	\x03\u{13d}\x03\u{13e}\x03\u{13e}\x03\u{13e}\x03\u{13e}\x03\u{13e}\x05\u{13e}\
	\u{f3a}\x0a\u{13e}\x03\u{13e}\x03\u{13e}\x05\u{13e}\u{f3e}\x0a\u{13e}\x05\
	\u{13e}\u{f40}\x0a\u{13e}\x03\u{13e}\x05\u{13e}\u{f43}\x0a\u{13e}\x03\u{13f}\
	\x03\u{13f}\x03\u{13f}\x03\u{13f}\x03\u{13f}\x03\u{13f}\x03\u{13f}\x03\u{13f}\
	\x03\u{13f}\x07\u{13f}\u{f4e}\x0a\u{13f}\x0c\u{13f}\x0e\u{13f}\u{f51}\x0b\
	\u{13f}\x05\u{13f}\u{f53}\x0a\u{13f}\x03\u{13f}\x05\u{13f}\u{f56}\x0a\u{13f}\
	\x03\u{13f}\x03\u{13f}\x03\u{13f}\x03\u{13f}\x03\u{13f}\x03\u{13f}\x03\u{13f}\
	\x03\u{13f}\x07\u{13f}\u{f60}\x0a\u{13f}\x0c\u{13f}\x0e\u{13f}\u{f63}\x0b\
	\u{13f}\x05\u{13f}\u{f65}\x0a\u{13f}\x03\u{13f}\x03\u{13f}\x03\u{13f}\x03\
	\u{13f}\x03\u{13f}\x05\u{13f}\u{f6c}\x0a\u{13f}\x03\u{13f}\x03\u{13f}\x03\
	\u{13f}\x03\u{13f}\x03\u{13f}\x07\u{13f}\u{f73}\x0a\u{13f}\x0c\u{13f}\x0e\
	\u{13f}\u{f76}\x0b\u{13f}\x03\u{13f}\x03\u{13f}\x05\u{13f}\u{f7a}\x0a\u{13f}\
	\x05\u{13f}\u{f7c}\x0a\u{13f}\x05\u{13f}\u{f7e}\x0a\u{13f}\x03\u{140}\x03\
	\u{140}\x03\u{141}\x03\u{141}\x03\u{141}\x03\u{141}\x03\u{141}\x03\u{141}\
	\x03\u{141}\x03\u{141}\x03\u{141}\x03\u{141}\x03\u{141}\x07\u{141}\u{f8d}\
	\x0a\u{141}\x0c\u{141}\x0e\u{141}\u{f90}\x0b\u{141}\x05\u{141}\u{f92}\x0a\
	\u{141}\x03\u{141}\x03\u{141}\x03\u{142}\x03\u{142}\x03\u{142}\x03\u{142}\
	\x03\u{142}\x05\u{142}\u{f9b}\x0a\u{142}\x03\u{142}\x03\u{142}\x03\u{143}\
	\x03\u{143}\x05\u{143}\u{fa1}\x0a\u{143}\x03\u{144}\x03\u{144}\x05\u{144}\
	\u{fa5}\x0a\u{144}\x03\u{144}\x05\u{144}\u{fa8}\x0a\u{144}\x03\u{144}\x05\
	\u{144}\u{fab}\x0a\u{144}\x03\u{144}\x05\u{144}\u{fae}\x0a\u{144}\x03\u{144}\
	\x05\u{144}\u{fb1}\x0a\u{144}\x03\u{145}\x03\u{145}\x03\u{145}\x03\u{145}\
	\x03\u{145}\x03\u{145}\x03\u{145}\x03\u{145}\x03\u{145}\x03\u{145}\x05\u{145}\
	\u{fbd}\x0a\u{145}\x03\u{146}\x03\u{146}\x05\u{146}\u{fc1}\x0a\u{146}\x03\
	\u{146}\x05\u{146}\u{fc4}\x0a\u{146}\x03\u{146}\x05\u{146}\u{fc7}\x0a\u{146}\
	\x03\u{147}\x03\u{147}\x03\u{147}\x03\u{147}\x03\u{147}\x05\u{147}\u{fce}\
	\x0a\u{147}\x03\u{147}\x05\u{147}\u{fd1}\x0a\u{147}\x03\u{148}\x03\u{148}\
	\x03\u{148}\x05\u{148}\u{fd6}\x0a\u{148}\x03\u{148}\x03\u{148}\x03\u{149}\
	\x03\u{149}\x03\u{149}\x03\u{149}\x05\u{149}\u{fde}\x0a\u{149}\x03\u{149}\
	\x03\u{149}\x03\u{14a}\x03\u{14a}\x05\u{14a}\u{fe4}\x0a\u{14a}\x03\u{14a}\
	\x03\u{14a}\x03\u{14a}\x05\u{14a}\u{fe9}\x0a\u{14a}\x03\u{14a}\x03\u{14a}\
	\x05\u{14a}\u{fed}\x0a\u{14a}\x03\u{14b}\x03\u{14b}\x03\u{14b}\x05\u{14b}\
	\u{ff2}\x0a\u{14b}\x03\u{14c}\x03\u{14c}\x03\u{14c}\x03\u{14c}\x03\u{14c}\
	\x05\u{14c}\u{ff9}\x0a\u{14c}\x03\u{14c}\x03\u{14c}\x03\u{14c}\x03\u{14c}\
	\x03\u{14c}\x03\u{14c}\x03\u{14c}\x03\u{14c}\x03\u{14c}\x03\u{14c}\x07\u{14c}\
	\u{1005}\x0a\u{14c}\x0c\u{14c}\x0e\u{14c}\u{1008}\x0b\u{14c}\x05\u{14c}\
	\u{100a}\x0a\u{14c}\x03\u{14c}\x03\u{14c}\x05\u{14c}\u{100e}\x0a\u{14c}\
	\x03\u{14d}\x03\u{14d}\x03\u{14d}\x03\u{14e}\x03\u{14e}\x03\u{14f}\x03\u{14f}\
	\x03\u{150}\x03\u{150}\x03\u{150}\x03\u{151}\x03\u{151}\x03\u{151}\x07\u{151}\
	\u{101d}\x0a\u{151}\x0c\u{151}\x0e\u{151}\u{1020}\x0b\u{151}\x03\u{151}\
	\x03\u{151}\x03\u{151}\x07\u{151}\u{1025}\x0a\u{151}\x0c\u{151}\x0e\u{151}\
	\u{1028}\x0b\u{151}\x05\u{151}\u{102a}\x0a\u{151}\x03\u{152}\x03\u{152}\
	\x03\u{153}\x03\u{153}\x03\u{153}\x03\u{153}\x03\u{154}\x03\u{154}\x03\u{154}\
	\x03\u{154}\x03\u{154}\x05\u{154}\u{1037}\x0a\u{154}\x03\u{154}\x03\u{154}\
	\x03\u{154}\x03\u{154}\x03\u{154}\x07\u{154}\u{103e}\x0a\u{154}\x0c\u{154}\
	\x0e\u{154}\u{1041}\x0b\u{154}\x05\u{154}\u{1043}\x0a\u{154}\x03\u{154}\
	\x03\u{154}\x03\u{155}\x03\u{155}\x05\u{155}\u{1049}\x0a\u{155}\x03\u{155}\
	\x05\u{155}\u{104c}\x0a\u{155}\x03\u{155}\x03\u{155}\x03\u{155}\x05\u{155}\
	\u{1051}\x0a\u{155}\x03\u{155}\x05\u{155}\u{1054}\x0a\u{155}\x03\u{156}\
	\x03\u{156}\x03\u{157}\x03\u{157}\x03\u{157}\x07\u{157}\u{105b}\x0a\u{157}\
	\x0c\u{157}\x0e\u{157}\u{105e}\x0b\u{157}\x03\u{158}\x03\u{158}\x03\u{158}\
	\x03\u{158}\x03\u{158}\x03\u{158}\x03\u{158}\x03\u{158}\x03\u{158}\x03\u{158}\
	\x03\u{158}\x05\u{158}\u{106b}\x0a\u{158}\x03\u{158}\x03\u{158}\x03\u{158}\
	\x03\u{158}\x05\u{158}\u{1071}\x0a\u{158}\x05\u{158}\u{1073}\x0a\u{158}\
	\x03\u{158}\x03\u{158}\x03\u{158}\x03\u{159}\x03\u{159}\x03\u{159}\x05\u{159}\
	\u{107b}\x0a\u{159}\x03\u{159}\x03\u{159}\x03\u{159}\x03\u{159}\x03\u{159}\
	\x03\u{159}\x07\u{159}\u{1083}\x0a\u{159}\x0c\u{159}\x0e\u{159}\u{1086}\
	\x0b\u{159}\x03\u{159}\x03\u{159}\x05\u{159}\u{108a}\x0a\u{159}\x05\u{159}\
	\u{108c}\x0a\u{159}\x03\u{15a}\x03\u{15a}\x03\u{15a}\x03\u{15a}\x03\u{15a}\
	\x03\u{15a}\x03\u{15a}\x03\u{15a}\x03\u{15a}\x03\u{15a}\x05\u{15a}\u{1098}\
	\x0a\u{15a}\x03\u{15a}\x03\u{15a}\x03\u{15a}\x03\u{15a}\x05\u{15a}\u{109e}\
	\x0a\u{15a}\x05\u{15a}\u{10a0}\x0a\u{15a}\x03\u{15a}\x03\u{15a}\x03\u{15a}\
	\x03\u{15b}\x03\u{15b}\x05\u{15b}\u{10a7}\x0a\u{15b}\x03\u{15c}\x03\u{15c}\
	\x03\u{15c}\x07\u{15c}\u{10ac}\x0a\u{15c}\x0c\u{15c}\x0e\u{15c}\u{10af}\
	\x0b\u{15c}\x03\u{15d}\x03\u{15d}\x03\u{15d}\x03\u{15d}\x07\u{15d}\u{10b5}\
	\x0a\u{15d}\x0c\u{15d}\x0e\u{15d}\u{10b8}\x0b\u{15d}\x03\u{15e}\x03\u{15e}\
	\x03\u{15e}\x03\u{15e}\x03\u{15f}\x03\u{15f}\x03\u{15f}\x05\u{15f}\u{10c1}\
	\x0a\u{15f}\x03\u{15f}\x05\u{15f}\u{10c4}\x0a\u{15f}\x03\u{15f}\x05\u{15f}\
	\u{10c7}\x0a\u{15f}\x03\u{15f}\x05\u{15f}\u{10ca}\x0a\u{15f}\x03\u{160}\
	\x03\u{160}\x05\u{160}\u{10ce}\x0a\u{160}\x03\u{161}\x03\u{161}\x03\u{161}\
	\x03\u{161}\x03\u{161}\x03\u{161}\x03\u{161}\x05\u{161}\u{10d7}\x0a\u{161}\
	\x03\u{162}\x03\u{162}\x03\u{162}\x03\u{162}\x03\u{162}\x03\u{162}\x03\u{162}\
	\x05\u{162}\u{10e0}\x0a\u{162}\x03\u{163}\x03\u{163}\x03\u{163}\x03\u{163}\
	\x03\u{163}\x03\u{163}\x05\u{163}\u{10e8}\x0a\u{163}\x03\u{164}\x03\u{164}\
	\x03\u{164}\x03\u{164}\x05\u{164}\u{10ee}\x0a\u{164}\x03\u{165}\x03\u{165}\
	\x03\u{165}\x03\u{165}\x03\u{166}\x03\u{166}\x03\u{166}\x05\u{166}\u{10f7}\
	\x0a\u{166}\x03\u{167}\x03\u{167}\x03\u{167}\x03\u{168}\x03\u{168}\x05\u{168}\
	\u{10fe}\x0a\u{168}\x03\u{168}\x03\u{168}\x03\u{168}\x03\u{168}\x07\u{168}\
	\u{1104}\x0a\u{168}\x0c\u{168}\x0e\u{168}\u{1107}\x0b\u{168}\x03\u{168}\
	\x03\u{168}\x03\u{169}\x03\u{169}\x03\u{169}\x03\u{169}\x03\u{169}\x05\u{169}\
	\u{1110}\x0a\u{169}\x03\u{169}\x03\u{169}\x03\u{169}\x03\u{169}\x03\u{169}\
	\x03\u{169}\x07\u{169}\u{1118}\x0a\u{169}\x0c\u{169}\x0e\u{169}\u{111b}\
	\x0b\u{169}\x03\u{169}\x03\u{169}\x05\u{169}\u{111f}\x0a\u{169}\x03\u{16a}\
	\x03\u{16a}\x05\u{16a}\u{1123}\x0a\u{16a}\x03\u{16b}\x03\u{16b}\x05\u{16b}\
	\u{1127}\x0a\u{16b}\x03\u{16b}\x03\u{16b}\x07\u{16b}\u{112b}\x0a\u{16b}\
	\x0c\u{16b}\x0e\u{16b}\u{112e}\x0b\u{16b}\x03\u{16b}\x03\u{16b}\x03\u{16c}\
	\x03\u{16c}\x03\u{16d}\x03\u{16d}\x03\u{16d}\x03\u{16e}\x03\u{16e}\x03\u{16e}\
	\x03\u{16f}\x03\u{16f}\x03\u{170}\x03\u{170}\x03\u{170}\x03\u{170}\x03\u{171}\
	\x03\u{171}\x05\u{171}\u{1142}\x0a\u{171}\x03\u{172}\x03\u{172}\x06\u{172}\
	\u{1146}\x0a\u{172}\x0d\u{172}\x0e\u{172}\u{1147}\x03\u{173}\x03\u{173}\
	\x05\u{173}\u{114c}\x0a\u{173}\x03\u{174}\x03\u{174}\x05\u{174}\u{1150}\
	\x0a\u{174}\x03\u{174}\x05\u{174}\u{1153}\x0a\u{174}\x03\u{174}\x03\u{174}\
	\x07\u{174}\u{1157}\x0a\u{174}\x0c\u{174}\x0e\u{174}\u{115a}\x0b\u{174}\
	\x03\u{175}\x03\u{175}\x05\u{175}\u{115e}\x0a\u{175}\x03\u{175}\x05\u{175}\
	\u{1161}\x0a\u{175}\x03\u{176}\x03\u{176}\x05\u{176}\u{1165}\x0a\u{176}\
	\x03\u{177}\x03\u{177}\x03\u{177}\x03\u{177}\x07\u{177}\u{116b}\x0a\u{177}\
	\x0c\u{177}\x0e\u{177}\u{116e}\x0b\u{177}\x03\u{177}\x03\u{177}\x03\u{178}\
	\x03\u{178}\x03\u{178}\x07\u{178}\u{1175}\x0a\u{178}\x0c\u{178}\x0e\u{178}\
	\u{1178}\x0b\u{178}\x03\u{179}\x03\u{179}\x03\u{179}\x03\u{179}\x03\u{179}\
	\x07\u{179}\u{117f}\x0a\u{179}\x0c\u{179}\x0e\u{179}\u{1182}\x0b\u{179}\
	\x03\u{17a}\x03\u{17a}\x03\u{17a}\x03\u{17a}\x03\u{17b}\x03\u{17b}\x03\u{17b}\
	\x03\u{17b}\x03\u{17c}\x03\u{17c}\x03\u{17c}\x03\u{17c}\x03\u{17d}\x03\u{17d}\
	\x03\u{17d}\x03\u{17d}\x05\u{17d}\u{1194}\x0a\u{17d}\x03\u{17e}\x03\u{17e}\
	\x03\u{17e}\x03\u{17e}\x03\u{17e}\x05\u{17e}\u{119b}\x0a\u{17e}\x03\u{17e}\
	\x05\u{17e}\u{119e}\x0a\u{17e}\x03\u{17e}\x03\u{17e}\x03\u{17e}\x03\u{17e}\
	\x03\u{17f}\x03\u{17f}\x03\u{17f}\x03\u{17f}\x03\u{17f}\x05\u{17f}\u{11a9}\
	\x0a\u{17f}\x03\u{17f}\x03\u{17f}\x03\u{17f}\x07\u{17f}\u{11ae}\x0a\u{17f}\
	\x0c\u{17f}\x0e\u{17f}\u{11b1}\x0b\u{17f}\x05\u{17f}\u{11b3}\x0a\u{17f}\
	\x05\u{17f}\u{11b5}\x0a\u{17f}\x03\u{17f}\x03\u{17f}\x03\u{17f}\x03\u{17f}\
	\x03\u{17f}\x03\u{17f}\x03\u{17f}\x03\u{17f}\x03\u{17f}\x05\u{17f}\u{11c0}\
	\x0a\u{17f}\x03\u{17f}\x03\u{17f}\x03\u{17f}\x03\u{17f}\x03\u{17f}\x03\u{17f}\
	\x03\u{17f}\x03\u{17f}\x05\u{17f}\u{11ca}\x0a\u{17f}\x05\u{17f}\u{11cc}\
	\x0a\u{17f}\x03\u{180}\x03\u{180}\x03\u{180}\x03\u{180}\x05\u{180}\u{11d2}\
	\x0a\u{180}\x03\u{181}\x03\u{181}\x05\u{181}\u{11d6}\x0a\u{181}\x03\u{182}\
	\x03\u{182}\x03\u{182}\x03\u{182}\x03\u{182}\x03\u{182}\x03\u{182}\x05\u{182}\
	\u{11df}\x0a\u{182}\x03\u{182}\x03\u{182}\x03\u{183}\x03\u{183}\x03\u{183}\
	\x03\u{183}\x03\u{183}\x03\u{183}\x03\u{183}\x06\u{183}\u{11ea}\x0a\u{183}\
	\x0d\u{183}\x0e\u{183}\u{11eb}\x03\u{183}\x03\u{183}\x05\u{183}\u{11f0}\
	\x0a\u{183}\x03\u{183}\x03\u{183}\x03\u{184}\x03\u{184}\x03\u{184}\x03\u{184}\
	\x03\u{184}\x03\u{184}\x06\u{184}\u{11fa}\x0a\u{184}\x0d\u{184}\x0e\u{184}\
	\u{11fb}\x03\u{184}\x03\u{184}\x05\u{184}\u{1200}\x0a\u{184}\x03\u{184}\
	\x03\u{184}\x03\u{185}\x03\u{185}\x03\u{185}\x03\u{185}\x03\u{185}\x05\u{185}\
	\u{1209}\x0a\u{185}\x03\u{185}\x03\u{185}\x03\u{186}\x03\u{186}\x03\u{187}\
	\x03\u{187}\x03\u{187}\x03\u{187}\x03\u{187}\x03\u{187}\x03\u{187}\x03\u{188}\
	\x03\u{188}\x03\u{189}\x03\u{189}\x03\u{189}\x03\u{189}\x03\u{189}\x03\u{189}\
	\x03\u{189}\x03\u{189}\x03\u{189}\x03\u{189}\x03\u{189}\x03\u{189}\x03\u{189}\
	\x05\u{189}\u{1225}\x0a\u{189}\x03\u{18a}\x03\u{18a}\x03\u{18b}\x03\u{18b}\
	\x03\u{18c}\x03\u{18c}\x06\u{18c}\u{122d}\x0a\u{18c}\x0d\u{18c}\x0e\u{18c}\
	\u{122e}\x03\u{18d}\x03\u{18d}\x03\u{18d}\x03\u{18e}\x03\u{18e}\x03\u{18e}\
	\x05\u{18e}\u{1237}\x0a\u{18e}\x03\u{18f}\x03\u{18f}\x03\u{18f}\x05\u{18f}\
	\u{123c}\x0a\u{18f}\x03\u{190}\x03\u{190}\x03\u{190}\x03\u{191}\x03\u{191}\
	\x03\u{192}\x03\u{192}\x03\u{192}\x03\u{193}\x03\u{193}\x03\u{193}\x03\u{193}\
	\x03\u{193}\x03\u{193}\x03\u{193}\x03\u{193}\x03\u{193}\x03\u{193}\x03\u{193}\
	\x05\u{193}\u{1251}\x0a\u{193}\x03\u{193}\x03\u{193}\x05\u{193}\u{1255}\
	\x0a\u{193}\x03\u{194}\x03\u{194}\x03\u{194}\x03\u{194}\x03\u{194}\x03\u{194}\
	\x03\u{194}\x03\u{194}\x03\u{194}\x03\u{194}\x03\u{194}\x03\u{194}\x05\u{194}\
	\u{1263}\x0a\u{194}\x03\u{195}\x03\u{195}\x03\u{196}\x03\u{196}\x03\u{196}\
	\x03\u{196}\x03\u{196}\x03\u{196}\x03\u{196}\x03\u{196}\x03\u{196}\x03\u{196}\
	\x03\u{196}\x05\u{196}\u{1272}\x0a\u{196}\x03\u{197}\x03\u{197}\x03\u{197}\
	\x03\u{197}\x03\u{197}\x03\u{197}\x03\u{197}\x07\u{197}\u{127b}\x0a\u{197}\
	\x0c\u{197}\x0e\u{197}\u{127e}\x0b\u{197}\x03\u{198}\x03\u{198}\x03\u{199}\
	\x07\u{199}\u{1283}\x0a\u{199}\x0c\u{199}\x0e\u{199}\u{1286}\x0b\u{199}\
	\x03\u{199}\x03\u{199}\x03\u{19a}\x03\u{19a}\x03\u{19b}\x03\u{19b}\x03\u{19b}\
	\x03\u{19b}\x07\u{19b}\u{1290}\x0a\u{19b}\x0c\u{19b}\x0e\u{19b}\u{1293}\
	\x0b\u{19b}\x03\u{19c}\x03\u{19c}\x03\u{19d}\x03\u{19d}\x03\u{19d}\x03\u{19d}\
	\x07\u{19d}\u{129b}\x0a\u{19d}\x0c\u{19d}\x0e\u{19d}\u{129e}\x0b\u{19d}\
	\x03\u{19e}\x03\u{19e}\x03\u{19f}\x03\u{19f}\x03\u{19f}\x03\u{19f}\x07\u{19f}\
	\u{12a6}\x0a\u{19f}\x0c\u{19f}\x0e\u{19f}\u{12a9}\x0b\u{19f}\x03\u{1a0}\
	\x03\u{1a0}\x03\u{1a1}\x03\u{1a1}\x03\u{1a1}\x03\u{1a1}\x07\u{1a1}\u{12b1}\
	\x0a\u{1a1}\x0c\u{1a1}\x0e\u{1a1}\u{12b4}\x0b\u{1a1}\x03\u{1a2}\x03\u{1a2}\
	\x03\u{1a3}\x03\u{1a3}\x03\u{1a3}\x03\u{1a3}\x07\u{1a3}\u{12bc}\x0a\u{1a3}\
	\x0c\u{1a3}\x0e\u{1a3}\u{12bf}\x0b\u{1a3}\x03\u{1a4}\x03\u{1a4}\x03\u{1a5}\
	\x03\u{1a5}\x03\u{1a5}\x03\u{1a5}\x07\u{1a5}\u{12c7}\x0a\u{1a5}\x0c\u{1a5}\
	\x0e\u{1a5}\u{12ca}\x0b\u{1a5}\x03\u{1a6}\x03\u{1a6}\x03\u{1a7}\x03\u{1a7}\
	\x03\u{1a7}\x03\u{1a7}\x03\u{1a7}\x05\u{1a7}\u{12d3}\x0a\u{1a7}\x03\u{1a8}\
	\x03\u{1a8}\x03\u{1a8}\x03\u{1a8}\x03\u{1a9}\x03\u{1a9}\x03\u{1a9}\x05\u{1a9}\
	\u{12dc}\x0a\u{1a9}\x03\u{1aa}\x03\u{1aa}\x05\u{1aa}\u{12e0}\x0a\u{1aa}\
	\x03\u{1ab}\x03\u{1ab}\x03\u{1ab}\x03\u{1ab}\x03\u{1ab}\x03\u{1ab}\x05\u{1ab}\
	\u{12e8}\x0a\u{1ab}\x03\u{1ac}\x03\u{1ac}\x03\u{1ac}\x03\u{1ac}\x03\u{1ac}\
	\x03\u{1ac}\x03\u{1ac}\x03\u{1ac}\x03\u{1ac}\x03\u{1ac}\x03\u{1ac}\x05\u{1ac}\
	\u{12f5}\x0a\u{1ac}\x03\u{1ad}\x03\u{1ad}\x03\u{1ad}\x03\u{1ad}\x03\u{1ae}\
	\x03\u{1ae}\x03\u{1af}\x03\u{1af}\x05\u{1af}\u{12ff}\x0a\u{1af}\x03\u{1b0}\
	\x03\u{1b0}\x03\u{1b0}\x03\u{1b0}\x05\u{1b0}\u{1305}\x0a\u{1b0}\x03\u{1b1}\
	\x03\u{1b1}\x03\u{1b1}\x03\u{1b1}\x03\u{1b2}\x03\u{1b2}\x03\u{1b2}\x03\u{1b2}\
	\x03\u{1b2}\x03\u{1b2}\x03\u{1b2}\x05\u{1b2}\u{1312}\x0a\u{1b2}\x03\u{1b3}\
	\x03\u{1b3}\x03\u{1b3}\x03\u{1b3}\x03\u{1b3}\x03\u{1b3}\x03\u{1b3}\x07\u{1b3}\
	\u{131b}\x0a\u{1b3}\x0c\u{1b3}\x0e\u{1b3}\u{131e}\x0b\u{1b3}\x03\u{1b4}\
	\x03\u{1b4}\x03\u{1b4}\x03\u{1b4}\x03\u{1b4}\x03\u{1b4}\x03\u{1b4}\x03\u{1b4}\
	\x03\u{1b4}\x03\u{1b4}\x03\u{1b4}\x03\u{1b4}\x05\u{1b4}\u{132c}\x0a\u{1b4}\
	\x03\u{1b5}\x03\u{1b5}\x03\u{1b5}\x05\u{1b5}\u{1331}\x0a\u{1b5}\x03\u{1b6}\
	\x03\u{1b6}\x03\u{1b7}\x07\u{1b7}\u{1336}\x0a\u{1b7}\x0c\u{1b7}\x0e\u{1b7}\
	\u{1339}\x0b\u{1b7}\x03\u{1b7}\x03\u{1b7}\x03\u{1b8}\x03\u{1b8}\x03\u{1b9}\
	\x03\u{1b9}\x03\u{1b9}\x03\u{1b9}\x07\u{1b9}\u{1343}\x0a\u{1b9}\x0c\u{1b9}\
	\x0e\u{1b9}\u{1346}\x0b\u{1b9}\x03\u{1ba}\x03\u{1ba}\x03\u{1bb}\x03\u{1bb}\
	\x03\u{1bb}\x03\u{1bb}\x07\u{1bb}\u{134e}\x0a\u{1bb}\x0c\u{1bb}\x0e\u{1bb}\
	\u{1351}\x0b\u{1bb}\x03\u{1bc}\x03\u{1bc}\x03\u{1bd}\x03\u{1bd}\x03\u{1be}\
	\x03\u{1be}\x05\u{1be}\u{1359}\x0a\u{1be}\x03\u{1bf}\x03\u{1bf}\x03\u{1bf}\
	\x03\u{1bf}\x03\u{1bf}\x07\u{1bf}\u{1360}\x0a\u{1bf}\x0c\u{1bf}\x0e\u{1bf}\
	\u{1363}\x0b\u{1bf}\x03\u{1bf}\x03\u{1bf}\x03\u{1c0}\x03\u{1c0}\x03\u{1c0}\
	\x05\u{1c0}\u{136a}\x0a\u{1c0}\x03\u{1c1}\x03\u{1c1}\x03\u{1c1}\x03\u{1c1}\
	\x07\u{1c1}\u{1370}\x0a\u{1c1}\x0c\u{1c1}\x0e\u{1c1}\u{1373}\x0b\u{1c1}\
	\x03\u{1c1}\x03\u{1c1}\x03\u{1c2}\x03\u{1c2}\x03\u{1c2}\x03\u{1c2}\x03\u{1c3}\
	\x03\u{1c3}\x05\u{1c3}\u{137d}\x0a\u{1c3}\x03\u{1c4}\x03\u{1c4}\x03\u{1c5}\
	\x03\u{1c5}\x03\u{1c6}\x03\u{1c6}\x03\u{1c6}\x05\u{1c6}\u{1386}\x0a\u{1c6}\
	\x03\u{1c7}\x03\u{1c7}\x05\u{1c7}\u{138a}\x0a\u{1c7}\x03\u{1c8}\x03\u{1c8}\
	\x03\u{1c8}\x05\u{1c8}\u{138f}\x0a\u{1c8}\x03\u{1c9}\x03\u{1c9}\x03\u{1ca}\
	\x03\u{1ca}\x03\u{1cb}\x03\u{1cb}\x03\u{1cc}\x03\u{1cc}\x03\u{1cc}\x03\u{1cd}\
	\x03\u{1cd}\x03\u{1cd}\x07\u{1cd}\u{139d}\x0a\u{1cd}\x0c\u{1cd}\x0e\u{1cd}\
	\u{13a0}\x0b\u{1cd}\x03\u{1ce}\x03\u{1ce}\x03\u{1ce}\x03\u{1ce}\x03\u{1ce}\
	\x05\u{1ce}\u{13a7}\x0a\u{1ce}\x03\u{1cf}\x03\u{1cf}\x03\u{1d0}\x03\u{1d0}\
	\x03\u{1d0}\x07\u{1d0}\u{13ae}\x0a\u{1d0}\x0c\u{1d0}\x0e\u{1d0}\u{13b1}\
	\x0b\u{1d0}\x03\u{1d1}\x03\u{1d1}\x03\u{1d2}\x03\u{1d2}\x03\u{1d2}\x03\u{1d2}\
	\x03\u{1d2}\x03\u{1d3}\x03\u{1d3}\x03\u{1d3}\x03\u{1d3}\x03\u{1d3}\x03\u{1d4}\
	\x03\u{1d4}\x03\u{1d4}\x07\u{1d4}\u{13c2}\x0a\u{1d4}\x0c\u{1d4}\x0e\u{1d4}\
	\u{13c5}\x0b\u{1d4}\x03\u{1d5}\x03\u{1d5}\x03\u{1d5}\x03\u{1d5}\x03\u{1d5}\
	\x03\u{1d5}\x03\u{1d5}\x03\u{1d5}\x03\u{1d5}\x03\u{1d5}\x03\u{1d5}\x03\u{1d5}\
	\x03\u{1d5}\x03\u{1d5}\x05\u{1d5}\u{13d5}\x0a\u{1d5}\x03\u{1d6}\x03\u{1d6}\
	\x03\u{1d6}\x03\u{1d6}\x03\u{1d6}\x03\u{1d6}\x03\u{1d6}\x05\u{1d6}\u{13de}\
	\x0a\u{1d6}\x03\u{1d7}\x03\u{1d7}\x03\u{1d7}\x07\u{1d7}\u{13e3}\x0a\u{1d7}\
	\x0c\u{1d7}\x0e\u{1d7}\u{13e6}\x0b\u{1d7}\x03\u{1d8}\x03\u{1d8}\x03\u{1d8}\
	\x05\u{1d8}\u{13eb}\x0a\u{1d8}\x03\u{1d9}\x03\u{1d9}\x03\u{1d9}\x07\u{1d9}\
	\u{13f0}\x0a\u{1d9}\x0c\u{1d9}\x0e\u{1d9}\u{13f3}\x0b\u{1d9}\x03\u{1da}\
	\x03\u{1da}\x03\u{1da}\x03\u{1da}\x05\u{1da}\u{13f9}\x0a\u{1da}\x03\u{1da}\
	\x03\u{1da}\x03\u{1da}\x03\u{1da}\x03\u{1da}\x03\u{1da}\x03\u{1da}\x05\u{1da}\
	\u{1402}\x0a\u{1da}\x05\u{1da}\u{1404}\x0a\u{1da}\x03\u{1db}\x03\u{1db}\
	\x03\u{1db}\x03\u{1dc}\x03\u{1dc}\x05\u{1dc}\u{140b}\x0a\u{1dc}\x03\u{1dd}\
	\x03\u{1dd}\x03\u{1de}\x03\u{1de}\x03\u{1df}\x03\u{1df}\x03\u{1e0}\x03\u{1e0}\
	\x03\u{1e0}\x03\u{1e0}\x03\u{1e0}\x03\u{1e0}\x03\u{1e0}\x03\u{1e0}\x03\u{1e0}\
	\x03\u{1e0}\x03\u{1e0}\x03\u{1e0}\x03\u{1e0}\x03\u{1e0}\x03\u{1e0}\x05\u{1e0}\
	\u{1422}\x0a\u{1e0}\x03\u{1e0}\x03\u{1e0}\x05\u{1e0}\u{1426}\x0a\u{1e0}\
	\x05\u{1e0}\u{1428}\x0a\u{1e0}\x03\u{1e1}\x03\u{1e1}\x03\u{1e1}\x03\u{1e1}\
	\x03\u{1e2}\x03\u{1e2}\x03\u{1e2}\x03\u{1e2}\x03\u{1e2}\x03\u{1e2}\x03\u{1e2}\
	\x03\u{1e2}\x03\u{1e2}\x03\u{1e2}\x03\u{1e2}\x03\u{1e2}\x05\u{1e2}\u{143a}\
	\x0a\u{1e2}\x03\u{1e3}\x03\u{1e3}\x03\u{1e3}\x03\u{1e3}\x05\u{1e3}\u{1440}\
	\x0a\u{1e3}\x03\u{1e3}\x03\u{1e3}\x03\u{1e4}\x03\u{1e4}\x03\u{1e4}\x07\u{1e4}\
	\u{1447}\x0a\u{1e4}\x0c\u{1e4}\x0e\u{1e4}\u{144a}\x0b\u{1e4}\x03\u{1e5}\
	\x03\u{1e5}\x03\u{1e6}\x03\u{1e6}\x03\u{1e6}\x03\u{1e7}\x03\u{1e7}\x03\u{1e7}\
	\x07\u{1e7}\u{1454}\x0a\u{1e7}\x0c\u{1e7}\x0e\u{1e7}\u{1457}\x0b\u{1e7}\
	\x03\u{1e8}\x03\u{1e8}\x03\u{1e8}\x07\u{1e8}\u{145c}\x0a\u{1e8}\x0c\u{1e8}\
	\x0e\u{1e8}\u{145f}\x0b\u{1e8}\x03\u{1e9}\x03\u{1e9}\x03\u{1e9}\x03\u{1e9}\
	\x03\u{1ea}\x03\u{1ea}\x03\u{1eb}\x03\u{1eb}\x03\u{1ec}\x03\u{1ec}\x03\u{1ec}\
	\x03\u{1ec}\x05\u{1ec}\u{146d}\x0a\u{1ec}\x03\u{1ed}\x03\u{1ed}\x03\u{1ed}\
	\x03\u{1ee}\x03\u{1ee}\x03\u{1ee}\x03\u{1ee}\x03\u{1ee}\x03\u{1ee}\x03\u{1ee}\
	\x03\u{1ee}\x03\u{1ee}\x03\u{1ee}\x03\u{1ef}\x03\u{1ef}\x03\u{1ef}\x03\u{1ef}\
	\x03\u{1ef}\x03\u{1ef}\x03\u{1ef}\x03\u{1ef}\x03\u{1ef}\x03\u{1ef}\x03\u{1ef}\
	\x03\u{1ef}\x03\u{1ef}\x03\u{1ef}\x05\u{1ef}\u{148a}\x0a\u{1ef}\x03\u{1ef}\
	\x03\u{1ef}\x03\u{1ef}\x05\u{1ef}\u{148f}\x0a\u{1ef}\x05\u{1ef}\u{1491}\
	\x0a\u{1ef}\x03\u{1f0}\x03\u{1f0}\x03\u{1f0}\x03\u{1f0}\x03\u{1f0}\x03\u{1f0}\
	\x03\u{1f1}\x03\u{1f1}\x03\u{1f1}\x03\u{1f1}\x03\u{1f1}\x03\u{1f1}\x03\u{1f1}\
	\x03\u{1f1}\x03\u{1f1}\x03\u{1f1}\x03\u{1f1}\x03\u{1f1}\x05\u{1f1}\u{14a5}\
	\x0a\u{1f1}\x03\u{1f2}\x03\u{1f2}\x03\u{1f2}\x07\u{1f2}\u{14aa}\x0a\u{1f2}\
	\x0c\u{1f2}\x0e\u{1f2}\u{14ad}\x0b\u{1f2}\x03\u{1f3}\x03\u{1f3}\x03\u{1f3}\
	\x03\u{1f3}\x03\u{1f3}\x03\u{1f3}\x03\u{1f3}\x03\u{1f3}\x03\u{1f4}\x03\u{1f4}\
	\x03\u{1f4}\x03\u{1f4}\x03\u{1f4}\x03\u{1f4}\x03\u{1f4}\x03\u{1f4}\x03\u{1f4}\
	\x03\u{1f4}\x03\u{1f4}\x03\u{1f4}\x05\u{1f4}\u{14c3}\x0a\u{1f4}\x03\u{1f5}\
	\x03\u{1f5}\x03\u{1f5}\x03\u{1f5}\x03\u{1f5}\x03\u{1f5}\x03\u{1f6}\x03\u{1f6}\
	\x03\u{1f6}\x03\u{1f6}\x03\u{1f6}\x03\u{1f6}\x03\u{1f6}\x03\u{1f6}\x03\u{1f6}\
	\x05\u{1f6}\u{14d4}\x0a\u{1f6}\x03\u{1f6}\x03\u{1f6}\x03\u{1f6}\x05\u{1f6}\
	\u{14d9}\x0a\u{1f6}\x03\u{1f7}\x03\u{1f7}\x03\u{1f7}\x03\u{1f7}\x03\u{1f7}\
	\x03\u{1f7}\x03\u{1f7}\x03\u{1f7}\x03\u{1f7}\x05\u{1f7}\u{14e4}\x0a\u{1f7}\
	\x03\u{1f7}\x03\u{1f7}\x03\u{1f7}\x05\u{1f7}\u{14e9}\x0a\u{1f7}\x03\u{1f8}\
	\x03\u{1f8}\x03\u{1f8}\x03\u{1f8}\x03\u{1f8}\x03\u{1f8}\x03\u{1f8}\x03\u{1f8}\
	\x02\x02\u{1f9}\x02\x04\x06\x08\x0a\x0c\x0e\x10\x12\x14\x16\x18\x1a\x1c\
	\x1e\x20\x22\x24\x26\x28\x2a\x2c\x2e\x30\x32\x34\x36\x38\x3a\x3c\x3e\x40\
	\x42\x44\x46\x48\x4a\x4c\x4e\x50\x52\x54\x56\x58\x5a\x5c\x5e\x60\x62\x64\
	\x66\x68\x6a\x6c\x6e\x70\x72\x74\x76\x78\x7a\x7c\x7e\u{80}\u{82}\u{84}\u{86}\
	\u{88}\u{8a}\u{8c}\u{8e}\u{90}\u{92}\u{94}\u{96}\u{98}\u{9a}\u{9c}\u{9e}\
	\u{a0}\u{a2}\u{a4}\u{a6}\u{a8}\u{aa}\u{ac}\u{ae}\u{b0}\u{b2}\u{b4}\u{b6}\
	\u{b8}\u{ba}\u{bc}\u{be}\u{c0}\u{c2}\u{c4}\u{c6}\u{c8}\u{ca}\u{cc}\u{ce}\
	\u{d0}\u{d2}\u{d4}\u{d6}\u{d8}\u{da}\u{dc}\u{de}\u{e0}\u{e2}\u{e4}\u{e6}\
	\u{e8}\u{ea}\u{ec}\u{ee}\u{f0}\u{f2}\u{f4}\u{f6}\u{f8}\u{fa}\u{fc}\u{fe}\
	\u{100}\u{102}\u{104}\u{106}\u{108}\u{10a}\u{10c}\u{10e}\u{110}\u{112}\u{114}\
	\u{116}\u{118}\u{11a}\u{11c}\u{11e}\u{120}\u{122}\u{124}\u{126}\u{128}\u{12a}\
	\u{12c}\u{12e}\u{130}\u{132}\u{134}\u{136}\u{138}\u{13a}\u{13c}\u{13e}\u{140}\
	\u{142}\u{144}\u{146}\u{148}\u{14a}\u{14c}\u{14e}\u{150}\u{152}\u{154}\u{156}\
	\u{158}\u{15a}\u{15c}\u{15e}\u{160}\u{162}\u{164}\u{166}\u{168}\u{16a}\u{16c}\
	\u{16e}\u{170}\u{172}\u{174}\u{176}\u{178}\u{17a}\u{17c}\u{17e}\u{180}\u{182}\
	\u{184}\u{186}\u{188}\u{18a}\u{18c}\u{18e}\u{190}\u{192}\u{194}\u{196}\u{198}\
	\u{19a}\u{19c}\u{19e}\u{1a0}\u{1a2}\u{1a4}\u{1a6}\u{1a8}\u{1aa}\u{1ac}\u{1ae}\
	\u{1b0}\u{1b2}\u{1b4}\u{1b6}\u{1b8}\u{1ba}\u{1bc}\u{1be}\u{1c0}\u{1c2}\u{1c4}\
	\u{1c6}\u{1c8}\u{1ca}\u{1cc}\u{1ce}\u{1d0}\u{1d2}\u{1d4}\u{1d6}\u{1d8}\u{1da}\
	\u{1dc}\u{1de}\u{1e0}\u{1e2}\u{1e4}\u{1e6}\u{1e8}\u{1ea}\u{1ec}\u{1ee}\u{1f0}\
	\u{1f2}\u{1f4}\u{1f6}\u{1f8}\u{1fa}\u{1fc}\u{1fe}\u{200}\u{202}\u{204}\u{206}\
	\u{208}\u{20a}\u{20c}\u{20e}\u{210}\u{212}\u{214}\u{216}\u{218}\u{21a}\u{21c}\
	\u{21e}\u{220}\u{222}\u{224}\u{226}\u{228}\u{22a}\u{22c}\u{22e}\u{230}\u{232}\
	\u{234}\u{236}\u{238}\u{23a}\u{23c}\u{23e}\u{240}\u{242}\u{244}\u{246}\u{248}\
	\u{24a}\u{24c}\u{24e}\u{250}\u{252}\u{254}\u{256}\u{258}\u{25a}\u{25c}\u{25e}\
	\u{260}\u{262}\u{264}\u{266}\u{268}\u{26a}\u{26c}\u{26e}\u{270}\u{272}\u{274}\
	\u{276}\u{278}\u{27a}\u{27c}\u{27e}\u{280}\u{282}\u{284}\u{286}\u{288}\u{28a}\
	\u{28c}\u{28e}\u{290}\u{292}\u{294}\u{296}\u{298}\u{29a}\u{29c}\u{29e}\u{2a0}\
	\u{2a2}\u{2a4}\u{2a6}\u{2a8}\u{2aa}\u{2ac}\u{2ae}\u{2b0}\u{2b2}\u{2b4}\u{2b6}\
	\u{2b8}\u{2ba}\u{2bc}\u{2be}\u{2c0}\u{2c2}\u{2c4}\u{2c6}\u{2c8}\u{2ca}\u{2cc}\
	\u{2ce}\u{2d0}\u{2d2}\u{2d4}\u{2d6}\u{2d8}\u{2da}\u{2dc}\u{2de}\u{2e0}\u{2e2}\
	\u{2e4}\u{2e6}\u{2e8}\u{2ea}\u{2ec}\u{2ee}\u{2f0}\u{2f2}\u{2f4}\u{2f6}\u{2f8}\
	\u{2fa}\u{2fc}\u{2fe}\u{300}\u{302}\u{304}\u{306}\u{308}\u{30a}\u{30c}\u{30e}\
	\u{310}\u{312}\u{314}\u{316}\u{318}\u{31a}\u{31c}\u{31e}\u{320}\u{322}\u{324}\
	\u{326}\u{328}\u{32a}\u{32c}\u{32e}\u{330}\u{332}\u{334}\u{336}\u{338}\u{33a}\
	\u{33c}\u{33e}\u{340}\u{342}\u{344}\u{346}\u{348}\u{34a}\u{34c}\u{34e}\u{350}\
	\u{352}\u{354}\u{356}\u{358}\u{35a}\u{35c}\u{35e}\u{360}\u{362}\u{364}\u{366}\
	\u{368}\u{36a}\u{36c}\u{36e}\u{370}\u{372}\u{374}\u{376}\u{378}\u{37a}\u{37c}\
	\u{37e}\u{380}\u{382}\u{384}\u{386}\u{388}\u{38a}\u{38c}\u{38e}\u{390}\u{392}\
	\u{394}\u{396}\u{398}\u{39a}\u{39c}\u{39e}\u{3a0}\u{3a2}\u{3a4}\u{3a6}\u{3a8}\
	\u{3aa}\u{3ac}\u{3ae}\u{3b0}\u{3b2}\u{3b4}\u{3b6}\u{3b8}\u{3ba}\u{3bc}\u{3be}\
	\u{3c0}\u{3c2}\u{3c4}\u{3c6}\u{3c8}\u{3ca}\u{3cc}\u{3ce}\u{3d0}\u{3d2}\u{3d4}\
	\u{3d6}\u{3d8}\u{3da}\u{3dc}\u{3de}\u{3e0}\u{3e2}\u{3e4}\u{3e6}\u{3e8}\u{3ea}\
	\u{3ec}\u{3ee}\x02\x32\x04\x02\x3b\x3b\u{a6}\u{a6}\x06\x02\x5a\x5a\x75\x75\
	\u{d9}\u{d9}\u{13b}\u{13b}\x04\x02\x24\x24\u{111}\u{111}\x03\x02\x58\x59\
	\x04\x02\u{87}\u{87}\u{95}\u{95}\x04\x02\x45\x45\u{11e}\u{11e}\x04\x02\x46\
	\x46\u{11f}\u{11f}\x04\x02\x6e\x6e\u{129}\u{129}\x0c\x02\x09\x09\x0b\x0b\
	\x3c\x3c\x55\x55\x63\x63\u{9c}\u{9c}\u{b7}\u{b7}\u{121}\u{121}\u{12b}\u{12b}\
	\u{163}\u{163}\x05\x02\x06\x06\x63\x63\u{13c}\u{13c}\x05\x02\x11\x11\x7c\
	\x7c\u{a4}\u{a4}\x03\x02\u{89}\u{8a}\x06\x02\x4b\x4b\u{90}\u{90}\u{c8}\u{c8}\
	\u{17d}\u{17d}\x04\x02\x20\x20\u{155}\u{155}\x04\x02\x5d\x5d\x67\x67\x04\
	\x02\u{d0}\u{d0}\u{16b}\u{16b}\x04\x02\u{cd}\u{cd}\u{107}\u{107}\x04\x02\
	\x14\x14\x58\x58\x04\x02\x7e\x7e\u{ab}\u{ab}\x04\x02\x29\x29\u{16e}\u{16e}\
	\x06\x02\x6c\x6c\u{9e}\u{9e}\u{c6}\u{c6}\u{15a}\u{15a}\x04\x02\x09\x09\x5e\
	\x5e\x04\x02\u{d8}\u{d8}\u{17c}\u{17c}\x04\x02\u{b6}\u{b6}\u{bd}\u{bd}\x04\
	\x02\x2c\x2c\u{131}\u{131}\x04\x02\u{19d}\u{19d}\u{1a2}\u{1a2}\x04\x02\u{88}\
	\u{88}\u{114}\u{114}\x05\x02\x0e\x0e\u{de}\u{de}\u{122}\u{122}\x04\x02\u{e8}\
	\u{e8}\u{11b}\u{11b}\x04\x02\u{bf}\u{bf}\u{103}\u{103}\x04\x02\u{158}\u{158}\
	\u{1a2}\u{1a2}\x04\x02\u{81}\u{81}\u{ee}\u{ee}\x09\x02\x4b\x4b\u{90}\u{90}\
	\u{c7}\u{c8}\u{f8}\u{f8}\u{120}\u{120}\u{173}\u{173}\u{17d}\u{17d}\x04\x02\
	\u{191}\u{192}\u{197}\u{197}\x04\x02\u{190}\u{190}\u{193}\u{195}\x03\x02\
	\u{191}\u{192}\x05\x02\u{b1}\u{b1}\u{105}\u{105}\u{115}\u{115}\x04\x02\x09\
	\x09\x0f\x0f\x05\x02\x09\x09\x0f\x0f\u{12f}\u{12f}\x04\x02\x79\x79\u{154}\
	\u{154}\x04\x02\u{189}\u{189}\u{18b}\u{18f}\x19\x02\x0d\x0d\x12\x12\x1b\
	\x1e\x25\x25\x62\x62\x7f\u{80}\u{92}\u{92}\u{95}\u{95}\u{9d}\u{9d}\u{b1}\
	\u{b1}\u{bf}\u{bf}\u{cf}\u{cf}\u{db}\u{db}\u{ff}\u{ff}\u{105}\u{105}\u{115}\
	\u{115}\u{12d}\u{12d}\u{139}\u{13a}\u{14a}\u{14a}\u{15b}\u{15b}\u{174}\u{174}\
	\u{189}\u{198}\u{19a}\u{19a}\x57\x02\x03\x08\x0a\x0a\x0c\x0c\x11\x11\x14\
	\x16\x18\x1a\x20\x21\x23\x24\x27\x28\x2a\x2e\x30\x31\x33\x34\x36\x37\x3a\
	\x3b\x3d\x3d\x44\x44\x46\x46\x4a\x4e\x50\x50\x52\x54\x56\x58\x5a\x5d\x5f\
	\x61\x64\x65\x67\x67\x69\x6b\x6e\x70\x72\x75\x7b\x7e\u{85}\u{86}\u{8a}\u{8a}\
	\u{8f}\u{91}\u{93}\u{93}\u{96}\u{97}\u{99}\u{9b}\u{a2}\u{a4}\u{a6}\u{ab}\
	\u{b0}\u{b0}\u{b2}\u{b4}\u{b6}\u{ba}\u{bc}\u{be}\u{c0}\u{c3}\u{c5}\u{c5}\
	\u{c7}\u{c8}\u{ca}\u{cb}\u{cd}\u{ce}\u{d0}\u{d1}\u{d3}\u{d3}\u{d5}\u{d6}\
	\u{d9}\u{da}\u{df}\u{e0}\u{e2}\u{e3}\u{e5}\u{e7}\u{ea}\u{ed}\u{f3}\u{f3}\
	\u{f5}\u{f6}\u{f8}\u{fa}\u{fc}\u{fd}\u{100}\u{102}\u{106}\u{111}\u{113}\
	\u{113}\u{116}\u{117}\u{11c}\u{120}\u{122}\u{125}\u{127}\u{12c}\u{12e}\u{12e}\
	\u{130}\u{133}\u{135}\u{13b}\u{13d}\u{13e}\u{140}\u{140}\u{142}\u{144}\u{149}\
	\u{14a}\u{14c}\u{14c}\u{14e}\u{150}\u{153}\u{153}\u{156}\u{157}\u{159}\u{159}\
	\u{15b}\u{15b}\u{15e}\u{162}\u{164}\u{166}\u{169}\u{16b}\u{16d}\u{16d}\u{16f}\
	\u{173}\u{176}\u{176}\u{179}\u{17e}\x0f\x02\x12\x12\x1c\x1e\x41\x42\x49\
	\x49\x62\x62\x7f\x7f\u{8d}\u{8d}\u{92}\u{92}\u{9d}\u{9d}\u{bf}\u{bf}\u{ff}\
	\u{ff}\u{12d}\u{12d}\u{147}\u{147}\x06\x02\u{c0}\u{c0}\u{e9}\u{e9}\u{122}\
	\u{122}\u{138}\u{138}\x04\x02\u{cc}\u{cc}\u{1a2}\u{1a3}\x04\x02\x06\x06\
	\x63\x63\x05\x02\x10\x10\u{8c}\u{8c}\u{167}\u{167}\x02\u{166d}\x02\u{3f3}\
	\x03\x02\x02\x02\x04\u{3fa}\x03\x02\x02\x02\x06\u{3ff}\x03\x02\x02\x02\x08\
	\u{421}\x03\x02\x02\x02\x0a\u{423}\x03\x02\x02\x02\x0c\u{425}\x03\x02\x02\
	\x02\x0e\u{435}\x03\x02\x02\x02\x10\u{437}\x03\x02\x02\x02\x12\u{447}\x03\
	\x02\x02\x02\x14\u{450}\x03\x02\x02\x02\x16\u{458}\x03\x02\x02\x02\x18\u{465}\
	\x03\x02\x02\x02\x1a\u{470}\x03\x02\x02\x02\x1c\u{475}\x03\x02\x02\x02\x1e\
	\u{480}\x03\x02\x02\x02\x20\u{484}\x03\x02\x02\x02\x22\u{48c}\x03\x02\x02\
	\x02\x24\u{491}\x03\x02\x02\x02\x26\u{4c7}\x03\x02\x02\x02\x28\u{4c9}\x03\
	\x02\x02\x02\x2a\u{4cc}\x03\x02\x02\x02\x2c\u{4ce}\x03\x02\x02\x02\x2e\u{4d2}\
	\x03\x02\x02\x02\x30\u{4d4}\x03\x02\x02\x02\x32\u{4d7}\x03\x02\x02\x02\x34\
	\u{4da}\x03\x02\x02\x02\x36\u{4de}\x03\x02\x02\x02\x38\u{505}\x03\x02\x02\
	\x02\x3a\u{507}\x03\x02\x02\x02\x3c\u{50a}\x03\x02\x02\x02\x3e\u{50d}\x03\
	\x02\x02\x02\x40\u{511}\x03\x02\x02\x02\x42\u{519}\x03\x02\x02\x02\x44\u{51c}\
	\x03\x02\x02\x02\x46\u{51f}\x03\x02\x02\x02\x48\u{528}\x03\x02\x02\x02\x4a\
	\u{52b}\x03\x02\x02\x02\x4c\u{53a}\x03\x02\x02\x02\x4e\u{546}\x03\x02\x02\
	\x02\x50\u{54b}\x03\x02\x02\x02\x52\u{55f}\x03\x02\x02\x02\x54\u{563}\x03\
	\x02\x02\x02\x56\u{56a}\x03\x02\x02\x02\x58\u{583}\x03\x02\x02\x02\x5a\u{594}\
	\x03\x02\x02\x02\x5c\u{596}\x03\x02\x02\x02\x5e\u{64d}\x03\x02\x02\x02\x60\
	\u{657}\x03\x02\x02\x02\x62\u{659}\x03\x02\x02\x02\x64\u{661}\x03\x02\x02\
	\x02\x66\u{666}\x03\x02\x02\x02\x68\u{668}\x03\x02\x02\x02\x6a\u{66e}\x03\
	\x02\x02\x02\x6c\u{672}\x03\x02\x02\x02\x6e\u{676}\x03\x02\x02\x02\x70\u{67a}\
	\x03\x02\x02\x02\x72\u{684}\x03\x02\x02\x02\x74\u{68f}\x03\x02\x02\x02\x76\
	\u{6a0}\x03\x02\x02\x02\x78\u{6b2}\x03\x02\x02\x02\x7a\u{6b7}\x03\x02\x02\
	\x02\x7c\u{6ba}\x03\x02\x02\x02\x7e\u{6be}\x03\x02\x02\x02\u{80}\u{6c5}\
	\x03\x02\x02\x02\u{82}\u{6ce}\x03\x02\x02\x02\u{84}\u{6d4}\x03\x02\x02\x02\
	\u{86}\u{6d6}\x03\x02\x02\x02\u{88}\u{6e7}\x03\x02\x02\x02\u{8a}\u{6fd}\
	\x03\x02\x02\x02\u{8c}\u{6ff}\x03\x02\x02\x02\u{8e}\u{707}\x03\x02\x02\x02\
	\u{90}\u{70e}\x03\x02\x02\x02\u{92}\u{710}\x03\x02\x02\x02\u{94}\u{71e}\
	\x03\x02\x02\x02\u{96}\u{720}\x03\x02\x02\x02\u{98}\u{724}\x03\x02\x02\x02\
	\u{9a}\u{728}\x03\x02\x02\x02\u{9c}\u{72c}\x03\x02\x02\x02\u{9e}\u{730}\
	\x03\x02\x02\x02\u{a0}\u{73d}\x03\x02\x02\x02\u{a2}\u{745}\x03\x02\x02\x02\
	\u{a4}\u{748}\x03\x02\x02\x02\u{a6}\u{74a}\x03\x02\x02\x02\u{a8}\u{756}\
	\x03\x02\x02\x02\u{aa}\u{760}\x03\x02\x02\x02\u{ac}\u{763}\x03\x02\x02\x02\
	\u{ae}\u{76e}\x03\x02\x02\x02\u{b0}\u{776}\x03\x02\x02\x02\u{b2}\u{7a2}\
	\x03\x02\x02\x02\u{b4}\u{7ab}\x03\x02\x02\x02\u{b6}\u{7c6}\x03\x02\x02\x02\
	\u{b8}\u{7d3}\x03\x02\x02\x02\u{ba}\u{7d5}\x03\x02\x02\x02\u{bc}\u{7db}\
	\x03\x02\x02\x02\u{be}\u{7de}\x03\x02\x02\x02\u{c0}\u{7e4}\x03\x02\x02\x02\
	\u{c2}\u{7ea}\x03\x02\x02\x02\u{c4}\u{7f1}\x03\x02\x02\x02\u{c6}\u{813}\
	\x03\x02\x02\x02\u{c8}\u{81b}\x03\x02\x02\x02\u{ca}\u{828}\x03\x02\x02\x02\
	\u{cc}\u{82d}\x03\x02\x02\x02\u{ce}\u{838}\x03\x02\x02\x02\u{d0}\u{849}\
	\x03\x02\x02\x02\u{d2}\u{84b}\x03\x02\x02\x02\u{d4}\u{850}\x03\x02\x02\x02\
	\u{d6}\u{857}\x03\x02\x02\x02\u{d8}\u{85b}\x03\x02\x02\x02\u{da}\u{85d}\
	\x03\x02\x02\x02\u{dc}\u{860}\x03\x02\x02\x02\u{de}\u{86e}\x03\x02\x02\x02\
	\u{e0}\u{876}\x03\x02\x02\x02\u{e2}\u{87e}\x03\x02\x02\x02\u{e4}\u{886}\
	\x03\x02\x02\x02\u{e6}\u{895}\x03\x02\x02\x02\u{e8}\u{897}\x03\x02\x02\x02\
	\u{ea}\u{8a8}\x03\x02\x02\x02\u{ec}\u{8ad}\x03\x02\x02\x02\u{ee}\u{8bb}\
	\x03\x02\x02\x02\u{f0}\u{8bd}\x03\x02\x02\x02\u{f2}\u{8c0}\x03\x02\x02\x02\
	\u{f4}\u{8c3}\x03\x02\x02\x02\u{f6}\u{8cc}\x03\x02\x02\x02\u{f8}\u{8e0}\
	\x03\x02\x02\x02\u{fa}\u{8e2}\x03\x02\x02\x02\u{fc}\u{8e5}\x03\x02\x02\x02\
	\u{fe}\u{8f9}\x03\x02\x02\x02\u{100}\u{8fb}\x03\x02\x02\x02\u{102}\u{8ff}\
	\x03\x02\x02\x02\u{104}\u{901}\x03\x02\x02\x02\u{106}\u{90a}\x03\x02\x02\
	\x02\u{108}\u{910}\x03\x02\x02\x02\u{10a}\u{916}\x03\x02\x02\x02\u{10c}\
	\u{91b}\x03\x02\x02\x02\u{10e}\u{949}\x03\x02\x02\x02\u{110}\u{94b}\x03\
	\x02\x02\x02\u{112}\u{94e}\x03\x02\x02\x02\u{114}\u{956}\x03\x02\x02\x02\
	\u{116}\u{95e}\x03\x02\x02\x02\u{118}\u{966}\x03\x02\x02\x02\u{11a}\u{96e}\
	\x03\x02\x02\x02\u{11c}\u{970}\x03\x02\x02\x02\u{11e}\u{97d}\x03\x02\x02\
	\x02\u{120}\u{985}\x03\x02\x02\x02\u{122}\u{98e}\x03\x02\x02\x02\u{124}\
	\u{990}\x03\x02\x02\x02\u{126}\u{992}\x03\x02\x02\x02\u{128}\u{997}\x03\
	\x02\x02\x02\u{12a}\u{999}\x03\x02\x02\x02\u{12c}\u{99d}\x03\x02\x02\x02\
	\u{12e}\u{9a3}\x03\x02\x02\x02\u{130}\u{9ab}\x03\x02\x02\x02\u{132}\u{9ad}\
	\x03\x02\x02\x02\u{134}\u{9b0}\x03\x02\x02\x02\u{136}\u{9b7}\x03\x02\x02\
	\x02\u{138}\u{9c2}\x03\x02\x02\x02\u{13a}\u{9cf}\x03\x02\x02\x02\u{13c}\
	\u{9d1}\x03\x02\x02\x02\u{13e}\u{9d9}\x03\x02\x02\x02\u{140}\u{9dd}\x03\
	\x02\x02\x02\u{142}\u{9e5}\x03\x02\x02\x02\u{144}\u{9e9}\x03\x02\x02\x02\
	\u{146}\u{9eb}\x03\x02\x02\x02\u{148}\u{9ed}\x03\x02\x02\x02\u{14a}\u{9f0}\
	\x03\x02\x02\x02\u{14c}\u{9f7}\x03\x02\x02\x02\u{14e}\u{9ff}\x03\x02\x02\
	\x02\u{150}\u{a04}\x03\x02\x02\x02\u{152}\u{a06}\x03\x02\x02\x02\u{154}\
	\u{a0d}\x03\x02\x02\x02\u{156}\u{a15}\x03\x02\x02\x02\u{158}\u{a19}\x03\
	\x02\x02\x02\u{15a}\u{a1b}\x03\x02\x02\x02\u{15c}\u{a26}\x03\x02\x02\x02\
	\u{15e}\u{a2a}\x03\x02\x02\x02\u{160}\u{a36}\x03\x02\x02\x02\u{162}\u{a3e}\
	\x03\x02\x02\x02\u{164}\u{a42}\x03\x02\x02\x02\u{166}\u{a4e}\x03\x02\x02\
	\x02\u{168}\u{a5a}\x03\x02\x02\x02\u{16a}\u{a5f}\x03\x02\x02\x02\u{16c}\
	\u{a64}\x03\x02\x02\x02\u{16e}\u{a66}\x03\x02\x02\x02\u{170}\u{a6a}\x03\
	\x02\x02\x02\u{172}\u{a6e}\x03\x02\x02\x02\u{174}\u{a75}\x03\x02\x02\x02\
	\u{176}\u{a77}\x03\x02\x02\x02\u{178}\u{a84}\x03\x02\x02\x02\u{17a}\u{aaa}\
	\x03\x02\x02\x02\u{17c}\u{aac}\x03\x02\x02\x02\u{17e}\u{ab1}\x03\x02\x02\
	\x02\u{180}\u{ab6}\x03\x02\x02\x02\u{182}\u{abd}\x03\x02\x02\x02\u{184}\
	\u{ac2}\x03\x02\x02\x02\u{186}\u{ac7}\x03\x02\x02\x02\u{188}\u{acd}\x03\
	\x02\x02\x02\u{18a}\u{acf}\x03\x02\x02\x02\u{18c}\u{ad8}\x03\x02\x02\x02\
	\u{18e}\u{ae4}\x03\x02\x02\x02\u{190}\u{aed}\x03\x02\x02\x02\u{192}\u{af7}\
	\x03\x02\x02\x02\u{194}\u{b11}\x03\x02\x02\x02\u{196}\u{b13}\x03\x02\x02\
	\x02\u{198}\u{b29}\x03\x02\x02\x02\u{19a}\u{b2e}\x03\x02\x02\x02\u{19c}\
	\u{b77}\x03\x02\x02\x02\u{19e}\u{b79}\x03\x02\x02\x02\u{1a0}\u{b99}\x03\
	\x02\x02\x02\u{1a2}\u{b9b}\x03\x02\x02\x02\u{1a4}\u{ba6}\x03\x02\x02\x02\
	\u{1a6}\u{bac}\x03\x02\x02\x02\u{1a8}\u{bb2}\x03\x02\x02\x02\u{1aa}\u{bb4}\
	\x03\x02\x02\x02\u{1ac}\u{bbd}\x03\x02\x02\x02\u{1ae}\u{bc7}\x03\x02\x02\
	\x02\u{1b0}\u{bc9}\x03\x02\x02\x02\u{1b2}\u{bd7}\x03\x02\x02\x02\u{1b4}\
	\u{bd9}\x03\x02\x02\x02\u{1b6}\u{bdc}\x03\x02\x02\x02\u{1b8}\u{be0}\x03\
	\x02\x02\x02\u{1ba}\u{be2}\x03\x02\x02\x02\u{1bc}\u{be6}\x03\x02\x02\x02\
	\u{1be}\u{bea}\x03\x02\x02\x02\u{1c0}\u{bee}\x03\x02\x02\x02\u{1c2}\u{bf5}\
	\x03\x02\x02\x02\u{1c4}\u{bfc}\x03\x02\x02\x02\u{1c6}\u{c12}\x03\x02\x02\
	\x02\u{1c8}\u{c18}\x03\x02\x02\x02\u{1ca}\u{c27}\x03\x02\x02\x02\u{1cc}\
	\u{c2e}\x03\x02\x02\x02\u{1ce}\u{c36}\x03\x02\x02\x02\u{1d0}\u{c38}\x03\
	\x02\x02\x02\u{1d2}\u{c3f}\x03\x02\x02\x02\u{1d4}\u{c43}\x03\x02\x02\x02\
	\u{1d6}\u{c46}\x03\x02\x02\x02\u{1d8}\u{c49}\x03\x02\x02\x02\u{1da}\u{c4c}\
	\x03\x02\x02\x02\u{1dc}\u{c79}\x03\x02\x02\x02\u{1de}\u{c8a}\x03\x02\x02\
	\x02\u{1e0}\u{c8c}\x03\x02\x02\x02\u{1e2}\u{c97}\x03\x02\x02\x02\u{1e4}\
	\u{c9b}\x03\x02\x02\x02\u{1e6}\u{c9f}\x03\x02\x02\x02\u{1e8}\u{ca1}\x03\
	\x02\x02\x02\u{1ea}\u{ca6}\x03\x02\x02\x02\u{1ec}\u{ca8}\x03\x02\x02\x02\
	\u{1ee}\u{cad}\x03\x02\x02\x02\u{1f0}\u{cb2}\x03\x02\x02\x02\u{1f2}\u{cb7}\
	\x03\x02\x02\x02\u{1f4}\u{cbc}\x03\x02\x02\x02\u{1f6}\u{cc2}\x03\x02\x02\
	\x02\u{1f8}\u{ccb}\x03\x02\x02\x02\u{1fa}\u{cd0}\x03\x02\x02\x02\u{1fc}\
	\u{cdd}\x03\x02\x02\x02\u{1fe}\u{cdf}\x03\x02\x02\x02\u{200}\u{ce3}\x03\
	\x02\x02\x02\u{202}\u{cf7}\x03\x02\x02\x02\u{204}\u{d04}\x03\x02\x02\x02\
	\u{206}\u{d0c}\x03\x02\x02\x02\u{208}\u{d0e}\x03\x02\x02\x02\u{20a}\u{d17}\
	\x03\x02\x02\x02\u{20c}\u{d1b}\x03\x02\x02\x02\u{20e}\u{d22}\x03\x02\x02\
	\x02\u{210}\u{d29}\x03\x02\x02\x02\u{212}\u{d30}\x03\x02\x02\x02\u{214}\
	\u{d33}\x03\x02\x02\x02\u{216}\u{d50}\x03\x02\x02\x02\u{218}\u{d5b}\x03\
	\x02\x02\x02\u{21a}\u{d6c}\x03\x02\x02\x02\u{21c}\u{d6e}\x03\x02\x02\x02\
	\u{21e}\u{d72}\x03\x02\x02\x02\u{220}\u{d79}\x03\x02\x02\x02\u{222}\u{d7b}\
	\x03\x02\x02\x02\u{224}\u{d80}\x03\x02\x02\x02\u{226}\u{d84}\x03\x02\x02\
	\x02\u{228}\u{d8c}\x03\x02\x02\x02\u{22a}\u{d90}\x03\x02\x02\x02\u{22c}\
	\u{d9a}\x03\x02\x02\x02\u{22e}\u{d9c}\x03\x02\x02\x02\u{230}\u{da2}\x03\
	\x02\x02\x02\u{232}\u{da6}\x03\x02\x02\x02\u{234}\u{db3}\x03\x02\x02\x02\
	\u{236}\u{db5}\x03\x02\x02\x02\u{238}\u{db9}\x03\x02\x02\x02\u{23a}\u{dbc}\
	\x03\x02\x02\x02\u{23c}\u{dbf}\x03\x02\x02\x02\u{23e}\u{dd3}\x03\x02\x02\
	\x02\u{240}\u{dd7}\x03\x02\x02\x02\u{242}\u{dde}\x03\x02\x02\x02\u{244}\
	\u{dec}\x03\x02\x02\x02\u{246}\u{e01}\x03\x02\x02\x02\u{248}\u{e06}\x03\
	\x02\x02\x02\u{24a}\u{e08}\x03\x02\x02\x02\u{24c}\u{e0d}\x03\x02\x02\x02\
	\u{24e}\u{e12}\x03\x02\x02\x02\u{250}\u{e20}\x03\x02\x02\x02\u{252}\u{e9d}\
	\x03\x02\x02\x02\u{254}\u{e9f}\x03\x02\x02\x02\u{256}\u{eaf}\x03\x02\x02\
	\x02\u{258}\u{eb2}\x03\x02\x02\x02\u{25a}\u{eb5}\x03\x02\x02\x02\u{25c}\
	\u{eb8}\x03\x02\x02\x02\u{25e}\u{ebc}\x03\x02\x02\x02\u{260}\u{ec8}\x03\
	\x02\x02\x02\u{262}\u{eca}\x03\x02\x02\x02\u{264}\u{ecc}\x03\x02\x02\x02\
	\u{266}\u{ece}\x03\x02\x02\x02\u{268}\u{ed6}\x03\x02\x02\x02\u{26a}\u{ede}\
	\x03\x02\x02\x02\u{26c}\u{eea}\x03\x02\x02\x02\u{26e}\u{f0c}\x03\x02\x02\
	\x02\u{270}\u{f0e}\x03\x02\x02\x02\u{272}\u{f20}\x03\x02\x02\x02\u{274}\
	\u{f29}\x03\x02\x02\x02\u{276}\u{f2e}\x03\x02\x02\x02\u{278}\u{f32}\x03\
	\x02\x02\x02\u{27a}\u{f42}\x03\x02\x02\x02\u{27c}\u{f7d}\x03\x02\x02\x02\
	\u{27e}\u{f7f}\x03\x02\x02\x02\u{280}\u{f81}\x03\x02\x02\x02\u{282}\u{f95}\
	\x03\x02\x02\x02\u{284}\u{fa0}\x03\x02\x02\x02\u{286}\u{fa2}\x03\x02\x02\
	\x02\u{288}\u{fb2}\x03\x02\x02\x02\u{28a}\u{fbe}\x03\x02\x02\x02\u{28c}\
	\u{fd0}\x03\x02\x02\x02\u{28e}\u{fd5}\x03\x02\x02\x02\u{290}\u{fd9}\x03\
	\x02\x02\x02\u{292}\u{fec}\x03\x02\x02\x02\u{294}\u{ff1}\x03\x02\x02\x02\
	\u{296}\u{ff3}\x03\x02\x02\x02\u{298}\u{100f}\x03\x02\x02\x02\u{29a}\u{1012}\
	\x03\x02\x02\x02\u{29c}\u{1014}\x03\x02\x02\x02\u{29e}\u{1016}\x03\x02\x02\
	\x02\u{2a0}\u{1029}\x03\x02\x02\x02\u{2a2}\u{102b}\x03\x02\x02\x02\u{2a4}\
	\u{102d}\x03\x02\x02\x02\u{2a6}\u{1031}\x03\x02\x02\x02\u{2a8}\u{1053}\x03\
	\x02\x02\x02\u{2aa}\u{1055}\x03\x02\x02\x02\u{2ac}\u{1057}\x03\x02\x02\x02\
	\u{2ae}\u{105f}\x03\x02\x02\x02\u{2b0}\u{108b}\x03\x02\x02\x02\u{2b2}\u{108d}\
	\x03\x02\x02\x02\u{2b4}\u{10a6}\x03\x02\x02\x02\u{2b6}\u{10a8}\x03\x02\x02\
	\x02\u{2b8}\u{10b0}\x03\x02\x02\x02\u{2ba}\u{10b9}\x03\x02\x02\x02\u{2bc}\
	\u{10c9}\x03\x02\x02\x02\u{2be}\u{10cd}\x03\x02\x02\x02\u{2c0}\u{10cf}\x03\
	\x02\x02\x02\u{2c2}\u{10d8}\x03\x02\x02\x02\u{2c4}\u{10e7}\x03\x02\x02\x02\
	\u{2c6}\u{10ed}\x03\x02\x02\x02\u{2c8}\u{10ef}\x03\x02\x02\x02\u{2ca}\u{10f6}\
	\x03\x02\x02\x02\u{2cc}\u{10f8}\x03\x02\x02\x02\u{2ce}\u{10fd}\x03\x02\x02\
	\x02\u{2d0}\u{110a}\x03\x02\x02\x02\u{2d2}\u{1122}\x03\x02\x02\x02\u{2d4}\
	\u{1124}\x03\x02\x02\x02\u{2d6}\u{1131}\x03\x02\x02\x02\u{2d8}\u{1133}\x03\
	\x02\x02\x02\u{2da}\u{1136}\x03\x02\x02\x02\u{2dc}\u{1139}\x03\x02\x02\x02\
	\u{2de}\u{113b}\x03\x02\x02\x02\u{2e0}\u{113f}\x03\x02\x02\x02\u{2e2}\u{1145}\
	\x03\x02\x02\x02\u{2e4}\u{114b}\x03\x02\x02\x02\u{2e6}\u{114d}\x03\x02\x02\
	\x02\u{2e8}\u{115b}\x03\x02\x02\x02\u{2ea}\u{1164}\x03\x02\x02\x02\u{2ec}\
	\u{1166}\x03\x02\x02\x02\u{2ee}\u{1171}\x03\x02\x02\x02\u{2f0}\u{1179}\x03\
	\x02\x02\x02\u{2f2}\u{1183}\x03\x02\x02\x02\u{2f4}\u{1187}\x03\x02\x02\x02\
	\u{2f6}\u{118b}\x03\x02\x02\x02\u{2f8}\u{118f}\x03\x02\x02\x02\u{2fa}\u{1195}\
	\x03\x02\x02\x02\u{2fc}\u{11cb}\x03\x02\x02\x02\u{2fe}\u{11d1}\x03\x02\x02\
	\x02\u{300}\u{11d5}\x03\x02\x02\x02\u{302}\u{11d7}\x03\x02\x02\x02\u{304}\
	\u{11e2}\x03\x02\x02\x02\u{306}\u{11f3}\x03\x02\x02\x02\u{308}\u{1203}\x03\
	\x02\x02\x02\u{30a}\u{120c}\x03\x02\x02\x02\u{30c}\u{120e}\x03\x02\x02\x02\
	\u{30e}\u{1215}\x03\x02\x02\x02\u{310}\u{1224}\x03\x02\x02\x02\u{312}\u{1226}\
	\x03\x02\x02\x02\u{314}\u{1228}\x03\x02\x02\x02\u{316}\u{122a}\x03\x02\x02\
	\x02\u{318}\u{1230}\x03\x02\x02\x02\u{31a}\u{1236}\x03\x02\x02\x02\u{31c}\
	\u{123b}\x03\x02\x02\x02\u{31e}\u{123d}\x03\x02\x02\x02\u{320}\u{1240}\x03\
	\x02\x02\x02\u{322}\u{1242}\x03\x02\x02\x02\u{324}\u{1254}\x03\x02\x02\x02\
	\u{326}\u{1262}\x03\x02\x02\x02\u{328}\u{1264}\x03\x02\x02\x02\u{32a}\u{1271}\
	\x03\x02\x02\x02\u{32c}\u{1273}\x03\x02\x02\x02\u{32e}\u{127f}\x03\x02\x02\
	\x02\u{330}\u{1284}\x03\x02\x02\x02\u{332}\u{1289}\x03\x02\x02\x02\u{334}\
	\u{128b}\x03\x02\x02\x02\u{336}\u{1294}\x03\x02\x02\x02\u{338}\u{1296}\x03\
	\x02\x02\x02\u{33a}\u{129f}\x03\x02\x02\x02\u{33c}\u{12a1}\x03\x02\x02\x02\
	\u{33e}\u{12aa}\x03\x02\x02\x02\u{340}\u{12ac}\x03\x02\x02\x02\u{342}\u{12b5}\
	\x03\x02\x02\x02\u{344}\u{12b7}\x03\x02\x02\x02\u{346}\u{12c0}\x03\x02\x02\
	\x02\u{348}\u{12c2}\x03\x02\x02\x02\u{34a}\u{12cb}\x03\x02\x02\x02\u{34c}\
	\u{12d2}\x03\x02\x02\x02\u{34e}\u{12d4}\x03\x02\x02\x02\u{350}\u{12db}\x03\
	\x02\x02\x02\u{352}\u{12dd}\x03\x02\x02\x02\u{354}\u{12e7}\x03\x02\x02\x02\
	\u{356}\u{12f4}\x03\x02\x02\x02\u{358}\u{12f6}\x03\x02\x02\x02\u{35a}\u{12fa}\
	\x03\x02\x02\x02\u{35c}\u{12fe}\x03\x02\x02\x02\u{35e}\u{1304}\x03\x02\x02\
	\x02\u{360}\u{1306}\x03\x02\x02\x02\u{362}\u{1311}\x03\x02\x02\x02\u{364}\
	\u{1313}\x03\x02\x02\x02\u{366}\u{132b}\x03\x02\x02\x02\u{368}\u{132d}\x03\
	\x02\x02\x02\u{36a}\u{1332}\x03\x02\x02\x02\u{36c}\u{1337}\x03\x02\x02\x02\
	\u{36e}\u{133c}\x03\x02\x02\x02\u{370}\u{133e}\x03\x02\x02\x02\u{372}\u{1347}\
	\x03\x02\x02\x02\u{374}\u{1349}\x03\x02\x02\x02\u{376}\u{1352}\x03\x02\x02\
	\x02\u{378}\u{1354}\x03\x02\x02\x02\u{37a}\u{1356}\x03\x02\x02\x02\u{37c}\
	\u{135a}\x03\x02\x02\x02\u{37e}\u{1366}\x03\x02\x02\x02\u{380}\u{136b}\x03\
	\x02\x02\x02\u{382}\u{1376}\x03\x02\x02\x02\u{384}\u{137c}\x03\x02\x02\x02\
	\u{386}\u{137e}\x03\x02\x02\x02\u{388}\u{1380}\x03\x02\x02\x02\u{38a}\u{1385}\
	\x03\x02\x02\x02\u{38c}\u{1389}\x03\x02\x02\x02\u{38e}\u{138b}\x03\x02\x02\
	\x02\u{390}\u{1390}\x03\x02\x02\x02\u{392}\u{1392}\x03\x02\x02\x02\u{394}\
	\u{1394}\x03\x02\x02\x02\u{396}\u{1396}\x03\x02\x02\x02\u{398}\u{1399}\x03\
	\x02\x02\x02\u{39a}\u{13a1}\x03\x02\x02\x02\u{39c}\u{13a8}\x03\x02\x02\x02\
	\u{39e}\u{13aa}\x03\x02\x02\x02\u{3a0}\u{13b2}\x03\x02\x02\x02\u{3a2}\u{13b4}\
	\x03\x02\x02\x02\u{3a4}\u{13b9}\x03\x02\x02\x02\u{3a6}\u{13be}\x03\x02\x02\
	\x02\u{3a8}\u{13d4}\x03\x02\x02\x02\u{3aa}\u{13dd}\x03\x02\x02\x02\u{3ac}\
	\u{13df}\x03\x02\x02\x02\u{3ae}\u{13ea}\x03\x02\x02\x02\u{3b0}\u{13ec}\x03\
	\x02\x02\x02\u{3b2}\u{13f4}\x03\x02\x02\x02\u{3b4}\u{1405}\x03\x02\x02\x02\
	\u{3b6}\u{1408}\x03\x02\x02\x02\u{3b8}\u{140c}\x03\x02\x02\x02\u{3ba}\u{140e}\
	\x03\x02\x02\x02\u{3bc}\u{1410}\x03\x02\x02\x02\u{3be}\u{1412}\x03\x02\x02\
	\x02\u{3c0}\u{1429}\x03\x02\x02\x02\u{3c2}\u{142d}\x03\x02\x02\x02\u{3c4}\
	\u{143b}\x03\x02\x02\x02\u{3c6}\u{1443}\x03\x02\x02\x02\u{3c8}\u{144b}\x03\
	\x02\x02\x02\u{3ca}\u{144d}\x03\x02\x02\x02\u{3cc}\u{1450}\x03\x02\x02\x02\
	\u{3ce}\u{1458}\x03\x02\x02\x02\u{3d0}\u{1460}\x03\x02\x02\x02\u{3d2}\u{1464}\
	\x03\x02\x02\x02\u{3d4}\u{1466}\x03\x02\x02\x02\u{3d6}\u{146c}\x03\x02\x02\
	\x02\u{3d8}\u{146e}\x03\x02\x02\x02\u{3da}\u{1471}\x03\x02\x02\x02\u{3dc}\
	\u{147b}\x03\x02\x02\x02\u{3de}\u{1492}\x03\x02\x02\x02\u{3e0}\u{14a4}\x03\
	\x02\x02\x02\u{3e2}\u{14a6}\x03\x02\x02\x02\u{3e4}\u{14ae}\x03\x02\x02\x02\
	\u{3e6}\u{14b6}\x03\x02\x02\x02\u{3e8}\u{14c4}\x03\x02\x02\x02\u{3ea}\u{14ca}\
	\x03\x02\x02\x02\u{3ec}\u{14da}\x03\x02\x02\x02\u{3ee}\u{14ea}\x03\x02\x02\
	\x02\u{3f0}\u{3f2}\x05\x04\x03\x02\u{3f1}\u{3f0}\x03\x02\x02\x02\u{3f2}\
	\u{3f5}\x03\x02\x02\x02\u{3f3}\u{3f1}\x03\x02\x02\x02\u{3f3}\u{3f4}\x03\
	\x02\x02\x02\u{3f4}\u{3f6}\x03\x02\x02\x02\u{3f5}\u{3f3}\x03\x02\x02\x02\
	\u{3f6}\u{3f7}\x07\x02\x02\x03\u{3f7}\x03\x03\x02\x02\x02\u{3f8}\u{3fb}\
	\x05\x06\x04\x02\u{3f9}\u{3fb}\x05\x0e\x08\x02\u{3fa}\u{3f8}\x03\x02\x02\
	\x02\u{3fa}\u{3f9}\x03\x02\x02\x02\u{3fb}\u{3fd}\x03\x02\x02\x02\u{3fc}\
	\u{3fe}\x07\u{182}\x02\x02\u{3fd}\u{3fc}\x03\x02\x02\x02\u{3fd}\u{3fe}\x03\
	\x02\x02\x02\u{3fe}\x05\x03\x02\x02\x02\u{3ff}\u{409}\x07\x73\x02\x02\u{400}\
	\u{402}\x05\x08\x05\x02\u{401}\u{400}\x03\x02\x02\x02\u{402}\u{405}\x03\
	\x02\x02\x02\u{403}\u{401}\x03\x02\x02\x02\u{403}\u{404}\x03\x02\x02\x02\
	\u{404}\u{406}\x03\x02\x02\x02\u{405}\u{403}\x03\x02\x02\x02\u{406}\u{40a}\
	\x05\x0e\x08\x02\u{407}\u{408}\x07\u{113}\x02\x02\u{408}\u{40a}\x05\u{186}\
	\u{c4}\x02\u{409}\u{403}\x03\x02\x02\x02\u{409}\u{407}\x03\x02\x02\x02\u{40a}\
	\x07\x03\x02\x02\x02\u{40b}\u{422}\x07\x76\x02\x02\u{40c}\u{422}\x07\u{86}\
	\x02\x02\u{40d}\u{422}\x07\x57\x02\x02\u{40e}\u{410}\x07\x27\x02\x02\u{40f}\
	\u{411}\x09\x02\x02\x02\u{410}\u{40f}\x03\x02\x02\x02\u{410}\u{411}\x03\
	\x02\x02\x02\u{411}\u{422}\x03\x02\x02\x02\u{412}\u{422}\x07\u{b9}\x02\x02\
	\u{413}\u{422}\x07\x17\x02\x02\u{414}\u{422}\x07\x0c\x02\x02\u{415}\u{422}\
	\x07\u{10a}\x02\x02\u{416}\u{422}\x07\u{b8}\x02\x02\u{417}\u{422}\x07\x15\
	\x02\x02\u{418}\u{41a}\x07\u{16f}\x02\x02\u{419}\u{41b}\x05\x0a\x06\x02\
	\u{41a}\u{419}\x03\x02\x02\x02\u{41a}\u{41b}\x03\x02\x02\x02\u{41b}\u{41d}\
	\x03\x02\x02\x02\u{41c}\u{41e}\x05\x0c\x07\x02\u{41d}\u{41c}\x03\x02\x02\
	\x02\u{41d}\u{41e}\x03\x02\x02\x02\u{41e}\u{422}\x03\x02\x02\x02\u{41f}\
	\u{422}\x07\x50\x02\x02\u{420}\u{422}\x07\x4f\x02\x02\u{421}\u{40b}\x03\
	\x02\x02\x02\u{421}\u{40c}\x03\x02\x02\x02\u{421}\u{40d}\x03\x02\x02\x02\
	\u{421}\u{40e}\x03\x02\x02\x02\u{421}\u{412}\x03\x02\x02\x02\u{421}\u{413}\
	\x03\x02\x02\x02\u{421}\u{414}\x03\x02\x02\x02\u{421}\u{415}\x03\x02\x02\
	\x02\u{421}\u{416}\x03\x02\x02\x02\u{421}\u{417}\x03\x02\x02\x02\u{421}\
	\u{418}\x03\x02\x02\x02\u{421}\u{41f}\x03\x02\x02\x02\u{421}\u{420}\x03\
	\x02\x02\x02\u{422}\x09\x03\x02\x02\x02\u{423}\u{424}\x07\u{d8}\x02\x02\
	\u{424}\x0b\x03\x02\x02\x02\u{425}\u{426}\x09\x03\x02\x02\u{426}\x0d\x03\
	\x02\x02\x02\u{427}\u{436}\x05\u{186}\u{c4}\x02\u{428}\u{436}\x05\x10\x09\
	\x02\u{429}\u{436}\x05\x14\x0b\x02\u{42a}\u{436}\x05\x16\x0c\x02\u{42b}\
	\u{436}\x05\x18\x0d\x02\u{42c}\u{436}\x05\x1c\x0f\x02\u{42d}\u{436}\x05\
	\x24\x13\x02\u{42e}\u{436}\x05\x26\x14\x02\u{42f}\u{436}\x05\u{1a4}\u{d3}\
	\x02\u{430}\u{436}\x05\u{1ac}\u{d7}\x02\u{431}\u{436}\x05\u{1ae}\u{d8}\x02\
	\u{432}\u{436}\x05\u{1c4}\u{e3}\x02\u{433}\u{436}\x05\u{3a2}\u{1d2}\x02\
	\u{434}\u{436}\x05\u{3a4}\u{1d3}\x02\u{435}\u{427}\x03\x02\x02\x02\u{435}\
	\u{428}\x03\x02\x02\x02\u{435}\u{429}\x03\x02\x02\x02\u{435}\u{42a}\x03\
	\x02\x02\x02\u{435}\u{42b}\x03\x02\x02\x02\u{435}\u{42c}\x03\x02\x02\x02\
	\u{435}\u{42d}\x03\x02\x02\x02\u{435}\u{42e}\x03\x02\x02\x02\u{435}\u{42f}\
	\x03\x02\x02\x02\u{435}\u{430}\x03\x02\x02\x02\u{435}\u{431}\x03\x02\x02\
	\x02\u{435}\u{432}\x03\x02\x02\x02\u{435}\u{433}\x03\x02\x02\x02\u{435}\
	\u{434}\x03\x02\x02\x02\u{436}\x0f\x03\x02\x02\x02\u{437}\u{438}\x07\u{b4}\
	\x02\x02\u{438}\u{43a}\x07\x44\x02\x02\u{439}\u{43b}\x07\u{b5}\x02\x02\u{43a}\
	\u{439}\x03\x02\x02\x02\u{43a}\u{43b}\x03\x02\x02\x02\u{43b}\u{43c}\x03\
	\x02\x02\x02\u{43c}\u{43d}\x07\u{99}\x02\x02\u{43d}\u{43f}\x07\u{19d}\x02\
	\x02\u{43e}\u{440}\x07\u{e2}\x02\x02\u{43f}\u{43e}\x03\x02\x02\x02\u{43f}\
	\u{440}\x03\x02\x02\x02\u{440}\u{441}\x03\x02\x02\x02\u{441}\u{442}\x07\
	\u{a0}\x02\x02\u{442}\u{443}\x07\u{13f}\x02\x02\u{443}\u{445}\x05\u{37a}\
	\u{1be}\x02\u{444}\u{446}\x05\x4e\x28\x02\u{445}\u{444}\x03\x02\x02\x02\
	\u{445}\u{446}\x03\x02\x02\x02\u{446}\x11\x03\x02\x02\x02\u{447}\u{449}\
	\x07\u{82}\x02\x02\u{448}\u{44a}\x07\u{c5}\x02\x02\u{449}\u{448}\x03\x02\
	\x02\x02\u{449}\u{44a}\x03\x02\x02\x02\u{44a}\u{44b}\x03\x02\x02\x02\u{44b}\
	\u{44c}\x07\u{10e}\x02\x02\u{44c}\u{44d}\x07\u{183}\x02\x02\u{44d}\u{44e}\
	\x07\u{19d}\x02\x02\u{44e}\u{44f}\x07\u{184}\x02\x02\u{44f}\x13\x03\x02\
	\x02\x02\u{450}\u{451}\x07\x74\x02\x02\u{451}\u{452}\x07\u{13f}\x02\x02\
	\u{452}\u{453}\x05\u{37a}\u{1be}\x02\u{453}\u{454}\x07\u{14b}\x02\x02\u{454}\
	\u{456}\x07\u{19d}\x02\x02\u{455}\u{457}\x05\x12\x0a\x02\u{456}\u{455}\x03\
	\x02\x02\x02\u{456}\u{457}\x03\x02\x02\x02\u{457}\x15\x03\x02\x02\x02\u{458}\
	\u{45e}\x07\u{94}\x02\x02\u{459}\u{45b}\x07\x77\x02\x02\u{45a}\u{459}\x03\
	\x02\x02\x02\u{45a}\u{45b}\x03\x02\x02\x02\u{45b}\u{45c}\x03\x02\x02\x02\
	\u{45c}\u{45d}\x07\u{13f}\x02\x02\u{45d}\u{45f}\x05\u{37a}\u{1be}\x02\u{45e}\
	\u{45a}\x03\x02\x02\x02\u{45e}\u{45f}\x03\x02\x02\x02\u{45f}\u{460}\x03\
	\x02\x02\x02\u{460}\u{461}\x07\u{87}\x02\x02\u{461}\u{463}\x07\u{19d}\x02\
	\x02\u{462}\u{464}\x05\u{110}\u{89}\x02\u{463}\u{462}\x03\x02\x02\x02\u{463}\
	\u{464}\x03\x02\x02\x02\u{464}\x17\x03\x02\x02\x02\u{465}\u{466}\x07\u{10c}\
	\x02\x02\u{466}\u{467}\x07\x64\x02\x02\u{467}\u{46a}\x05\x1a\x0e\x02\u{468}\
	\u{469}\x07\u{10d}\x02\x02\u{469}\u{46b}\x05\x1a\x0e\x02\u{46a}\u{468}\x03\
	\x02\x02\x02\u{46a}\u{46b}\x03\x02\x02\x02\u{46b}\u{46e}\x03\x02\x02\x02\
	\u{46c}\u{46d}\x07\u{178}\x02\x02\u{46d}\u{46f}\x05\x1e\x10\x02\u{46e}\u{46c}\
	\x03\x02\x02\x02\u{46e}\u{46f}\x03\x02\x02\x02\u{46f}\x19\x03\x02\x02\x02\
	\u{470}\u{473}\x05\u{38c}\u{1c7}\x02\u{471}\u{472}\x07\u{17f}\x02\x02\u{472}\
	\u{474}\x05\x22\x12\x02\u{473}\u{471}\x03\x02\x02\x02\u{473}\u{474}\x03\
	\x02\x02\x02\u{474}\x1b\x03\x02\x02\x02\u{475}\u{476}\x07\u{10c}\x02\x02\
	\u{476}\u{477}\x07\u{b4}\x02\x02\u{477}\u{47a}\x05\x1a\x0e\x02\u{478}\u{479}\
	\x07\u{a0}\x02\x02\u{479}\u{47b}\x05\u{38c}\u{1c7}\x02\u{47a}\u{478}\x03\
	\x02\x02\x02\u{47a}\u{47b}\x03\x02\x02\x02\u{47b}\u{47e}\x03\x02\x02\x02\
	\u{47c}\u{47d}\x07\u{178}\x02\x02\u{47d}\u{47f}\x05\x1e\x10\x02\u{47e}\u{47c}\
	\x03\x02\x02\x02\u{47e}\u{47f}\x03\x02\x02\x02\u{47f}\x1d\x03\x02\x02\x02\
	\u{480}\u{481}\x07\u{183}\x02\x02\u{481}\u{482}\x05\x20\x11\x02\u{482}\u{483}\
	\x07\u{184}\x02\x02\u{483}\x1f\x03\x02\x02\x02\u{484}\u{489}\x05\u{100}\
	\u{81}\x02\u{485}\u{486}\x07\u{181}\x02\x02\u{486}\u{488}\x05\u{100}\u{81}\
	\x02\u{487}\u{485}\x03\x02\x02\x02\u{488}\u{48b}\x03\x02\x02\x02\u{489}\
	\u{487}\x03\x02\x02\x02\u{489}\u{48a}\x03\x02\x02\x02\u{48a}\x21\x03\x02\
	\x02\x02\u{48b}\u{489}\x03\x02\x02\x02\u{48c}\u{48f}\x07\u{19d}\x02\x02\
	\u{48d}\u{48e}\x07\u{17f}\x02\x02\u{48e}\u{490}\x07\u{19d}\x02\x02\u{48f}\
	\u{48d}\x03\x02\x02\x02\u{48f}\u{490}\x03\x02\x02\x02\u{490}\x23\x03\x02\
	\x02\x02\u{491}\u{492}\x07\u{10c}\x02\x02\u{492}\u{493}\x07\u{136}\x02\x02\
	\u{493}\u{496}\x05\u{38c}\u{1c7}\x02\u{494}\u{495}\x07\u{178}\x02\x02\u{495}\
	\u{497}\x05\x1e\x10\x02\u{496}\u{494}\x03\x02\x02\x02\u{496}\u{497}\x03\
	\x02\x02\x02\u{497}\x25\x03\x02\x02\x02\u{498}\u{4c8}\x05\x38\x1d\x02\u{499}\
	\u{4c8}\x05\x44\x23\x02\u{49a}\u{4c8}\x05\x46\x24\x02\u{49b}\u{4c8}\x05\
	\u{252}\u{12a}\x02\u{49c}\u{4c8}\x05\x4c\x27\x02\u{49d}\u{4c8}\x05\x4a\x26\
	\x02\u{49e}\u{4c8}\x05\u{1da}\u{ee}\x02\u{49f}\u{4c8}\x05\x56\x2c\x02\u{4a0}\
	\u{4c8}\x05\x5e\x30\x02\u{4a1}\u{4c8}\x05\u{9e}\x50\x02\u{4a2}\u{4c8}\x05\
	\u{b4}\x5b\x02\u{4a3}\u{4c8}\x05\u{c4}\x63\x02\u{4a4}\u{4c8}\x05\u{c8}\x65\
	\x02\u{4a5}\u{4c8}\x05\u{cc}\x67\x02\u{4a6}\u{4c8}\x05\u{ca}\x66\x02\u{4a7}\
	\u{4c8}\x05\u{c2}\x62\x02\u{4a8}\u{4c8}\x05\u{c6}\x64\x02\u{4a9}\u{4c8}\
	\x05\u{a6}\x54\x02\u{4aa}\u{4c8}\x05\u{ac}\x57\x02\u{4ab}\u{4c8}\x05\u{a8}\
	\x55\x02\u{4ac}\u{4c8}\x05\u{aa}\x56\x02\u{4ad}\u{4c8}\x05\u{ae}\x58\x02\
	\u{4ae}\u{4c8}\x05\u{b0}\x59\x02\u{4af}\u{4c8}\x05\u{b2}\x5a\x02\u{4b0}\
	\u{4c8}\x05\x58\x2d\x02\u{4b1}\u{4c8}\x05\x62\x32\x02\u{4b2}\u{4c8}\x05\
	\x68\x35\x02\u{4b3}\u{4c8}\x05\x64\x33\x02\u{4b4}\u{4c8}\x05\x6a\x36\x02\
	\u{4b5}\u{4c8}\x05\x6c\x37\x02\u{4b6}\u{4c8}\x05\x6e\x38\x02\u{4b7}\u{4c8}\
	\x05\x70\x39\x02\u{4b8}\u{4c8}\x05\x72\x3a\x02\u{4b9}\u{4c8}\x05\u{80}\x41\
	\x02\u{4ba}\u{4c8}\x05\x78\x3d\x02\u{4bb}\u{4c8}\x05\u{82}\x42\x02\u{4bc}\
	\u{4c8}\x05\x7a\x3e\x02\u{4bd}\u{4c8}\x05\x74\x3b\x02\u{4be}\u{4c8}\x05\
	\x76\x3c\x02\u{4bf}\u{4c8}\x05\x7e\x40\x02\u{4c0}\u{4c8}\x05\x7c\x3f\x02\
	\u{4c1}\u{4c8}\x05\u{1c0}\u{e1}\x02\u{4c2}\u{4c8}\x05\u{1c2}\u{e2}\x02\u{4c3}\
	\u{4c8}\x05\u{1d0}\u{e9}\x02\u{4c4}\u{4c8}\x05\u{3a8}\u{1d5}\x02\u{4c5}\
	\u{4c8}\x05\u{254}\u{12b}\x02\u{4c6}\u{4c8}\x05\u{25e}\u{130}\x02\u{4c7}\
	\u{498}\x03\x02\x02\x02\u{4c7}\u{499}\x03\x02\x02\x02\u{4c7}\u{49a}\x03\
	\x02\x02\x02\u{4c7}\u{49b}\x03\x02\x02\x02\u{4c7}\u{49c}\x03\x02\x02\x02\
	\u{4c7}\u{49d}\x03\x02\x02\x02\u{4c7}\u{49e}\x03\x02\x02\x02\u{4c7}\u{49f}\
	\x03\x02\x02\x02\u{4c7}\u{4a0}\x03\x02\x02\x02\u{4c7}\u{4a1}\x03\x02\x02\
	\x02\u{4c7}\u{4a2}\x03\x02\x02\x02\u{4c7}\u{4a3}\x03\x02\x02\x02\u{4c7}\
	\u{4a4}\x03\x02\x02\x02\u{4c7}\u{4a5}\x03\x02\x02\x02\u{4c7}\u{4a6}\x03\
	\x02\x02\x02\u{4c7}\u{4a7}\x03\x02\x02\x02\u{4c7}\u{4a8}\x03\x02\x02\x02\
	\u{4c7}\u{4a9}\x03\x02\x02\x02\u{4c7}\u{4aa}\x03\x02\x02\x02\u{4c7}\u{4ab}\
	\x03\x02\x02\x02\u{4c7}\u{4ac}\x03\x02\x02\x02\u{4c7}\u{4ad}\x03\x02\x02\
	\x02\u{4c7}\u{4ae}\x03\x02\x02\x02\u{4c7}\u{4af}\x03\x02\x02\x02\u{4c7}\
	\u{4b0}\x03\x02\x02\x02\u{4c7}\u{4b1}\x03\x02\x02\x02\u{4c7}\u{4b2}\x03\
	\x02\x02\x02\u{4c7}\u{4b3}\x03\x02\x02\x02\u{4c7}\u{4b4}\x03\x02\x02\x02\
	\u{4c7}\u{4b5}\x03\x02\x02\x02\u{4c7}\u{4b6}\x03\x02\x02\x02\u{4c7}\u{4b7}\
	\x03\x02\x02\x02\u{4c7}\u{4b8}\x03\x02\x02\x02\u{4c7}\u{4b9}\x03\x02\x02\
	\x02\u{4c7}\u{4ba}\x03\x02\x02\x02\u{4c7}\u{4bb}\x03\x02\x02\x02\u{4c7}\
	\u{4bc}\x03\x02\x02\x02\u{4c7}\u{4bd}\x03\x02\x02\x02\u{4c7}\u{4be}\x03\
	\x02\x02\x02\u{4c7}\u{4bf}\x03\x02\x02\x02\u{4c7}\u{4c0}\x03\x02\x02\x02\
	\u{4c7}\u{4c1}\x03\x02\x02\x02\u{4c7}\u{4c2}\x03\x02\x02\x02\u{4c7}\u{4c3}\
	\x03\x02\x02\x02\u{4c7}\u{4c4}\x03\x02\x02\x02\u{4c7}\u{4c5}\x03\x02\x02\
	\x02\u{4c7}\u{4c6}\x03\x02\x02\x02\u{4c8}\x27\x03\x02\x02\x02\u{4c9}\u{4ca}\
	\x07\u{92}\x02\x02\u{4ca}\u{4cb}\x07\x71\x02\x02\u{4cb}\x29\x03\x02\x02\
	\x02\u{4cc}\u{4cd}\x09\x04\x02\x02\u{4cd}\x2b\x03\x02\x02\x02\u{4ce}\u{4cf}\
	\x07\u{92}\x02\x02\u{4cf}\u{4d0}\x07\u{cf}\x02\x02\u{4d0}\u{4d1}\x07\x71\
	\x02\x02\u{4d1}\x2d\x03\x02\x02\x02\u{4d2}\u{4d3}\x07\u{83}\x02\x02\u{4d3}\
	\x2f\x03\x02\x02\x02\u{4d4}\u{4d5}\x07\x67\x02\x02\u{4d5}\u{4d6}\x07\u{113}\
	\x02\x02\u{4d6}\x31\x03\x02\x02\x02\u{4d7}\u{4d8}\x07\x5d\x02\x02\u{4d8}\
	\u{4d9}\x07\u{113}\x02\x02\u{4d9}\x33\x03\x02\x02\x02\u{4da}\u{4db}\x07\
	\u{137}\x02\x02\u{4db}\u{4dc}\x07\x13\x02\x02\u{4dc}\u{4dd}\x07\x5b\x02\
	\x02\u{4dd}\x35\x03\x02\x02\x02\u{4de}\u{4df}\x07\u{db}\x02\x02\u{4df}\u{4e0}\
	\x07\u{10d}\x02\x02\u{4e0}\x37\x03\x02\x02\x02\u{4e1}\u{4e2}\x07\x3c\x02\
	\x02\u{4e2}\u{4e4}\x05\x5c\x2f\x02\u{4e3}\u{4e5}\x05\x2c\x17\x02\u{4e4}\
	\u{4e3}\x03\x02\x02\x02\u{4e4}\u{4e5}\x03\x02\x02\x02\u{4e5}\u{4e6}\x03\
	\x02\x02\x02\u{4e6}\u{4e8}\x05\u{38c}\u{1c7}\x02\u{4e7}\u{4e9}\x05\x48\x25\
	\x02\u{4e8}\u{4e7}\x03\x02\x02\x02\u{4e8}\u{4e9}\x03\x02\x02\x02\u{4e9}\
	\u{4eb}\x03\x02\x02\x02\u{4ea}\u{4ec}\x05\x3a\x1e\x02\u{4eb}\u{4ea}\x03\
	\x02\x02\x02\u{4eb}\u{4ec}\x03\x02\x02\x02\u{4ec}\u{4ee}\x03\x02\x02\x02\
	\u{4ed}\u{4ef}\x05\x3c\x1f\x02\u{4ee}\u{4ed}\x03\x02\x02\x02\u{4ee}\u{4ef}\
	\x03\x02\x02\x02\u{4ef}\u{4f3}\x03\x02\x02\x02\u{4f0}\u{4f1}\x07\u{178}\
	\x02\x02\u{4f1}\u{4f2}\x07\x4d\x02\x02\u{4f2}\u{4f4}\x05\x3e\x20\x02\u{4f3}\
	\u{4f0}\x03\x02\x02\x02\u{4f3}\u{4f4}\x03\x02\x02\x02\u{4f4}\u{506}\x03\
	\x02\x02\x02\u{4f5}\u{4f6}\x07\x3c\x02\x02\u{4f6}\u{4f7}\x07\u{108}\x02\
	\x02\u{4f7}\u{4f9}\x05\x5c\x2f\x02\u{4f8}\u{4fa}\x05\x2c\x17\x02\u{4f9}\
	\u{4f8}\x03\x02\x02\x02\u{4f9}\u{4fa}\x03\x02\x02\x02\u{4fa}\u{4fb}\x03\
	\x02\x02\x02\u{4fb}\u{4fd}\x05\u{38c}\u{1c7}\x02\u{4fc}\u{4fe}\x05\x48\x25\
	\x02\u{4fd}\u{4fc}\x03\x02\x02\x02\u{4fd}\u{4fe}\x03\x02\x02\x02\u{4fe}\
	\u{4ff}\x03\x02\x02\x02\u{4ff}\u{503}\x05\x42\x22\x02\u{500}\u{501}\x07\
	\u{178}\x02\x02\u{501}\u{502}\x07\x4d\x02\x02\u{502}\u{504}\x05\x3e\x20\
	\x02\u{503}\u{500}\x03\x02\x02\x02\u{503}\u{504}\x03\x02\x02\x02\u{504}\
	\u{506}\x03\x02\x02\x02\u{505}\u{4e1}\x03\x02\x02\x02\u{505}\u{4f5}\x03\
	\x02\x02\x02\u{506}\x39\x03\x02\x02\x02\u{507}\u{508}\x07\u{b6}\x02\x02\
	\u{508}\u{509}\x07\u{19d}\x02\x02\u{509}\x3b\x03\x02\x02\x02\u{50a}\u{50b}\
	\x07\u{bd}\x02\x02\u{50b}\u{50c}\x07\u{19d}\x02\x02\u{50c}\x3d\x03\x02\x02\
	\x02\u{50d}\u{50e}\x07\u{183}\x02\x02\u{50e}\u{50f}\x05\x40\x21\x02\u{50f}\
	\u{510}\x07\u{184}\x02\x02\u{510}\x3f\x03\x02\x02\x02\u{511}\u{516}\x05\
	\u{100}\u{81}\x02\u{512}\u{513}\x07\u{181}\x02\x02\u{513}\u{515}\x05\u{100}\
	\u{81}\x02\u{514}\u{512}\x03\x02\x02\x02\u{515}\u{518}\x03\x02\x02\x02\u{516}\
	\u{514}\x03\x02\x02\x02\u{516}\u{517}\x03\x02\x02\x02\u{517}\x41\x03\x02\
	\x02\x02\u{518}\u{516}\x03\x02\x02\x02\u{519}\u{51a}\x07\u{168}\x02\x02\
	\u{51a}\u{51b}\x05\u{38c}\u{1c7}\x02\u{51b}\x43\x03\x02\x02\x02\u{51c}\u{51d}\
	\x07\u{166}\x02\x02\u{51d}\u{51e}\x05\u{38c}\u{1c7}\x02\u{51e}\x45\x03\x02\
	\x02\x02\u{51f}\u{520}\x07\x63\x02\x02\u{520}\u{522}\x05\x5c\x2f\x02\u{521}\
	\u{523}\x05\x28\x15\x02\u{522}\u{521}\x03\x02\x02\x02\u{522}\u{523}\x03\
	\x02\x02\x02\u{523}\u{524}\x03\x02\x02\x02\u{524}\u{526}\x05\u{38c}\u{1c7}\
	\x02\u{525}\u{527}\x05\x2a\x16\x02\u{526}\u{525}\x03\x02\x02\x02\u{526}\
	\u{527}\x03\x02\x02\x02\u{527}\x47\x03\x02\x02\x02\u{528}\u{529}\x07\x31\
	\x02\x02\u{529}\u{52a}\x07\u{19d}\x02\x02\u{52a}\x49\x03\x02\x02\x02\u{52b}\
	\u{52d}\x07\u{155}\x02\x02\u{52c}\u{52e}\x07\u{13f}\x02\x02\u{52d}\u{52c}\
	\x03\x02\x02\x02\u{52d}\u{52e}\x03\x02\x02\x02\u{52e}\u{52f}\x03\x02\x02\
	\x02\u{52f}\u{535}\x05\u{21c}\u{10f}\x02\u{530}\u{531}\x07\x30\x02\x02\u{531}\
	\u{532}\x07\u{183}\x02\x02\u{532}\u{533}\x05\u{118}\u{8d}\x02\u{533}\u{534}\
	\x07\u{184}\x02\x02\u{534}\u{536}\x03\x02\x02\x02\u{535}\u{530}\x03\x02\
	\x02\x02\u{535}\u{536}\x03\x02\x02\x02\u{536}\u{538}\x03\x02\x02\x02\u{537}\
	\u{539}\x05\x2e\x18\x02\u{538}\u{537}\x03\x02\x02\x02\u{538}\u{539}\x03\
	\x02\x02\x02\u{539}\x4b\x03\x02\x02\x02\u{53a}\u{53b}\x07\x63\x02\x02\u{53b}\
	\u{53d}\x07\u{13f}\x02\x02\u{53c}\u{53e}\x05\x28\x15\x02\u{53d}\u{53c}\x03\
	\x02\x02\x02\u{53d}\u{53e}\x03\x02\x02\x02\u{53e}\u{53f}\x03\x02\x02\x02\
	\u{53f}\u{541}\x05\u{28c}\u{147}\x02\u{540}\u{542}\x07\u{f6}\x02\x02\u{541}\
	\u{540}\x03\x02\x02\x02\u{541}\u{542}\x03\x02\x02\x02\u{542}\u{544}\x03\
	\x02\x02\x02\u{543}\u{545}\x05\x12\x0a\x02\u{544}\u{543}\x03\x02\x02\x02\
	\u{544}\u{545}\x03\x02\x02\x02\u{545}\x4d\x03\x02\x02\x02\u{546}\u{547}\
	\x07\u{9b}\x02\x02\u{547}\u{548}\x07\u{19d}\x02\x02\u{548}\u{549}\x07\u{123}\
	\x02\x02\u{549}\u{54a}\x07\u{19d}\x02\x02\u{54a}\x4f\x03\x02\x02\x02\u{54b}\
	\u{54e}\x05\u{38c}\u{1c7}\x02\u{54c}\u{54d}\x07\u{17f}\x02\x02\u{54d}\u{54f}\
	\x05\u{38c}\u{1c7}\x02\u{54e}\u{54c}\x03\x02\x02\x02\u{54e}\u{54f}\x03\x02\
	\x02\x02\u{54f}\u{55d}\x03\x02\x02\x02\u{550}\u{55a}\x05\u{38c}\u{1c7}\x02\
	\u{551}\u{556}\x07\u{17f}\x02\x02\u{552}\u{557}\x07\x65\x02\x02\u{553}\u{557}\
	\x07\u{a9}\x02\x02\u{554}\u{557}\x07\u{16d}\x02\x02\u{555}\u{557}\x05\u{38c}\
	\u{1c7}\x02\u{556}\u{552}\x03\x02\x02\x02\u{556}\u{553}\x03\x02\x02\x02\
	\u{556}\u{554}\x03\x02\x02\x02\u{556}\u{555}\x03\x02\x02\x02\u{557}\u{559}\
	\x03\x02\x02\x02\u{558}\u{551}\x03\x02\x02\x02\u{559}\u{55c}\x03\x02\x02\
	\x02\u{55a}\u{558}\x03\x02\x02\x02\u{55a}\u{55b}\x03\x02\x02\x02\u{55b}\
	\u{55e}\x03\x02\x02\x02\u{55c}\u{55a}\x03\x02\x02\x02\u{55d}\u{550}\x03\
	\x02\x02\x02\u{55d}\u{55e}\x03\x02\x02\x02\u{55e}\x51\x03\x02\x02\x02\u{55f}\
	\u{561}\x05\x50\x29\x02\u{560}\u{562}\x05\u{37c}\u{1bf}\x02\u{561}\u{560}\
	\x03\x02\x02\x02\u{561}\u{562}\x03\x02\x02\x02\u{562}\x53\x03\x02\x02\x02\
	\u{563}\u{565}\x05\u{28c}\u{147}\x02\u{564}\u{566}\x05\u{37c}\u{1bf}\x02\
	\u{565}\u{564}\x03\x02\x02\x02\u{565}\u{566}\x03\x02\x02\x02\u{566}\u{568}\
	\x03\x02\x02\x02\u{567}\u{569}\x05\u{11c}\u{8f}\x02\u{568}\u{567}\x03\x02\
	\x02\x02\u{568}\u{569}\x03\x02\x02\x02\u{569}\x55\x03\x02\x02\x02\u{56a}\
	\u{581}\x09\x05\x02\x02\u{56b}\u{56d}\x05\x5c\x2f\x02\u{56c}\u{56e}\x07\
	\x76\x02\x02\u{56d}\u{56c}\x03\x02\x02\x02\u{56d}\u{56e}\x03\x02\x02\x02\
	\u{56e}\u{56f}\x03\x02\x02\x02\u{56f}\u{570}\x05\u{38c}\u{1c7}\x02\u{570}\
	\u{582}\x03\x02\x02\x02\u{571}\u{573}\x07\x47\x02\x02\u{572}\u{574}\x07\
	\x76\x02\x02\u{573}\u{572}\x03\x02\x02\x02\u{573}\u{574}\x03\x02\x02\x02\
	\u{574}\u{575}\x03\x02\x02\x02\u{575}\u{582}\x05\u{38c}\u{1c7}\x02\u{576}\
	\u{578}\x07\u{89}\x02\x02\u{577}\u{579}\x07\x76\x02\x02\u{578}\u{577}\x03\
	\x02\x02\x02\u{578}\u{579}\x03\x02\x02\x02\u{579}\u{57a}\x03\x02\x02\x02\
	\u{57a}\u{582}\x05\u{38a}\u{1c6}\x02\u{57b}\u{57e}\x07\u{86}\x02\x02\u{57c}\
	\u{57e}\x07\x76\x02\x02\u{57d}\u{57b}\x03\x02\x02\x02\u{57d}\u{57c}\x03\
	\x02\x02\x02\u{57e}\u{57f}\x03\x02\x02\x02\u{57f}\u{582}\x05\x54\x2b\x02\
	\u{580}\u{582}\x05\x54\x2b\x02\u{581}\u{56b}\x03\x02\x02\x02\u{581}\u{571}\
	\x03\x02\x02\x02\u{581}\u{576}\x03\x02\x02\x02\u{581}\u{57d}\x03\x02\x02\
	\x02\u{581}\u{580}\x03\x02\x02\x02\u{582}\x57\x03\x02\x02\x02\u{583}\u{584}\
	\x07\x0c\x02\x02\u{584}\u{585}\x07\u{13f}\x02\x02\u{585}\u{592}\x05\u{37a}\
	\u{1be}\x02\u{586}\u{587}\x07\x36\x02\x02\u{587}\u{58e}\x07\u{135}\x02\x02\
	\u{588}\u{58f}\x07\u{ce}\x02\x02\u{589}\u{58a}\x07\u{82}\x02\x02\u{58a}\
	\u{58c}\x07\x30\x02\x02\u{58b}\u{58d}\x05\u{118}\u{8d}\x02\u{58c}\u{58b}\
	\x03\x02\x02\x02\u{58c}\u{58d}\x03\x02\x02\x02\u{58d}\u{58f}\x03\x02\x02\
	\x02\u{58e}\u{588}\x03\x02\x02\x02\u{58e}\u{589}\x03\x02\x02\x02\u{58e}\
	\u{58f}\x03\x02\x02\x02\u{58f}\u{593}\x03\x02\x02\x02\u{590}\u{591}\x07\
	\x23\x02\x02\u{591}\u{593}\x07\u{c5}\x02\x02\u{592}\u{586}\x03\x02\x02\x02\
	\u{592}\u{590}\x03\x02\x02\x02\u{593}\x59\x03\x02\x02\x02\u{594}\u{595}\
	\x09\x06\x02\x02\u{595}\x5b\x03\x02\x02\x02\u{596}\u{597}\x09\x07\x02\x02\
	\u{597}\x5d\x03\x02\x02\x02\u{598}\u{599}\x07\u{12a}\x02\x02\u{599}\u{59c}\
	\x09\x08\x02\x02\u{59a}\u{59b}\x07\u{b1}\x02\x02\u{59b}\u{59d}\x05\u{d8}\
	\x6d\x02\u{59c}\u{59a}\x03\x02\x02\x02\u{59c}\u{59d}\x03\x02\x02\x02\u{59d}\
	\u{64e}\x03\x02\x02\x02\u{59e}\u{5a0}\x07\u{12a}\x02\x02\u{59f}\u{5a1}\x07\
	\x76\x02\x02\u{5a0}\u{59f}\x03\x02\x02\x02\u{5a0}\u{5a1}\x03\x02\x02\x02\
	\u{5a1}\u{5a2}\x03\x02\x02\x02\u{5a2}\u{5a6}\x07\u{140}\x02\x02\u{5a3}\u{5a4}\
	\x05\x5a\x2e\x02\u{5a4}\u{5a5}\x05\u{38c}\u{1c7}\x02\u{5a5}\u{5a7}\x03\x02\
	\x02\x02\u{5a6}\u{5a3}\x03\x02\x02\x02\u{5a6}\u{5a7}\x03\x02\x02\x02\u{5a7}\
	\u{5a9}\x03\x02\x02\x02\u{5a8}\u{5aa}\x05\x60\x31\x02\u{5a9}\u{5a8}\x03\
	\x02\x02\x02\u{5a9}\u{5aa}\x03\x02\x02\x02\u{5aa}\u{64e}\x03\x02\x02\x02\
	\u{5ab}\u{5ac}\x07\u{12a}\x02\x02\u{5ac}\u{5b0}\x07\u{171}\x02\x02\u{5ad}\
	\u{5ae}\x05\x5a\x2e\x02\u{5ae}\u{5af}\x05\u{38c}\u{1c7}\x02\u{5af}\u{5b1}\
	\x03\x02\x02\x02\u{5b0}\u{5ad}\x03\x02\x02\x02\u{5b0}\u{5b1}\x03\x02\x02\
	\x02\u{5b1}\u{5b5}\x03\x02\x02\x02\u{5b2}\u{5b3}\x07\u{b1}\x02\x02\u{5b3}\
	\u{5b6}\x05\u{d8}\x6d\x02\u{5b4}\u{5b6}\x05\u{d8}\x6d\x02\u{5b5}\u{5b2}\
	\x03\x02\x02\x02\u{5b5}\u{5b4}\x03\x02\x02\x02\u{5b5}\u{5b6}\x03\x02\x02\
	\x02\u{5b6}\u{64e}\x03\x02\x02\x02\u{5b7}\u{5b8}\x07\u{12a}\x02\x02\u{5b8}\
	\u{5b9}\x07\u{c3}\x02\x02\u{5b9}\u{5bd}\x07\u{171}\x02\x02\u{5ba}\u{5bb}\
	\x05\x5a\x2e\x02\u{5bb}\u{5bc}\x05\u{38c}\u{1c7}\x02\u{5bc}\u{5be}\x03\x02\
	\x02\x02\u{5bd}\u{5ba}\x03\x02\x02\x02\u{5bd}\u{5be}\x03\x02\x02\x02\u{5be}\
	\u{5c2}\x03\x02\x02\x02\u{5bf}\u{5c0}\x07\u{b1}\x02\x02\u{5c0}\u{5c3}\x05\
	\u{d8}\x6d\x02\u{5c1}\u{5c3}\x05\u{d8}\x6d\x02\u{5c2}\u{5bf}\x03\x02\x02\
	\x02\u{5c2}\u{5c1}\x03\x02\x02\x02\u{5c2}\u{5c3}\x03\x02\x02\x02\u{5c3}\
	\u{64e}\x03\x02\x02\x02\u{5c4}\u{5c6}\x07\u{12a}\x02\x02\u{5c5}\u{5c7}\x07\
	\u{131}\x02\x02\u{5c6}\u{5c5}\x03\x02\x02\x02\u{5c6}\u{5c7}\x03\x02\x02\
	\x02\u{5c7}\u{5c8}\x03\x02\x02\x02\u{5c8}\u{5c9}\x07\x30\x02\x02\u{5c9}\
	\u{5ca}\x05\x5a\x2e\x02\u{5ca}\u{5ce}\x05\u{28c}\u{147}\x02\u{5cb}\u{5cc}\
	\x05\x5a\x2e\x02\u{5cc}\u{5cd}\x05\u{38c}\u{1c7}\x02\u{5cd}\u{5cf}\x03\x02\
	\x02\x02\u{5ce}\u{5cb}\x03\x02\x02\x02\u{5ce}\u{5cf}\x03\x02\x02\x02\u{5cf}\
	\u{5d3}\x03\x02\x02\x02\u{5d0}\u{5d1}\x07\u{b1}\x02\x02\u{5d1}\u{5d4}\x05\
	\u{d8}\x6d\x02\u{5d2}\u{5d4}\x05\u{d8}\x6d\x02\u{5d3}\u{5d0}\x03\x02\x02\
	\x02\u{5d3}\u{5d2}\x03\x02\x02\x02\u{5d3}\u{5d4}\x03\x02\x02\x02\u{5d4}\
	\u{64e}\x03\x02\x02\x02\u{5d5}\u{5d6}\x07\u{12a}\x02\x02\u{5d6}\u{5d9}\x07\
	\u{8a}\x02\x02\u{5d7}\u{5d8}\x07\u{b1}\x02\x02\u{5d8}\u{5da}\x05\u{d6}\x6c\
	\x02\u{5d9}\u{5d7}\x03\x02\x02\x02\u{5d9}\u{5da}\x03\x02\x02\x02\u{5da}\
	\u{64e}\x03\x02\x02\x02\u{5db}\u{5dc}\x07\u{12a}\x02\x02\u{5dc}\u{5dd}\x07\
	\u{e6}\x02\x02\u{5dd}\u{5df}\x05\u{28c}\u{147}\x02\u{5de}\u{5e0}\x05\u{37c}\
	\u{1bf}\x02\u{5df}\u{5de}\x03\x02\x02\x02\u{5df}\u{5e0}\x03\x02\x02\x02\
	\u{5e0}\u{5e2}\x03\x02\x02\x02\u{5e1}\u{5e3}\x05\u{298}\u{14d}\x02\u{5e2}\
	\u{5e1}\x03\x02\x02\x02\u{5e2}\u{5e3}\x03\x02\x02\x02\u{5e3}\u{5e5}\x03\
	\x02\x02\x02\u{5e4}\u{5e6}\x05\u{2f0}\u{179}\x02\u{5e5}\u{5e4}\x03\x02\x02\
	\x02\u{5e5}\u{5e6}\x03\x02\x02\x02\u{5e6}\u{5e8}\x03\x02\x02\x02\u{5e7}\
	\u{5e9}\x05\u{1a2}\u{d2}\x02\u{5e8}\u{5e7}\x03\x02\x02\x02\u{5e8}\u{5e9}\
	\x03\x02\x02\x02\u{5e9}\u{64e}\x03\x02\x02\x02\u{5ea}\u{5eb}\x07\u{12a}\
	\x02\x02\u{5eb}\u{5f1}\x07\x3c\x02\x02\u{5ec}\u{5ed}\x05\x5c\x2f\x02\u{5ed}\
	\u{5ee}\x05\u{38c}\u{1c7}\x02\u{5ee}\u{5f2}\x03\x02\x02\x02\u{5ef}\u{5f0}\
	\x07\u{13f}\x02\x02\u{5f0}\u{5f2}\x05\u{28c}\u{147}\x02\u{5f1}\u{5ec}\x03\
	\x02\x02\x02\u{5f1}\u{5ef}\x03\x02\x02\x02\u{5f2}\u{64e}\x03\x02\x02\x02\
	\u{5f3}\u{5f4}\x07\u{12a}\x02\x02\u{5f4}\u{5f5}\x07\u{13f}\x02\x02\u{5f5}\
	\u{5f9}\x07\x76\x02\x02\u{5f6}\u{5f7}\x05\x5a\x2e\x02\u{5f7}\u{5f8}\x05\
	\u{38c}\u{1c7}\x02\u{5f8}\u{5fa}\x03\x02\x02\x02\u{5f9}\u{5f6}\x03\x02\x02\
	\x02\u{5f9}\u{5fa}\x03\x02\x02\x02\u{5fa}\u{5fb}\x03\x02\x02\x02\u{5fb}\
	\u{5fc}\x07\u{b1}\x02\x02\u{5fc}\u{5fe}\x05\u{d8}\x6d\x02\u{5fd}\u{5ff}\
	\x05\u{37c}\u{1bf}\x02\u{5fe}\u{5fd}\x03\x02\x02\x02\u{5fe}\u{5ff}\x03\x02\
	\x02\x02\u{5ff}\u{64e}\x03\x02\x02\x02\u{600}\u{601}\x07\u{12a}\x02\x02\
	\u{601}\u{602}\x07\u{142}\x02\x02\u{602}\u{606}\x05\u{28c}\u{147}\x02\u{603}\
	\u{604}\x07\u{183}\x02\x02\u{604}\u{605}\x07\u{19d}\x02\x02\u{605}\u{607}\
	\x07\u{184}\x02\x02\u{606}\u{603}\x03\x02\x02\x02\u{606}\u{607}\x03\x02\
	\x02\x02\u{607}\u{64e}\x03\x02\x02\x02\u{608}\u{609}\x07\u{12a}\x02\x02\
	\u{609}\u{615}\x07\u{b8}\x02\x02\u{60a}\u{60b}\x05\x5c\x2f\x02\u{60b}\u{60d}\
	\x05\u{38c}\u{1c7}\x02\u{60c}\u{60e}\x07\x76\x02\x02\u{60d}\u{60c}\x03\x02\
	\x02\x02\u{60d}\u{60e}\x03\x02\x02\x02\u{60e}\u{616}\x03\x02\x02\x02\u{60f}\
	\u{611}\x05\x52\x2a\x02\u{610}\u{60f}\x03\x02\x02\x02\u{610}\u{611}\x03\
	\x02\x02\x02\u{611}\u{613}\x03\x02\x02\x02\u{612}\u{614}\x07\x76\x02\x02\
	\u{613}\u{612}\x03\x02\x02\x02\u{613}\u{614}\x03\x02\x02\x02\u{614}\u{616}\
	\x03\x02\x02\x02\u{615}\u{60a}\x03\x02\x02\x02\u{615}\u{610}\x03\x02\x02\
	\x02\u{616}\u{64e}\x03\x02\x02\x02\u{617}\u{618}\x07\u{12a}\x02\x02\u{618}\
	\u{63d}\x07\x34\x02\x02\u{619}\u{63e}\x05\u{1d2}\u{ea}\x02\u{61a}\u{61b}\
	\x05\x5c\x2f\x02\u{61b}\u{61d}\x05\u{38c}\u{1c7}\x02\u{61c}\u{61e}\x05\u{1d4}\
	\u{eb}\x02\u{61d}\u{61c}\x03\x02\x02\x02\u{61d}\u{61e}\x03\x02\x02\x02\u{61e}\
	\u{620}\x03\x02\x02\x02\u{61f}\u{621}\x05\u{1d6}\u{ec}\x02\u{620}\u{61f}\
	\x03\x02\x02\x02\u{620}\u{621}\x03\x02\x02\x02\u{621}\u{623}\x03\x02\x02\
	\x02\u{622}\u{624}\x05\u{1d8}\u{ed}\x02\u{623}\u{622}\x03\x02\x02\x02\u{623}\
	\u{624}\x03\x02\x02\x02\u{624}\u{626}\x03\x02\x02\x02\u{625}\u{627}\x05\
	\u{2f0}\u{179}\x02\u{626}\u{625}\x03\x02\x02\x02\u{626}\u{627}\x03\x02\x02\
	\x02\u{627}\u{629}\x03\x02\x02\x02\u{628}\u{62a}\x05\u{1a2}\u{d2}\x02\u{629}\
	\u{628}\x03\x02\x02\x02\u{629}\u{62a}\x03\x02\x02\x02\u{62a}\u{63e}\x03\
	\x02\x02\x02\u{62b}\u{62d}\x05\x52\x2a\x02\u{62c}\u{62b}\x03\x02\x02\x02\
	\u{62c}\u{62d}\x03\x02\x02\x02\u{62d}\u{62f}\x03\x02\x02\x02\u{62e}\u{630}\
	\x05\u{1d4}\u{eb}\x02\u{62f}\u{62e}\x03\x02\x02\x02\u{62f}\u{630}\x03\x02\
	\x02\x02\u{630}\u{632}\x03\x02\x02\x02\u{631}\u{633}\x05\u{1d6}\u{ec}\x02\
	\u{632}\u{631}\x03\x02\x02\x02\u{632}\u{633}\x03\x02\x02\x02\u{633}\u{635}\
	\x03\x02\x02\x02\u{634}\u{636}\x05\u{1d8}\u{ed}\x02\u{635}\u{634}\x03\x02\
	\x02\x02\u{635}\u{636}\x03\x02\x02\x02\u{636}\u{638}\x03\x02\x02\x02\u{637}\
	\u{639}\x05\u{2f0}\u{179}\x02\u{638}\u{637}\x03\x02\x02\x02\u{638}\u{639}\
	\x03\x02\x02\x02\u{639}\u{63b}\x03\x02\x02\x02\u{63a}\u{63c}\x05\u{1a2}\
	\u{d2}\x02\u{63b}\u{63a}\x03\x02\x02\x02\u{63b}\u{63c}\x03\x02\x02\x02\u{63c}\
	\u{63e}\x03\x02\x02\x02\u{63d}\u{619}\x03\x02\x02\x02\u{63d}\u{61a}\x03\
	\x02\x02\x02\u{63d}\u{62c}\x03\x02\x02\x02\u{63e}\u{64e}\x03\x02\x02\x02\
	\u{63f}\u{640}\x07\u{12a}\x02\x02\u{640}\u{64e}\x07\u{150}\x02\x02\u{641}\
	\u{642}\x07\u{12a}\x02\x02\u{642}\u{643}\x07\x38\x02\x02\u{643}\u{64e}\x07\
	\u{19d}\x02\x02\u{644}\u{645}\x07\u{12a}\x02\x02\u{645}\u{649}\x07\u{10f}\
	\x02\x02\u{646}\u{647}\x07\u{ea}\x02\x02\u{647}\u{64a}\x05\u{38c}\u{1c7}\
	\x02\u{648}\u{64a}\x07\u{eb}\x02\x02\u{649}\u{646}\x03\x02\x02\x02\u{649}\
	\u{648}\x03\x02\x02\x02\u{64a}\u{64e}\x03\x02\x02\x02\u{64b}\u{64c}\x07\
	\u{12a}\x02\x02\u{64c}\u{64e}\x07\x48\x02\x02\u{64d}\u{598}\x03\x02\x02\
	\x02\u{64d}\u{59e}\x03\x02\x02\x02\u{64d}\u{5ab}\x03\x02\x02\x02\u{64d}\
	\u{5b7}\x03\x02\x02\x02\u{64d}\u{5c4}\x03\x02\x02\x02\u{64d}\u{5d5}\x03\
	\x02\x02\x02\u{64d}\u{5db}\x03\x02\x02\x02\u{64d}\u{5ea}\x03\x02\x02\x02\
	\u{64d}\u{5f3}\x03\x02\x02\x02\u{64d}\u{600}\x03\x02\x02\x02\u{64d}\u{608}\
	\x03\x02\x02\x02\u{64d}\u{617}\x03\x02\x02\x02\u{64d}\u{63f}\x03\x02\x02\
	\x02\u{64d}\u{641}\x03\x02\x02\x02\u{64d}\u{644}\x03\x02\x02\x02\u{64d}\
	\u{64b}\x03\x02\x02\x02\u{64e}\x5f\x03\x02\x02\x02\u{64f}\u{650}\x07\u{175}\
	\x02\x02\u{650}\u{651}\x05\u{38c}\u{1c7}\x02\u{651}\u{652}\x07\u{189}\x02\
	\x02\u{652}\u{653}\x07\u{19d}\x02\x02\u{653}\u{658}\x03\x02\x02\x02\u{654}\
	\u{655}\x07\u{b1}\x02\x02\u{655}\u{658}\x05\u{d8}\x6d\x02\u{656}\u{658}\
	\x05\u{d8}\x6d\x02\u{657}\u{64f}\x03\x02\x02\x02\u{657}\u{654}\x03\x02\x02\
	\x02\u{657}\u{656}\x03\x02\x02\x02\u{658}\x61\x03\x02\x02\x02\u{659}\u{65a}\
	\x07\u{b7}\x02\x02\u{65a}\u{65b}\x07\u{13f}\x02\x02\u{65b}\u{65d}\x05\u{28c}\
	\u{147}\x02\u{65c}\u{65e}\x05\u{37c}\u{1bf}\x02\u{65d}\u{65c}\x03\x02\x02\
	\x02\u{65d}\u{65e}\x03\x02\x02\x02\u{65e}\u{65f}\x03\x02\x02\x02\u{65f}\
	\u{660}\x05\x66\x34\x02\u{660}\x63\x03\x02\x02\x02\u{661}\u{662}\x07\u{b7}\
	\x02\x02\u{662}\u{663}\x05\x5c\x2f\x02\u{663}\u{664}\x05\u{38c}\u{1c7}\x02\
	\u{664}\u{665}\x05\x66\x34\x02\u{665}\x65\x03\x02\x02\x02\u{666}\u{667}\
	\x09\x09\x02\x02\u{667}\x67\x03\x02\x02\x02\u{668}\u{669}\x07\u{15f}\x02\
	\x02\u{669}\u{66a}\x07\u{13f}\x02\x02\u{66a}\u{66c}\x05\u{28c}\u{147}\x02\
	\u{66b}\u{66d}\x05\u{37c}\u{1bf}\x02\u{66c}\u{66b}\x03\x02\x02\x02\u{66c}\
	\u{66d}\x03\x02\x02\x02\u{66d}\x69\x03\x02\x02\x02\u{66e}\u{66f}\x07\u{15f}\
	\x02\x02\u{66f}\u{670}\x05\x5c\x2f\x02\u{670}\u{671}\x05\u{38c}\u{1c7}\x02\
	\u{671}\x6b\x03\x02\x02\x02\u{672}\u{673}\x07\x3c\x02\x02\u{673}\u{674}\
	\x07\u{116}\x02\x02\u{674}\u{675}\x05\u{38c}\u{1c7}\x02\u{675}\x6d\x03\x02\
	\x02\x02\u{676}\u{677}\x07\x63\x02\x02\u{677}\u{678}\x07\u{116}\x02\x02\
	\u{678}\u{679}\x05\u{38c}\u{1c7}\x02\u{679}\x6f\x03\x02\x02\x02\u{67a}\u{67b}\
	\x07\u{8b}\x02\x02\u{67b}\u{67d}\x05\u{8c}\x47\x02\u{67c}\u{67e}\x05\u{86}\
	\x44\x02\u{67d}\u{67c}\x03\x02\x02\x02\u{67d}\u{67e}\x03\x02\x02\x02\u{67e}\
	\u{67f}\x03\x02\x02\x02\u{67f}\u{680}\x07\u{14b}\x02\x02\u{680}\u{682}\x05\
	\u{92}\x4a\x02\u{681}\u{683}\x05\u{96}\x4c\x02\u{682}\u{681}\x03\x02\x02\
	\x02\u{682}\u{683}\x03\x02\x02\x02\u{683}\x71\x03\x02\x02\x02\u{684}\u{686}\
	\x07\u{112}\x02\x02\u{685}\u{687}\x05\u{98}\x4d\x02\u{686}\u{685}\x03\x02\
	\x02\x02\u{686}\u{687}\x03\x02\x02\x02\u{687}\u{688}\x03\x02\x02\x02\u{688}\
	\u{68a}\x05\u{8c}\x47\x02\u{689}\u{68b}\x05\u{86}\x44\x02\u{68a}\u{689}\
	\x03\x02\x02\x02\u{68a}\u{68b}\x03\x02\x02\x02\u{68b}\u{68c}\x03\x02\x02\
	\x02\u{68c}\u{68d}\x07\u{87}\x02\x02\u{68d}\u{68e}\x05\u{92}\x4a\x02\u{68e}\
	\x73\x03\x02\x02\x02\u{68f}\u{691}\x07\u{8b}\x02\x02\u{690}\u{692}\x07\u{116}\
	\x02\x02\u{691}\u{690}\x03\x02\x02\x02\u{691}\u{692}\x03\x02\x02\x02\u{692}\
	\u{693}\x03\x02\x02\x02\u{693}\u{698}\x05\u{38c}\u{1c7}\x02\u{694}\u{695}\
	\x07\u{181}\x02\x02\u{695}\u{697}\x05\u{38c}\u{1c7}\x02\u{696}\u{694}\x03\
	\x02\x02\x02\u{697}\u{69a}\x03\x02\x02\x02\u{698}\u{696}\x03\x02\x02\x02\
	\u{698}\u{699}\x03\x02\x02\x02\u{699}\u{69b}\x03\x02\x02\x02\u{69a}\u{698}\
	\x03\x02\x02\x02\u{69b}\u{69c}\x07\u{14b}\x02\x02\u{69c}\u{69e}\x05\u{92}\
	\x4a\x02\u{69d}\u{69f}\x05\u{9c}\x4f\x02\u{69e}\u{69d}\x03\x02\x02\x02\u{69e}\
	\u{69f}\x03\x02\x02\x02\u{69f}\x75\x03\x02\x02\x02\u{6a0}\u{6a2}\x07\u{112}\
	\x02\x02\u{6a1}\u{6a3}\x05\u{9a}\x4e\x02\u{6a2}\u{6a1}\x03\x02\x02\x02\u{6a2}\
	\u{6a3}\x03\x02\x02\x02\u{6a3}\u{6a5}\x03\x02\x02\x02\u{6a4}\u{6a6}\x07\
	\u{116}\x02\x02\u{6a5}\u{6a4}\x03\x02\x02\x02\u{6a5}\u{6a6}\x03\x02\x02\
	\x02\u{6a6}\u{6a7}\x03\x02\x02\x02\u{6a7}\u{6ac}\x05\u{38c}\u{1c7}\x02\u{6a8}\
	\u{6a9}\x07\u{181}\x02\x02\u{6a9}\u{6ab}\x05\u{38c}\u{1c7}\x02\u{6aa}\u{6a8}\
	\x03\x02\x02\x02\u{6ab}\u{6ae}\x03\x02\x02\x02\u{6ac}\u{6aa}\x03\x02\x02\
	\x02\u{6ac}\u{6ad}\x03\x02\x02\x02\u{6ad}\u{6af}\x03\x02\x02\x02\u{6ae}\
	\u{6ac}\x03\x02\x02\x02\u{6af}\u{6b0}\x07\u{87}\x02\x02\u{6b0}\u{6b1}\x05\
	\u{92}\x4a\x02\u{6b1}\x77\x03\x02\x02\x02\u{6b2}\u{6b3}\x07\u{12a}\x02\x02\
	\u{6b3}\u{6b4}\x07\u{116}\x02\x02\u{6b4}\u{6b5}\x07\u{8b}\x02\x02\u{6b5}\
	\u{6b6}\x05\u{94}\x4b\x02\u{6b6}\x79\x03\x02\x02\x02\u{6b7}\u{6b8}\x07\u{12a}\
	\x02\x02\u{6b8}\u{6b9}\x07\u{117}\x02\x02\u{6b9}\x7b\x03\x02\x02\x02\u{6ba}\
	\u{6bb}\x07\u{12a}\x02\x02\u{6bb}\u{6bc}\x07\x40\x02\x02\u{6bc}\u{6bd}\x07\
	\u{117}\x02\x02\u{6bd}\x7d\x03\x02\x02\x02\u{6be}\u{6bf}\x07\u{126}\x02\
	\x02\u{6bf}\u{6c3}\x07\u{116}\x02\x02\u{6c0}\u{6c4}\x07\x09\x02\x02\u{6c1}\
	\u{6c4}\x07\u{cc}\x02\x02\u{6c2}\u{6c4}\x05\u{38c}\u{1c7}\x02\u{6c3}\u{6c0}\
	\x03\x02\x02\x02\u{6c3}\u{6c1}\x03\x02\x02\x02\u{6c3}\u{6c2}\x03\x02\x02\
	\x02\u{6c4}\x7f\x03\x02\x02\x02\u{6c5}\u{6c6}\x07\u{12a}\x02\x02\u{6c6}\
	\u{6c8}\x07\u{8b}\x02\x02\u{6c7}\u{6c9}\x05\u{94}\x4b\x02\u{6c8}\u{6c7}\
	\x03\x02\x02\x02\u{6c8}\u{6c9}\x03\x02\x02\x02\u{6c9}\u{6cc}\x03\x02\x02\
	\x02\u{6ca}\u{6cb}\x07\u{d7}\x02\x02\u{6cb}\u{6cd}\x05\u{84}\x43\x02\u{6cc}\
	\u{6ca}\x03\x02\x02\x02\u{6cc}\u{6cd}\x03\x02\x02\x02\u{6cd}\u{81}\x03\x02\
	\x02\x02\u{6ce}\u{6cf}\x07\u{12a}\x02\x02\u{6cf}\u{6d0}\x07\u{f3}\x02\x02\
	\u{6d0}\u{6d1}\x05\u{38c}\u{1c7}\x02\u{6d1}\u{83}\x03\x02\x02\x02\u{6d2}\
	\u{6d5}\x07\x09\x02\x02\u{6d3}\u{6d5}\x05\u{8a}\x46\x02\u{6d4}\u{6d2}\x03\
	\x02\x02\x02\u{6d4}\u{6d3}\x03\x02\x02\x02\u{6d5}\u{85}\x03\x02\x02\x02\
	\u{6d6}\u{6d7}\x07\u{d7}\x02\x02\u{6d7}\u{6d8}\x05\u{88}\x45\x02\u{6d8}\
	\u{87}\x03\x02\x02\x02\u{6d9}\u{6da}\x05\x5c\x2f\x02\u{6da}\u{6db}\x05\u{38c}\
	\u{1c7}\x02\u{6db}\u{6e8}\x03\x02\x02\x02\u{6dc}\u{6de}\x07\u{13f}\x02\x02\
	\u{6dd}\u{6dc}\x03\x02\x02\x02\u{6dd}\u{6de}\x03\x02\x02\x02\u{6de}\u{6df}\
	\x03\x02\x02\x02\u{6df}\u{6e1}\x05\u{28c}\u{147}\x02\u{6e0}\u{6e2}\x05\u{37c}\
	\u{1bf}\x02\u{6e1}\u{6e0}\x03\x02\x02\x02\u{6e1}\u{6e2}\x03\x02\x02\x02\
	\u{6e2}\u{6e8}\x03\x02\x02\x02\u{6e3}\u{6e4}\x07\u{164}\x02\x02\u{6e4}\u{6e8}\
	\x07\u{19d}\x02\x02\u{6e5}\u{6e6}\x07\u{125}\x02\x02\u{6e6}\u{6e8}\x05\u{38c}\
	\u{1c7}\x02\u{6e7}\u{6d9}\x03\x02\x02\x02\u{6e7}\u{6dd}\x03\x02\x02\x02\
	\u{6e7}\u{6e3}\x03\x02\x02\x02\u{6e7}\u{6e5}\x03\x02\x02\x02\u{6e8}\u{89}\
	\x03\x02\x02\x02\u{6e9}\u{6ea}\x05\x5c\x2f\x02\u{6ea}\u{6eb}\x05\u{38c}\
	\u{1c7}\x02\u{6eb}\u{6fe}\x03\x02\x02\x02\u{6ec}\u{6ee}\x07\u{13f}\x02\x02\
	\u{6ed}\u{6ec}\x03\x02\x02\x02\u{6ed}\u{6ee}\x03\x02\x02\x02\u{6ee}\u{6ef}\
	\x03\x02\x02\x02\u{6ef}\u{6f4}\x05\u{28c}\u{147}\x02\u{6f0}\u{6f1}\x07\u{183}\
	\x02\x02\u{6f1}\u{6f2}\x05\u{118}\u{8d}\x02\u{6f2}\u{6f3}\x07\u{184}\x02\
	\x02\u{6f3}\u{6f5}\x03\x02\x02\x02\u{6f4}\u{6f0}\x03\x02\x02\x02\u{6f4}\
	\u{6f5}\x03\x02\x02\x02\u{6f5}\u{6f7}\x03\x02\x02\x02\u{6f6}\u{6f8}\x05\
	\u{37c}\u{1bf}\x02\u{6f7}\u{6f6}\x03\x02\x02\x02\u{6f7}\u{6f8}\x03\x02\x02\
	\x02\u{6f8}\u{6fe}\x03\x02\x02\x02\u{6f9}\u{6fa}\x07\u{164}\x02\x02\u{6fa}\
	\u{6fe}\x07\u{19d}\x02\x02\u{6fb}\u{6fc}\x07\u{125}\x02\x02\u{6fc}\u{6fe}\
	\x05\u{38c}\u{1c7}\x02\u{6fd}\u{6e9}\x03\x02\x02\x02\u{6fd}\u{6ed}\x03\x02\
	\x02\x02\u{6fd}\u{6f9}\x03\x02\x02\x02\u{6fd}\u{6fb}\x03\x02\x02\x02\u{6fe}\
	\u{8b}\x03\x02\x02\x02\u{6ff}\u{704}\x05\u{8e}\x48\x02\u{700}\u{701}\x07\
	\u{181}\x02\x02\u{701}\u{703}\x05\u{8e}\x48\x02\u{702}\u{700}\x03\x02\x02\
	\x02\u{703}\u{706}\x03\x02\x02\x02\u{704}\u{702}\x03\x02\x02\x02\u{704}\
	\u{705}\x03\x02\x02\x02\u{705}\u{8d}\x03\x02\x02\x02\u{706}\u{704}\x03\x02\
	\x02\x02\u{707}\u{70c}\x05\u{90}\x49\x02\u{708}\u{709}\x07\u{183}\x02\x02\
	\u{709}\u{70a}\x05\u{118}\u{8d}\x02\u{70a}\u{70b}\x07\u{184}\x02\x02\u{70b}\
	\u{70d}\x03\x02\x02\x02\u{70c}\u{708}\x03\x02\x02\x02\u{70c}\u{70d}\x03\
	\x02\x02\x02\u{70d}\u{8f}\x03\x02\x02\x02\u{70e}\u{70f}\x09\x0a\x02\x02\
	\u{70f}\u{91}\x03\x02\x02\x02\u{710}\u{715}\x05\u{94}\x4b\x02\u{711}\u{712}\
	\x07\u{181}\x02\x02\u{712}\u{714}\x05\u{94}\x4b\x02\u{713}\u{711}\x03\x02\
	\x02\x02\u{714}\u{717}\x03\x02\x02\x02\u{715}\u{713}\x03\x02\x02\x02\u{715}\
	\u{716}\x03\x02\x02\x02\u{716}\u{93}\x03\x02\x02\x02\u{717}\u{715}\x03\x02\
	\x02\x02\u{718}\u{719}\x07\u{167}\x02\x02\u{719}\u{71f}\x05\u{390}\u{1c9}\
	\x02\u{71a}\u{71b}\x07\u{8c}\x02\x02\u{71b}\u{71f}\x05\u{390}\u{1c9}\x02\
	\u{71c}\u{71d}\x07\u{116}\x02\x02\u{71d}\u{71f}\x05\u{38c}\u{1c7}\x02\u{71e}\
	\u{718}\x03\x02\x02\x02\u{71e}\u{71a}\x03\x02\x02\x02\u{71e}\u{71c}\x03\
	\x02\x02\x02\u{71f}\u{95}\x03\x02\x02\x02\u{720}\u{721}\x07\u{178}\x02\x02\
	\u{721}\u{722}\x07\u{8b}\x02\x02\u{722}\u{723}\x07\u{da}\x02\x02\u{723}\
	\u{97}\x03\x02\x02\x02\u{724}\u{725}\x07\u{8b}\x02\x02\u{725}\u{726}\x07\
	\u{da}\x02\x02\u{726}\u{727}\x07\u{82}\x02\x02\u{727}\u{99}\x03\x02\x02\
	\x02\u{728}\u{729}\x07\x07\x02\x02\u{729}\u{72a}\x07\u{da}\x02\x02\u{72a}\
	\u{72b}\x07\u{82}\x02\x02\u{72b}\u{9b}\x03\x02\x02\x02\u{72c}\u{72d}\x07\
	\u{178}\x02\x02\u{72d}\u{72e}\x07\x07\x02\x02\u{72e}\u{72f}\x07\u{da}\x02\
	\x02\u{72f}\u{9d}\x03\x02\x02\x02\u{730}\u{732}\x07\u{cb}\x02\x02\u{731}\
	\u{733}\x07\u{10b}\x02\x02\u{732}\u{731}\x03\x02\x02\x02\u{732}\u{733}\x03\
	\x02\x02\x02\u{733}\u{734}\x03\x02\x02\x02\u{734}\u{735}\x07\u{13f}\x02\
	\x02\u{735}\u{73b}\x05\u{28c}\u{147}\x02\u{736}\u{737}\x09\x0b\x02\x02\u{737}\
	\u{739}\x07\u{e6}\x02\x02\u{738}\u{73a}\x05\u{380}\u{1c1}\x02\u{739}\u{738}\
	\x03\x02\x02\x02\u{739}\u{73a}\x03\x02\x02\x02\u{73a}\u{73c}\x03\x02\x02\
	\x02\u{73b}\u{736}\x03\x02\x02\x02\u{73b}\u{73c}\x03\x02\x02\x02\u{73c}\
	\u{9f}\x03\x02\x02\x02\u{73d}\u{742}\x05\u{a2}\x52\x02\u{73e}\u{73f}\x07\
	\u{181}\x02\x02\u{73f}\u{741}\x05\u{a2}\x52\x02\u{740}\u{73e}\x03\x02\x02\
	\x02\u{741}\u{744}\x03\x02\x02\x02\u{742}\u{740}\x03\x02\x02\x02\u{742}\
	\u{743}\x03\x02\x02\x02\u{743}\u{a1}\x03\x02\x02\x02\u{744}\u{742}\x03\x02\
	\x02\x02\u{745}\u{746}\x05\u{a4}\x53\x02\u{746}\u{747}\x07\u{19d}\x02\x02\
	\u{747}\u{a3}\x03\x02\x02\x02\u{748}\u{749}\x09\x0c\x02\x02\u{749}\u{a5}\
	\x03\x02\x02\x02\u{74a}\u{74c}\x07\x3c\x02\x02\u{74b}\u{74d}\x07\u{143}\
	\x02\x02\u{74c}\u{74b}\x03\x02\x02\x02\u{74c}\u{74d}\x03\x02\x02\x02\u{74d}\
	\u{74e}\x03\x02\x02\x02\u{74e}\u{74f}\x07\u{89}\x02\x02\u{74f}\u{750}\x05\
	\u{38e}\u{1c8}\x02\u{750}\u{751}\x07\x13\x02\x02\u{751}\u{754}\x07\u{19d}\
	\x02\x02\u{752}\u{753}\x07\u{168}\x02\x02\u{753}\u{755}\x05\u{a0}\x51\x02\
	\u{754}\u{752}\x03\x02\x02\x02\u{754}\u{755}\x03\x02\x02\x02\u{755}\u{a7}\
	\x03\x02\x02\x02\u{756}\u{758}\x07\x63\x02\x02\u{757}\u{759}\x07\u{143}\
	\x02\x02\u{758}\u{757}\x03\x02\x02\x02\u{758}\u{759}\x03\x02\x02\x02\u{759}\
	\u{75a}\x03\x02\x02\x02\u{75a}\u{75c}\x07\u{89}\x02\x02\u{75b}\u{75d}\x05\
	\x28\x15\x02\u{75c}\u{75b}\x03\x02\x02\x02\u{75c}\u{75d}\x03\x02\x02\x02\
	\u{75d}\u{75e}\x03\x02\x02\x02\u{75e}\u{75f}\x05\u{38e}\u{1c8}\x02\u{75f}\
	\u{a9}\x03\x02\x02\x02\u{760}\u{761}\x07\u{106}\x02\x02\u{761}\u{762}\x09\
	\x0d\x02\x02\u{762}\u{ab}\x03\x02\x02\x02\u{763}\u{764}\x07\x3c\x02\x02\
	\u{764}\u{765}\x07\u{143}\x02\x02\u{765}\u{766}\x07\u{bb}\x02\x02\u{766}\
	\u{767}\x07\u{1a3}\x02\x02\u{767}\u{769}\x07\u{183}\x02\x02\u{768}\u{76a}\
	\x05\u{112}\u{8a}\x02\u{769}\u{768}\x03\x02\x02\x02\u{769}\u{76a}\x03\x02\
	\x02\x02\u{76a}\u{76b}\x03\x02\x02\x02\u{76b}\u{76c}\x07\u{184}\x02\x02\
	\u{76c}\u{76d}\x05\u{328}\u{195}\x02\u{76d}\u{ad}\x03\x02\x02\x02\u{76e}\
	\u{76f}\x07\x63\x02\x02\u{76f}\u{770}\x07\u{143}\x02\x02\u{770}\u{772}\x07\
	\u{bb}\x02\x02\u{771}\u{773}\x05\x28\x15\x02\u{772}\u{771}\x03\x02\x02\x02\
	\u{772}\u{773}\x03\x02\x02\x02\u{773}\u{774}\x03\x02\x02\x02\u{774}\u{775}\
	\x07\u{1a3}\x02\x02\u{775}\u{af}\x03\x02\x02\x02\u{776}\u{777}\x07\x3c\x02\
	\x02\u{777}\u{778}\x07\u{96}\x02\x02\u{778}\u{779}\x05\u{38c}\u{1c7}\x02\
	\u{779}\u{77a}\x07\u{d7}\x02\x02\u{77a}\u{77b}\x07\u{13f}\x02\x02\u{77b}\
	\u{77c}\x05\u{28c}\u{147}\x02\u{77c}\u{77d}\x05\u{120}\u{91}\x02\u{77d}\
	\u{77e}\x07\x13\x02\x02\u{77e}\u{782}\x07\u{19d}\x02\x02\u{77f}\u{780}\x07\
	\u{178}\x02\x02\u{780}\u{781}\x07\x53\x02\x02\u{781}\u{783}\x07\u{100}\x02\
	\x02\u{782}\u{77f}\x03\x02\x02\x02\u{782}\u{783}\x03\x02\x02\x02\u{783}\
	\u{786}\x03\x02\x02\x02\u{784}\u{785}\x07\u{91}\x02\x02\u{785}\u{787}\x05\
	\u{fc}\x7f\x02\u{786}\u{784}\x03\x02\x02\x02\u{786}\u{787}\x03\x02\x02\x02\
	\u{787}\u{78b}\x03\x02\x02\x02\u{788}\u{789}\x07\u{95}\x02\x02\u{789}\u{78a}\
	\x07\u{13f}\x02\x02\u{78a}\u{78c}\x05\u{28c}\u{147}\x02\u{78b}\u{788}\x03\
	\x02\x02\x02\u{78b}\u{78c}\x03\x02\x02\x02\u{78c}\u{790}\x03\x02\x02\x02\
	\u{78d}\u{78e}\x07\u{e5}\x02\x02\u{78e}\u{78f}\x07\x22\x02\x02\u{78f}\u{791}\
	\x05\u{120}\u{91}\x02\u{790}\u{78d}\x03\x02\x02\x02\u{790}\u{791}\x03\x02\
	\x02\x02\u{791}\u{796}\x03\x02\x02\x02\u{792}\u{794}\x05\u{f8}\x7d\x02\u{793}\
	\u{792}\x03\x02\x02\x02\u{793}\u{794}\x03\x02\x02\x02\u{794}\u{795}\x03\
	\x02\x02\x02\u{795}\u{797}\x05\u{10e}\u{88}\x02\u{796}\u{793}\x03\x02\x02\
	\x02\u{796}\u{797}\x03\x02\x02\x02\u{797}\u{79a}\x03\x02\x02\x02\u{798}\
	\u{799}\x07\u{b6}\x02\x02\u{799}\u{79b}\x07\u{19d}\x02\x02\u{79a}\u{798}\
	\x03\x02\x02\x02\u{79a}\u{79b}\x03\x02\x02\x02\u{79b}\u{79d}\x03\x02\x02\
	\x02\u{79c}\u{79e}\x05\u{fa}\x7e\x02\u{79d}\u{79c}\x03\x02\x02\x02\u{79d}\
	\u{79e}\x03\x02\x02\x02\u{79e}\u{7a0}\x03\x02\x02\x02\u{79f}\u{7a1}\x05\
	\u{da}\x6e\x02\u{7a0}\u{79f}\x03\x02\x02\x02\u{7a0}\u{7a1}\x03\x02\x02\x02\
	\u{7a1}\u{b1}\x03\x02\x02\x02\u{7a2}\u{7a3}\x07\x63\x02\x02\u{7a3}\u{7a5}\
	\x07\u{96}\x02\x02\u{7a4}\u{7a6}\x05\x28\x15\x02\u{7a5}\u{7a4}\x03\x02\x02\
	\x02\u{7a5}\u{7a6}\x03\x02\x02\x02\u{7a6}\u{7a7}\x03\x02\x02\x02\u{7a7}\
	\u{7a8}\x05\u{38c}\u{1c7}\x02\u{7a8}\u{7a9}\x07\u{d7}\x02\x02\u{7a9}\u{7aa}\
	\x05\u{28c}\u{147}\x02\u{7aa}\u{b3}\x03\x02\x02\x02\u{7ab}\u{7ad}\x07\x3c\
	\x02\x02\u{7ac}\u{7ae}\x05\x36\x1c\x02\u{7ad}\u{7ac}\x03\x02\x02\x02\u{7ad}\
	\u{7ae}\x03\x02\x02\x02\u{7ae}\u{7af}\x03\x02\x02\x02\u{7af}\u{7b1}\x07\
	\u{170}\x02\x02\u{7b0}\u{7b2}\x05\x2c\x17\x02\u{7b1}\u{7b0}\x03\x02\x02\
	\x02\u{7b1}\u{7b2}\x03\x02\x02\x02\u{7b2}\u{7b3}\x03\x02\x02\x02\u{7b3}\
	\u{7b8}\x05\u{28c}\u{147}\x02\u{7b4}\u{7b5}\x07\u{183}\x02\x02\u{7b5}\u{7b6}\
	\x05\u{14c}\u{a7}\x02\u{7b6}\u{7b7}\x07\u{184}\x02\x02\u{7b7}\u{7b9}\x03\
	\x02\x02\x02\u{7b8}\u{7b4}\x03\x02\x02\x02\u{7b8}\u{7b9}\x03\x02\x02\x02\
	\u{7b9}\u{7bb}\x03\x02\x02\x02\u{7ba}\u{7bc}\x05\u{da}\x6e\x02\u{7bb}\u{7ba}\
	\x03\x02\x02\x02\u{7bb}\u{7bc}\x03\x02\x02\x02\u{7bc}\u{7be}\x03\x02\x02\
	\x02\u{7bd}\u{7bf}\x05\u{b6}\x5c\x02\u{7be}\u{7bd}\x03\x02\x02\x02\u{7be}\
	\u{7bf}\x03\x02\x02\x02\u{7bf}\u{7c1}\x03\x02\x02\x02\u{7c0}\u{7c2}\x05\
	\u{fa}\x7e\x02\u{7c1}\u{7c0}\x03\x02\x02\x02\u{7c1}\u{7c2}\x03\x02\x02\x02\
	\u{7c2}\u{7c3}\x03\x02\x02\x02\u{7c3}\u{7c4}\x07\x13\x02\x02\u{7c4}\u{7c5}\
	\x05\u{19a}\u{ce}\x02\u{7c5}\u{b5}\x03\x02\x02\x02\u{7c6}\u{7c7}\x07\u{e5}\
	\x02\x02\u{7c7}\u{7cd}\x07\u{d7}\x02\x02\u{7c8}\u{7c9}\x07\u{183}\x02\x02\
	\u{7c9}\u{7ce}\x05\u{118}\u{8d}\x02\u{7ca}\u{7cb}\x07\u{132}\x02\x02\u{7cb}\
	\u{7cc}\x07\u{183}\x02\x02\u{7cc}\u{7ce}\x05\u{e2}\x72\x02\u{7cd}\u{7c8}\
	\x03\x02\x02\x02\u{7cd}\u{7ca}\x03\x02\x02\x02\u{7ce}\u{7cf}\x03\x02\x02\
	\x02\u{7cf}\u{7d0}\x07\u{184}\x02\x02\u{7d0}\u{b7}\x03\x02\x02\x02\u{7d1}\
	\u{7d4}\x05\u{ba}\x5e\x02\u{7d2}\u{7d4}\x05\u{bc}\x5f\x02\u{7d3}\u{7d1}\
	\x03\x02\x02\x02\u{7d3}\u{7d2}\x03\x02\x02\x02\u{7d4}\u{b9}\x03\x02\x02\
	\x02\u{7d5}\u{7d6}\x07\x2c\x02\x02\u{7d6}\u{7d7}\x07\u{d7}\x02\x02\u{7d7}\
	\u{7d8}\x07\u{183}\x02\x02\u{7d8}\u{7d9}\x05\u{118}\u{8d}\x02\u{7d9}\u{7da}\
	\x07\u{184}\x02\x02\u{7da}\u{bb}\x03\x02\x02\x02\u{7db}\u{7dc}\x05\u{be}\
	\x60\x02\u{7dc}\u{7dd}\x05\u{c0}\x61\x02\u{7dd}\u{bd}\x03\x02\x02\x02\u{7de}\
	\u{7df}\x07\x60\x02\x02\u{7df}\u{7e0}\x07\u{d7}\x02\x02\u{7e0}\u{7e1}\x07\
	\u{183}\x02\x02\u{7e1}\u{7e2}\x05\u{118}\u{8d}\x02\u{7e2}\u{7e3}\x07\u{184}\
	\x02\x02\u{7e3}\u{bf}\x03\x02\x02\x02\u{7e4}\u{7e5}\x07\u{131}\x02\x02\u{7e5}\
	\u{7e6}\x07\u{d7}\x02\x02\u{7e6}\u{7e7}\x07\u{183}\x02\x02\u{7e7}\u{7e8}\
	\x05\u{118}\u{8d}\x02\u{7e8}\u{7e9}\x07\u{184}\x02\x02\u{7e9}\u{c1}\x03\
	\x02\x02\x02\u{7ea}\u{7eb}\x07\x63\x02\x02\u{7eb}\u{7ed}\x07\u{170}\x02\
	\x02\u{7ec}\u{7ee}\x05\x28\x15\x02\u{7ed}\u{7ec}\x03\x02\x02\x02\u{7ed}\
	\u{7ee}\x03\x02\x02\x02\u{7ee}\u{7ef}\x03\x02\x02\x02\u{7ef}\u{7f0}\x05\
	\u{28e}\u{148}\x02\u{7f0}\u{c3}\x03\x02\x02\x02\u{7f1}\u{7f2}\x07\x3c\x02\
	\x02\u{7f2}\u{7f3}\x07\u{c3}\x02\x02\u{7f3}\u{7f5}\x07\u{170}\x02\x02\u{7f4}\
	\u{7f6}\x05\x2c\x17\x02\u{7f5}\u{7f4}\x03\x02\x02\x02\u{7f5}\u{7f6}\x03\
	\x02\x02\x02\u{7f6}\u{7f7}\x03\x02\x02\x02\u{7f7}\u{7f9}\x05\u{28c}\u{147}\
	\x02\u{7f8}\u{7fa}\x05\x32\x1a\x02\u{7f9}\u{7f8}\x03\x02\x02\x02\u{7f9}\
	\u{7fa}\x03\x02\x02\x02\u{7fa}\u{7fc}\x03\x02\x02\x02\u{7fb}\u{7fd}\x05\
	\u{da}\x6e\x02\u{7fc}\u{7fb}\x03\x02\x02\x02\u{7fc}\u{7fd}\x03\x02\x02\x02\
	\u{7fd}\u{7ff}\x03\x02\x02\x02\u{7fe}\u{800}\x05\u{b6}\x5c\x02\u{7ff}\u{7fe}\
	\x03\x02\x02\x02\u{7ff}\u{800}\x03\x02\x02\x02\u{800}\u{802}\x03\x02\x02\
	\x02\u{801}\u{803}\x05\u{b8}\x5d\x02\u{802}\u{801}\x03\x02\x02\x02\u{802}\
	\u{803}\x03\x02\x02\x02\u{803}\u{805}\x03\x02\x02\x02\u{804}\u{806}\x05\
	\u{f8}\x7d\x02\u{805}\u{804}\x03\x02\x02\x02\u{805}\u{806}\x03\x02\x02\x02\
	\u{806}\u{808}\x03\x02\x02\x02\u{807}\u{809}\x05\u{10e}\u{88}\x02\u{808}\
	\u{807}\x03\x02\x02\x02\u{808}\u{809}\x03\x02\x02\x02\u{809}\u{80b}\x03\
	\x02\x02\x02\u{80a}\u{80c}\x05\u{110}\u{89}\x02\u{80b}\u{80a}\x03\x02\x02\
	\x02\u{80b}\u{80c}\x03\x02\x02\x02\u{80c}\u{80e}\x03\x02\x02\x02\u{80d}\
	\u{80f}\x05\u{fa}\x7e\x02\u{80e}\u{80d}\x03\x02\x02\x02\u{80e}\u{80f}\x03\
	\x02\x02\x02\u{80f}\u{810}\x03\x02\x02\x02\u{810}\u{811}\x07\x13\x02\x02\
	\u{811}\u{812}\x05\u{19a}\u{ce}\x02\u{812}\u{c5}\x03\x02\x02\x02\u{813}\
	\u{814}\x07\x63\x02\x02\u{814}\u{815}\x07\u{c3}\x02\x02\u{815}\u{817}\x07\
	\u{170}\x02\x02\u{816}\u{818}\x05\x28\x15\x02\u{817}\u{816}\x03\x02\x02\
	\x02\u{817}\u{818}\x03\x02\x02\x02\u{818}\u{819}\x03\x02\x02\x02\u{819}\
	\u{81a}\x05\u{28e}\u{148}\x02\u{81a}\u{c7}\x03\x02\x02\x02\u{81b}\u{81c}\
	\x07\x3c\x02\x02\u{81c}\u{81d}\x07\u{11c}\x02\x02\u{81d}\u{81e}\x07\u{f9}\
	\x02\x02\u{81e}\u{81f}\x05\u{38c}\u{1c7}\x02\u{81f}\u{821}\x05\u{d0}\x69\
	\x02\u{820}\u{822}\x05\u{d2}\x6a\x02\u{821}\u{820}\x03\x02\x02\x02\u{821}\
	\u{822}\x03\x02\x02\x02\u{822}\u{824}\x03\x02\x02\x02\u{823}\u{825}\x05\
	\u{124}\u{93}\x02\u{824}\u{823}\x03\x02\x02\x02\u{824}\u{825}\x03\x02\x02\
	\x02\u{825}\u{826}\x03\x02\x02\x02\u{826}\u{827}\x05\u{d4}\x6b\x02\u{827}\
	\u{c9}\x03\x02\x02\x02\u{828}\u{829}\x07\x63\x02\x02\u{829}\u{82a}\x07\u{11c}\
	\x02\x02\u{82a}\u{82b}\x07\u{f9}\x02\x02\u{82b}\u{82c}\x05\u{38c}\u{1c7}\
	\x02\u{82c}\u{cb}\x03\x02\x02\x02\u{82d}\u{82e}\x07\x0b\x02\x02\u{82e}\u{82f}\
	\x07\u{11c}\x02\x02\u{82f}\u{830}\x07\u{f9}\x02\x02\u{830}\u{831}\x05\u{38c}\
	\u{1c7}\x02\u{831}\u{832}\x05\u{ce}\x68\x02\u{832}\u{cd}\x03\x02\x02\x02\
	\u{833}\u{839}\x05\u{d0}\x69\x02\u{834}\u{839}\x05\u{d2}\x6a\x02\u{835}\
	\u{839}\x05\u{124}\u{93}\x02\u{836}\u{839}\x05\u{d4}\x6b\x02\u{837}\u{839}\
	\x07\x6f\x02\x02\u{838}\u{833}\x03\x02\x02\x02\u{838}\u{834}\x03\x02\x02\
	\x02\u{838}\u{835}\x03\x02\x02\x02\u{838}\u{836}\x03\x02\x02\x02\u{838}\
	\u{837}\x03\x02\x02\x02\u{839}\u{cf}\x03\x02\x02\x02\u{83a}\u{83b}\x07\x3d\
	\x02\x02\u{83b}\u{84a}\x07\u{19d}\x02\x02\u{83c}\u{83e}\x07\x6b\x02\x02\
	\u{83d}\u{83f}\x07\u{1a2}\x02\x02\u{83e}\u{83d}\x03\x02\x02\x02\u{83e}\u{83f}\
	\x03\x02\x02\x02\u{83f}\u{840}\x03\x02\x02\x02\u{840}\u{847}\x05\u{326}\
	\u{194}\x02\u{841}\u{845}\x07\x16\x02\x02\u{842}\u{843}\x07\u{d6}\x02\x02\
	\u{843}\u{845}\x07\x22\x02\x02\u{844}\u{841}\x03\x02\x02\x02\u{844}\u{842}\
	\x03\x02\x02\x02\u{845}\u{846}\x03\x02\x02\x02\u{846}\u{848}\x07\u{19d}\
	\x02\x02\u{847}\u{844}\x03\x02\x02\x02\u{847}\u{848}\x03\x02\x02\x02\u{848}\
	\u{84a}\x03\x02\x02\x02\u{849}\u{83a}\x03\x02\x02\x02\u{849}\u{83c}\x03\
	\x02\x02\x02\u{84a}\u{d1}\x03\x02\x02\x02\u{84b}\u{84c}\x07\x70\x02\x02\
	\u{84c}\u{84d}\x07\x13\x02\x02\u{84d}\u{84e}\x07\u{19d}\x02\x02\u{84e}\u{d3}\
	\x03\x02\x02\x02\u{84f}\u{851}\x07\x54\x02\x02\u{850}\u{84f}\x03\x02\x02\
	\x02\u{850}\u{851}\x03\x02\x02\x02\u{851}\u{852}\x03\x02\x02\x02\u{852}\
	\u{853}\x07\x13\x02\x02\u{853}\u{854}\x05\x04\x03\x02\u{854}\u{d5}\x03\x02\
	\x02\x02\u{855}\u{858}\x05\u{38e}\u{1c8}\x02\u{856}\u{858}\x07\u{19d}\x02\
	\x02\u{857}\u{855}\x03\x02\x02\x02\u{857}\u{856}\x03\x02\x02\x02\u{858}\
	\u{d7}\x03\x02\x02\x02\u{859}\u{85c}\x05\u{38c}\u{1c7}\x02\u{85a}\u{85c}\
	\x07\u{19d}\x02\x02\u{85b}\u{859}\x03\x02\x02\x02\u{85b}\u{85a}\x03\x02\
	\x02\x02\u{85c}\u{d9}\x03\x02\x02\x02\u{85d}\u{85e}\x07\x31\x02\x02\u{85e}\
	\u{85f}\x07\u{19d}\x02\x02\u{85f}\u{db}\x03\x02\x02\x02\u{860}\u{861}\x07\
	\u{e5}\x02\x02\u{861}\u{86a}\x07\x22\x02\x02\u{862}\u{865}\x07\u{183}\x02\
	\x02\u{863}\u{866}\x05\u{de}\x70\x02\u{864}\u{866}\x05\u{e0}\x71\x02\u{865}\
	\u{863}\x03\x02\x02\x02\u{865}\u{864}\x03\x02\x02\x02\u{866}\u{86b}\x03\
	\x02\x02\x02\u{867}\u{868}\x07\u{132}\x02\x02\u{868}\u{869}\x07\u{183}\x02\
	\x02\u{869}\u{86b}\x05\u{e2}\x72\x02\u{86a}\u{862}\x03\x02\x02\x02\u{86a}\
	\u{867}\x03\x02\x02\x02\u{86b}\u{86c}\x03\x02\x02\x02\u{86c}\u{86d}\x07\
	\u{184}\x02\x02\u{86d}\u{dd}\x03\x02\x02\x02\u{86e}\u{873}\x05\u{15a}\u{ae}\
	\x02\u{86f}\u{870}\x07\u{181}\x02\x02\u{870}\u{872}\x05\u{15a}\u{ae}\x02\
	\u{871}\u{86f}\x03\x02\x02\x02\u{872}\u{875}\x03\x02\x02\x02\u{873}\u{871}\
	\x03\x02\x02\x02\u{873}\u{874}\x03\x02\x02\x02\u{874}\u{df}\x03\x02\x02\
	\x02\u{875}\u{873}\x03\x02\x02\x02\u{876}\u{87b}\x05\u{11a}\u{8e}\x02\u{877}\
	\u{878}\x07\u{181}\x02\x02\u{878}\u{87a}\x05\u{11a}\u{8e}\x02\u{879}\u{877}\
	\x03\x02\x02\x02\u{87a}\u{87d}\x03\x02\x02\x02\u{87b}\u{879}\x03\x02\x02\
	\x02\u{87b}\u{87c}\x03\x02\x02\x02\u{87c}\u{e1}\x03\x02\x02\x02\u{87d}\u{87b}\
	\x03\x02\x02\x02\u{87e}\u{883}\x05\u{e4}\x73\x02\u{87f}\u{880}\x07\u{181}\
	\x02\x02\u{880}\u{882}\x05\u{e4}\x73\x02\u{881}\u{87f}\x03\x02\x02\x02\u{882}\
	\u{885}\x03\x02\x02\x02\u{883}\u{881}\x03\x02\x02\x02\u{883}\u{884}\x03\
	\x02\x02\x02\u{884}\u{e3}\x03\x02\x02\x02\u{885}\u{883}\x03\x02\x02\x02\
	\u{886}\u{887}\x05\u{e6}\x74\x02\u{887}\u{e5}\x03\x02\x02\x02\u{888}\u{896}\
	\x05\u{11a}\u{8e}\x02\u{889}\u{88a}\x09\x0e\x02\x02\u{88a}\u{88b}\x07\u{183}\
	\x02\x02\u{88b}\u{88c}\x05\u{11a}\u{8e}\x02\u{88c}\u{88d}\x07\u{184}\x02\
	\x02\u{88d}\u{896}\x03\x02\x02\x02\u{88e}\u{88f}\x09\x0f\x02\x02\u{88f}\
	\u{890}\x07\u{183}\x02\x02\u{890}\u{891}\x07\u{1a2}\x02\x02\u{891}\u{892}\
	\x07\u{181}\x02\x02\u{892}\u{893}\x05\u{11a}\u{8e}\x02\u{893}\u{894}\x07\
	\u{184}\x02\x02\u{894}\u{896}\x03\x02\x02\x02\u{895}\u{888}\x03\x02\x02\
	\x02\u{895}\u{889}\x03\x02\x02\x02\u{895}\u{88e}\x03\x02\x02\x02\u{896}\
	\u{e7}\x03\x02\x02\x02\u{897}\u{898}\x07\x2c\x02\x02\u{898}\u{899}\x07\x22\
	\x02\x02\u{899}\u{89a}\x07\u{183}\x02\x02\u{89a}\u{89b}\x05\u{118}\u{8d}\
	\x02\u{89b}\u{8a2}\x07\u{184}\x02\x02\u{89c}\u{89d}\x07\u{131}\x02\x02\u{89d}\
	\u{89e}\x07\x22\x02\x02\u{89e}\u{89f}\x07\u{183}\x02\x02\u{89f}\u{8a0}\x05\
	\u{11e}\u{90}\x02\u{8a0}\u{8a1}\x07\u{184}\x02\x02\u{8a1}\u{8a3}\x03\x02\
	\x02\x02\u{8a2}\u{89c}\x03\x02\x02\x02\u{8a2}\u{8a3}\x03\x02\x02\x02\u{8a3}\
	\u{8a4}\x03\x02\x02\x02\u{8a4}\u{8a5}\x07\u{a0}\x02\x02\u{8a5}\u{8a6}\x07\
	\u{1a2}\x02\x02\u{8a6}\u{8a7}\x07\x21\x02\x02\u{8a7}\u{e9}\x03\x02\x02\x02\
	\u{8a8}\u{8a9}\x07\x2c\x02\x02\u{8a9}\u{8aa}\x07\u{a0}\x02\x02\u{8aa}\u{8ab}\
	\x07\u{1a2}\x02\x02\u{8ab}\u{8ac}\x07\x21\x02\x02\u{8ac}\u{eb}\x03\x02\x02\
	\x02\u{8ad}\u{8ae}\x07\u{12c}\x02\x02\u{8ae}\u{8af}\x07\x22\x02\x02\u{8af}\
	\u{8b0}\x07\u{183}\x02\x02\u{8b0}\u{8b1}\x05\u{118}\u{8d}\x02\u{8b1}\u{8b2}\
	\x07\u{184}\x02\x02\u{8b2}\u{8b3}\x07\u{d7}\x02\x02\u{8b3}\u{8b4}\x07\u{183}\
	\x02\x02\u{8b4}\u{8b5}\x05\u{13a}\u{9e}\x02\u{8b5}\u{8b7}\x07\u{184}\x02\
	\x02\u{8b6}\u{8b8}\x05\x34\x1b\x02\u{8b7}\u{8b6}\x03\x02\x02\x02\u{8b7}\
	\u{8b8}\x03\x02\x02\x02\u{8b8}\u{ed}\x03\x02\x02\x02\u{8b9}\u{8bc}\x05\u{f4}\
	\x7b\x02\u{8ba}\u{8bc}\x05\u{f6}\x7c\x02\u{8bb}\u{8b9}\x03\x02\x02\x02\u{8bb}\
	\u{8ba}\x03\x02\x02\x02\u{8bc}\u{ef}\x03\x02\x02\x02\u{8bd}\u{8be}\x07\u{101}\
	\x02\x02\u{8be}\u{8bf}\x07\u{19d}\x02\x02\u{8bf}\u{f1}\x03\x02\x02\x02\u{8c0}\
	\u{8c1}\x07\u{102}\x02\x02\u{8c1}\u{8c2}\x07\u{19d}\x02\x02\u{8c2}\u{f3}\
	\x03\x02\x02\x02\u{8c3}\u{8c4}\x07\u{11a}\x02\x02\u{8c4}\u{8c5}\x07\u{85}\
	\x02\x02\u{8c5}\u{8c6}\x07\u{123}\x02\x02\u{8c6}\u{8ca}\x07\u{19d}\x02\x02\
	\u{8c7}\u{8c8}\x07\u{178}\x02\x02\u{8c8}\u{8c9}\x07\u{124}\x02\x02\u{8c9}\
	\u{8cb}\x05\u{fc}\x7f\x02\u{8ca}\u{8c7}\x03\x02\x02\x02\u{8ca}\u{8cb}\x03\
	\x02\x02\x02\u{8cb}\u{f5}\x03\x02\x02\x02\u{8cc}\u{8cd}\x07\u{11a}\x02\x02\
	\u{8cd}\u{8ce}\x07\u{85}\x02\x02\u{8ce}\u{8d0}\x07\x56\x02\x02\u{8cf}\u{8d1}\
	\x05\u{104}\u{83}\x02\u{8d0}\u{8cf}\x03\x02\x02\x02\u{8d0}\u{8d1}\x03\x02\
	\x02\x02\u{8d1}\u{8d3}\x03\x02\x02\x02\u{8d2}\u{8d4}\x05\u{106}\u{84}\x02\
	\u{8d3}\u{8d2}\x03\x02\x02\x02\u{8d3}\u{8d4}\x03\x02\x02\x02\u{8d4}\u{8d6}\
	\x03\x02\x02\x02\u{8d5}\u{8d7}\x05\u{108}\u{85}\x02\u{8d6}\u{8d5}\x03\x02\
	\x02\x02\u{8d6}\u{8d7}\x03\x02\x02\x02\u{8d7}\u{8d9}\x03\x02\x02\x02\u{8d8}\
	\u{8da}\x05\u{10a}\u{86}\x02\u{8d9}\u{8d8}\x03\x02\x02\x02\u{8d9}\u{8da}\
	\x03\x02\x02\x02\u{8da}\u{8dc}\x03\x02\x02\x02\u{8db}\u{8dd}\x05\u{10c}\
	\u{87}\x02\u{8dc}\u{8db}\x03\x02\x02\x02\u{8dc}\u{8dd}\x03\x02\x02\x02\u{8dd}\
	\u{f7}\x03\x02\x02\x02\u{8de}\u{8e1}\x05\u{f6}\x7c\x02\u{8df}\u{8e1}\x05\
	\u{f4}\x7b\x02\u{8e0}\u{8de}\x03\x02\x02\x02\u{8e0}\u{8df}\x03\x02\x02\x02\
	\u{8e1}\u{f9}\x03\x02\x02\x02\u{8e2}\u{8e3}\x07\u{142}\x02\x02\u{8e3}\u{8e4}\
	\x05\u{fc}\x7f\x02\u{8e4}\u{fb}\x03\x02\x02\x02\u{8e5}\u{8e6}\x07\u{183}\
	\x02\x02\u{8e6}\u{8e7}\x05\u{fe}\u{80}\x02\u{8e7}\u{8e8}\x07\u{184}\x02\
	\x02\u{8e8}\u{fd}\x03\x02\x02\x02\u{8e9}\u{8ee}\x05\u{100}\u{81}\x02\u{8ea}\
	\u{8eb}\x07\u{181}\x02\x02\u{8eb}\u{8ed}\x05\u{100}\u{81}\x02\u{8ec}\u{8ea}\
	\x03\x02\x02\x02\u{8ed}\u{8f0}\x03\x02\x02\x02\u{8ee}\u{8ec}\x03\x02\x02\
	\x02\u{8ee}\u{8ef}\x03\x02\x02\x02\u{8ef}\u{8fa}\x03\x02\x02\x02\u{8f0}\
	\u{8ee}\x03\x02\x02\x02\u{8f1}\u{8f6}\x05\u{102}\u{82}\x02\u{8f2}\u{8f3}\
	\x07\u{181}\x02\x02\u{8f3}\u{8f5}\x05\u{102}\u{82}\x02\u{8f4}\u{8f2}\x03\
	\x02\x02\x02\u{8f5}\u{8f8}\x03\x02\x02\x02\u{8f6}\u{8f4}\x03\x02\x02\x02\
	\u{8f6}\u{8f7}\x03\x02\x02\x02\u{8f7}\u{8fa}\x03\x02\x02\x02\u{8f8}\u{8f6}\
	\x03\x02\x02\x02\u{8f9}\u{8e9}\x03\x02\x02\x02\u{8f9}\u{8f1}\x03\x02\x02\
	\x02\u{8fa}\u{ff}\x03\x02\x02\x02\u{8fb}\u{8fc}\x07\u{19d}\x02\x02\u{8fc}\
	\u{8fd}\x07\u{189}\x02\x02\u{8fd}\u{8fe}\x07\u{19d}\x02\x02\u{8fe}\u{101}\
	\x03\x02\x02\x02\u{8ff}\u{900}\x07\u{19d}\x02\x02\u{900}\u{103}\x03\x02\
	\x02\x02\u{901}\u{902}\x07\x7b\x02\x02\u{902}\u{903}\x07\u{144}\x02\x02\
	\u{903}\u{904}\x07\x22\x02\x02\u{904}\u{908}\x07\u{19d}\x02\x02\u{905}\u{906}\
	\x07\x6a\x02\x02\u{906}\u{907}\x07\x22\x02\x02\u{907}\u{909}\x07\u{19d}\
	\x02\x02\u{908}\u{905}\x03\x02\x02\x02\u{908}\u{909}\x03\x02\x02\x02\u{909}\
	\u{105}\x03\x02\x02\x02\u{90a}\u{90b}\x07\x2e\x02\x02\u{90b}\u{90c}\x07\
	\u{a3}\x02\x02\u{90c}\u{90d}\x07\u{144}\x02\x02\u{90d}\u{90e}\x07\x22\x02\
	\x02\u{90e}\u{90f}\x07\u{19d}\x02\x02\u{90f}\u{107}\x03\x02\x02\x02\u{910}\
	\u{911}\x07\u{bf}\x02\x02\u{911}\u{912}\x07\u{a8}\x02\x02\u{912}\u{913}\
	\x07\u{144}\x02\x02\u{913}\u{914}\x07\x22\x02\x02\u{914}\u{915}\x07\u{19d}\
	\x02\x02\u{915}\u{109}\x03\x02\x02\x02\u{916}\u{917}\x07\u{b3}\x02\x02\u{917}\
	\u{918}\x07\u{144}\x02\x02\u{918}\u{919}\x07\x22\x02\x02\u{919}\u{91a}\x07\
	\u{19d}\x02\x02\u{91a}\u{10b}\x03\x02\x02\x02\u{91b}\u{91c}\x07\u{d2}\x02\
	\x02\u{91c}\u{91d}\x07\x54\x02\x02\u{91d}\u{91e}\x07\x13\x02\x02\u{91e}\
	\u{91f}\x07\u{19d}\x02\x02\u{91f}\u{10d}\x03\x02\x02\x02\u{920}\u{921}\x07\
	\u{137}\x02\x02\u{921}\u{922}\x07\x13\x02\x02\u{922}\u{923}\x07\u{9b}\x02\
	\x02\u{923}\u{924}\x07\u{19d}\x02\x02\u{924}\u{925}\x07\u{e0}\x02\x02\u{925}\
	\u{92a}\x07\u{19d}\x02\x02\u{926}\u{927}\x07\u{9a}\x02\x02\u{927}\u{928}\
	\x07\u{19d}\x02\x02\u{928}\u{929}\x07\u{df}\x02\x02\u{929}\u{92b}\x07\u{19d}\
	\x02\x02\u{92a}\u{926}\x03\x02\x02\x02\u{92a}\u{92b}\x03\x02\x02\x02\u{92b}\
	\u{94a}\x03\x02\x02\x02\u{92c}\u{92d}\x07\u{137}\x02\x02\u{92d}\u{92e}\x07\
	\x22\x02\x02\u{92e}\u{932}\x07\u{19d}\x02\x02\u{92f}\u{930}\x07\u{178}\x02\
	\x02\u{930}\u{931}\x07\u{124}\x02\x02\u{931}\u{933}\x05\u{fc}\x7f\x02\u{932}\
	\u{92f}\x03\x02\x02\x02\u{932}\u{933}\x03\x02\x02\x02\u{933}\u{937}\x03\
	\x02\x02\x02\u{934}\u{935}\x07\u{137}\x02\x02\u{935}\u{936}\x07\x13\x02\
	\x02\u{936}\u{938}\x05\u{38c}\u{1c7}\x02\u{937}\u{934}\x03\x02\x02\x02\u{937}\
	\u{938}\x03\x02\x02\x02\u{938}\u{94a}\x03\x02\x02\x02\u{939}\u{93a}\x07\
	\u{137}\x02\x02\u{93a}\u{93b}\x07\x22\x02\x02\u{93b}\u{93f}\x05\u{38c}\u{1c7}\
	\x02\u{93c}\u{93d}\x07\u{178}\x02\x02\u{93d}\u{93e}\x07\u{124}\x02\x02\u{93e}\
	\u{940}\x05\u{fc}\x7f\x02\u{93f}\u{93c}\x03\x02\x02\x02\u{93f}\u{940}\x03\
	\x02\x02\x02\u{940}\u{944}\x03\x02\x02\x02\u{941}\u{942}\x07\u{137}\x02\
	\x02\u{942}\u{943}\x07\x13\x02\x02\u{943}\u{945}\x05\u{38c}\u{1c7}\x02\u{944}\
	\u{941}\x03\x02\x02\x02\u{944}\u{945}\x03\x02\x02\x02\u{945}\u{94a}\x03\
	\x02\x02\x02\u{946}\u{947}\x07\u{137}\x02\x02\u{947}\u{948}\x07\x13\x02\
	\x02\u{948}\u{94a}\x05\u{38c}\u{1c7}\x02\u{949}\u{920}\x03\x02\x02\x02\u{949}\
	\u{92c}\x03\x02\x02\x02\u{949}\u{939}\x03\x02\x02\x02\u{949}\u{946}\x03\
	\x02\x02\x02\u{94a}\u{10f}\x03\x02\x02\x02\u{94b}\u{94c}\x07\u{b6}\x02\x02\
	\u{94c}\u{94d}\x07\u{19d}\x02\x02\u{94d}\u{111}\x03\x02\x02\x02\u{94e}\u{953}\
	\x05\u{154}\u{ab}\x02\u{94f}\u{950}\x07\u{181}\x02\x02\u{950}\u{952}\x05\
	\u{154}\u{ab}\x02\u{951}\u{94f}\x03\x02\x02\x02\u{952}\u{955}\x03\x02\x02\
	\x02\u{953}\u{951}\x03\x02\x02\x02\u{953}\u{954}\x03\x02\x02\x02\u{954}\
	\u{113}\x03\x02\x02\x02\u{955}\u{953}\x03\x02\x02\x02\u{956}\u{95b}\x05\
	\u{156}\u{ac}\x02\u{957}\u{958}\x07\u{181}\x02\x02\u{958}\u{95a}\x05\u{156}\
	\u{ac}\x02\u{959}\u{957}\x03\x02\x02\x02\u{95a}\u{95d}\x03\x02\x02\x02\u{95b}\
	\u{959}\x03\x02\x02\x02\u{95b}\u{95c}\x03\x02\x02\x02\u{95c}\u{115}\x03\
	\x02\x02\x02\u{95d}\u{95b}\x03\x02\x02\x02\u{95e}\u{963}\x05\u{172}\u{ba}\
	\x02\u{95f}\u{960}\x07\u{181}\x02\x02\u{960}\u{962}\x05\u{172}\u{ba}\x02\
	\u{961}\u{95f}\x03\x02\x02\x02\u{962}\u{965}\x03\x02\x02\x02\u{963}\u{961}\
	\x03\x02\x02\x02\u{963}\u{964}\x03\x02\x02\x02\u{964}\u{117}\x03\x02\x02\
	\x02\u{965}\u{963}\x03\x02\x02\x02\u{966}\u{96b}\x05\u{11a}\u{8e}\x02\u{967}\
	\u{968}\x07\u{181}\x02\x02\u{968}\u{96a}\x05\u{11a}\u{8e}\x02\u{969}\u{967}\
	\x03\x02\x02\x02\u{96a}\u{96d}\x03\x02\x02\x02\u{96b}\u{969}\x03\x02\x02\
	\x02\u{96b}\u{96c}\x03\x02\x02\x02\u{96c}\u{119}\x03\x02\x02\x02\u{96d}\
	\u{96b}\x03\x02\x02\x02\u{96e}\u{96f}\x05\u{38c}\u{1c7}\x02\u{96f}\u{11b}\
	\x03\x02\x02\x02\u{970}\u{97a}\x05\u{38c}\u{1c7}\x02\u{971}\u{976}\x07\u{17f}\
	\x02\x02\u{972}\u{977}\x07\x65\x02\x02\u{973}\u{977}\x07\u{a9}\x02\x02\u{974}\
	\u{977}\x07\u{16d}\x02\x02\u{975}\u{977}\x05\u{38c}\u{1c7}\x02\u{976}\u{972}\
	\x03\x02\x02\x02\u{976}\u{973}\x03\x02\x02\x02\u{976}\u{974}\x03\x02\x02\
	\x02\u{976}\u{975}\x03\x02\x02\x02\u{977}\u{979}\x03\x02\x02\x02\u{978}\
	\u{971}\x03\x02\x02\x02\u{979}\u{97c}\x03\x02\x02\x02\u{97a}\u{978}\x03\
	\x02\x02\x02\u{97a}\u{97b}\x03\x02\x02\x02\u{97b}\u{11d}\x03\x02\x02\x02\
	\u{97c}\u{97a}\x03\x02\x02\x02\u{97d}\u{982}\x05\u{14a}\u{a6}\x02\u{97e}\
	\u{97f}\x07\u{181}\x02\x02\u{97f}\u{981}\x05\u{14a}\u{a6}\x02\u{980}\u{97e}\
	\x03\x02\x02\x02\u{981}\u{984}\x03\x02\x02\x02\u{982}\u{980}\x03\x02\x02\
	\x02\u{982}\u{983}\x03\x02\x02\x02\u{983}\u{11f}\x03\x02\x02\x02\u{984}\
	\u{982}\x03\x02\x02\x02\u{985}\u{986}\x07\u{183}\x02\x02\u{986}\u{987}\x05\
	\u{118}\u{8d}\x02\u{987}\u{988}\x07\u{184}\x02\x02\u{988}\u{121}\x03\x02\
	\x02\x02\u{989}\u{98b}\x05\u{124}\u{93}\x02\u{98a}\u{98c}\x05\u{126}\u{94}\
	\x02\u{98b}\u{98a}\x03\x02\x02\x02\u{98b}\u{98c}\x03\x02\x02\x02\u{98c}\
	\u{98f}\x03\x02\x02\x02\u{98d}\u{98f}\x05\u{128}\u{95}\x02\u{98e}\u{989}\
	\x03\x02\x02\x02\u{98e}\u{98d}\x03\x02\x02\x02\u{98f}\u{123}\x03\x02\x02\
	\x02\u{990}\u{991}\x09\x10\x02\x02\u{991}\u{125}\x03\x02\x02\x02\u{992}\
	\u{993}\x09\x11\x02\x02\u{993}\u{127}\x03\x02\x02\x02\u{994}\u{998}\x07\
	\x69\x02\x02\u{995}\u{996}\x07\u{cf}\x02\x02\u{996}\u{998}\x07\x69\x02\x02\
	\u{997}\u{994}\x03\x02\x02\x02\u{997}\u{995}\x03\x02\x02\x02\u{998}\u{129}\
	\x03\x02\x02\x02\u{999}\u{99a}\x09\x12\x02\x02\u{99a}\u{12b}\x03\x02\x02\
	\x02\u{99b}\u{99c}\x07\x39\x02\x02\u{99c}\u{99e}\x05\u{38c}\u{1c7}\x02\u{99d}\
	\u{99b}\x03\x02\x02\x02\u{99d}\u{99e}\x03\x02\x02\x02\u{99e}\u{99f}\x03\
	\x02\x02\x02\u{99f}\u{9a1}\x05\u{130}\u{99}\x02\u{9a0}\u{9a2}\x05\u{16e}\
	\u{b8}\x02\u{9a1}\u{9a0}\x03\x02\x02\x02\u{9a1}\u{9a2}\x03\x02\x02\x02\u{9a2}\
	\u{12d}\x03\x02\x02\x02\u{9a3}\u{9a4}\x07\x39\x02\x02\u{9a4}\u{9a5}\x05\
	\u{38c}\u{1c7}\x02\u{9a5}\u{9a7}\x05\u{130}\u{99}\x02\u{9a6}\u{9a8}\x05\
	\u{170}\u{b9}\x02\u{9a7}\u{9a6}\x03\x02\x02\x02\u{9a7}\u{9a8}\x03\x02\x02\
	\x02\u{9a8}\u{12f}\x03\x02\x02\x02\u{9a9}\u{9ac}\x05\u{132}\u{9a}\x02\u{9aa}\
	\u{9ac}\x05\u{134}\u{9b}\x02\u{9ab}\u{9a9}\x03\x02\x02\x02\u{9ab}\u{9aa}\
	\x03\x02\x02\x02\u{9ac}\u{131}\x03\x02\x02\x02\u{9ad}\u{9ae}\x05\u{16c}\
	\u{b7}\x02\u{9ae}\u{9af}\x05\u{120}\u{91}\x02\u{9af}\u{133}\x03\x02\x02\
	\x02\u{9b0}\u{9b1}\x07\x2a\x02\x02\u{9b1}\u{9b2}\x07\u{183}\x02\x02\u{9b2}\
	\u{9b3}\x05\u{328}\u{195}\x02\u{9b3}\u{9b4}\x07\u{184}\x02\x02\u{9b4}\u{135}\
	\x03\x02\x02\x02\u{9b5}\u{9b6}\x07\x39\x02\x02\u{9b6}\u{9b8}\x05\u{38c}\
	\u{1c7}\x02\u{9b7}\u{9b5}\x03\x02\x02\x02\u{9b7}\u{9b8}\x03\x02\x02\x02\
	\u{9b8}\u{9b9}\x03\x02\x02\x02\u{9b9}\u{9ba}\x07\u{84}\x02\x02\u{9ba}\u{9bb}\
	\x07\u{a7}\x02\x02\u{9bb}\u{9bc}\x05\u{120}\u{91}\x02\u{9bc}\u{9bd}\x07\
	\u{104}\x02\x02\u{9bd}\u{9be}\x05\u{28c}\u{147}\x02\u{9be}\u{9c0}\x05\u{120}\
	\u{91}\x02\u{9bf}\u{9c1}\x05\u{16e}\u{b8}\x02\u{9c0}\u{9bf}\x03\x02\x02\
	\x02\u{9c0}\u{9c1}\x03\x02\x02\x02\u{9c1}\u{137}\x03\x02\x02\x02\u{9c2}\
	\u{9c3}\x07\x39\x02\x02\u{9c3}\u{9c4}\x05\u{38c}\u{1c7}\x02\u{9c4}\u{9c5}\
	\x07\u{84}\x02\x02\u{9c5}\u{9c6}\x07\u{a7}\x02\x02\u{9c6}\u{9c7}\x05\u{120}\
	\u{91}\x02\u{9c7}\u{9c8}\x07\u{104}\x02\x02\u{9c8}\u{9c9}\x05\u{28c}\u{147}\
	\x02\u{9c9}\u{9cb}\x05\u{120}\u{91}\x02\u{9ca}\u{9cc}\x05\u{170}\u{b9}\x02\
	\u{9cb}\u{9ca}\x03\x02\x02\x02\u{9cb}\u{9cc}\x03\x02\x02\x02\u{9cc}\u{139}\
	\x03\x02\x02\x02\u{9cd}\u{9d0}\x05\u{140}\u{a1}\x02\u{9ce}\u{9d0}\x05\u{13c}\
	\u{9f}\x02\u{9cf}\u{9cd}\x03\x02\x02\x02\u{9cf}\u{9ce}\x03\x02\x02\x02\u{9d0}\
	\u{13b}\x03\x02\x02\x02\u{9d1}\u{9d6}\x05\u{13e}\u{a0}\x02\u{9d2}\u{9d3}\
	\x07\u{181}\x02\x02\u{9d3}\u{9d5}\x05\u{13e}\u{a0}\x02\u{9d4}\u{9d2}\x03\
	\x02\x02\x02\u{9d5}\u{9d8}\x03\x02\x02\x02\u{9d6}\u{9d4}\x03\x02\x02\x02\
	\u{9d6}\u{9d7}\x03\x02\x02\x02\u{9d7}\u{13d}\x03\x02\x02\x02\u{9d8}\u{9d6}\
	\x03\x02\x02\x02\u{9d9}\u{9da}\x07\u{183}\x02\x02\u{9da}\u{9db}\x05\u{140}\
	\u{a1}\x02\u{9db}\u{9dc}\x07\u{184}\x02\x02\u{9dc}\u{13f}\x03\x02\x02\x02\
	\u{9dd}\u{9e2}\x05\u{142}\u{a2}\x02\u{9de}\u{9df}\x07\u{181}\x02\x02\u{9df}\
	\u{9e1}\x05\u{142}\u{a2}\x02\u{9e0}\u{9de}\x03\x02\x02\x02\u{9e1}\u{9e4}\
	\x03\x02\x02\x02\u{9e2}\u{9e0}\x03\x02\x02\x02\u{9e2}\u{9e3}\x03\x02\x02\
	\x02\u{9e3}\u{141}\x03\x02\x02\x02\u{9e4}\u{9e2}\x03\x02\x02\x02\u{9e5}\
	\u{9e6}\x05\u{310}\u{189}\x02\u{9e6}\u{143}\x03\x02\x02\x02\u{9e7}\u{9ea}\
	\x05\u{142}\u{a2}\x02\u{9e8}\u{9ea}\x05\u{13e}\u{a0}\x02\u{9e9}\u{9e7}\x03\
	\x02\x02\x02\u{9e9}\u{9e8}\x03\x02\x02\x02\u{9ea}\u{145}\x03\x02\x02\x02\
	\u{9eb}\u{9ec}\x09\x13\x02\x02\u{9ec}\u{147}\x03\x02\x02\x02\u{9ed}\u{9ee}\
	\x07\u{d3}\x02\x02\u{9ee}\u{9ef}\x09\x14\x02\x02\u{9ef}\u{149}\x03\x02\x02\
	\x02\u{9f0}\u{9f2}\x05\u{38c}\u{1c7}\x02\u{9f1}\u{9f3}\x05\u{146}\u{a4}\
	\x02\u{9f2}\u{9f1}\x03\x02\x02\x02\u{9f2}\u{9f3}\x03\x02\x02\x02\u{9f3}\
	\u{9f5}\x03\x02\x02\x02\u{9f4}\u{9f6}\x05\u{148}\u{a5}\x02\u{9f5}\u{9f4}\
	\x03\x02\x02\x02\u{9f5}\u{9f6}\x03\x02\x02\x02\u{9f6}\u{14b}\x03\x02\x02\
	\x02\u{9f7}\u{9fc}\x05\u{14e}\u{a8}\x02\u{9f8}\u{9f9}\x07\u{181}\x02\x02\
	\u{9f9}\u{9fb}\x05\u{14e}\u{a8}\x02\u{9fa}\u{9f8}\x03\x02\x02\x02\u{9fb}\
	\u{9fe}\x03\x02\x02\x02\u{9fc}\u{9fa}\x03\x02\x02\x02\u{9fc}\u{9fd}\x03\
	\x02\x02\x02\u{9fd}\u{14d}\x03\x02\x02\x02\u{9fe}\u{9fc}\x03\x02\x02\x02\
	\u{9ff}\u{a02}\x05\u{38c}\u{1c7}\x02\u{a00}\u{a01}\x07\x31\x02\x02\u{a01}\
	\u{a03}\x07\u{19d}\x02\x02\u{a02}\u{a00}\x03\x02\x02\x02\u{a02}\u{a03}\x03\
	\x02\x02\x02\u{a03}\u{14f}\x03\x02\x02\x02\u{a04}\u{a05}\x09\x13\x02\x02\
	\u{a05}\u{151}\x03\x02\x02\x02\u{a06}\u{a08}\x05\u{328}\u{195}\x02\u{a07}\
	\u{a09}\x05\u{150}\u{a9}\x02\u{a08}\u{a07}\x03\x02\x02\x02\u{a08}\u{a09}\
	\x03\x02\x02\x02\u{a09}\u{a0b}\x03\x02\x02\x02\u{a0a}\u{a0c}\x05\u{148}\
	\u{a5}\x02\u{a0b}\u{a0a}\x03\x02\x02\x02\u{a0b}\u{a0c}\x03\x02\x02\x02\u{a0c}\
	\u{153}\x03\x02\x02\x02\u{a0d}\u{a0e}\x05\u{38c}\u{1c7}\x02\u{a0e}\u{a11}\
	\x05\u{174}\u{bb}\x02\u{a0f}\u{a10}\x07\x31\x02\x02\u{a10}\u{a12}\x07\u{19d}\
	\x02\x02\u{a11}\u{a0f}\x03\x02\x02\x02\u{a11}\u{a12}\x03\x02\x02\x02\u{a12}\
	\u{155}\x03\x02\x02\x02\u{a13}\u{a16}\x05\u{158}\u{ad}\x02\u{a14}\u{a16}\
	\x05\u{15a}\u{ae}\x02\u{a15}\u{a13}\x03\x02\x02\x02\u{a15}\u{a14}\x03\x02\
	\x02\x02\u{a16}\u{157}\x03\x02\x02\x02\u{a17}\u{a1a}\x05\u{136}\u{9c}\x02\
	\u{a18}\u{a1a}\x05\u{12c}\u{97}\x02\u{a19}\u{a17}\x03\x02\x02\x02\u{a19}\
	\u{a18}\x03\x02\x02\x02\u{a1a}\u{159}\x03\x02\x02\x02\u{a1b}\u{a1c}\x05\
	\u{38c}\u{1c7}\x02\u{a1c}\u{a1e}\x05\u{174}\u{bb}\x02\u{a1d}\u{a1f}\x05\
	\u{15c}\u{af}\x02\u{a1e}\u{a1d}\x03\x02\x02\x02\u{a1e}\u{a1f}\x03\x02\x02\
	\x02\u{a1f}\u{a22}\x03\x02\x02\x02\u{a20}\u{a21}\x07\x31\x02\x02\u{a21}\
	\u{a23}\x07\u{19d}\x02\x02\u{a22}\u{a20}\x03\x02\x02\x02\u{a22}\u{a23}\x03\
	\x02\x02\x02\u{a23}\u{15b}\x03\x02\x02\x02\u{a24}\u{a27}\x05\u{15e}\u{b0}\
	\x02\u{a25}\u{a27}\x05\u{160}\u{b1}\x02\u{a26}\u{a24}\x03\x02\x02\x02\u{a26}\
	\u{a25}\x03\x02\x02\x02\u{a27}\u{15d}\x03\x02\x02\x02\u{a28}\u{a29}\x07\
	\x39\x02\x02\u{a29}\u{a2b}\x05\u{38c}\u{1c7}\x02\u{a2a}\u{a28}\x03\x02\x02\
	\x02\u{a2a}\u{a2b}\x03\x02\x02\x02\u{a2b}\u{a2c}\x03\x02\x02\x02\u{a2c}\
	\u{a2d}\x07\u{104}\x02\x02\u{a2d}\u{a2e}\x05\u{28c}\u{147}\x02\u{a2e}\u{a2f}\
	\x07\u{183}\x02\x02\u{a2f}\u{a30}\x05\u{11a}\u{8e}\x02\u{a30}\u{a32}\x07\
	\u{184}\x02\x02\u{a31}\u{a33}\x05\u{16e}\u{b8}\x02\u{a32}\u{a31}\x03\x02\
	\x02\x02\u{a32}\u{a33}\x03\x02\x02\x02\u{a33}\u{15f}\x03\x02\x02\x02\u{a34}\
	\u{a35}\x07\x39\x02\x02\u{a35}\u{a37}\x05\u{38c}\u{1c7}\x02\u{a36}\u{a34}\
	\x03\x02\x02\x02\u{a36}\u{a37}\x03\x02\x02\x02\u{a37}\u{a38}\x03\x02\x02\
	\x02\u{a38}\u{a3a}\x05\u{168}\u{b5}\x02\u{a39}\u{a3b}\x05\u{16e}\u{b8}\x02\
	\u{a3a}\u{a39}\x03\x02\x02\x02\u{a3a}\u{a3b}\x03\x02\x02\x02\u{a3b}\u{161}\
	\x03\x02\x02\x02\u{a3c}\u{a3f}\x05\u{164}\u{b3}\x02\u{a3d}\u{a3f}\x05\u{166}\
	\u{b4}\x02\u{a3e}\u{a3c}\x03\x02\x02\x02\u{a3e}\u{a3d}\x03\x02\x02\x02\u{a3f}\
	\u{163}\x03\x02\x02\x02\u{a40}\u{a41}\x07\x39\x02\x02\u{a41}\u{a43}\x05\
	\u{38c}\u{1c7}\x02\u{a42}\u{a40}\x03\x02\x02\x02\u{a42}\u{a43}\x03\x02\x02\
	\x02\u{a43}\u{a44}\x03\x02\x02\x02\u{a44}\u{a45}\x07\u{104}\x02\x02\u{a45}\
	\u{a46}\x05\u{28c}\u{147}\x02\u{a46}\u{a47}\x07\u{183}\x02\x02\u{a47}\u{a48}\
	\x05\u{11a}\u{8e}\x02\u{a48}\u{a4a}\x07\u{184}\x02\x02\u{a49}\u{a4b}\x05\
	\u{170}\u{b9}\x02\u{a4a}\u{a49}\x03\x02\x02\x02\u{a4a}\u{a4b}\x03\x02\x02\
	\x02\u{a4b}\u{165}\x03\x02\x02\x02\u{a4c}\u{a4d}\x07\x39\x02\x02\u{a4d}\
	\u{a4f}\x05\u{38c}\u{1c7}\x02\u{a4e}\u{a4c}\x03\x02\x02\x02\u{a4e}\u{a4f}\
	\x03\x02\x02\x02\u{a4f}\u{a50}\x03\x02\x02\x02\u{a50}\u{a52}\x05\u{168}\
	\u{b5}\x02\u{a51}\u{a53}\x05\u{170}\u{b9}\x02\u{a52}\u{a51}\x03\x02\x02\
	\x02\u{a52}\u{a53}\x03\x02\x02\x02\u{a53}\u{167}\x03\x02\x02\x02\u{a54}\
	\u{a55}\x07\u{cf}\x02\x02\u{a55}\u{a5b}\x07\u{d2}\x02\x02\u{a56}\u{a57}\
	\x07\x52\x02\x02\u{a57}\u{a5b}\x05\u{16a}\u{b6}\x02\u{a58}\u{a5b}\x05\u{134}\
	\u{9b}\x02\u{a59}\u{a5b}\x05\u{16c}\u{b7}\x02\u{a5a}\u{a54}\x03\x02\x02\
	\x02\u{a5a}\u{a56}\x03\x02\x02\x02\u{a5a}\u{a58}\x03\x02\x02\x02\u{a5a}\
	\u{a59}\x03\x02\x02\x02\u{a5b}\u{169}\x03\x02\x02\x02\u{a5c}\u{a60}\x05\
	\u{310}\u{189}\x02\u{a5d}\u{a60}\x05\u{2fc}\u{17f}\x02\u{a5e}\u{a60}\x05\
	\u{302}\u{182}\x02\u{a5f}\u{a5c}\x03\x02\x02\x02\u{a5f}\u{a5d}\x03\x02\x02\
	\x02\u{a5f}\u{a5e}\x03\x02\x02\x02\u{a60}\u{16b}\x03\x02\x02\x02\u{a61}\
	\u{a62}\x07\u{f2}\x02\x02\u{a62}\u{a65}\x07\u{a7}\x02\x02\u{a63}\u{a65}\
	\x07\u{15c}\x02\x02\u{a64}\u{a61}\x03\x02\x02\x02\u{a64}\u{a63}\x03\x02\
	\x02\x02\u{a65}\u{16d}\x03\x02\x02\x02\u{a66}\u{a68}\x05\u{122}\u{92}\x02\
	\u{a67}\u{a69}\x05\u{12a}\u{96}\x02\u{a68}\u{a67}\x03\x02\x02\x02\u{a68}\
	\u{a69}\x03\x02\x02\x02\u{a69}\u{16f}\x03\x02\x02\x02\u{a6a}\u{a6c}\x05\
	\u{122}\u{92}\x02\u{a6b}\u{a6d}\x05\u{12a}\u{96}\x02\u{a6c}\u{a6b}\x03\x02\
	\x02\x02\u{a6c}\u{a6d}\x03\x02\x02\x02\u{a6d}\u{171}\x03\x02\x02\x02\u{a6e}\
	\u{a6f}\x05\u{38c}\u{1c7}\x02\u{a6f}\u{a70}\x07\u{180}\x02\x02\u{a70}\u{a73}\
	\x05\u{174}\u{bb}\x02\u{a71}\u{a72}\x07\x31\x02\x02\u{a72}\u{a74}\x07\u{19d}\
	\x02\x02\u{a73}\u{a71}\x03\x02\x02\x02\u{a73}\u{a74}\x03\x02\x02\x02\u{a74}\
	\u{173}\x03\x02\x02\x02\u{a75}\u{a76}\x05\u{178}\u{bd}\x02\u{a76}\u{175}\
	\x03\x02\x02\x02\u{a77}\u{a7c}\x05\u{174}\u{bb}\x02\u{a78}\u{a79}\x07\u{181}\
	\x02\x02\u{a79}\u{a7b}\x05\u{174}\u{bb}\x02\u{a7a}\u{a78}\x03\x02\x02\x02\
	\u{a7b}\u{a7e}\x03\x02\x02\x02\u{a7c}\u{a7a}\x03\x02\x02\x02\u{a7c}\u{a7d}\
	\x03\x02\x02\x02\u{a7d}\u{177}\x03\x02\x02\x02\u{a7e}\u{a7c}\x03\x02\x02\
	\x02\u{a7f}\u{a85}\x05\u{17a}\u{be}\x02\u{a80}\u{a85}\x05\u{17c}\u{bf}\x02\
	\u{a81}\u{a85}\x05\u{17e}\u{c0}\x02\u{a82}\u{a85}\x05\u{180}\u{c1}\x02\u{a83}\
	\u{a85}\x05\u{182}\u{c2}\x02\u{a84}\u{a7f}\x03\x02\x02\x02\u{a84}\u{a80}\
	\x03\x02\x02\x02\u{a84}\u{a81}\x03\x02\x02\x02\u{a84}\u{a82}\x03\x02\x02\
	\x02\u{a84}\u{a83}\x03\x02\x02\x02\u{a85}\u{179}\x03\x02\x02\x02\u{a86}\
	\u{aab}\x07\u{14a}\x02\x02\u{a87}\u{aab}\x07\u{12d}\x02\x02\u{a88}\u{aab}\
	\x07\u{9d}\x02\x02\u{a89}\u{aab}\x07\x1c\x02\x02\u{a8a}\u{aab}\x07\x1e\x02\
	\x02\u{a8b}\u{aab}\x07\x7f\x02\x02\u{a8c}\u{aab}\x07\u{ff}\x02\x02\u{a8d}\
	\u{a8f}\x07\x62\x02\x02\u{a8e}\u{a90}\x07\u{ef}\x02\x02\u{a8f}\u{a8e}\x03\
	\x02\x02\x02\u{a8f}\u{a90}\x03\x02\x02\x02\u{a90}\u{aab}\x03\x02\x02\x02\
	\u{a91}\u{aab}\x07\x49\x02\x02\u{a92}\u{aab}\x07\x4a\x02\x02\u{a93}\u{aab}\
	\x07\u{147}\x02\x02\u{a94}\u{aab}\x07\u{148}\x02\x02\u{a95}\u{a96}\x07\u{147}\
	\x02\x02\u{a96}\u{a97}\x07\u{178}\x02\x02\u{a97}\u{a98}\x07\u{b5}\x02\x02\
	\u{a98}\u{a99}\x07\u{146}\x02\x02\u{a99}\u{aab}\x07\u{17e}\x02\x02\u{a9a}\
	\u{aab}\x07\u{139}\x02\x02\u{a9b}\u{aab}\x07\x1d\x02\x02\u{a9c}\u{aa4}\x07\
	\x51\x02\x02\u{a9d}\u{a9e}\x07\u{183}\x02\x02\u{a9e}\u{aa1}\x07\u{1a2}\x02\
	\x02\u{a9f}\u{aa0}\x07\u{181}\x02\x02\u{aa0}\u{aa2}\x07\u{1a2}\x02\x02\u{aa1}\
	\u{a9f}\x03\x02\x02\x02\u{aa1}\u{aa2}\x03\x02\x02\x02\u{aa2}\u{aa3}\x03\
	\x02\x02\x02\u{aa3}\u{aa5}\x07\u{184}\x02\x02\u{aa4}\u{a9d}\x03\x02\x02\
	\x02\u{aa4}\u{aa5}\x03\x02\x02\x02\u{aa5}\u{aab}\x03\x02\x02\x02\u{aa6}\
	\u{aa7}\x09\x15\x02\x02\u{aa7}\u{aa8}\x07\u{183}\x02\x02\u{aa8}\u{aa9}\x07\
	\u{1a2}\x02\x02\u{aa9}\u{aab}\x07\u{184}\x02\x02\u{aaa}\u{a86}\x03\x02\x02\
	\x02\u{aaa}\u{a87}\x03\x02\x02\x02\u{aaa}\u{a88}\x03\x02\x02\x02\u{aaa}\
	\u{a89}\x03\x02\x02\x02\u{aaa}\u{a8a}\x03\x02\x02\x02\u{aaa}\u{a8b}\x03\
	\x02\x02\x02\u{aaa}\u{a8c}\x03\x02\x02\x02\u{aaa}\u{a8d}\x03\x02\x02\x02\
	\u{aaa}\u{a91}\x03\x02\x02\x02\u{aaa}\u{a92}\x03\x02\x02\x02\u{aaa}\u{a93}\
	\x03\x02\x02\x02\u{aaa}\u{a94}\x03\x02\x02\x02\u{aaa}\u{a95}\x03\x02\x02\
	\x02\u{aaa}\u{a9a}\x03\x02\x02\x02\u{aaa}\u{a9b}\x03\x02\x02\x02\u{aaa}\
	\u{a9c}\x03\x02\x02\x02\u{aaa}\u{aa6}\x03\x02\x02\x02\u{aab}\u{17b}\x03\
	\x02\x02\x02\u{aac}\u{aad}\x07\x12\x02\x02\u{aad}\u{aae}\x07\u{18d}\x02\
	\x02\u{aae}\u{aaf}\x05\u{178}\u{bd}\x02\u{aaf}\u{ab0}\x07\u{18f}\x02\x02\
	\u{ab0}\u{17d}\x03\x02\x02\x02\u{ab1}\u{ab2}\x07\u{13a}\x02\x02\u{ab2}\u{ab3}\
	\x07\u{18d}\x02\x02\u{ab3}\u{ab4}\x05\u{116}\u{8c}\x02\u{ab4}\u{ab5}\x07\
	\u{18f}\x02\x02\u{ab5}\u{17f}\x03\x02\x02\x02\u{ab6}\u{ab7}\x07\u{bf}\x02\
	\x02\u{ab7}\u{ab8}\x07\u{18d}\x02\x02\u{ab8}\u{ab9}\x05\u{17a}\u{be}\x02\
	\u{ab9}\u{aba}\x07\u{181}\x02\x02\u{aba}\u{abb}\x05\u{178}\u{bd}\x02\u{abb}\
	\u{abc}\x07\u{18f}\x02\x02\u{abc}\u{181}\x03\x02\x02\x02\u{abd}\u{abe}\x07\
	\u{15b}\x02\x02\u{abe}\u{abf}\x07\u{18d}\x02\x02\u{abf}\u{ac0}\x05\u{176}\
	\u{bc}\x02\u{ac0}\u{ac1}\x07\u{18f}\x02\x02\u{ac1}\u{183}\x03\x02\x02\x02\
	\u{ac2}\u{ac4}\x09\x16\x02\x02\u{ac3}\u{ac5}\x09\x17\x02\x02\u{ac4}\u{ac3}\
	\x03\x02\x02\x02\u{ac4}\u{ac5}\x03\x02\x02\x02\u{ac5}\u{185}\x03\x02\x02\
	\x02\u{ac6}\u{ac8}\x05\u{18a}\u{c6}\x02\u{ac7}\u{ac6}\x03\x02\x02\x02\u{ac7}\
	\u{ac8}\x03\x02\x02\x02\u{ac8}\u{ac9}\x03\x02\x02\x02\u{ac9}\u{aca}\x05\
	\u{188}\u{c5}\x02\u{aca}\u{187}\x03\x02\x02\x02\u{acb}\u{ace}\x05\u{18e}\
	\u{c8}\x02\u{acc}\u{ace}\x05\u{192}\u{ca}\x02\u{acd}\u{acb}\x03\x02\x02\
	\x02\u{acd}\u{acc}\x03\x02\x02\x02\u{ace}\u{189}\x03\x02\x02\x02\u{acf}\
	\u{ad0}\x07\u{178}\x02\x02\u{ad0}\u{ad5}\x05\u{18c}\u{c7}\x02\u{ad1}\u{ad2}\
	\x07\u{181}\x02\x02\u{ad2}\u{ad4}\x05\u{18c}\u{c7}\x02\u{ad3}\u{ad1}\x03\
	\x02\x02\x02\u{ad4}\u{ad7}\x03\x02\x02\x02\u{ad5}\u{ad3}\x03\x02\x02\x02\
	\u{ad5}\u{ad6}\x03\x02\x02\x02\u{ad6}\u{18b}\x03\x02\x02\x02\u{ad7}\u{ad5}\
	\x03\x02\x02\x02\u{ad8}\u{add}\x05\u{38c}\u{1c7}\x02\u{ad9}\u{ada}\x07\u{183}\
	\x02\x02\u{ada}\u{adb}\x05\u{118}\u{8d}\x02\u{adb}\u{adc}\x07\u{184}\x02\
	\x02\u{adc}\u{ade}\x03\x02\x02\x02\u{add}\u{ad9}\x03\x02\x02\x02\u{add}\
	\u{ade}\x03\x02\x02\x02\u{ade}\u{adf}\x03\x02\x02\x02\u{adf}\u{ae0}\x07\
	\x13\x02\x02\u{ae0}\u{ae1}\x07\u{183}\x02\x02\u{ae1}\u{ae2}\x05\u{186}\u{c4}\
	\x02\u{ae2}\u{ae3}\x07\u{184}\x02\x02\u{ae3}\u{18d}\x03\x02\x02\x02\u{ae4}\
	\u{aea}\x05\u{190}\u{c9}\x02\u{ae5}\u{ae6}\x05\u{184}\u{c3}\x02\u{ae6}\u{ae7}\
	\x05\u{190}\u{c9}\x02\u{ae7}\u{ae9}\x03\x02\x02\x02\u{ae8}\u{ae5}\x03\x02\
	\x02\x02\u{ae9}\u{aec}\x03\x02\x02\x02\u{aea}\u{ae8}\x03\x02\x02\x02\u{aea}\
	\u{aeb}\x03\x02\x02\x02\u{aeb}\u{18f}\x03\x02\x02\x02\u{aec}\u{aea}\x03\
	\x02\x02\x02\u{aed}\u{aef}\x05\u{26a}\u{136}\x02\u{aee}\u{af0}\x05\u{19c}\
	\u{cf}\x02\u{aef}\u{aee}\x03\x02\x02\x02\u{af0}\u{af1}\x03\x02\x02\x02\u{af1}\
	\u{aef}\x03\x02\x02\x02\u{af1}\u{af2}\x03\x02\x02\x02\u{af2}\u{191}\x03\
	\x02\x02\x02\u{af3}\u{af4}\x05\u{19e}\u{d0}\x02\u{af4}\u{af5}\x05\u{196}\
	\u{cc}\x02\u{af5}\u{af8}\x03\x02\x02\x02\u{af6}\u{af8}\x05\u{196}\u{cc}\
	\x02\u{af7}\u{af3}\x03\x02\x02\x02\u{af7}\u{af6}\x03\x02\x02\x02\u{af8}\
	\u{193}\x03\x02\x02\x02\u{af9}\u{afb}\x05\u{2a8}\u{155}\x02\u{afa}\u{afc}\
	\x05\u{26a}\u{136}\x02\u{afb}\u{afa}\x03\x02\x02\x02\u{afb}\u{afc}\x03\x02\
	\x02\x02\u{afc}\u{afe}\x03\x02\x02\x02\u{afd}\u{aff}\x05\u{298}\u{14d}\x02\
	\u{afe}\u{afd}\x03\x02\x02\x02\u{afe}\u{aff}\x03\x02\x02\x02\u{aff}\u{b01}\
	\x03\x02\x02\x02\u{b00}\u{b02}\x05\u{2c8}\u{165}\x02\u{b01}\u{b00}\x03\x02\
	\x02\x02\u{b01}\u{b02}\x03\x02\x02\x02\u{b02}\u{b04}\x03\x02\x02\x02\u{b03}\
	\u{b05}\x05\u{2d8}\u{16d}\x02\u{b04}\u{b03}\x03\x02\x02\x02\u{b04}\u{b05}\
	\x03\x02\x02\x02\u{b05}\u{b07}\x03\x02\x02\x02\u{b06}\u{b08}\x05\u{2b8}\
	\u{15d}\x02\u{b07}\u{b06}\x03\x02\x02\x02\u{b07}\u{b08}\x03\x02\x02\x02\
	\u{b08}\u{b0a}\x03\x02\x02\x02\u{b09}\u{b0b}\x05\u{2da}\u{16e}\x02\u{b0a}\
	\u{b09}\x03\x02\x02\x02\u{b0a}\u{b0b}\x03\x02\x02\x02\u{b0b}\u{b12}\x03\
	\x02\x02\x02\u{b0c}\u{b0d}\x07\u{183}\x02\x02\u{b0d}\u{b0e}\x05\u{196}\u{cc}\
	\x02\u{b0e}\u{b0f}\x07\u{184}\x02\x02\u{b0f}\u{b12}\x03\x02\x02\x02\u{b10}\
	\u{b12}\x05\u{29c}\u{14f}\x02\u{b11}\u{af9}\x03\x02\x02\x02\u{b11}\u{b0c}\
	\x03\x02\x02\x02\u{b11}\u{b10}\x03\x02\x02\x02\u{b12}\u{195}\x03\x02\x02\
	\x02\u{b13}\u{b15}\x05\u{194}\u{cb}\x02\u{b14}\u{b16}\x05\u{198}\u{cd}\x02\
	\u{b15}\u{b14}\x03\x02\x02\x02\u{b15}\u{b16}\x03\x02\x02\x02\u{b16}\u{b18}\
	\x03\x02\x02\x02\u{b17}\u{b19}\x05\u{2f0}\u{179}\x02\u{b18}\u{b17}\x03\x02\
	\x02\x02\u{b18}\u{b19}\x03\x02\x02\x02\u{b19}\u{b1b}\x03\x02\x02\x02\u{b1a}\
	\u{b1c}\x05\u{2f2}\u{17a}\x02\u{b1b}\u{b1a}\x03\x02\x02\x02\u{b1b}\u{b1c}\
	\x03\x02\x02\x02\u{b1c}\u{b1e}\x03\x02\x02\x02\u{b1d}\u{b1f}\x05\u{2f6}\
	\u{17c}\x02\u{b1e}\u{b1d}\x03\x02\x02\x02\u{b1e}\u{b1f}\x03\x02\x02\x02\
	\u{b1f}\u{b21}\x03\x02\x02\x02\u{b20}\u{b22}\x05\u{2f8}\u{17d}\x02\u{b21}\
	\u{b20}\x03\x02\x02\x02\u{b21}\u{b22}\x03\x02\x02\x02\u{b22}\u{b24}\x03\
	\x02\x02\x02\u{b23}\u{b25}\x05\u{1a2}\u{d2}\x02\u{b24}\u{b23}\x03\x02\x02\
	\x02\u{b24}\u{b25}\x03\x02\x02\x02\u{b25}\u{197}\x03\x02\x02\x02\u{b26}\
	\u{b27}\x05\u{184}\u{c3}\x02\u{b27}\u{b28}\x05\u{194}\u{cb}\x02\u{b28}\u{b2a}\
	\x03\x02\x02\x02\u{b29}\u{b26}\x03\x02\x02\x02\u{b2a}\u{b2b}\x03\x02\x02\
	\x02\u{b2b}\u{b29}\x03\x02\x02\x02\u{b2b}\u{b2c}\x03\x02\x02\x02\u{b2c}\
	\u{199}\x03\x02\x02\x02\u{b2d}\u{b2f}\x05\u{18a}\u{c6}\x02\u{b2e}\u{b2d}\
	\x03\x02\x02\x02\u{b2e}\u{b2f}\x03\x02\x02\x02\u{b2f}\u{b30}\x03\x02\x02\
	\x02\u{b30}\u{b31}\x05\u{196}\u{cc}\x02\u{b31}\u{19b}\x03\x02\x02\x02\u{b32}\
	\u{b33}\x05\u{19e}\u{d0}\x02\u{b33}\u{b35}\x05\u{2a8}\u{155}\x02\u{b34}\
	\u{b36}\x05\u{27c}\u{13f}\x02\u{b35}\u{b34}\x03\x02\x02\x02\u{b35}\u{b36}\
	\x03\x02\x02\x02\u{b36}\u{b38}\x03\x02\x02\x02\u{b37}\u{b39}\x05\u{298}\
	\u{14d}\x02\u{b38}\u{b37}\x03\x02\x02\x02\u{b38}\u{b39}\x03\x02\x02\x02\
	\u{b39}\u{b3b}\x03\x02\x02\x02\u{b3a}\u{b3c}\x05\u{2c8}\u{165}\x02\u{b3b}\
	\u{b3a}\x03\x02\x02\x02\u{b3b}\u{b3c}\x03\x02\x02\x02\u{b3c}\u{b3e}\x03\
	\x02\x02\x02\u{b3d}\u{b3f}\x05\u{2d8}\u{16d}\x02\u{b3e}\u{b3d}\x03\x02\x02\
	\x02\u{b3e}\u{b3f}\x03\x02\x02\x02\u{b3f}\u{b41}\x03\x02\x02\x02\u{b40}\
	\u{b42}\x05\u{2b8}\u{15d}\x02\u{b41}\u{b40}\x03\x02\x02\x02\u{b41}\u{b42}\
	\x03\x02\x02\x02\u{b42}\u{b44}\x03\x02\x02\x02\u{b43}\u{b45}\x05\u{2da}\
	\u{16e}\x02\u{b44}\u{b43}\x03\x02\x02\x02\u{b44}\u{b45}\x03\x02\x02\x02\
	\u{b45}\u{b47}\x03\x02\x02\x02\u{b46}\u{b48}\x05\u{2f0}\u{179}\x02\u{b47}\
	\u{b46}\x03\x02\x02\x02\u{b47}\u{b48}\x03\x02\x02\x02\u{b48}\u{b4a}\x03\
	\x02\x02\x02\u{b49}\u{b4b}\x05\u{2f2}\u{17a}\x02\u{b4a}\u{b49}\x03\x02\x02\
	\x02\u{b4a}\u{b4b}\x03\x02\x02\x02\u{b4b}\u{b4d}\x03\x02\x02\x02\u{b4c}\
	\u{b4e}\x05\u{2f6}\u{17c}\x02\u{b4d}\u{b4c}\x03\x02\x02\x02\u{b4d}\u{b4e}\
	\x03\x02\x02\x02\u{b4e}\u{b50}\x03\x02\x02\x02\u{b4f}\u{b51}\x05\u{2f8}\
	\u{17d}\x02\u{b50}\u{b4f}\x03\x02\x02\x02\u{b50}\u{b51}\x03\x02\x02\x02\
	\u{b51}\u{b53}\x03\x02\x02\x02\u{b52}\u{b54}\x05\u{1a2}\u{d2}\x02\u{b53}\
	\u{b52}\x03\x02\x02\x02\u{b53}\u{b54}\x03\x02\x02\x02\u{b54}\u{b78}\x03\
	\x02\x02\x02\u{b55}\u{b57}\x05\u{2a8}\u{155}\x02\u{b56}\u{b58}\x05\u{27c}\
	\u{13f}\x02\u{b57}\u{b56}\x03\x02\x02\x02\u{b57}\u{b58}\x03\x02\x02\x02\
	\u{b58}\u{b5a}\x03\x02\x02\x02\u{b59}\u{b5b}\x05\u{298}\u{14d}\x02\u{b5a}\
	\u{b59}\x03\x02\x02\x02\u{b5a}\u{b5b}\x03\x02\x02\x02\u{b5b}\u{b5d}\x03\
	\x02\x02\x02\u{b5c}\u{b5e}\x05\u{2c8}\u{165}\x02\u{b5d}\u{b5c}\x03\x02\x02\
	\x02\u{b5d}\u{b5e}\x03\x02\x02\x02\u{b5e}\u{b60}\x03\x02\x02\x02\u{b5f}\
	\u{b61}\x05\u{2d8}\u{16d}\x02\u{b60}\u{b5f}\x03\x02\x02\x02\u{b60}\u{b61}\
	\x03\x02\x02\x02\u{b61}\u{b63}\x03\x02\x02\x02\u{b62}\u{b64}\x05\u{2b8}\
	\u{15d}\x02\u{b63}\u{b62}\x03\x02\x02\x02\u{b63}\u{b64}\x03\x02\x02\x02\
	\u{b64}\u{b66}\x03\x02\x02\x02\u{b65}\u{b67}\x05\u{2da}\u{16e}\x02\u{b66}\
	\u{b65}\x03\x02\x02\x02\u{b66}\u{b67}\x03\x02\x02\x02\u{b67}\u{b69}\x03\
	\x02\x02\x02\u{b68}\u{b6a}\x05\u{2f0}\u{179}\x02\u{b69}\u{b68}\x03\x02\x02\
	\x02\u{b69}\u{b6a}\x03\x02\x02\x02\u{b6a}\u{b6c}\x03\x02\x02\x02\u{b6b}\
	\u{b6d}\x05\u{2f2}\u{17a}\x02\u{b6c}\u{b6b}\x03\x02\x02\x02\u{b6c}\u{b6d}\
	\x03\x02\x02\x02\u{b6d}\u{b6f}\x03\x02\x02\x02\u{b6e}\u{b70}\x05\u{2f6}\
	\u{17c}\x02\u{b6f}\u{b6e}\x03\x02\x02\x02\u{b6f}\u{b70}\x03\x02\x02\x02\
	\u{b70}\u{b72}\x03\x02\x02\x02\u{b71}\u{b73}\x05\u{2f8}\u{17d}\x02\u{b72}\
	\u{b71}\x03\x02\x02\x02\u{b72}\u{b73}\x03\x02\x02\x02\u{b73}\u{b75}\x03\
	\x02\x02\x02\u{b74}\u{b76}\x05\u{1a2}\u{d2}\x02\u{b75}\u{b74}\x03\x02\x02\
	\x02\u{b75}\u{b76}\x03\x02\x02\x02\u{b76}\u{b78}\x03\x02\x02\x02\u{b77}\
	\u{b32}\x03\x02\x02\x02\u{b77}\u{b55}\x03\x02\x02\x02\u{b78}\u{19d}\x03\
	\x02\x02\x02\u{b79}\u{b8a}\x07\u{9c}\x02\x02\u{b7a}\u{b7b}\x07\u{e2}\x02\
	\x02\u{b7b}\u{b7d}\x05\u{1a0}\u{d1}\x02\u{b7c}\u{b7e}\x05\x2c\x17\x02\u{b7d}\
	\u{b7c}\x03\x02\x02\x02\u{b7d}\u{b7e}\x03\x02\x02\x02\u{b7e}\u{b8b}\x03\
	\x02\x02\x02\u{b7f}\u{b81}\x07\u{a0}\x02\x02\u{b80}\u{b82}\x07\u{13f}\x02\
	\x02\u{b81}\u{b80}\x03\x02\x02\x02\u{b81}\u{b82}\x03\x02\x02\x02\u{b82}\
	\u{b83}\x03\x02\x02\x02\u{b83}\u{b88}\x05\u{37a}\u{1be}\x02\u{b84}\u{b85}\
	\x07\u{183}\x02\x02\u{b85}\u{b86}\x05\u{118}\u{8d}\x02\u{b86}\u{b87}\x07\
	\u{184}\x02\x02\u{b87}\u{b89}\x03\x02\x02\x02\u{b88}\u{b84}\x03\x02\x02\
	\x02\u{b88}\u{b89}\x03\x02\x02\x02\u{b89}\u{b8b}\x03\x02\x02\x02\u{b8a}\
	\u{b7a}\x03\x02\x02\x02\u{b8a}\u{b7f}\x03\x02\x02\x02\u{b8b}\u{19f}\x03\
	\x02\x02\x02\u{b8c}\u{b8e}\x07\u{b5}\x02\x02\u{b8d}\u{b8c}\x03\x02\x02\x02\
	\u{b8d}\u{b8e}\x03\x02\x02\x02\u{b8e}\u{b8f}\x03\x02\x02\x02\u{b8f}\u{b90}\
	\x07\x5c\x02\x02\u{b90}\u{b92}\x07\u{19d}\x02\x02\u{b91}\u{b93}\x05\u{f8}\
	\x7d\x02\u{b92}\u{b91}\x03\x02\x02\x02\u{b92}\u{b93}\x03\x02\x02\x02\u{b93}\
	\u{b95}\x03\x02\x02\x02\u{b94}\u{b96}\x05\u{10e}\u{88}\x02\u{b95}\u{b94}\
	\x03\x02\x02\x02\u{b95}\u{b96}\x03\x02\x02\x02\u{b96}\u{b9a}\x03\x02\x02\
	\x02\u{b97}\u{b98}\x07\u{13f}\x02\x02\u{b98}\u{b9a}\x05\u{37a}\u{1be}\x02\
	\u{b99}\u{b8d}\x03\x02\x02\x02\u{b99}\u{b97}\x03\x02\x02\x02\u{b9a}\u{1a1}\
	\x03\x02\x02\x02\u{b9b}\u{ba4}\x07\u{b2}\x02\x02\u{b9c}\u{b9d}\x07\u{1a2}\
	\x02\x02\u{b9d}\u{b9f}\x07\u{181}\x02\x02\u{b9e}\u{b9c}\x03\x02\x02\x02\
	\u{b9e}\u{b9f}\x03\x02\x02\x02\u{b9f}\u{ba0}\x03\x02\x02\x02\u{ba0}\u{ba5}\
	\x07\u{1a2}\x02\x02\u{ba1}\u{ba2}\x07\u{1a2}\x02\x02\u{ba2}\u{ba3}\x07\u{d6}\
	\x02\x02\u{ba3}\u{ba5}\x07\u{1a2}\x02\x02\u{ba4}\u{b9e}\x03\x02\x02\x02\
	\u{ba4}\u{ba1}\x03\x02\x02\x02\u{ba5}\u{1a3}\x03\x02\x02\x02\u{ba6}\u{ba7}\
	\x07\x55\x02\x02\u{ba7}\u{ba8}\x07\u{87}\x02\x02\u{ba8}\u{baa}\x05\u{28c}\
	\u{147}\x02\u{ba9}\u{bab}\x05\u{298}\u{14d}\x02\u{baa}\u{ba9}\x03\x02\x02\
	\x02\u{baa}\u{bab}\x03\x02\x02\x02\u{bab}\u{1a5}\x03\x02\x02\x02\u{bac}\
	\u{bad}\x05\u{262}\u{132}\x02\u{bad}\u{bae}\x07\u{189}\x02\x02\u{bae}\u{baf}\
	\x05\u{1a8}\u{d5}\x02\u{baf}\u{1a7}\x03\x02\x02\x02\u{bb0}\u{bb3}\x05\u{264}\
	\u{133}\x02\u{bb1}\u{bb3}\x05\u{33c}\u{19f}\x02\u{bb2}\u{bb0}\x03\x02\x02\
	\x02\u{bb2}\u{bb1}\x03\x02\x02\x02\u{bb3}\u{1a9}\x03\x02\x02\x02\u{bb4}\
	\u{bb5}\x07\u{126}\x02\x02\u{bb5}\u{bba}\x05\u{1a6}\u{d4}\x02\u{bb6}\u{bb7}\
	\x07\u{181}\x02\x02\u{bb7}\u{bb9}\x05\u{1a6}\u{d4}\x02\u{bb8}\u{bb6}\x03\
	\x02\x02\x02\u{bb9}\u{bbc}\x03\x02\x02\x02\u{bba}\u{bb8}\x03\x02\x02\x02\
	\u{bba}\u{bbb}\x03\x02\x02\x02\u{bbb}\u{1ab}\x03\x02\x02\x02\u{bbc}\u{bba}\
	\x03\x02\x02\x02\u{bbd}\u{bbe}\x07\u{163}\x02\x02\u{bbe}\u{bbf}\x05\u{28c}\
	\u{147}\x02\u{bbf}\u{bc1}\x05\u{1aa}\u{d6}\x02\u{bc0}\u{bc2}\x05\u{298}\
	\u{14d}\x02\u{bc1}\u{bc0}\x03\x02\x02\x02\u{bc1}\u{bc2}\x03\x02\x02\x02\
	\u{bc2}\u{1ad}\x03\x02\x02\x02\u{bc3}\u{bc8}\x05\u{1b0}\u{d9}\x02\u{bc4}\
	\u{bc8}\x05\u{1ba}\u{de}\x02\u{bc5}\u{bc8}\x05\u{1bc}\u{df}\x02\u{bc6}\u{bc8}\
	\x05\u{1be}\u{e0}\x02\u{bc7}\u{bc3}\x03\x02\x02\x02\u{bc7}\u{bc4}\x03\x02\
	\x02\x02\u{bc7}\u{bc5}\x03\x02\x02\x02\u{bc7}\u{bc6}\x03\x02\x02\x02\u{bc8}\
	\u{1af}\x03\x02\x02\x02\u{bc9}\u{bca}\x07\u{134}\x02\x02\u{bca}\u{bd3}\x07\
	\u{14e}\x02\x02\u{bcb}\u{bd0}\x05\u{1b2}\u{da}\x02\u{bcc}\u{bcd}\x07\u{181}\
	\x02\x02\u{bcd}\u{bcf}\x05\u{1b2}\u{da}\x02\u{bce}\u{bcc}\x03\x02\x02\x02\
	\u{bcf}\u{bd2}\x03\x02\x02\x02\u{bd0}\u{bce}\x03\x02\x02\x02\u{bd0}\u{bd1}\
	\x03\x02\x02\x02\u{bd1}\u{bd4}\x03\x02\x02\x02\u{bd2}\u{bd0}\x03\x02\x02\
	\x02\u{bd3}\u{bcb}\x03\x02\x02\x02\u{bd3}\u{bd4}\x03\x02\x02\x02\u{bd4}\
	\u{1b1}\x03\x02\x02\x02\u{bd5}\u{bd8}\x05\u{1b6}\u{dc}\x02\u{bd6}\u{bd8}\
	\x05\u{1b4}\u{db}\x02\u{bd7}\u{bd5}\x03\x02\x02\x02\u{bd7}\u{bd6}\x03\x02\
	\x02\x02\u{bd8}\u{1b3}\x03\x02\x02\x02\u{bd9}\u{bda}\x07\u{fc}\x02\x02\u{bda}\
	\u{bdb}\x09\x18\x02\x02\u{bdb}\u{1b5}\x03\x02\x02\x02\u{bdc}\u{bdd}\x07\
	\u{a2}\x02\x02\u{bdd}\u{bde}\x07\u{b0}\x02\x02\u{bde}\u{bdf}\x05\u{1b8}\
	\u{dd}\x02\u{bdf}\u{1b7}\x03\x02\x02\x02\u{be0}\u{be1}\x07\u{12e}\x02\x02\
	\u{be1}\u{1b9}\x03\x02\x02\x02\u{be2}\u{be4}\x07\x32\x02\x02\u{be3}\u{be5}\
	\x07\u{17a}\x02\x02\u{be4}\u{be3}\x03\x02\x02\x02\u{be4}\u{be5}\x03\x02\
	\x02\x02\u{be5}\u{1bb}\x03\x02\x02\x02\u{be6}\u{be8}\x07\u{118}\x02\x02\
	\u{be7}\u{be9}\x07\u{17a}\x02\x02\u{be8}\u{be7}\x03\x02\x02\x02\u{be8}\u{be9}\
	\x03\x02\x02\x02\u{be9}\u{1bd}\x03\x02\x02\x02\u{bea}\u{beb}\x07\u{126}\
	\x02\x02\u{beb}\u{bec}\x07\x18\x02\x02\u{bec}\u{bed}\x05\u{378}\u{1bd}\x02\
	\u{bed}\u{1bf}\x03\x02\x02\x02\u{bee}\u{bef}\x07\x03\x02\x02\u{bef}\u{bf1}\
	\x07\u{150}\x02\x02\u{bf0}\u{bf2}\x07\u{1a2}\x02\x02\u{bf1}\u{bf0}\x03\x02\
	\x02\x02\u{bf2}\u{bf3}\x03\x02\x02\x02\u{bf3}\u{bf1}\x03\x02\x02\x02\u{bf3}\
	\u{bf4}\x03\x02\x02\x02\u{bf4}\u{1c1}\x03\x02\x02\x02\u{bf5}\u{bf6}\x07\
	\x03\x02\x02\u{bf6}\u{bf8}\x07\x34\x02\x02\u{bf7}\u{bf9}\x07\u{1a2}\x02\
	\x02\u{bf8}\u{bf7}\x03\x02\x02\x02\u{bf9}\u{bfa}\x03\x02\x02\x02\u{bfa}\
	\u{bf8}\x03\x02\x02\x02\u{bfa}\u{bfb}\x03\x02\x02\x02\u{bfb}\u{1c3}\x03\
	\x02\x02\x02\u{bfc}\u{bfe}\x07\u{c4}\x02\x02\u{bfd}\u{bff}\x07\u{1a7}\x02\
	\x02\u{bfe}\u{bfd}\x03\x02\x02\x02\u{bfe}\u{bff}\x03\x02\x02\x02\u{bff}\
	\u{c00}\x03\x02\x02\x02\u{c00}\u{c01}\x07\u{a0}\x02\x02\u{c01}\u{c06}\x05\
	\u{28c}\u{147}\x02\u{c02}\u{c04}\x07\x13\x02\x02\u{c03}\u{c02}\x03\x02\x02\
	\x02\u{c03}\u{c04}\x03\x02\x02\x02\u{c04}\u{c05}\x03\x02\x02\x02\u{c05}\
	\u{c07}\x05\u{38c}\u{1c7}\x02\u{c06}\u{c03}\x03\x02\x02\x02\u{c06}\u{c07}\
	\x03\x02\x02\x02\u{c07}\u{c08}\x03\x02\x02\x02\u{c08}\u{c09}\x07\u{168}\
	\x02\x02\u{c09}\u{c0a}\x05\u{272}\u{13a}\x02\u{c0a}\u{c0b}\x07\u{d7}\x02\
	\x02\u{c0b}\u{c0c}\x05\u{328}\u{195}\x02\u{c0c}\u{c0d}\x05\u{1c6}\u{e4}\
	\x02\u{c0d}\u{1c5}\x03\x02\x02\x02\u{c0e}\u{c11}\x05\u{1ca}\u{e6}\x02\u{c0f}\
	\u{c11}\x05\u{1cc}\u{e7}\x02\u{c10}\u{c0e}\x03\x02\x02\x02\u{c10}\u{c0f}\
	\x03\x02\x02\x02\u{c11}\u{c14}\x03\x02\x02\x02\u{c12}\u{c10}\x03\x02\x02\
	\x02\u{c12}\u{c13}\x03\x02\x02\x02\u{c13}\u{c16}\x03\x02\x02\x02\u{c14}\
	\u{c12}\x03\x02\x02\x02\u{c15}\u{c17}\x05\u{1c8}\u{e5}\x02\u{c16}\u{c15}\
	\x03\x02\x02\x02\u{c16}\u{c17}\x03\x02\x02\x02\u{c17}\u{1c7}\x03\x02\x02\
	\x02\u{c18}\u{c19}\x07\u{174}\x02\x02\u{c19}\u{c1a}\x07\u{cf}\x02\x02\u{c1a}\
	\u{c1d}\x07\u{c2}\x02\x02\u{c1b}\u{c1c}\x07\x0d\x02\x02\u{c1c}\u{c1e}\x05\
	\u{328}\u{195}\x02\u{c1d}\u{c1b}\x03\x02\x02\x02\u{c1d}\u{c1e}\x03\x02\x02\
	\x02\u{c1e}\u{c1f}\x03\x02\x02\x02\u{c1f}\u{c20}\x07\u{145}\x02\x02\u{c20}\
	\u{c22}\x07\u{9c}\x02\x02\u{c21}\u{c23}\x05\u{120}\u{91}\x02\u{c22}\u{c21}\
	\x03\x02\x02\x02\u{c22}\u{c23}\x03\x02\x02\x02\u{c23}\u{c24}\x03\x02\x02\
	\x02\u{c24}\u{c25}\x07\u{16c}\x02\x02\u{c25}\u{c26}\x05\u{2a2}\u{152}\x02\
	\u{c26}\u{1c9}\x03\x02\x02\x02\u{c27}\u{c28}\x07\u{174}\x02\x02\u{c28}\u{c29}\
	\x07\u{c2}\x02\x02\u{c29}\u{c2a}\x07\x0d\x02\x02\u{c2a}\u{c2b}\x05\u{328}\
	\u{195}\x02\u{c2b}\u{c2c}\x07\u{145}\x02\x02\u{c2c}\u{c2d}\x05\u{1ce}\u{e8}\
	\x02\u{c2d}\u{1cb}\x03\x02\x02\x02\u{c2e}\u{c2f}\x07\u{174}\x02\x02\u{c2f}\
	\u{c30}\x07\u{c2}\x02\x02\u{c30}\u{c31}\x07\u{145}\x02\x02\u{c31}\u{c32}\
	\x05\u{1ce}\u{e8}\x02\u{c32}\u{1cd}\x03\x02\x02\x02\u{c33}\u{c34}\x07\u{163}\
	\x02\x02\u{c34}\u{c37}\x05\u{1aa}\u{d6}\x02\u{c35}\u{c37}\x07\x55\x02\x02\
	\u{c36}\u{c33}\x03\x02\x02\x02\u{c36}\u{c35}\x03\x02\x02\x02\u{c37}\u{1cf}\
	\x03\x02\x02\x02\u{c38}\u{c39}\x07\u{aa}\x02\x02\u{c39}\u{c3b}\x07\u{f9}\
	\x02\x02\u{c3a}\u{c3c}\x07\u{19d}\x02\x02\u{c3b}\u{c3a}\x03\x02\x02\x02\
	\u{c3c}\u{c3d}\x03\x02\x02\x02\u{c3d}\u{c3b}\x03\x02\x02\x02\u{c3d}\u{c3e}\
	\x03\x02\x02\x02\u{c3e}\u{1d1}\x03\x02\x02\x02\u{c3f}\u{c40}\x07\x35\x02\
	\x02\u{c40}\u{c41}\x07\u{189}\x02\x02\u{c41}\u{c42}\x07\u{1a2}\x02\x02\u{c42}\
	\u{1d3}\x03\x02\x02\x02\u{c43}\u{c44}\x07\u{ed}\x02\x02\u{c44}\u{c45}\x07\
	\u{19d}\x02\x02\u{c45}\u{1d5}\x03\x02\x02\x02\u{c46}\u{c47}\x07\u{156}\x02\
	\x02\u{c47}\u{c48}\x07\u{19d}\x02\x02\u{c48}\u{1d7}\x03\x02\x02\x02\u{c49}\
	\u{c4a}\x07\u{136}\x02\x02\u{c4a}\u{c4b}\x07\u{19d}\x02\x02\u{c4b}\u{1d9}\
	\x03\x02\x02\x02\u{c4c}\u{c64}\x07\x0b\x02\x02\u{c4d}\u{c4e}\x07\u{13f}\
	\x02\x02\u{c4e}\u{c4f}\x05\u{28c}\u{147}\x02\u{c4f}\u{c50}\x05\u{1dc}\u{ef}\
	\x02\u{c50}\u{c65}\x03\x02\x02\x02\u{c51}\u{c52}\x07\u{170}\x02\x02\u{c52}\
	\u{c54}\x05\u{28c}\u{147}\x02\u{c53}\u{c55}\x07\x13\x02\x02\u{c54}\u{c53}\
	\x03\x02\x02\x02\u{c54}\u{c55}\x03\x02\x02\x02\u{c55}\u{c56}\x03\x02\x02\
	\x02\u{c56}\u{c57}\x05\u{1e2}\u{f2}\x02\u{c57}\u{c65}\x03\x02\x02\x02\u{c58}\
	\u{c59}\x07\u{c3}\x02\x02\u{c59}\u{c5a}\x07\u{170}\x02\x02\u{c5a}\u{c5b}\
	\x05\u{28c}\u{147}\x02\u{c5b}\u{c5c}\x05\u{1e4}\u{f3}\x02\u{c5c}\u{c65}\
	\x03\x02\x02\x02\u{c5d}\u{c5e}\x05\x5c\x2f\x02\u{c5e}\u{c5f}\x05\u{1ea}\
	\u{f6}\x02\u{c5f}\u{c65}\x03\x02\x02\x02\u{c60}\u{c61}\x07\x47\x02\x02\u{c61}\
	\u{c65}\x05\u{248}\u{125}\x02\u{c62}\u{c63}\x07\u{96}\x02\x02\u{c63}\u{c65}\
	\x05\u{244}\u{123}\x02\u{c64}\u{c4d}\x03\x02\x02\x02\u{c64}\u{c51}\x03\x02\
	\x02\x02\u{c64}\u{c58}\x03\x02\x02\x02\u{c64}\u{c5d}\x03\x02\x02\x02\u{c64}\
	\u{c60}\x03\x02\x02\x02\u{c64}\u{c62}\x03\x02\x02\x02\u{c65}\u{1db}\x03\
	\x02\x02\x02\u{c66}\u{c7a}\x05\u{1f4}\u{fb}\x02\u{c67}\u{c7a}\x05\u{214}\
	\u{10b}\x02\u{c68}\u{c7a}\x05\u{208}\u{105}\x02\u{c69}\u{c7a}\x05\u{20c}\
	\u{107}\x02\u{c6a}\u{c7a}\x05\u{20e}\u{108}\x02\u{c6b}\u{c7a}\x05\u{210}\
	\u{109}\x02\u{c6c}\u{c7a}\x05\u{216}\u{10c}\x02\u{c6d}\u{c7a}\x05\u{22c}\
	\u{117}\x02\u{c6e}\u{c7a}\x05\u{22e}\u{118}\x02\u{c6f}\u{c7a}\x05\u{1e0}\
	\u{f1}\x02\u{c70}\u{c7a}\x05\u{1fe}\u{100}\x02\u{c71}\u{c7a}\x05\u{1f8}\
	\u{fd}\x02\u{c72}\u{c7a}\x05\u{1de}\u{f0}\x02\u{c73}\u{c74}\x05\u{37c}\u{1bf}\
	\x02\u{c74}\u{c75}\x05\u{1de}\u{f0}\x02\u{c75}\u{c7a}\x03\x02\x02\x02\u{c76}\
	\u{c7a}\x05\u{23e}\u{120}\x02\u{c77}\u{c7a}\x05\u{240}\u{121}\x02\u{c78}\
	\u{c7a}\x05\u{242}\u{122}\x02\u{c79}\u{c66}\x03\x02\x02\x02\u{c79}\u{c67}\
	\x03\x02\x02\x02\u{c79}\u{c68}\x03\x02\x02\x02\u{c79}\u{c69}\x03\x02\x02\
	\x02\u{c79}\u{c6a}\x03\x02\x02\x02\u{c79}\u{c6b}\x03\x02\x02\x02\u{c79}\
	\u{c6c}\x03\x02\x02\x02\u{c79}\u{c6d}\x03\x02\x02\x02\u{c79}\u{c6e}\x03\
	\x02\x02\x02\u{c79}\u{c6f}\x03\x02\x02\x02\u{c79}\u{c70}\x03\x02\x02\x02\
	\u{c79}\u{c71}\x03\x02\x02\x02\u{c79}\u{c72}\x03\x02\x02\x02\u{c79}\u{c73}\
	\x03\x02\x02\x02\u{c79}\u{c76}\x03\x02\x02\x02\u{c79}\u{c77}\x03\x02\x02\
	\x02\u{c79}\u{c78}\x03\x02\x02\x02\u{c7a}\u{1dd}\x03\x02\x02\x02\u{c7b}\
	\u{c8b}\x05\u{21e}\u{110}\x02\u{c7c}\u{c8b}\x05\u{22a}\u{116}\x02\u{c7d}\
	\u{c8b}\x05\u{234}\u{11b}\x02\u{c7e}\u{c8b}\x05\u{21a}\u{10e}\x02\u{c7f}\
	\u{c8b}\x05\u{230}\u{119}\x02\u{c80}\u{c8b}\x05\u{236}\u{11c}\x02\u{c81}\
	\u{c8b}\x05\u{222}\u{112}\x02\u{c82}\u{c8b}\x05\u{220}\u{111}\x02\u{c83}\
	\u{c8b}\x05\u{23c}\u{11f}\x02\u{c84}\u{c8b}\x05\u{202}\u{102}\x02\u{c85}\
	\u{c8b}\x05\u{204}\u{103}\x02\u{c86}\u{c8b}\x05\u{200}\u{101}\x02\u{c87}\
	\u{c8b}\x05\u{1f6}\u{fc}\x02\u{c88}\u{c8b}\x05\u{1fa}\u{fe}\x02\u{c89}\u{c8b}\
	\x05\u{1fc}\u{ff}\x02\u{c8a}\u{c7b}\x03\x02\x02\x02\u{c8a}\u{c7c}\x03\x02\
	\x02\x02\u{c8a}\u{c7d}\x03\x02\x02\x02\u{c8a}\u{c7e}\x03\x02\x02\x02\u{c8a}\
	\u{c7f}\x03\x02\x02\x02\u{c8a}\u{c80}\x03\x02\x02\x02\u{c8a}\u{c81}\x03\
	\x02\x02\x02\u{c8a}\u{c82}\x03\x02\x02\x02\u{c8a}\u{c83}\x03\x02\x02\x02\
	\u{c8a}\u{c84}\x03\x02\x02\x02\u{c8a}\u{c85}\x03\x02\x02\x02\u{c8a}\u{c86}\
	\x03\x02\x02\x02\u{c8a}\u{c87}\x03\x02\x02\x02\u{c8a}\u{c88}\x03\x02\x02\
	\x02\u{c8a}\u{c89}\x03\x02\x02\x02\u{c8b}\u{1df}\x03\x02\x02\x02\u{c8c}\
	\u{c8d}\x07\u{e4}\x02\x02\u{c8d}\u{c8e}\x07\x2f\x02\x02\u{c8e}\u{c8f}\x07\
	\u{183}\x02\x02\u{c8f}\u{c90}\x05\u{154}\u{ab}\x02\u{c90}\u{c91}\x07\u{184}\
	\x02\x02\u{c91}\u{1e1}\x03\x02\x02\x02\u{c92}\u{c98}\x05\u{218}\u{10d}\x02\
	\u{c93}\u{c98}\x05\u{1f4}\u{fb}\x02\u{c94}\u{c98}\x05\u{208}\u{105}\x02\
	\u{c95}\u{c98}\x05\u{214}\u{10b}\x02\u{c96}\u{c98}\x05\u{19a}\u{ce}\x02\
	\u{c97}\u{c92}\x03\x02\x02\x02\u{c97}\u{c93}\x03\x02\x02\x02\u{c97}\u{c94}\
	\x03\x02\x02\x02\u{c97}\u{c95}\x03\x02\x02\x02\u{c97}\u{c96}\x03\x02\x02\
	\x02\u{c98}\u{1e3}\x03\x02\x02\x02\u{c99}\u{c9c}\x05\u{1e6}\u{f4}\x02\u{c9a}\
	\u{c9c}\x05\u{1e8}\u{f5}\x02\u{c9b}\u{c99}\x03\x02\x02\x02\u{c9b}\u{c9a}\
	\x03\x02\x02\x02\u{c9c}\u{1e5}\x03\x02\x02\x02\u{c9d}\u{ca0}\x05\x30\x19\
	\x02\u{c9e}\u{ca0}\x05\x32\x1a\x02\u{c9f}\u{c9d}\x03\x02\x02\x02\u{c9f}\
	\u{c9e}\x03\x02\x02\x02\u{ca0}\u{1e7}\x03\x02\x02\x02\u{ca1}\u{ca2}\x07\
	\u{100}\x02\x02\u{ca2}\u{1e9}\x03\x02\x02\x02\u{ca3}\u{ca7}\x05\u{1ec}\u{f7}\
	\x02\u{ca4}\u{ca7}\x05\u{1ee}\u{f8}\x02\u{ca5}\u{ca7}\x05\u{1f0}\u{f9}\x02\
	\u{ca6}\u{ca3}\x03\x02\x02\x02\u{ca6}\u{ca4}\x03\x02\x02\x02\u{ca6}\u{ca5}\
	\x03\x02\x02\x02\u{ca7}\u{1eb}\x03\x02\x02\x02\u{ca8}\u{ca9}\x05\u{38c}\
	\u{1c7}\x02\u{ca9}\u{caa}\x07\u{126}\x02\x02\u{caa}\u{cab}\x07\x4d\x02\x02\
	\u{cab}\u{cac}\x05\x3e\x20\x02\u{cac}\u{1ed}\x03\x02\x02\x02\u{cad}\u{cae}\
	\x05\u{38c}\u{1c7}\x02\u{cae}\u{caf}\x07\u{126}\x02\x02\u{caf}\u{cb0}\x07\
	\u{e3}\x02\x02\u{cb0}\u{cb1}\x05\u{94}\x4b\x02\u{cb1}\u{1ef}\x03\x02\x02\
	\x02\u{cb2}\u{cb3}\x05\u{38c}\u{1c7}\x02\u{cb3}\u{cb4}\x07\u{126}\x02\x02\
	\u{cb4}\u{cb5}\x09\x19\x02\x02\u{cb5}\u{cb6}\x07\u{19d}\x02\x02\u{cb6}\u{1f1}\
	\x03\x02\x02\x02\u{cb7}\u{cb8}\x05\u{38c}\u{1c7}\x02\u{cb8}\u{cb9}\x07\u{126}\
	\x02\x02\u{cb9}\u{cba}\x07\u{bd}\x02\x02\u{cba}\u{cbb}\x07\u{19d}\x02\x02\
	\u{cbb}\u{1f3}\x03\x02\x02\x02\u{cbc}\u{cbd}\x07\u{109}\x02\x02\u{cbd}\u{cbe}\
	\x07\u{14b}\x02\x02\u{cbe}\u{cbf}\x05\u{28c}\u{147}\x02\u{cbf}\u{1f5}\x03\
	\x02\x02\x02\u{cc0}\u{cc3}\x07\x06\x02\x02\u{cc1}\u{cc3}\x07\u{10d}\x02\
	\x02\u{cc2}\u{cc0}\x03\x02\x02\x02\u{cc2}\u{cc1}\x03\x02\x02\x02\u{cc3}\
	\u{cc4}\x03\x02\x02\x02\u{cc4}\u{cc5}\x07\x30\x02\x02\u{cc5}\u{cc6}\x07\
	\u{183}\x02\x02\u{cc6}\u{cc7}\x05\u{112}\u{8a}\x02\u{cc7}\u{cc9}\x07\u{184}\
	\x02\x02\u{cc8}\u{cca}\x05\x2a\x16\x02\u{cc9}\u{cc8}\x03\x02\x02\x02\u{cc9}\
	\u{cca}\x03\x02\x02\x02\u{cca}\u{1f7}\x03\x02\x02\x02\u{ccb}\u{cce}\x07\
	\x06\x02\x02\u{ccc}\u{ccf}\x05\u{138}\u{9d}\x02\u{ccd}\u{ccf}\x05\u{12e}\
	\u{98}\x02\u{cce}\u{ccc}\x03\x02\x02\x02\u{cce}\u{ccd}\x03\x02\x02\x02\u{ccf}\
	\u{1f9}\x03\x02\x02\x02\u{cd0}\u{cd1}\x07\u{163}\x02\x02\u{cd1}\u{cd3}\x07\
	\x30\x02\x02\u{cd2}\u{cd4}\x05\x2a\x16\x02\u{cd3}\u{cd2}\x03\x02\x02\x02\
	\u{cd3}\u{cd4}\x03\x02\x02\x02\u{cd4}\u{1fb}\x03\x02\x02\x02\u{cd5}\u{cd6}\
	\x05\u{124}\u{93}\x02\u{cd6}\u{cd8}\x07\u{d1}\x02\x02\u{cd7}\u{cd9}\x07\
	\x24\x02\x02\u{cd8}\u{cd7}\x03\x02\x02\x02\u{cd8}\u{cd9}\x03\x02\x02\x02\
	\u{cd9}\u{cde}\x03\x02\x02\x02\u{cda}\u{cdb}\x05\u{124}\u{93}\x02\u{cdb}\
	\u{cdc}\x07\u{d5}\x02\x02\u{cdc}\u{cde}\x03\x02\x02\x02\u{cdd}\u{cd5}\x03\
	\x02\x02\x02\u{cdd}\u{cda}\x03\x02\x02\x02\u{cde}\u{1fd}\x03\x02\x02\x02\
	\u{cdf}\u{ce0}\x07\x63\x02\x02\u{ce0}\u{ce1}\x07\x39\x02\x02\u{ce1}\u{ce2}\
	\x05\u{38c}\u{1c7}\x02\u{ce2}\u{1ff}\x03\x02\x02\x02\u{ce3}\u{ce5}\x07\x28\
	\x02\x02\u{ce4}\u{ce6}\x07\x2f\x02\x02\u{ce5}\u{ce4}\x03\x02\x02\x02\u{ce5}\
	\u{ce6}\x03\x02\x02\x02\u{ce6}\u{ce7}\x03\x02\x02\x02\u{ce7}\u{ce8}\x05\
	\u{38c}\u{1c7}\x02\u{ce8}\u{ce9}\x05\u{38c}\u{1c7}\x02\u{ce9}\u{ceb}\x05\
	\u{174}\u{bb}\x02\u{cea}\u{cec}\x05\u{162}\u{b2}\x02\u{ceb}\u{cea}\x03\x02\
	\x02\x02\u{ceb}\u{cec}\x03\x02\x02\x02\u{cec}\u{cef}\x03\x02\x02\x02\u{ced}\
	\u{cee}\x07\x31\x02\x02\u{cee}\u{cf0}\x07\u{19d}\x02\x02\u{cef}\u{ced}\x03\
	\x02\x02\x02\u{cef}\u{cf0}\x03\x02\x02\x02\u{cf0}\u{cf2}\x03\x02\x02\x02\
	\u{cf1}\u{cf3}\x05\u{206}\u{104}\x02\u{cf2}\u{cf1}\x03\x02\x02\x02\u{cf2}\
	\u{cf3}\x03\x02\x02\x02\u{cf3}\u{cf5}\x03\x02\x02\x02\u{cf4}\u{cf6}\x05\
	\x2a\x16\x02\u{cf5}\u{cf4}\x03\x02\x02\x02\u{cf5}\u{cf6}\x03\x02\x02\x02\
	\u{cf6}\u{201}\x03\x02\x02\x02\u{cf7}\u{cf8}\x07\u{163}\x02\x02\u{cf8}\u{cf9}\
	\x07\u{135}\x02\x02\u{cf9}\u{cfb}\x07\u{82}\x02\x02\u{cfa}\u{cfc}\x07\x2f\
	\x02\x02\u{cfb}\u{cfa}\x03\x02\x02\x02\u{cfb}\u{cfc}\x03\x02\x02\x02\u{cfc}\
	\u{cfd}\x03\x02\x02\x02\u{cfd}\u{cfe}\x05\u{38c}\u{1c7}\x02\u{cfe}\u{cff}\
	\x07\u{126}\x02\x02\u{cff}\u{d02}\x05\u{fc}\x7f\x02\u{d00}\u{d01}\x07\x31\
	\x02\x02\u{d01}\u{d03}\x07\u{19d}\x02\x02\u{d02}\u{d00}\x03\x02\x02\x02\
	\u{d02}\u{d03}\x03\x02\x02\x02\u{d03}\u{203}\x03\x02\x02\x02\u{d04}\u{d05}\
	\x07\u{163}\x02\x02\u{d05}\u{d06}\x07\u{135}\x02\x02\u{d06}\u{d07}\x07\u{126}\
	\x02\x02\u{d07}\u{d08}\x05\u{fc}\x7f\x02\u{d08}\u{205}\x03\x02\x02\x02\u{d09}\
	\u{d0d}\x07\x7e\x02\x02\u{d0a}\u{d0b}\x07\x08\x02\x02\u{d0b}\u{d0d}\x05\
	\u{38c}\u{1c7}\x02\u{d0c}\u{d09}\x03\x02\x02\x02\u{d0c}\u{d0a}\x03\x02\x02\
	\x02\u{d0d}\u{207}\x03\x02\x02\x02\u{d0e}\u{d10}\x07\x06\x02\x02\u{d0f}\
	\u{d11}\x05\x2c\x17\x02\u{d10}\u{d0f}\x03\x02\x02\x02\u{d10}\u{d11}\x03\
	\x02\x02\x02\u{d11}\u{d13}\x03\x02\x02\x02\u{d12}\u{d14}\x05\u{20a}\u{106}\
	\x02\u{d13}\u{d12}\x03\x02\x02\x02\u{d14}\u{d15}\x03\x02\x02\x02\u{d15}\
	\u{d13}\x03\x02\x02\x02\u{d15}\u{d16}\x03\x02\x02\x02\u{d16}\u{209}\x03\
	\x02\x02\x02\u{d17}\u{d19}\x05\u{37c}\u{1bf}\x02\u{d18}\u{d1a}\x05\u{212}\
	\u{10a}\x02\u{d19}\u{d18}\x03\x02\x02\x02\u{d19}\u{d1a}\x03\x02\x02\x02\
	\u{d1a}\u{20b}\x03\x02\x02\x02\u{d1b}\u{d1f}\x07\u{14c}\x02\x02\u{d1c}\u{d1e}\
	\x05\u{37c}\u{1bf}\x02\u{d1d}\u{d1c}\x03\x02\x02\x02\u{d1e}\u{d21}\x03\x02\
	\x02\x02\u{d1f}\u{d1d}\x03\x02\x02\x02\u{d1f}\u{d20}\x03\x02\x02\x02\u{d20}\
	\u{20d}\x03\x02\x02\x02\u{d21}\u{d1f}\x03\x02\x02\x02\u{d22}\u{d26}\x07\
	\x11\x02\x02\u{d23}\u{d25}\x05\u{37c}\u{1bf}\x02\u{d24}\u{d23}\x03\x02\x02\
	\x02\u{d25}\u{d28}\x03\x02\x02\x02\u{d26}\u{d24}\x03\x02\x02\x02\u{d26}\
	\u{d27}\x03\x02\x02\x02\u{d27}\u{20f}\x03\x02\x02\x02\u{d28}\u{d26}\x03\
	\x02\x02\x02\u{d29}\u{d2d}\x07\u{157}\x02\x02\u{d2a}\u{d2c}\x05\u{37c}\u{1bf}\
	\x02\u{d2b}\u{d2a}\x03\x02\x02\x02\u{d2c}\u{d2f}\x03\x02\x02\x02\u{d2d}\
	\u{d2b}\x03\x02\x02\x02\u{d2d}\u{d2e}\x03\x02\x02\x02\u{d2e}\u{211}\x03\
	\x02\x02\x02\u{d2f}\u{d2d}\x03\x02\x02\x02\u{d30}\u{d31}\x07\u{b6}\x02\x02\
	\u{d31}\u{d32}\x07\u{19d}\x02\x02\u{d32}\u{213}\x03\x02\x02\x02\u{d33}\u{d35}\
	\x07\x63\x02\x02\u{d34}\u{d36}\x05\x28\x15\x02\u{d35}\u{d34}\x03\x02\x02\
	\x02\u{d35}\u{d36}\x03\x02\x02\x02\u{d36}\u{d37}\x03\x02\x02\x02\u{d37}\
	\u{d38}\x07\u{e4}\x02\x02\u{d38}\u{d3e}\x05\u{380}\u{1c1}\x02\u{d39}\u{d3a}\
	\x07\u{181}\x02\x02\u{d3a}\u{d3b}\x07\u{e4}\x02\x02\u{d3b}\u{d3d}\x05\u{380}\
	\u{1c1}\x02\u{d3c}\u{d39}\x03\x02\x02\x02\u{d3d}\u{d40}\x03\x02\x02\x02\
	\u{d3e}\u{d3c}\x03\x02\x02\x02\u{d3e}\u{d3f}\x03\x02\x02\x02\u{d3f}\u{d42}\
	\x03\x02\x02\x02\u{d40}\u{d3e}\x03\x02\x02\x02\u{d41}\u{d43}\x07\u{f6}\x02\
	\x02\u{d42}\u{d41}\x03\x02\x02\x02\u{d42}\u{d43}\x03\x02\x02\x02\u{d43}\
	\u{d45}\x03\x02\x02\x02\u{d44}\u{d46}\x05\x12\x0a\x02\u{d45}\u{d44}\x03\
	\x02\x02\x02\u{d45}\u{d46}\x03\x02\x02\x02\u{d46}\u{215}\x03\x02\x02\x02\
	\u{d47}\u{d48}\x07\u{126}\x02\x02\u{d48}\u{d49}\x07\u{142}\x02\x02\u{d49}\
	\u{d51}\x05\u{fc}\x7f\x02\u{d4a}\u{d4b}\x07\u{161}\x02\x02\u{d4b}\u{d4d}\
	\x07\u{142}\x02\x02\u{d4c}\u{d4e}\x05\x28\x15\x02\u{d4d}\u{d4c}\x03\x02\
	\x02\x02\u{d4d}\u{d4e}\x03\x02\x02\x02\u{d4e}\u{d4f}\x03\x02\x02\x02\u{d4f}\
	\u{d51}\x05\u{fc}\x7f\x02\u{d50}\u{d47}\x03\x02\x02\x02\u{d50}\u{d4a}\x03\
	\x02\x02\x02\u{d51}\u{217}\x03\x02\x02\x02\u{d52}\u{d53}\x07\u{126}\x02\
	\x02\u{d53}\u{d54}\x07\u{142}\x02\x02\u{d54}\u{d5c}\x05\u{fc}\x7f\x02\u{d55}\
	\u{d56}\x07\u{161}\x02\x02\u{d56}\u{d58}\x07\u{142}\x02\x02\u{d57}\u{d59}\
	\x05\x28\x15\x02\u{d58}\u{d57}\x03\x02\x02\x02\u{d58}\u{d59}\x03\x02\x02\
	\x02\u{d59}\u{d5a}\x03\x02\x02\x02\u{d5a}\u{d5c}\x05\u{fc}\x7f\x02\u{d5b}\
	\u{d52}\x03\x02\x02\x02\u{d5b}\u{d55}\x03\x02\x02\x02\u{d5c}\u{219}\x03\
	\x02\x02\x02\u{d5d}\u{d67}\x07\u{126}\x02\x02\u{d5e}\u{d5f}\x07\u{123}\x02\
	\x02\u{d5f}\u{d63}\x07\u{19d}\x02\x02\u{d60}\u{d61}\x07\u{178}\x02\x02\u{d61}\
	\u{d62}\x07\u{124}\x02\x02\u{d62}\u{d64}\x05\u{fc}\x7f\x02\u{d63}\u{d60}\
	\x03\x02\x02\x02\u{d63}\u{d64}\x03\x02\x02\x02\u{d64}\u{d68}\x03\x02\x02\
	\x02\u{d65}\u{d66}\x07\u{124}\x02\x02\u{d66}\u{d68}\x05\u{fc}\x7f\x02\u{d67}\
	\u{d5e}\x03\x02\x02\x02\u{d67}\u{d65}\x03\x02\x02\x02\u{d68}\u{d6d}\x03\
	\x02\x02\x02\u{d69}\u{d6a}\x07\u{161}\x02\x02\u{d6a}\u{d6b}\x07\u{124}\x02\
	\x02\u{d6b}\u{d6d}\x05\u{fc}\x7f\x02\u{d6c}\u{d5d}\x03\x02\x02\x02\u{d6c}\
	\u{d69}\x03\x02\x02\x02\u{d6d}\u{21b}\x03\x02\x02\x02\u{d6e}\u{d70}\x05\
	\u{28c}\u{147}\x02\u{d6f}\u{d71}\x05\u{37c}\u{1bf}\x02\u{d70}\u{d6f}\x03\
	\x02\x02\x02\u{d70}\u{d71}\x03\x02\x02\x02\u{d71}\u{21d}\x03\x02\x02\x02\
	\u{d72}\u{d73}\x07\u{126}\x02\x02\u{d73}\u{d74}\x07\x7d\x02\x02\u{d74}\u{d75}\
	\x05\u{246}\u{124}\x02\u{d75}\u{21f}\x03\x02\x02\x02\u{d76}\u{d77}\x07\u{cf}\
	\x02\x02\u{d77}\u{d7a}\x09\x1a\x02\x02\u{d78}\u{d7a}\x05\u{e8}\x75\x02\u{d79}\
	\u{d76}\x03\x02\x02\x02\u{d79}\u{d78}\x03\x02\x02\x02\u{d7a}\u{221}\x03\
	\x02\x02\x02\u{d7b}\u{d7c}\x07\u{126}\x02\x02\u{d7c}\u{d7d}\x07\u{12c}\x02\
	\x02\u{d7d}\u{d7e}\x07\u{b6}\x02\x02\u{d7e}\u{d7f}\x05\u{224}\u{113}\x02\
	\u{d7f}\u{223}\x03\x02\x02\x02\u{d80}\u{d81}\x07\u{183}\x02\x02\u{d81}\u{d82}\
	\x05\u{226}\u{114}\x02\u{d82}\u{d83}\x07\u{184}\x02\x02\u{d83}\u{225}\x03\
	\x02\x02\x02\u{d84}\u{d89}\x05\u{228}\u{115}\x02\u{d85}\u{d86}\x07\u{181}\
	\x02\x02\u{d86}\u{d88}\x05\u{228}\u{115}\x02\u{d87}\u{d85}\x03\x02\x02\x02\
	\u{d88}\u{d8b}\x03\x02\x02\x02\u{d89}\u{d87}\x03\x02\x02\x02\u{d89}\u{d8a}\
	\x03\x02\x02\x02\u{d8a}\u{227}\x03\x02\x02\x02\u{d8b}\u{d89}\x03\x02\x02\
	\x02\u{d8c}\u{d8d}\x05\u{144}\u{a3}\x02\u{d8d}\u{d8e}\x07\u{189}\x02\x02\
	\u{d8e}\u{d8f}\x07\u{19d}\x02\x02\u{d8f}\u{229}\x03\x02\x02\x02\u{d90}\u{d91}\
	\x07\u{126}\x02\x02\u{d91}\u{d92}\x07\u{b6}\x02\x02\u{d92}\u{d93}\x07\u{19d}\
	\x02\x02\u{d93}\u{22b}\x03\x02\x02\x02\u{d94}\u{d9b}\x05\u{ec}\x77\x02\u{d95}\
	\u{d98}\x07\u{cf}\x02\x02\u{d96}\u{d99}\x07\u{12c}\x02\x02\u{d97}\u{d99}\
	\x05\x34\x1b\x02\u{d98}\u{d96}\x03\x02\x02\x02\u{d98}\u{d97}\x03\x02\x02\
	\x02\u{d99}\u{d9b}\x03\x02\x02\x02\u{d9a}\u{d94}\x03\x02\x02\x02\u{d9a}\
	\u{d95}\x03\x02\x02\x02\u{d9b}\u{22d}\x03\x02\x02\x02\u{d9c}\u{d9d}\x07\
	\x6d\x02\x02\u{d9d}\u{d9e}\x05\u{37c}\u{1bf}\x02\u{d9e}\u{d9f}\x07\u{178}\
	\x02\x02\u{d9f}\u{da0}\x07\u{13f}\x02\x02\u{da0}\u{da1}\x05\u{28c}\u{147}\
	\x02\u{da1}\u{22f}\x03\x02\x02\x02\u{da2}\u{da3}\x07\u{109}\x02\x02\u{da3}\
	\u{da4}\x07\u{14b}\x02\x02\u{da4}\u{da5}\x05\u{37c}\u{1bf}\x02\u{da5}\u{231}\
	\x03\x02\x02\x02\u{da6}\u{da7}\x07\u{163}\x02\x02\u{da7}\u{da8}\x07\u{135}\
	\x02\x02\u{da8}\u{daa}\x07\u{82}\x02\x02\u{da9}\u{dab}\x07\x2f\x02\x02\u{daa}\
	\u{da9}\x03\x02\x02\x02\u{daa}\u{dab}\x03\x02\x02\x02\u{dab}\u{dac}\x03\
	\x02\x02\x02\u{dac}\u{dad}\x05\u{38c}\u{1c7}\x02\u{dad}\u{dae}\x07\u{126}\
	\x02\x02\u{dae}\u{db1}\x05\u{fc}\x7f\x02\u{daf}\u{db0}\x07\x31\x02\x02\u{db0}\
	\u{db2}\x07\u{19d}\x02\x02\u{db1}\u{daf}\x03\x02\x02\x02\u{db1}\u{db2}\x03\
	\x02\x02\x02\u{db2}\u{233}\x03\x02\x02\x02\u{db3}\u{db4}\x07\x37\x02\x02\
	\u{db4}\u{235}\x03\x02\x02\x02\u{db5}\u{db6}\x07\u{a0}\x02\x02\u{db6}\u{db7}\
	\x07\u{1a2}\x02\x02\u{db7}\u{db8}\x07\x21\x02\x02\u{db8}\u{237}\x03\x02\
	\x02\x02\u{db9}\u{dba}\x07\x0d\x02\x02\u{dba}\u{dbb}\x07\u{172}\x02\x02\
	\u{dbb}\u{239}\x03\x02\x02\x02\u{dbc}\u{dbd}\x07\u{ed}\x02\x02\u{dbd}\u{dbe}\
	\x07\u{19d}\x02\x02\u{dbe}\u{23b}\x03\x02\x02\x02\u{dbf}\u{dc0}\x07\x33\
	\x02\x02\u{dc0}\u{dc2}\x07\u{19d}\x02\x02\u{dc1}\u{dc3}\x05\u{238}\u{11d}\
	\x02\u{dc2}\u{dc1}\x03\x02\x02\x02\u{dc2}\u{dc3}\x03\x02\x02\x02\u{dc3}\
	\u{dc5}\x03\x02\x02\x02\u{dc4}\u{dc6}\x05\u{ea}\x76\x02\u{dc5}\u{dc4}\x03\
	\x02\x02\x02\u{dc5}\u{dc6}\x03\x02\x02\x02\u{dc6}\u{dc8}\x03\x02\x02\x02\
	\u{dc7}\u{dc9}\x05\u{2f0}\u{179}\x02\u{dc8}\u{dc7}\x03\x02\x02\x02\u{dc8}\
	\u{dc9}\x03\x02\x02\x02\u{dc9}\u{dcb}\x03\x02\x02\x02\u{dca}\u{dcc}\x05\
	\u{23a}\u{11e}\x02\u{dcb}\u{dca}\x03\x02\x02\x02\u{dcb}\u{dcc}\x03\x02\x02\
	\x02\u{dcc}\u{dd1}\x03\x02\x02\x02\u{dcd}\u{dce}\x07\u{178}\x02\x02\u{dce}\
	\u{dcf}\x07\u{e2}\x02\x02\u{dcf}\u{dd0}\x07\u{142}\x02\x02\u{dd0}\u{dd2}\
	\x05\u{fc}\x7f\x02\u{dd1}\u{dcd}\x03\x02\x02\x02\u{dd1}\u{dd2}\x03\x02\x02\
	\x02\u{dd2}\u{23d}\x03\x02\x02\x02\u{dd3}\u{dd4}\x07\u{126}\x02\x02\u{dd4}\
	\u{dd5}\x07\u{e3}\x02\x02\u{dd5}\u{dd6}\x05\u{94}\x4b\x02\u{dd6}\u{23f}\
	\x03\x02\x02\x02\u{dd7}\u{dd8}\x07\u{126}\x02\x02\u{dd8}\u{dd9}\x07\u{e4}\
	\x02\x02\u{dd9}\u{dda}\x07\u{132}\x02\x02\u{dda}\u{ddb}\x07\u{183}\x02\x02\
	\u{ddb}\u{ddc}\x05\u{e2}\x72\x02\u{ddc}\u{ddd}\x07\u{184}\x02\x02\u{ddd}\
	\u{241}\x03\x02\x02\x02\u{dde}\u{de8}\x07\x6f\x02\x02\u{ddf}\u{de0}\x07\
	\u{118}\x02\x02\u{de0}\u{de1}\x07\u{183}\x02\x02\u{de1}\u{de9}\x09\x1b\x02\
	\x02\u{de2}\u{de3}\x07\x72\x02\x02\u{de3}\u{de4}\x07\u{183}\x02\x02\u{de4}\
	\u{de9}\x07\u{19d}\x02\x02\u{de5}\u{de6}\x07\u{128}\x02\x02\u{de6}\u{de7}\
	\x07\u{183}\x02\x02\u{de7}\u{de9}\x07\u{1a2}\x02\x02\u{de8}\u{ddf}\x03\x02\
	\x02\x02\u{de8}\u{de2}\x03\x02\x02\x02\u{de8}\u{de5}\x03\x02\x02\x02\u{de9}\
	\u{dea}\x03\x02\x02\x02\u{dea}\u{deb}\x07\u{184}\x02\x02\u{deb}\u{243}\x03\
	\x02\x02\x02\u{dec}\u{ded}\x05\u{38c}\u{1c7}\x02\u{ded}\u{dee}\x07\u{d7}\
	\x02\x02\u{dee}\u{df0}\x05\u{28c}\u{147}\x02\u{def}\u{df1}\x05\u{37c}\u{1bf}\
	\x02\u{df0}\u{def}\x03\x02\x02\x02\u{df0}\u{df1}\x03\x02\x02\x02\u{df1}\
	\u{df2}\x03\x02\x02\x02\u{df2}\u{df3}\x07\u{100}\x02\x02\u{df3}\u{245}\x03\
	\x02\x02\x02\u{df4}\u{df5}\x07\u{9b}\x02\x02\u{df5}\u{df6}\x07\u{19d}\x02\
	\x02\u{df6}\u{df7}\x07\u{e0}\x02\x02\u{df7}\u{df8}\x07\u{19d}\x02\x02\u{df8}\
	\u{df9}\x07\u{123}\x02\x02\u{df9}\u{dfe}\x07\u{19d}\x02\x02\u{dfa}\u{dfb}\
	\x07\u{9a}\x02\x02\u{dfb}\u{dfc}\x07\u{19d}\x02\x02\u{dfc}\u{dfd}\x07\u{df}\
	\x02\x02\u{dfd}\u{dff}\x07\u{19d}\x02\x02\u{dfe}\u{dfa}\x03\x02\x02\x02\
	\u{dfe}\u{dff}\x03\x02\x02\x02\u{dff}\u{e02}\x03\x02\x02\x02\u{e00}\u{e02}\
	\x05\u{38c}\u{1c7}\x02\u{e01}\u{df4}\x03\x02\x02\x02\u{e01}\u{e00}\x03\x02\
	\x02\x02\u{e02}\u{247}\x03\x02\x02\x02\u{e03}\u{e07}\x05\u{24a}\u{126}\x02\
	\u{e04}\u{e07}\x05\u{24c}\u{127}\x02\u{e05}\u{e07}\x05\u{24e}\u{128}\x02\
	\u{e06}\u{e03}\x03\x02\x02\x02\u{e06}\u{e04}\x03\x02\x02\x02\u{e06}\u{e05}\
	\x03\x02\x02\x02\u{e07}\u{249}\x03\x02\x02\x02\u{e08}\u{e09}\x05\u{38c}\
	\u{1c7}\x02\u{e09}\u{e0a}\x07\u{126}\x02\x02\u{e0a}\u{e0b}\x07\x4e\x02\x02\
	\u{e0b}\u{e0c}\x05\u{25c}\u{12f}\x02\u{e0c}\u{24b}\x03\x02\x02\x02\u{e0d}\
	\u{e0e}\x05\u{38c}\u{1c7}\x02\u{e0e}\u{e0f}\x07\u{126}\x02\x02\u{e0f}\u{e10}\
	\x07\u{e3}\x02\x02\u{e10}\u{e11}\x05\u{94}\x4b\x02\u{e11}\u{24d}\x03\x02\
	\x02\x02\u{e12}\u{e13}\x05\u{38c}\u{1c7}\x02\u{e13}\u{e14}\x07\u{126}\x02\
	\x02\u{e14}\u{e15}\x07\u{165}\x02\x02\u{e15}\u{e16}\x07\u{19d}\x02\x02\u{e16}\
	\u{24f}\x03\x02\x02\x02\u{e17}\u{e18}\x07\u{b1}\x02\x02\u{e18}\u{e21}\x07\
	\x7c\x02\x02\u{e19}\u{e1a}\x07\u{b1}\x02\x02\u{e1a}\u{e1b}\x07\x7c\x02\x02\
	\u{e1b}\u{e1c}\x05\u{38c}\u{1c7}\x02\u{e1c}\u{e1d}\x07\u{19d}\x02\x02\u{e1d}\
	\u{e21}\x03\x02\x02\x02\u{e1e}\u{e1f}\x07\u{b1}\x02\x02\u{e1f}\u{e21}\x05\
	\u{28c}\u{147}\x02\u{e20}\u{e17}\x03\x02\x02\x02\u{e20}\u{e19}\x03\x02\x02\
	\x02\u{e20}\u{e1e}\x03\x02\x02\x02\u{e21}\u{251}\x03\x02\x02\x02\u{e22}\
	\u{e24}\x07\x3c\x02\x02\u{e23}\u{e25}\x07\u{143}\x02\x02\u{e24}\u{e23}\x03\
	\x02\x02\x02\u{e24}\u{e25}\x03\x02\x02\x02\u{e25}\u{e27}\x03\x02\x02\x02\
	\u{e26}\u{e28}\x07\u{14f}\x02\x02\u{e27}\u{e26}\x03\x02\x02\x02\u{e27}\u{e28}\
	\x03\x02\x02\x02\u{e28}\u{e2a}\x03\x02\x02\x02\u{e29}\u{e2b}\x07\x77\x02\
	\x02\u{e2a}\u{e29}\x03\x02\x02\x02\u{e2a}\u{e2b}\x03\x02\x02\x02\u{e2b}\
	\u{e2c}\x03\x02\x02\x02\u{e2c}\u{e2e}\x07\u{13f}\x02\x02\u{e2d}\u{e2f}\x05\
	\x2c\x17\x02\u{e2e}\u{e2d}\x03\x02\x02\x02\u{e2e}\u{e2f}\x03\x02\x02\x02\
	\u{e2f}\u{e30}\x03\x02\x02\x02\u{e30}\u{e63}\x05\u{28c}\u{147}\x02\u{e31}\
	\u{e33}\x05\u{250}\u{129}\x02\u{e32}\u{e34}\x05\u{dc}\x6f\x02\u{e33}\u{e32}\
	\x03\x02\x02\x02\u{e33}\u{e34}\x03\x02\x02\x02\u{e34}\u{e36}\x03\x02\x02\
	\x02\u{e35}\u{e37}\x05\u{f8}\x7d\x02\u{e36}\u{e35}\x03\x02\x02\x02\u{e36}\
	\u{e37}\x03\x02\x02\x02\u{e37}\u{e39}\x03\x02\x02\x02\u{e38}\u{e3a}\x05\
	\u{10e}\u{88}\x02\u{e39}\u{e38}\x03\x02\x02\x02\u{e39}\u{e3a}\x03\x02\x02\
	\x02\u{e3a}\u{e3c}\x03\x02\x02\x02\u{e3b}\u{e3d}\x05\u{110}\u{89}\x02\u{e3c}\
	\u{e3b}\x03\x02\x02\x02\u{e3c}\u{e3d}\x03\x02\x02\x02\u{e3d}\u{e3f}\x03\
	\x02\x02\x02\u{e3e}\u{e40}\x05\u{fa}\x7e\x02\u{e3f}\u{e3e}\x03\x02\x02\x02\
	\u{e3f}\u{e40}\x03\x02\x02\x02\u{e40}\u{e64}\x03\x02\x02\x02\u{e41}\u{e42}\
	\x07\u{183}\x02\x02\u{e42}\u{e43}\x05\u{114}\u{8b}\x02\u{e43}\u{e44}\x07\
	\u{184}\x02\x02\u{e44}\u{e46}\x03\x02\x02\x02\u{e45}\u{e41}\x03\x02\x02\
	\x02\u{e45}\u{e46}\x03\x02\x02\x02\u{e46}\u{e48}\x03\x02\x02\x02\u{e47}\
	\u{e49}\x05\u{da}\x6e\x02\u{e48}\u{e47}\x03\x02\x02\x02\u{e48}\u{e49}\x03\
	\x02\x02\x02\u{e49}\u{e4b}\x03\x02\x02\x02\u{e4a}\u{e4c}\x05\u{dc}\x6f\x02\
	\u{e4b}\u{e4a}\x03\x02\x02\x02\u{e4b}\u{e4c}\x03\x02\x02\x02\u{e4c}\u{e4e}\
	\x03\x02\x02\x02\u{e4d}\u{e4f}\x05\u{e8}\x75\x02\u{e4e}\u{e4d}\x03\x02\x02\
	\x02\u{e4e}\u{e4f}\x03\x02\x02\x02\u{e4f}\u{e51}\x03\x02\x02\x02\u{e50}\
	\u{e52}\x05\u{ec}\x77\x02\u{e51}\u{e50}\x03\x02\x02\x02\u{e51}\u{e52}\x03\
	\x02\x02\x02\u{e52}\u{e54}\x03\x02\x02\x02\u{e53}\u{e55}\x05\u{f8}\x7d\x02\
	\u{e54}\u{e53}\x03\x02\x02\x02\u{e54}\u{e55}\x03\x02\x02\x02\u{e55}\u{e57}\
	\x03\x02\x02\x02\u{e56}\u{e58}\x05\u{10e}\u{88}\x02\u{e57}\u{e56}\x03\x02\
	\x02\x02\u{e57}\u{e58}\x03\x02\x02\x02\u{e58}\u{e5a}\x03\x02\x02\x02\u{e59}\
	\u{e5b}\x05\u{110}\u{89}\x02\u{e5a}\u{e59}\x03\x02\x02\x02\u{e5a}\u{e5b}\
	\x03\x02\x02\x02\u{e5b}\u{e5d}\x03\x02\x02\x02\u{e5c}\u{e5e}\x05\u{fa}\x7e\
	\x02\u{e5d}\u{e5c}\x03\x02\x02\x02\u{e5d}\u{e5e}\x03\x02\x02\x02\u{e5e}\
	\u{e61}\x03\x02\x02\x02\u{e5f}\u{e60}\x07\x13\x02\x02\u{e60}\u{e62}\x05\
	\u{19a}\u{ce}\x02\u{e61}\u{e5f}\x03\x02\x02\x02\u{e61}\u{e62}\x03\x02\x02\
	\x02\u{e62}\u{e64}\x03\x02\x02\x02\u{e63}\u{e31}\x03\x02\x02\x02\u{e63}\
	\u{e45}\x03\x02\x02\x02\u{e64}\u{e9e}\x03\x02\x02\x02\u{e65}\u{e66}\x07\
	\x3c\x02\x02\u{e66}\u{e67}\x07\u{bc}\x02\x02\u{e67}\u{e69}\x07\u{13f}\x02\
	\x02\u{e68}\u{e6a}\x05\x2c\x17\x02\u{e69}\u{e68}\x03\x02\x02\x02\u{e69}\
	\u{e6a}\x03\x02\x02\x02\u{e6a}\u{e6b}\x03\x02\x02\x02\u{e6b}\u{e9b}\x05\
	\u{28c}\u{147}\x02\u{e6c}\u{e6e}\x05\u{250}\u{129}\x02\u{e6d}\u{e6f}\x05\
	\u{f8}\x7d\x02\u{e6e}\u{e6d}\x03\x02\x02\x02\u{e6e}\u{e6f}\x03\x02\x02\x02\
	\u{e6f}\u{e71}\x03\x02\x02\x02\u{e70}\u{e72}\x05\u{10e}\u{88}\x02\u{e71}\
	\u{e70}\x03\x02\x02\x02\u{e71}\u{e72}\x03\x02\x02\x02\u{e72}\u{e74}\x03\
	\x02\x02\x02\u{e73}\u{e75}\x05\u{110}\u{89}\x02\u{e74}\u{e73}\x03\x02\x02\
	\x02\u{e74}\u{e75}\x03\x02\x02\x02\u{e75}\u{e77}\x03\x02\x02\x02\u{e76}\
	\u{e78}\x05\u{fa}\x7e\x02\u{e77}\u{e76}\x03\x02\x02\x02\u{e77}\u{e78}\x03\
	\x02\x02\x02\u{e78}\u{e9c}\x03\x02\x02\x02\u{e79}\u{e7a}\x07\u{183}\x02\
	\x02\u{e7a}\u{e7b}\x05\u{114}\u{8b}\x02\u{e7b}\u{e7c}\x07\u{184}\x02\x02\
	\u{e7c}\u{e7e}\x03\x02\x02\x02\u{e7d}\u{e79}\x03\x02\x02\x02\u{e7d}\u{e7e}\
	\x03\x02\x02\x02\u{e7e}\u{e80}\x03\x02\x02\x02\u{e7f}\u{e81}\x05\u{da}\x6e\
	\x02\u{e80}\u{e7f}\x03\x02\x02\x02\u{e80}\u{e81}\x03\x02\x02\x02\u{e81}\
	\u{e83}\x03\x02\x02\x02\u{e82}\u{e84}\x05\u{dc}\x6f\x02\u{e83}\u{e82}\x03\
	\x02\x02\x02\u{e83}\u{e84}\x03\x02\x02\x02\u{e84}\u{e86}\x03\x02\x02\x02\
	\u{e85}\u{e87}\x05\u{e8}\x75\x02\u{e86}\u{e85}\x03\x02\x02\x02\u{e86}\u{e87}\
	\x03\x02\x02\x02\u{e87}\u{e89}\x03\x02\x02\x02\u{e88}\u{e8a}\x05\u{ec}\x77\
	\x02\u{e89}\u{e88}\x03\x02\x02\x02\u{e89}\u{e8a}\x03\x02\x02\x02\u{e8a}\
	\u{e8c}\x03\x02\x02\x02\u{e8b}\u{e8d}\x05\u{f8}\x7d\x02\u{e8c}\u{e8b}\x03\
	\x02\x02\x02\u{e8c}\u{e8d}\x03\x02\x02\x02\u{e8d}\u{e8f}\x03\x02\x02\x02\
	\u{e8e}\u{e90}\x05\u{10e}\u{88}\x02\u{e8f}\u{e8e}\x03\x02\x02\x02\u{e8f}\
	\u{e90}\x03\x02\x02\x02\u{e90}\u{e92}\x03\x02\x02\x02\u{e91}\u{e93}\x05\
	\u{110}\u{89}\x02\u{e92}\u{e91}\x03\x02\x02\x02\u{e92}\u{e93}\x03\x02\x02\
	\x02\u{e93}\u{e95}\x03\x02\x02\x02\u{e94}\u{e96}\x05\u{fa}\x7e\x02\u{e95}\
	\u{e94}\x03\x02\x02\x02\u{e95}\u{e96}\x03\x02\x02\x02\u{e96}\u{e99}\x03\
	\x02\x02\x02\u{e97}\u{e98}\x07\x13\x02\x02\u{e98}\u{e9a}\x05\u{19a}\u{ce}\
	\x02\u{e99}\u{e97}\x03\x02\x02\x02\u{e99}\u{e9a}\x03\x02\x02\x02\u{e9a}\
	\u{e9c}\x03\x02\x02\x02\u{e9b}\u{e6c}\x03\x02\x02\x02\u{e9b}\u{e7d}\x03\
	\x02\x02\x02\u{e9c}\u{e9e}\x03\x02\x02\x02\u{e9d}\u{e22}\x03\x02\x02\x02\
	\u{e9d}\u{e65}\x03\x02\x02\x02\u{e9e}\u{253}\x03\x02\x02\x02\u{e9f}\u{ea0}\
	\x07\x3c\x02\x02\u{ea0}\u{ea2}\x07\x47\x02\x02\u{ea1}\u{ea3}\x05\x2c\x17\
	\x02\u{ea2}\u{ea1}\x03\x02\x02\x02\u{ea2}\u{ea3}\x03\x02\x02\x02\u{ea3}\
	\u{ea4}\x03\x02\x02\x02\u{ea4}\u{ea5}\x05\u{38c}\u{1c7}\x02\u{ea5}\u{ea6}\
	\x05\u{25a}\u{12e}\x02\u{ea6}\u{ea8}\x05\u{258}\u{12d}\x02\u{ea7}\u{ea9}\
	\x05\u{256}\u{12c}\x02\u{ea8}\u{ea7}\x03\x02\x02\x02\u{ea8}\u{ea9}\x03\x02\
	\x02\x02\u{ea9}\u{ead}\x03\x02\x02\x02\u{eaa}\u{eab}\x07\u{178}\x02\x02\
	\u{eab}\u{eac}\x07\x4e\x02\x02\u{eac}\u{eae}\x05\u{25c}\u{12f}\x02\u{ead}\
	\u{eaa}\x03\x02\x02\x02\u{ead}\u{eae}\x03\x02\x02\x02\u{eae}\u{255}\x03\
	\x02\x02\x02\u{eaf}\u{eb0}\x07\x31\x02\x02\u{eb0}\u{eb1}\x07\u{19d}\x02\
	\x02\u{eb1}\u{257}\x03\x02\x02\x02\u{eb2}\u{eb3}\x07\u{165}\x02\x02\u{eb3}\
	\u{eb4}\x07\u{19d}\x02\x02\u{eb4}\u{259}\x03\x02\x02\x02\u{eb5}\u{eb6}\x07\
	\u{156}\x02\x02\u{eb6}\u{eb7}\x07\u{19d}\x02\x02\u{eb7}\u{25b}\x03\x02\x02\
	\x02\u{eb8}\u{eb9}\x07\u{183}\x02\x02\u{eb9}\u{eba}\x05\x40\x21\x02\u{eba}\
	\u{ebb}\x07\u{184}\x02\x02\u{ebb}\u{25d}\x03\x02\x02\x02\u{ebc}\u{ebd}\x07\
	\x63\x02\x02\u{ebd}\u{ebf}\x07\x47\x02\x02\u{ebe}\u{ec0}\x05\x28\x15\x02\
	\u{ebf}\u{ebe}\x03\x02\x02\x02\u{ebf}\u{ec0}\x03\x02\x02\x02\u{ec0}\u{ec1}\
	\x03\x02\x02\x02\u{ec1}\u{ec2}\x05\u{38c}\u{1c7}\x02\u{ec2}\u{25f}\x03\x02\
	\x02\x02\u{ec3}\u{ec9}\x07\u{193}\x02\x02\u{ec4}\u{ec5}\x05\u{28c}\u{147}\
	\x02\u{ec5}\u{ec6}\x07\u{17f}\x02\x02\u{ec6}\u{ec7}\x07\u{193}\x02\x02\u{ec7}\
	\u{ec9}\x03\x02\x02\x02\u{ec8}\u{ec3}\x03\x02\x02\x02\u{ec8}\u{ec4}\x03\
	\x02\x02\x02\u{ec9}\u{261}\x03\x02\x02\x02\u{eca}\u{ecb}\x05\u{38c}\u{1c7}\
	\x02\u{ecb}\u{263}\x03\x02\x02\x02\u{ecc}\u{ecd}\x07\x52\x02\x02\u{ecd}\
	\u{265}\x03\x02\x02\x02\u{ece}\u{ed3}\x05\u{328}\u{195}\x02\u{ecf}\u{ed0}\
	\x07\u{181}\x02\x02\u{ed0}\u{ed2}\x05\u{328}\u{195}\x02\u{ed1}\u{ecf}\x03\
	\x02\x02\x02\u{ed2}\u{ed5}\x03\x02\x02\x02\u{ed3}\u{ed1}\x03\x02\x02\x02\
	\u{ed3}\u{ed4}\x03\x02\x02\x02\u{ed4}\u{267}\x03\x02\x02\x02\u{ed5}\u{ed3}\
	\x03\x02\x02\x02\u{ed6}\u{edb}\x05\u{38c}\u{1c7}\x02\u{ed7}\u{ed8}\x07\u{181}\
	\x02\x02\u{ed8}\u{eda}\x05\u{38c}\u{1c7}\x02\u{ed9}\u{ed7}\x03\x02\x02\x02\
	\u{eda}\u{edd}\x03\x02\x02\x02\u{edb}\u{ed9}\x03\x02\x02\x02\u{edb}\u{edc}\
	\x03\x02\x02\x02\u{edc}\u{269}\x03\x02\x02\x02\u{edd}\u{edb}\x03\x02\x02\
	\x02\u{ede}\u{edf}\x07\u{87}\x02\x02\u{edf}\u{ee0}\x05\u{26c}\u{137}\x02\
	\u{ee0}\u{26b}\x03\x02\x02\x02\u{ee1}\u{ee2}\x05\u{278}\u{13d}\x02\u{ee2}\
	\u{ee5}\x05\u{274}\u{13b}\x02\u{ee3}\u{ee4}\x07\u{181}\x02\x02\u{ee4}\u{ee6}\
	\x05\u{274}\u{13b}\x02\u{ee5}\u{ee3}\x03\x02\x02\x02\u{ee6}\u{ee7}\x03\x02\
	\x02\x02\u{ee7}\u{ee5}\x03\x02\x02\x02\u{ee7}\u{ee8}\x03\x02\x02\x02\u{ee8}\
	\u{eeb}\x03\x02\x02\x02\u{ee9}\u{eeb}\x05\u{270}\u{139}\x02\u{eea}\u{ee1}\
	\x03\x02\x02\x02\u{eea}\u{ee9}\x03\x02\x02\x02\u{eeb}\u{26d}\x03\x02\x02\
	\x02\u{eec}\u{ef0}\x05\u{286}\u{144}\x02\u{eed}\u{eef}\x05\u{27c}\u{13f}\
	\x02\u{eee}\u{eed}\x03\x02\x02\x02\u{eef}\u{ef2}\x03\x02\x02\x02\u{ef0}\
	\u{eee}\x03\x02\x02\x02\u{ef0}\u{ef1}\x03\x02\x02\x02\u{ef1}\u{f0d}\x03\
	\x02\x02\x02\u{ef2}\u{ef0}\x03\x02\x02\x02\u{ef3}\u{ef7}\x05\u{2a6}\u{154}\
	\x02\u{ef4}\u{ef6}\x05\u{27c}\u{13f}\x02\u{ef5}\u{ef4}\x03\x02\x02\x02\u{ef6}\
	\u{ef9}\x03\x02\x02\x02\u{ef7}\u{ef5}\x03\x02\x02\x02\u{ef7}\u{ef8}\x03\
	\x02\x02\x02\u{ef8}\u{f0d}\x03\x02\x02\x02\u{ef9}\u{ef7}\x03\x02\x02\x02\
	\u{efa}\u{efe}\x05\u{290}\u{149}\x02\u{efb}\u{efd}\x05\u{27c}\u{13f}\x02\
	\u{efc}\u{efb}\x03\x02\x02\x02\u{efd}\u{f00}\x03\x02\x02\x02\u{efe}\u{efc}\
	\x03\x02\x02\x02\u{efe}\u{eff}\x03\x02\x02\x02\u{eff}\u{f0d}\x03\x02\x02\
	\x02\u{f00}\u{efe}\x03\x02\x02\x02\u{f01}\u{f05}\x05\u{296}\u{14c}\x02\u{f02}\
	\u{f04}\x05\u{27c}\u{13f}\x02\u{f03}\u{f02}\x03\x02\x02\x02\u{f04}\u{f07}\
	\x03\x02\x02\x02\u{f05}\u{f03}\x03\x02\x02\x02\u{f05}\u{f06}\x03\x02\x02\
	\x02\u{f06}\u{f0d}\x03\x02\x02\x02\u{f07}\u{f05}\x03\x02\x02\x02\u{f08}\
	\u{f09}\x07\u{183}\x02\x02\u{f09}\u{f0a}\x05\u{270}\u{139}\x02\u{f0a}\u{f0b}\
	\x07\u{184}\x02\x02\u{f0b}\u{f0d}\x03\x02\x02\x02\u{f0c}\u{eec}\x03\x02\
	\x02\x02\u{f0c}\u{ef3}\x03\x02\x02\x02\u{f0c}\u{efa}\x03\x02\x02\x02\u{f0c}\
	\u{f01}\x03\x02\x02\x02\u{f0c}\u{f08}\x03\x02\x02\x02\u{f0d}\u{26f}\x03\
	\x02\x02\x02\u{f0e}\u{f19}\x05\u{26e}\u{138}\x02\u{f0f}\u{f10}\x05\u{27a}\
	\u{13e}\x02\u{f10}\u{f15}\x05\u{272}\u{13a}\x02\u{f11}\u{f12}\x07\u{d7}\
	\x02\x02\u{f12}\u{f16}\x05\u{328}\u{195}\x02\u{f13}\u{f14}\x07\u{168}\x02\
	\x02\u{f14}\u{f16}\x05\u{120}\u{91}\x02\u{f15}\u{f11}\x03\x02\x02\x02\u{f15}\
	\u{f13}\x03\x02\x02\x02\u{f15}\u{f16}\x03\x02\x02\x02\u{f16}\u{f18}\x03\
	\x02\x02\x02\u{f17}\u{f0f}\x03\x02\x02\x02\u{f18}\u{f1b}\x03\x02\x02\x02\
	\u{f19}\u{f17}\x03\x02\x02\x02\u{f19}\u{f1a}\x03\x02\x02\x02\u{f1a}\u{271}\
	\x03\x02\x02\x02\u{f1b}\u{f19}\x03\x02\x02\x02\u{f1c}\u{f21}\x05\u{286}\
	\u{144}\x02\u{f1d}\u{f21}\x05\u{2a6}\u{154}\x02\u{f1e}\u{f21}\x05\u{290}\
	\u{149}\x02\u{f1f}\u{f21}\x05\u{296}\u{14c}\x02\u{f20}\u{f1c}\x03\x02\x02\
	\x02\u{f20}\u{f1d}\x03\x02\x02\x02\u{f20}\u{f1e}\x03\x02\x02\x02\u{f20}\
	\u{f1f}\x03\x02\x02\x02\u{f21}\u{f25}\x03\x02\x02\x02\u{f22}\u{f24}\x05\
	\u{27c}\u{13f}\x02\u{f23}\u{f22}\x03\x02\x02\x02\u{f24}\u{f27}\x03\x02\x02\
	\x02\u{f25}\u{f23}\x03\x02\x02\x02\u{f25}\u{f26}\x03\x02\x02\x02\u{f26}\
	\u{273}\x03\x02\x02\x02\u{f27}\u{f25}\x03\x02\x02\x02\u{f28}\u{f2a}\x07\
	\u{f1}\x02\x02\u{f29}\u{f28}\x03\x02\x02\x02\u{f29}\u{f2a}\x03\x02\x02\x02\
	\u{f2a}\u{f2b}\x03\x02\x02\x02\u{f2b}\u{f2c}\x05\u{28a}\u{146}\x02\u{f2c}\
	\u{f2d}\x05\u{276}\u{13c}\x02\u{f2d}\u{275}\x03\x02\x02\x02\u{f2e}\u{f2f}\
	\x07\u{183}\x02\x02\u{f2f}\u{f30}\x05\u{266}\u{134}\x02\u{f30}\u{f31}\x07\
	\u{184}\x02\x02\u{f31}\u{277}\x03\x02\x02\x02\u{f32}\u{f33}\x07\u{15d}\x02\
	\x02\u{f33}\u{279}\x03\x02\x02\x02\u{f34}\u{f43}\x07\u{181}\x02\x02\u{f35}\
	\u{f40}\x07\u{98}\x02\x02\u{f36}\u{f40}\x07\x3e\x02\x02\u{f37}\u{f39}\x09\
	\x1c\x02\x02\u{f38}\u{f3a}\x07\u{de}\x02\x02\u{f39}\u{f38}\x03\x02\x02\x02\
	\u{f39}\u{f3a}\x03\x02\x02\x02\u{f3a}\u{f40}\x03\x02\x02\x02\u{f3b}\u{f3d}\
	\x07\u{ae}\x02\x02\u{f3c}\u{f3e}\x09\x1d\x02\x02\u{f3d}\u{f3c}\x03\x02\x02\
	\x02\u{f3d}\u{f3e}\x03\x02\x02\x02\u{f3e}\u{f40}\x03\x02\x02\x02\u{f3f}\
	\u{f35}\x03\x02\x02\x02\u{f3f}\u{f36}\x03\x02\x02\x02\u{f3f}\u{f37}\x03\
	\x02\x02\x02\u{f3f}\u{f3b}\x03\x02\x02\x02\u{f3f}\u{f40}\x03\x02\x02\x02\
	\u{f40}\u{f41}\x03\x02\x02\x02\u{f41}\u{f43}\x07\u{a5}\x02\x02\u{f42}\u{f34}\
	\x03\x02\x02\x02\u{f42}\u{f3f}\x03\x02\x02\x02\u{f43}\u{27b}\x03\x02\x02\
	\x02\u{f44}\u{f45}\x07\u{ac}\x02\x02\u{f45}\u{f46}\x07\u{170}\x02\x02\u{f46}\
	\u{f47}\x07\u{de}\x02\x02\u{f47}\u{f48}\x05\u{2fc}\u{17f}\x02\u{f48}\u{f52}\
	\x05\u{27e}\u{140}\x02\u{f49}\u{f4a}\x07\x13\x02\x02\u{f4a}\u{f4f}\x05\u{38c}\
	\u{1c7}\x02\u{f4b}\u{f4c}\x07\u{181}\x02\x02\u{f4c}\u{f4e}\x05\u{38c}\u{1c7}\
	\x02\u{f4d}\u{f4b}\x03\x02\x02\x02\u{f4e}\u{f51}\x03\x02\x02\x02\u{f4f}\
	\u{f4d}\x03\x02\x02\x02\u{f4f}\u{f50}\x03\x02\x02\x02\u{f50}\u{f53}\x03\
	\x02\x02\x02\u{f51}\u{f4f}\x03\x02\x02\x02\u{f52}\u{f49}\x03\x02\x02\x02\
	\u{f52}\u{f53}\x03\x02\x02\x02\u{f53}\u{f7e}\x03\x02\x02\x02\u{f54}\u{f56}\
	\x07\u{181}\x02\x02\u{f55}\u{f54}\x03\x02\x02\x02\u{f55}\u{f56}\x03\x02\
	\x02\x02\u{f56}\u{f57}\x03\x02\x02\x02\u{f57}\u{f7b}\x07\u{ac}\x02\x02\u{f58}\
	\u{f59}\x07\u{170}\x02\x02\u{f59}\u{f5a}\x05\u{2fc}\u{17f}\x02\u{f5a}\u{f64}\
	\x05\u{27e}\u{140}\x02\u{f5b}\u{f5c}\x07\x13\x02\x02\u{f5c}\u{f61}\x05\u{38c}\
	\u{1c7}\x02\u{f5d}\u{f5e}\x07\u{181}\x02\x02\u{f5e}\u{f60}\x05\u{38c}\u{1c7}\
	\x02\u{f5f}\u{f5d}\x03\x02\x02\x02\u{f60}\u{f63}\x03\x02\x02\x02\u{f61}\
	\u{f5f}\x03\x02\x02\x02\u{f61}\u{f62}\x03\x02\x02\x02\u{f62}\u{f65}\x03\
	\x02\x02\x02\u{f63}\u{f61}\x03\x02\x02\x02\u{f64}\u{f5b}\x03\x02\x02\x02\
	\u{f64}\u{f65}\x03\x02\x02\x02\u{f65}\u{f7c}\x03\x02\x02\x02\u{f66}\u{f67}\
	\x07\u{13f}\x02\x02\u{f67}\u{f68}\x07\u{183}\x02\x02\u{f68}\u{f69}\x05\u{29e}\
	\u{150}\x02\u{f69}\u{f6b}\x07\u{184}\x02\x02\u{f6a}\u{f6c}\x07\x13\x02\x02\
	\u{f6b}\u{f6a}\x03\x02\x02\x02\u{f6b}\u{f6c}\x03\x02\x02\x02\u{f6c}\u{f6d}\
	\x03\x02\x02\x02\u{f6d}\u{f79}\x05\u{27e}\u{140}\x02\u{f6e}\u{f6f}\x07\u{183}\
	\x02\x02\u{f6f}\u{f74}\x05\u{38c}\u{1c7}\x02\u{f70}\u{f71}\x07\u{181}\x02\
	\x02\u{f71}\u{f73}\x05\u{38c}\u{1c7}\x02\u{f72}\u{f70}\x03\x02\x02\x02\u{f73}\
	\u{f76}\x03\x02\x02\x02\u{f74}\u{f72}\x03\x02\x02\x02\u{f74}\u{f75}\x03\
	\x02\x02\x02\u{f75}\u{f77}\x03\x02\x02\x02\u{f76}\u{f74}\x03\x02\x02\x02\
	\u{f77}\u{f78}\x07\u{184}\x02\x02\u{f78}\u{f7a}\x03\x02\x02\x02\u{f79}\u{f6e}\
	\x03\x02\x02\x02\u{f79}\u{f7a}\x03\x02\x02\x02\u{f7a}\u{f7c}\x03\x02\x02\
	\x02\u{f7b}\u{f58}\x03\x02\x02\x02\u{f7b}\u{f66}\x03\x02\x02\x02\u{f7c}\
	\u{f7e}\x03\x02\x02\x02\u{f7d}\u{f44}\x03\x02\x02\x02\u{f7d}\u{f55}\x03\
	\x02\x02\x02\u{f7e}\u{27d}\x03\x02\x02\x02\u{f7f}\u{f80}\x05\u{38c}\u{1c7}\
	\x02\u{f80}\u{27f}\x03\x02\x02\x02\u{f81}\u{f82}\x07\u{141}\x02\x02\u{f82}\
	\u{f83}\x07\u{183}\x02\x02\u{f83}\u{f84}\x07\x20\x02\x02\u{f84}\u{f85}\x07\
	\u{1a2}\x02\x02\u{f85}\u{f86}\x07\u{dd}\x02\x02\u{f86}\u{f87}\x07\u{d4}\
	\x02\x02\u{f87}\u{f91}\x07\u{1a2}\x02\x02\u{f88}\u{f89}\x07\u{d7}\x02\x02\
	\u{f89}\u{f8e}\x05\u{328}\u{195}\x02\u{f8a}\u{f8b}\x07\u{181}\x02\x02\u{f8b}\
	\u{f8d}\x05\u{328}\u{195}\x02\u{f8c}\u{f8a}\x03\x02\x02\x02\u{f8d}\u{f90}\
	\x03\x02\x02\x02\u{f8e}\u{f8c}\x03\x02\x02\x02\u{f8e}\u{f8f}\x03\x02\x02\
	\x02\u{f8f}\u{f92}\x03\x02\x02\x02\u{f90}\u{f8e}\x03\x02\x02\x02\u{f91}\
	\u{f88}\x03\x02\x02\x02\u{f91}\u{f92}\x03\x02\x02\x02\u{f92}\u{f93}\x03\
	\x02\x02\x02\u{f93}\u{f94}\x07\u{184}\x02\x02\u{f94}\u{281}\x03\x02\x02\
	\x02\u{f95}\u{f96}\x07\u{141}\x02\x02\u{f96}\u{f9a}\x07\u{183}\x02\x02\u{f97}\
	\u{f98}\x07\u{1a2}\x02\x02\u{f98}\u{f9b}\x09\x1e\x02\x02\u{f99}\u{f9b}\x07\
	\u{1a1}\x02\x02\u{f9a}\u{f97}\x03\x02\x02\x02\u{f9a}\u{f99}\x03\x02\x02\
	\x02\u{f9b}\u{f9c}\x03\x02\x02\x02\u{f9c}\u{f9d}\x07\u{184}\x02\x02\u{f9d}\
	\u{283}\x03\x02\x02\x02\u{f9e}\u{fa1}\x05\u{280}\u{141}\x02\u{f9f}\u{fa1}\
	\x05\u{282}\u{142}\x02\u{fa0}\u{f9e}\x03\x02\x02\x02\u{fa0}\u{f9f}\x03\x02\
	\x02\x02\u{fa1}\u{285}\x03\x02\x02\x02\u{fa2}\u{fa4}\x05\u{28c}\u{147}\x02\
	\u{fa3}\u{fa5}\x05\u{fc}\x7f\x02\u{fa4}\u{fa3}\x03\x02\x02\x02\u{fa4}\u{fa5}\
	\x03\x02\x02\x02\u{fa5}\u{fa7}\x03\x02\x02\x02\u{fa6}\u{fa8}\x05\u{284}\
	\u{143}\x02\u{fa7}\u{fa6}\x03\x02\x02\x02\u{fa7}\u{fa8}\x03\x02\x02\x02\
	\u{fa8}\u{faa}\x03\x02\x02\x02\u{fa9}\u{fab}\x05\u{288}\u{145}\x02\u{faa}\
	\u{fa9}\x03\x02\x02\x02\u{faa}\u{fab}\x03\x02\x02\x02\u{fab}\u{fb0}\x03\
	\x02\x02\x02\u{fac}\u{fae}\x07\x13\x02\x02\u{fad}\u{fac}\x03\x02\x02\x02\
	\u{fad}\u{fae}\x03\x02\x02\x02\u{fae}\u{faf}\x03\x02\x02\x02\u{faf}\u{fb1}\
	\x05\u{38c}\u{1c7}\x02\u{fb0}\u{fad}\x03\x02\x02\x02\u{fb0}\u{fb1}\x03\x02\
	\x02\x02\u{fb1}\u{287}\x03\x02\x02\x02\u{fb2}\u{fbc}\x07\u{82}\x02\x02\u{fb3}\
	\u{fb4}\x07\u{13d}\x02\x02\u{fb4}\u{fb5}\x07\x13\x02\x02\u{fb5}\u{fb6}\x07\
	\u{d4}\x02\x02\u{fb6}\u{fbd}\x05\u{328}\u{195}\x02\u{fb7}\u{fb8}\x07\u{82}\
	\x02\x02\u{fb8}\u{fb9}\x07\u{13e}\x02\x02\u{fb9}\u{fba}\x07\x13\x02\x02\
	\u{fba}\u{fbb}\x07\u{d4}\x02\x02\u{fbb}\u{fbd}\x07\u{1a2}\x02\x02\u{fbc}\
	\u{fb3}\x03\x02\x02\x02\u{fbc}\u{fb7}\x03\x02\x02\x02\u{fbd}\u{289}\x03\
	\x02\x02\x02\u{fbe}\u{fc0}\x05\u{28c}\u{147}\x02\u{fbf}\u{fc1}\x05\u{284}\
	\u{143}\x02\u{fc0}\u{fbf}\x03\x02\x02\x02\u{fc0}\u{fc1}\x03\x02\x02\x02\
	\u{fc1}\u{fc6}\x03\x02\x02\x02\u{fc2}\u{fc4}\x07\x13\x02\x02\u{fc3}\u{fc2}\
	\x03\x02\x02\x02\u{fc3}\u{fc4}\x03\x02\x02\x02\u{fc4}\u{fc5}\x03\x02\x02\
	\x02\u{fc5}\u{fc7}\x05\u{38c}\u{1c7}\x02\u{fc6}\u{fc3}\x03\x02\x02\x02\u{fc6}\
	\u{fc7}\x03\x02\x02\x02\u{fc7}\u{28b}\x03\x02\x02\x02\u{fc8}\u{fc9}\x05\
	\u{38c}\u{1c7}\x02\u{fc9}\u{fca}\x07\u{17f}\x02\x02\u{fca}\u{fcd}\x05\u{38c}\
	\u{1c7}\x02\u{fcb}\u{fcc}\x07\u{17f}\x02\x02\u{fcc}\u{fce}\x05\u{38c}\u{1c7}\
	\x02\u{fcd}\u{fcb}\x03\x02\x02\x02\u{fcd}\u{fce}\x03\x02\x02\x02\u{fce}\
	\u{fd1}\x03\x02\x02\x02\u{fcf}\u{fd1}\x05\u{38c}\u{1c7}\x02\u{fd0}\u{fc8}\
	\x03\x02\x02\x02\u{fd0}\u{fcf}\x03\x02\x02\x02\u{fd1}\u{28d}\x03\x02\x02\
	\x02\u{fd2}\u{fd3}\x05\u{38c}\u{1c7}\x02\u{fd3}\u{fd4}\x07\u{17f}\x02\x02\
	\u{fd4}\u{fd6}\x03\x02\x02\x02\u{fd5}\u{fd2}\x03\x02\x02\x02\u{fd5}\u{fd6}\
	\x03\x02\x02\x02\u{fd6}\u{fd7}\x03\x02\x02\x02\u{fd7}\u{fd8}\x05\u{38c}\
	\u{1c7}\x02\u{fd8}\u{28f}\x03\x02\x02\x02\u{fd9}\u{fda}\x07\u{183}\x02\x02\
	\u{fda}\u{fdb}\x05\u{186}\u{c4}\x02\u{fdb}\u{fdd}\x07\u{184}\x02\x02\u{fdc}\
	\u{fde}\x07\x13\x02\x02\u{fdd}\u{fdc}\x03\x02\x02\x02\u{fdd}\u{fde}\x03\
	\x02\x02\x02\u{fde}\u{fdf}\x03\x02\x02\x02\u{fdf}\u{fe0}\x05\u{38c}\u{1c7}\
	\x02\u{fe0}\u{291}\x03\x02\x02\x02\u{fe1}\u{fe3}\x05\u{2f4}\u{17b}\x02\u{fe2}\
	\u{fe4}\x05\u{2f0}\u{179}\x02\u{fe3}\u{fe2}\x03\x02\x02\x02\u{fe3}\u{fe4}\
	\x03\x02\x02\x02\u{fe4}\u{fed}\x03\x02\x02\x02\u{fe5}\u{fed}\x05\u{2f0}\
	\u{179}\x02\u{fe6}\u{fe8}\x05\u{2f6}\u{17c}\x02\u{fe7}\u{fe9}\x05\u{2f8}\
	\u{17d}\x02\u{fe8}\u{fe7}\x03\x02\x02\x02\u{fe8}\u{fe9}\x03\x02\x02\x02\
	\u{fe9}\u{fed}\x03\x02\x02\x02\u{fea}\u{fed}\x05\u{2f8}\u{17d}\x02\u{feb}\
	\u{fed}\x05\u{2f2}\u{17a}\x02\u{fec}\u{fe1}\x03\x02\x02\x02\u{fec}\u{fe5}\
	\x03\x02\x02\x02\u{fec}\u{fe6}\x03\x02\x02\x02\u{fec}\u{fea}\x03\x02\x02\
	\x02\u{fec}\u{feb}\x03\x02\x02\x02\u{fed}\u{293}\x03\x02\x02\x02\u{fee}\
	\u{ff2}\x05\u{290}\u{149}\x02\u{fef}\u{ff2}\x05\u{286}\u{144}\x02\u{ff0}\
	\u{ff2}\x05\u{296}\u{14c}\x02\u{ff1}\u{fee}\x03\x02\x02\x02\u{ff1}\u{fef}\
	\x03\x02\x02\x02\u{ff1}\u{ff0}\x03\x02\x02\x02\u{ff2}\u{295}\x03\x02\x02\
	\x02\u{ff3}\u{ff4}\x05\u{38c}\u{1c7}\x02\u{ff4}\u{ff5}\x07\u{183}\x02\x02\
	\u{ff5}\u{ff6}\x07\u{d7}\x02\x02\u{ff6}\u{ff8}\x05\u{294}\u{14b}\x02\u{ff7}\
	\u{ff9}\x05\u{292}\u{14a}\x02\u{ff8}\u{ff7}\x03\x02\x02\x02\u{ff8}\u{ff9}\
	\x03\x02\x02\x02\u{ff9}\u{1009}\x03\x02\x02\x02\u{ffa}\u{ffb}\x07\u{1a3}\
	\x02\x02\u{ffb}\u{ffc}\x07\u{183}\x02\x02\u{ffc}\u{ffd}\x05\u{328}\u{195}\
	\x02\u{ffd}\u{1006}\x07\u{184}\x02\x02\u{ffe}\u{fff}\x07\u{181}\x02\x02\
	\u{fff}\u{1000}\x07\u{1a3}\x02\x02\u{1000}\u{1001}\x07\u{183}\x02\x02\u{1001}\
	\u{1002}\x05\u{328}\u{195}\x02\u{1002}\u{1003}\x07\u{184}\x02\x02\u{1003}\
	\u{1005}\x03\x02\x02\x02\u{1004}\u{ffe}\x03\x02\x02\x02\u{1005}\u{1008}\
	\x03\x02\x02\x02\u{1006}\u{1004}\x03\x02\x02\x02\u{1006}\u{1007}\x03\x02\
	\x02\x02\u{1007}\u{100a}\x03\x02\x02\x02\u{1008}\u{1006}\x03\x02\x02\x02\
	\u{1009}\u{ffa}\x03\x02\x02\x02\u{1009}\u{100a}\x03\x02\x02\x02\u{100a}\
	\u{100b}\x03\x02\x02\x02\u{100b}\u{100d}\x07\u{184}\x02\x02\u{100c}\u{100e}\
	\x05\u{38c}\u{1c7}\x02\u{100d}\u{100c}\x03\x02\x02\x02\u{100d}\u{100e}\x03\
	\x02\x02\x02\u{100e}\u{297}\x03\x02\x02\x02\u{100f}\u{1010}\x07\u{175}\x02\
	\x02\u{1010}\u{1011}\x05\u{29a}\u{14e}\x02\u{1011}\u{299}\x03\x02\x02\x02\
	\u{1012}\u{1013}\x05\u{328}\u{195}\x02\u{1013}\u{29b}\x03\x02\x02\x02\u{1014}\
	\u{1015}\x05\u{29e}\u{150}\x02\u{1015}\u{29d}\x03\x02\x02\x02\u{1016}\u{1017}\
	\x07\u{16c}\x02\x02\u{1017}\u{1018}\x05\u{2a0}\u{151}\x02\u{1018}\u{29f}\
	\x03\x02\x02\x02\u{1019}\u{101e}\x05\u{2a2}\u{152}\x02\u{101a}\u{101b}\x07\
	\u{181}\x02\x02\u{101b}\u{101d}\x05\u{2a2}\u{152}\x02\u{101c}\u{101a}\x03\
	\x02\x02\x02\u{101d}\u{1020}\x03\x02\x02\x02\u{101e}\u{101c}\x03\x02\x02\
	\x02\u{101e}\u{101f}\x03\x02\x02\x02\u{101f}\u{102a}\x03\x02\x02\x02\u{1020}\
	\u{101e}\x03\x02\x02\x02\u{1021}\u{1026}\x05\u{2a4}\u{153}\x02\u{1022}\u{1023}\
	\x07\u{181}\x02\x02\u{1023}\u{1025}\x05\u{2a2}\u{152}\x02\u{1024}\u{1022}\
	\x03\x02\x02\x02\u{1025}\u{1028}\x03\x02\x02\x02\u{1026}\u{1024}\x03\x02\
	\x02\x02\u{1026}\u{1027}\x03\x02\x02\x02\u{1027}\u{102a}\x03\x02\x02\x02\
	\u{1028}\u{1026}\x03\x02\x02\x02\u{1029}\u{1019}\x03\x02\x02\x02\u{1029}\
	\u{1021}\x03\x02\x02\x02\u{102a}\u{2a1}\x03\x02\x02\x02\u{102b}\u{102c}\
	\x05\u{2de}\u{170}\x02\u{102c}\u{2a3}\x03\x02\x02\x02\u{102d}\u{102e}\x07\
	\u{183}\x02\x02\u{102e}\u{102f}\x05\u{2e6}\u{174}\x02\u{102f}\u{1030}\x07\
	\u{184}\x02\x02\u{1030}\u{2a5}\x03\x02\x02\x02\u{1031}\u{1032}\x07\u{13f}\
	\x02\x02\u{1032}\u{1033}\x07\u{183}\x02\x02\u{1033}\u{1034}\x05\u{29e}\u{150}\
	\x02\u{1034}\u{1036}\x07\u{184}\x02\x02\u{1035}\u{1037}\x07\x13\x02\x02\
	\u{1036}\u{1035}\x03\x02\x02\x02\u{1036}\u{1037}\x03\x02\x02\x02\u{1037}\
	\u{1038}\x03\x02\x02\x02\u{1038}\u{1042}\x05\u{27e}\u{140}\x02\u{1039}\u{103a}\
	\x07\u{183}\x02\x02\u{103a}\u{103f}\x05\u{38c}\u{1c7}\x02\u{103b}\u{103c}\
	\x07\u{181}\x02\x02\u{103c}\u{103e}\x05\u{38c}\u{1c7}\x02\u{103d}\u{103b}\
	\x03\x02\x02\x02\u{103e}\u{1041}\x03\x02\x02\x02\u{103f}\u{103d}\x03\x02\
	\x02\x02\u{103f}\u{1040}\x03\x02\x02\x02\u{1040}\u{1043}\x03\x02\x02\x02\
	\u{1041}\u{103f}\x03\x02\x02\x02\u{1042}\u{1039}\x03\x02\x02\x02\u{1042}\
	\u{1043}\x03\x02\x02\x02\u{1043}\u{1044}\x03\x02\x02\x02\u{1044}\u{1045}\
	\x07\u{184}\x02\x02\u{1045}\u{2a7}\x03\x02\x02\x02\u{1046}\u{1048}\x07\u{121}\
	\x02\x02\u{1047}\u{1049}\x07\u{1a7}\x02\x02\u{1048}\u{1047}\x03\x02\x02\
	\x02\u{1048}\u{1049}\x03\x02\x02\x02\u{1049}\u{1050}\x03\x02\x02\x02\u{104a}\
	\u{104c}\x05\u{2aa}\u{156}\x02\u{104b}\u{104a}\x03\x02\x02\x02\u{104b}\u{104c}\
	\x03\x02\x02\x02\u{104c}\u{104d}\x03\x02\x02\x02\u{104d}\u{1051}\x05\u{2ac}\
	\u{157}\x02\u{104e}\u{104f}\x07\u{151}\x02\x02\u{104f}\u{1051}\x05\u{2ae}\
	\u{158}\x02\u{1050}\u{104b}\x03\x02\x02\x02\u{1050}\u{104e}\x03\x02\x02\
	\x02\u{1051}\u{1054}\x03\x02\x02\x02\u{1052}\u{1054}\x05\u{2b2}\u{15a}\x02\
	\u{1053}\u{1046}\x03\x02\x02\x02\u{1053}\u{1052}\x03\x02\x02\x02\u{1054}\
	\u{2a9}\x03\x02\x02\x02\u{1055}\u{1056}\x09\x17\x02\x02\u{1056}\u{2ab}\x03\
	\x02\x02\x02\u{1057}\u{105c}\x05\u{2b0}\u{159}\x02\u{1058}\u{1059}\x07\u{181}\
	\x02\x02\u{1059}\u{105b}\x05\u{2b0}\u{159}\x02\u{105a}\u{1058}\x03\x02\x02\
	\x02\u{105b}\u{105e}\x03\x02\x02\x02\u{105c}\u{105a}\x03\x02\x02\x02\u{105c}\
	\u{105d}\x03\x02\x02\x02\u{105d}\u{2ad}\x03\x02\x02\x02\u{105e}\u{105c}\
	\x03\x02\x02\x02\u{105f}\u{1060}\x07\u{183}\x02\x02\u{1060}\u{1061}\x05\
	\u{2b6}\u{15c}\x02\u{1061}\u{1062}\x07\u{184}\x02\x02\u{1062}\u{1063}\x05\
	\u{ee}\x78\x02\u{1063}\u{1064}\x05\u{f2}\x7a\x02\u{1064}\u{1065}\x07\u{168}\
	\x02\x02\u{1065}\u{1072}\x07\u{19d}\x02\x02\u{1066}\u{1070}\x07\x13\x02\
	\x02\u{1067}\u{106a}\x07\u{183}\x02\x02\u{1068}\u{106b}\x05\u{268}\u{135}\
	\x02\u{1069}\u{106b}\x05\u{112}\u{8a}\x02\u{106a}\u{1068}\x03\x02\x02\x02\
	\u{106a}\u{1069}\x03\x02\x02\x02\u{106b}\u{106c}\x03\x02\x02\x02\u{106c}\
	\u{106d}\x07\u{184}\x02\x02\u{106d}\u{1071}\x03\x02\x02\x02\u{106e}\u{1071}\
	\x05\u{268}\u{135}\x02\u{106f}\u{1071}\x05\u{112}\u{8a}\x02\u{1070}\u{1067}\
	\x03\x02\x02\x02\u{1070}\u{106e}\x03\x02\x02\x02\u{1070}\u{106f}\x03\x02\
	\x02\x02\u{1071}\u{1073}\x03\x02\x02\x02\u{1072}\u{1066}\x03\x02\x02\x02\
	\u{1072}\u{1073}\x03\x02\x02\x02\u{1073}\u{1074}\x03\x02\x02\x02\u{1074}\
	\u{1075}\x05\u{ee}\x78\x02\u{1075}\u{1076}\x05\u{f0}\x79\x02\u{1076}\u{2af}\
	\x03\x02\x02\x02\u{1077}\u{108c}\x05\u{260}\u{131}\x02\u{1078}\u{1089}\x05\
	\u{328}\u{195}\x02\u{1079}\u{107b}\x07\x13\x02\x02\u{107a}\u{1079}\x03\x02\
	\x02\x02\u{107a}\u{107b}\x03\x02\x02\x02\u{107b}\u{107c}\x03\x02\x02\x02\
	\u{107c}\u{108a}\x05\u{38c}\u{1c7}\x02\u{107d}\u{107e}\x07\x13\x02\x02\u{107e}\
	\u{107f}\x07\u{183}\x02\x02\u{107f}\u{1084}\x05\u{38c}\u{1c7}\x02\u{1080}\
	\u{1081}\x07\u{181}\x02\x02\u{1081}\u{1083}\x05\u{38c}\u{1c7}\x02\u{1082}\
	\u{1080}\x03\x02\x02\x02\u{1083}\u{1086}\x03\x02\x02\x02\u{1084}\u{1082}\
	\x03\x02\x02\x02\u{1084}\u{1085}\x03\x02\x02\x02\u{1085}\u{1087}\x03\x02\
	\x02\x02\u{1086}\u{1084}\x03\x02\x02\x02\u{1087}\u{1088}\x07\u{184}\x02\
	\x02\u{1088}\u{108a}\x03\x02\x02\x02\u{1089}\u{107a}\x03\x02\x02\x02\u{1089}\
	\u{107d}\x03\x02\x02\x02\u{1089}\u{108a}\x03\x02\x02\x02\u{108a}\u{108c}\
	\x03\x02\x02\x02\u{108b}\u{1077}\x03\x02\x02\x02\u{108b}\u{1078}\x03\x02\
	\x02\x02\u{108c}\u{2b1}\x03\x02\x02\x02\u{108d}\u{108e}\x09\x1f\x02\x02\
	\u{108e}\u{108f}\x05\u{2b6}\u{15c}\x02\u{108f}\u{1090}\x05\u{ee}\x78\x02\
	\u{1090}\u{1091}\x05\u{f2}\x7a\x02\u{1091}\u{1092}\x07\u{168}\x02\x02\u{1092}\
	\u{109f}\x07\u{19d}\x02\x02\u{1093}\u{109d}\x07\x13\x02\x02\u{1094}\u{1097}\
	\x07\u{183}\x02\x02\u{1095}\u{1098}\x05\u{268}\u{135}\x02\u{1096}\u{1098}\
	\x05\u{112}\u{8a}\x02\u{1097}\u{1095}\x03\x02\x02\x02\u{1097}\u{1096}\x03\
	\x02\x02\x02\u{1098}\u{1099}\x03\x02\x02\x02\u{1099}\u{109a}\x07\u{184}\
	\x02\x02\u{109a}\u{109e}\x03\x02\x02\x02\u{109b}\u{109e}\x05\u{268}\u{135}\
	\x02\u{109c}\u{109e}\x05\u{112}\u{8a}\x02\u{109d}\u{1094}\x03\x02\x02\x02\
	\u{109d}\u{109b}\x03\x02\x02\x02\u{109d}\u{109c}\x03\x02\x02\x02\u{109e}\
	\u{10a0}\x03\x02\x02\x02\u{109f}\u{1093}\x03\x02\x02\x02\u{109f}\u{10a0}\
	\x03\x02\x02\x02\u{10a0}\u{10a1}\x03\x02\x02\x02\u{10a1}\u{10a2}\x05\u{ee}\
	\x78\x02\u{10a2}\u{10a3}\x05\u{f0}\x79\x02\u{10a3}\u{2b3}\x03\x02\x02\x02\
	\u{10a4}\u{10a7}\x05\u{260}\u{131}\x02\u{10a5}\u{10a7}\x05\u{328}\u{195}\
	\x02\u{10a6}\u{10a4}\x03\x02\x02\x02\u{10a6}\u{10a5}\x03\x02\x02\x02\u{10a7}\
	\u{2b5}\x03\x02\x02\x02\u{10a8}\u{10ad}\x05\u{2b4}\u{15b}\x02\u{10a9}\u{10aa}\
	\x07\u{181}\x02\x02\u{10aa}\u{10ac}\x05\u{2b4}\u{15b}\x02\u{10ab}\u{10a9}\
	\x03\x02\x02\x02\u{10ac}\u{10af}\x03\x02\x02\x02\u{10ad}\u{10ab}\x03\x02\
	\x02\x02\u{10ad}\u{10ae}\x03\x02\x02\x02\u{10ae}\u{2b7}\x03\x02\x02\x02\
	\u{10af}\u{10ad}\x03\x02\x02\x02\u{10b0}\u{10b1}\x07\u{177}\x02\x02\u{10b1}\
	\u{10b6}\x05\u{2ba}\u{15e}\x02\u{10b2}\u{10b3}\x07\u{181}\x02\x02\u{10b3}\
	\u{10b5}\x05\u{2ba}\u{15e}\x02\u{10b4}\u{10b2}\x03\x02\x02\x02\u{10b5}\u{10b8}\
	\x03\x02\x02\x02\u{10b6}\u{10b4}\x03\x02\x02\x02\u{10b6}\u{10b7}\x03\x02\
	\x02\x02\u{10b7}\u{2b9}\x03\x02\x02\x02\u{10b8}\u{10b6}\x03\x02\x02\x02\
	\u{10b9}\u{10ba}\x05\u{38c}\u{1c7}\x02\u{10ba}\u{10bb}\x07\x13\x02\x02\u{10bb}\
	\u{10bc}\x05\u{2bc}\u{15f}\x02\u{10bc}\u{2bb}\x03\x02\x02\x02\u{10bd}\u{10ca}\
	\x05\u{38c}\u{1c7}\x02\u{10be}\u{10c0}\x07\u{183}\x02\x02\u{10bf}\u{10c1}\
	\x05\u{38c}\u{1c7}\x02\u{10c0}\u{10bf}\x03\x02\x02\x02\u{10c0}\u{10c1}\x03\
	\x02\x02\x02\u{10c1}\u{10c3}\x03\x02\x02\x02\u{10c2}\u{10c4}\x05\u{292}\
	\u{14a}\x02\u{10c3}\u{10c2}\x03\x02\x02\x02\u{10c3}\u{10c4}\x03\x02\x02\
	\x02\u{10c4}\u{10c6}\x03\x02\x02\x02\u{10c5}\u{10c7}\x05\u{2be}\u{160}\x02\
	\u{10c6}\u{10c5}\x03\x02\x02\x02\u{10c6}\u{10c7}\x03\x02\x02\x02\u{10c7}\
	\u{10c8}\x03\x02\x02\x02\u{10c8}\u{10ca}\x07\u{184}\x02\x02\u{10c9}\u{10bd}\
	\x03\x02\x02\x02\u{10c9}\u{10be}\x03\x02\x02\x02\u{10ca}\u{2bd}\x03\x02\
	\x02\x02\u{10cb}\u{10ce}\x05\u{2c0}\u{161}\x02\u{10cc}\u{10ce}\x05\u{2c2}\
	\u{162}\x02\u{10cd}\u{10cb}\x03\x02\x02\x02\u{10cd}\u{10cc}\x03\x02\x02\
	\x02\u{10ce}\u{2bf}\x03\x02\x02\x02\u{10cf}\u{10d6}\x07\u{11b}\x02\x02\u{10d0}\
	\u{10d7}\x05\u{2c4}\u{163}\x02\u{10d1}\u{10d2}\x07\x1b\x02\x02\u{10d2}\u{10d3}\
	\x05\u{2c6}\u{164}\x02\u{10d3}\u{10d4}\x07\x0d\x02\x02\u{10d4}\u{10d5}\x05\
	\u{2c6}\u{164}\x02\u{10d5}\u{10d7}\x03\x02\x02\x02\u{10d6}\u{10d0}\x03\x02\
	\x02\x02\u{10d6}\u{10d1}\x03\x02\x02\x02\u{10d7}\u{2c1}\x03\x02\x02\x02\
	\u{10d8}\u{10df}\x07\u{fb}\x02\x02\u{10d9}\u{10e0}\x05\u{2c4}\u{163}\x02\
	\u{10da}\u{10db}\x07\x1b\x02\x02\u{10db}\u{10dc}\x05\u{2c6}\u{164}\x02\u{10dc}\
	\u{10dd}\x07\x0d\x02\x02\u{10dd}\u{10de}\x05\u{2c6}\u{164}\x02\u{10de}\u{10e0}\
	\x03\x02\x02\x02\u{10df}\u{10d9}\x03\x02\x02\x02\u{10df}\u{10da}\x03\x02\
	\x02\x02\u{10e0}\u{2c3}\x03\x02\x02\x02\u{10e1}\u{10e2}\x07\u{158}\x02\x02\
	\u{10e2}\u{10e8}\x07\u{ee}\x02\x02\u{10e3}\u{10e4}\x07\x40\x02\x02\u{10e4}\
	\u{10e8}\x07\u{11a}\x02\x02\u{10e5}\u{10e6}\x07\u{1a2}\x02\x02\u{10e6}\u{10e8}\
	\x07\u{ee}\x02\x02\u{10e7}\u{10e1}\x03\x02\x02\x02\u{10e7}\u{10e3}\x03\x02\
	\x02\x02\u{10e7}\u{10e5}\x03\x02\x02\x02\u{10e8}\u{2c5}\x03\x02\x02\x02\
	\u{10e9}\u{10ea}\x09\x20\x02\x02\u{10ea}\u{10ee}\x09\x21\x02\x02\u{10eb}\
	\u{10ec}\x07\x40\x02\x02\u{10ec}\u{10ee}\x07\u{11a}\x02\x02\u{10ed}\u{10e9}\
	\x03\x02\x02\x02\u{10ed}\u{10eb}\x03\x02\x02\x02\u{10ee}\u{2c7}\x03\x02\
	\x02\x02\u{10ef}\u{10f0}\x07\u{8c}\x02\x02\u{10f0}\u{10f1}\x07\x22\x02\x02\
	\u{10f1}\u{10f2}\x05\u{2ca}\u{166}\x02\u{10f2}\u{2c9}\x03\x02\x02\x02\u{10f3}\
	\u{10f7}\x05\u{2ce}\u{168}\x02\u{10f4}\u{10f7}\x05\u{2d0}\u{169}\x02\u{10f5}\
	\u{10f7}\x05\u{2cc}\u{167}\x02\u{10f6}\u{10f3}\x03\x02\x02\x02\u{10f6}\u{10f4}\
	\x03\x02\x02\x02\u{10f6}\u{10f5}\x03\x02\x02\x02\u{10f7}\u{2cb}\x03\x02\
	\x02\x02\u{10f8}\u{10f9}\x07\u{183}\x02\x02\u{10f9}\u{10fa}\x07\u{184}\x02\
	\x02\u{10fa}\u{2cd}\x03\x02\x02\x02\u{10fb}\u{10fe}\x07\u{119}\x02\x02\u{10fc}\
	\u{10fe}\x07\x3f\x02\x02\u{10fd}\u{10fb}\x03\x02\x02\x02\u{10fd}\u{10fc}\
	\x03\x02\x02\x02\u{10fe}\u{10ff}\x03\x02\x02\x02\u{10ff}\u{1100}\x07\u{183}\
	\x02\x02\u{1100}\u{1105}\x05\u{328}\u{195}\x02\u{1101}\u{1102}\x07\u{181}\
	\x02\x02\u{1102}\u{1104}\x05\u{328}\u{195}\x02\u{1103}\u{1101}\x03\x02\x02\
	\x02\u{1104}\u{1107}\x03\x02\x02\x02\u{1105}\u{1103}\x03\x02\x02\x02\u{1105}\
	\u{1106}\x03\x02\x02\x02\u{1106}\u{1108}\x03\x02\x02\x02\u{1107}\u{1105}\
	\x03\x02\x02\x02\u{1108}\u{1109}\x07\u{184}\x02\x02\u{1109}\u{2cf}\x03\x02\
	\x02\x02\u{110a}\u{110f}\x05\u{2e0}\u{171}\x02\u{110b}\u{110c}\x07\u{178}\
	\x02\x02\u{110c}\u{1110}\x07\u{119}\x02\x02\u{110d}\u{110e}\x07\u{178}\x02\
	\x02\u{110e}\u{1110}\x07\x3f\x02\x02\u{110f}\u{110b}\x03\x02\x02\x02\u{110f}\
	\u{110d}\x03\x02\x02\x02\u{110f}\u{1110}\x03\x02\x02\x02\u{1110}\u{111e}\
	\x03\x02\x02\x02\u{1111}\u{1112}\x07\u{8d}\x02\x02\u{1112}\u{1113}\x07\u{127}\
	\x02\x02\u{1113}\u{1114}\x07\u{183}\x02\x02\u{1114}\u{1119}\x05\u{2d2}\u{16a}\
	\x02\u{1115}\u{1116}\x07\u{181}\x02\x02\u{1116}\u{1118}\x05\u{2d2}\u{16a}\
	\x02\u{1117}\u{1115}\x03\x02\x02\x02\u{1118}\u{111b}\x03\x02\x02\x02\u{1119}\
	\u{1117}\x03\x02\x02\x02\u{1119}\u{111a}\x03\x02\x02\x02\u{111a}\u{111c}\
	\x03\x02\x02\x02\u{111b}\u{1119}\x03\x02\x02\x02\u{111c}\u{111d}\x07\u{184}\
	\x02\x02\u{111d}\u{111f}\x03\x02\x02\x02\u{111e}\u{1111}\x03\x02\x02\x02\
	\u{111e}\u{111f}\x03\x02\x02\x02\u{111f}\u{2d1}\x03\x02\x02\x02\u{1120}\
	\u{1123}\x05\u{2d4}\u{16b}\x02\u{1121}\u{1123}\x05\u{2d6}\u{16c}\x02\u{1122}\
	\u{1120}\x03\x02\x02\x02\u{1122}\u{1121}\x03\x02\x02\x02\u{1123}\u{2d3}\
	\x03\x02\x02\x02\u{1124}\u{1126}\x07\u{183}\x02\x02\u{1125}\u{1127}\x05\
	\u{328}\u{195}\x02\u{1126}\u{1125}\x03\x02\x02\x02\u{1126}\u{1127}\x03\x02\
	\x02\x02\u{1127}\u{112c}\x03\x02\x02\x02\u{1128}\u{1129}\x07\u{181}\x02\
	\x02\u{1129}\u{112b}\x05\u{328}\u{195}\x02\u{112a}\u{1128}\x03\x02\x02\x02\
	\u{112b}\u{112e}\x03\x02\x02\x02\u{112c}\u{112a}\x03\x02\x02\x02\u{112c}\
	\u{112d}\x03\x02\x02\x02\u{112d}\u{112f}\x03\x02\x02\x02\u{112e}\u{112c}\
	\x03\x02\x02\x02\u{112f}\u{1130}\x07\u{184}\x02\x02\u{1130}\u{2d5}\x03\x02\
	\x02\x02\u{1131}\u{1132}\x05\u{328}\u{195}\x02\u{1132}\u{2d7}\x03\x02\x02\
	\x02\u{1133}\u{1134}\x07\u{8e}\x02\x02\u{1134}\u{1135}\x05\u{2dc}\u{16f}\
	\x02\u{1135}\u{2d9}\x03\x02\x02\x02\u{1136}\u{1137}\x07\u{f7}\x02\x02\u{1137}\
	\u{1138}\x05\u{328}\u{195}\x02\u{1138}\u{2db}\x03\x02\x02\x02\u{1139}\u{113a}\
	\x05\u{328}\u{195}\x02\u{113a}\u{2dd}\x03\x02\x02\x02\u{113b}\u{113c}\x07\
	\u{183}\x02\x02\u{113c}\u{113d}\x05\u{2e0}\u{171}\x02\u{113d}\u{113e}\x07\
	\u{184}\x02\x02\u{113e}\u{2df}\x03\x02\x02\x02\u{113f}\u{1141}\x05\u{2e4}\
	\u{173}\x02\u{1140}\u{1142}\x05\u{2e2}\u{172}\x02\u{1141}\u{1140}\x03\x02\
	\x02\x02\u{1141}\u{1142}\x03\x02\x02\x02\u{1142}\u{2e1}\x03\x02\x02\x02\
	\u{1143}\u{1144}\x07\u{181}\x02\x02\u{1144}\u{1146}\x05\u{2e4}\u{173}\x02\
	\u{1145}\u{1143}\x03\x02\x02\x02\u{1146}\u{1147}\x03\x02\x02\x02\u{1147}\
	\u{1145}\x03\x02\x02\x02\u{1147}\u{1148}\x03\x02\x02\x02\u{1148}\u{2e3}\
	\x03\x02\x02\x02\u{1149}\u{114c}\x05\u{264}\u{133}\x02\u{114a}\u{114c}\x05\
	\u{328}\u{195}\x02\u{114b}\u{1149}\x03\x02\x02\x02\u{114b}\u{114a}\x03\x02\
	\x02\x02\u{114c}\u{2e5}\x03\x02\x02\x02\u{114d}\u{114f}\x05\u{328}\u{195}\
	\x02\u{114e}\u{1150}\x07\x13\x02\x02\u{114f}\u{114e}\x03\x02\x02\x02\u{114f}\
	\u{1150}\x03\x02\x02\x02\u{1150}\u{1152}\x03\x02\x02\x02\u{1151}\u{1153}\
	\x05\u{38c}\u{1c7}\x02\u{1152}\u{1151}\x03\x02\x02\x02\u{1152}\u{1153}\x03\
	\x02\x02\x02\u{1153}\u{1158}\x03\x02\x02\x02\u{1154}\u{1155}\x07\u{181}\
	\x02\x02\u{1155}\u{1157}\x05\u{2e8}\u{175}\x02\u{1156}\u{1154}\x03\x02\x02\
	\x02\u{1157}\u{115a}\x03\x02\x02\x02\u{1158}\u{1156}\x03\x02\x02\x02\u{1158}\
	\u{1159}\x03\x02\x02\x02\u{1159}\u{2e7}\x03\x02\x02\x02\u{115a}\u{1158}\
	\x03\x02\x02\x02\u{115b}\u{115d}\x05\u{328}\u{195}\x02\u{115c}\u{115e}\x07\
	\x13\x02\x02\u{115d}\u{115c}\x03\x02\x02\x02\u{115d}\u{115e}\x03\x02\x02\
	\x02\u{115e}\u{1160}\x03\x02\x02\x02\u{115f}\u{1161}\x05\u{38c}\u{1c7}\x02\
	\u{1160}\u{115f}\x03\x02\x02\x02\u{1160}\u{1161}\x03\x02\x02\x02\u{1161}\
	\u{2e9}\x03\x02\x02\x02\u{1162}\u{1165}\x05\u{2de}\u{170}\x02\u{1163}\u{1165}\
	\x05\u{2e0}\u{171}\x02\u{1164}\u{1162}\x03\x02\x02\x02\u{1164}\u{1163}\x03\
	\x02\x02\x02\u{1165}\u{2eb}\x03\x02\x02\x02\u{1166}\u{1167}\x07\u{183}\x02\
	\x02\u{1167}\u{116c}\x05\u{152}\u{aa}\x02\u{1168}\u{1169}\x07\u{181}\x02\
	\x02\u{1169}\u{116b}\x05\u{152}\u{aa}\x02\u{116a}\u{1168}\x03\x02\x02\x02\
	\u{116b}\u{116e}\x03\x02\x02\x02\u{116c}\u{116a}\x03\x02\x02\x02\u{116c}\
	\u{116d}\x03\x02\x02\x02\u{116d}\u{116f}\x03\x02\x02\x02\u{116e}\u{116c}\
	\x03\x02\x02\x02\u{116f}\u{1170}\x07\u{184}\x02\x02\u{1170}\u{2ed}\x03\x02\
	\x02\x02\u{1171}\u{1176}\x05\u{152}\u{aa}\x02\u{1172}\u{1173}\x07\u{181}\
	\x02\x02\u{1173}\u{1175}\x05\u{152}\u{aa}\x02\u{1174}\u{1172}\x03\x02\x02\
	\x02\u{1175}\u{1178}\x03\x02\x02\x02\u{1176}\u{1174}\x03\x02\x02\x02\u{1176}\
	\u{1177}\x03\x02\x02\x02\u{1177}\u{2ef}\x03\x02\x02\x02\u{1178}\u{1176}\
	\x03\x02\x02\x02\u{1179}\u{117a}\x07\u{dc}\x02\x02\u{117a}\u{117b}\x07\x22\
	\x02\x02\u{117b}\u{1180}\x05\u{152}\u{aa}\x02\u{117c}\u{117d}\x07\u{181}\
	\x02\x02\u{117d}\u{117f}\x05\u{152}\u{aa}\x02\u{117e}\u{117c}\x03\x02\x02\
	\x02\u{117f}\u{1182}\x03\x02\x02\x02\u{1180}\u{117e}\x03\x02\x02\x02\u{1180}\
	\u{1181}\x03\x02\x02\x02\u{1181}\u{2f1}\x03\x02\x02\x02\u{1182}\u{1180}\
	\x03\x02\x02\x02\u{1183}\u{1184}\x07\x2b\x02\x02\u{1184}\u{1185}\x07\x22\
	\x02\x02\u{1185}\u{1186}\x05\u{2ea}\u{176}\x02\u{1186}\u{2f3}\x03\x02\x02\
	\x02\u{1187}\u{1188}\x07\u{e4}\x02\x02\u{1188}\u{1189}\x07\x22\x02\x02\u{1189}\
	\u{118a}\x05\u{2ea}\u{176}\x02\u{118a}\u{2f5}\x03\x02\x02\x02\u{118b}\u{118c}\
	\x07\x5f\x02\x02\u{118c}\u{118d}\x07\x22\x02\x02\u{118d}\u{118e}\x05\u{2ea}\
	\u{176}\x02\u{118e}\u{2f7}\x03\x02\x02\x02\u{118f}\u{1190}\x07\u{130}\x02\
	\x02\u{1190}\u{1193}\x07\x22\x02\x02\u{1191}\u{1194}\x05\u{2ec}\u{177}\x02\
	\u{1192}\u{1194}\x05\u{2ee}\u{178}\x02\u{1193}\u{1191}\x03\x02\x02\x02\u{1193}\
	\u{1192}\x03\x02\x02\x02\u{1194}\u{2f9}\x03\x02\x02\x02\u{1195}\u{1196}\
	\x07\u{153}\x02\x02\u{1196}\u{119a}\x07\u{183}\x02\x02\u{1197}\u{119b}\x07\
	\u{ad}\x02\x02\u{1198}\u{119b}\x07\u{14d}\x02\x02\u{1199}\u{119b}\x07\x1f\
	\x02\x02\u{119a}\u{1197}\x03\x02\x02\x02\u{119a}\u{1198}\x03\x02\x02\x02\
	\u{119a}\u{1199}\x03\x02\x02\x02\u{119a}\u{119b}\x03\x02\x02\x02\u{119b}\
	\u{119d}\x03\x02\x02\x02\u{119c}\u{119e}\x05\u{2b4}\u{15b}\x02\u{119d}\u{119c}\
	\x03\x02\x02\x02\u{119d}\u{119e}\x03\x02\x02\x02\u{119e}\u{119f}\x03\x02\
	\x02\x02\u{119f}\u{11a0}\x07\u{87}\x02\x02\u{11a0}\u{11a1}\x05\u{2b4}\u{15b}\
	\x02\u{11a1}\u{11a2}\x07\u{184}\x02\x02\u{11a2}\u{2fb}\x03\x02\x02\x02\u{11a3}\
	\u{11cc}\x05\u{2fa}\u{17e}\x02\u{11a4}\u{11a5}\x05\u{300}\u{181}\x02\u{11a5}\
	\u{11b4}\x07\u{183}\x02\x02\u{11a6}\u{11b5}\x07\u{193}\x02\x02\u{11a7}\u{11a9}\
	\x05\u{2aa}\u{156}\x02\u{11a8}\u{11a7}\x03\x02\x02\x02\u{11a8}\u{11a9}\x03\
	\x02\x02\x02\u{11a9}\u{11b2}\x03\x02\x02\x02\u{11aa}\u{11af}\x05\u{2b4}\
	\u{15b}\x02\u{11ab}\u{11ac}\x07\u{181}\x02\x02\u{11ac}\u{11ae}\x05\u{2b4}\
	\u{15b}\x02\u{11ad}\u{11ab}\x03\x02\x02\x02\u{11ae}\u{11b1}\x03\x02\x02\
	\x02\u{11af}\u{11ad}\x03\x02\x02\x02\u{11af}\u{11b0}\x03\x02\x02\x02\u{11b0}\
	\u{11b3}\x03\x02\x02\x02\u{11b1}\u{11af}\x03\x02\x02\x02\u{11b2}\u{11aa}\
	\x03\x02\x02\x02\u{11b2}\u{11b3}\x03\x02\x02\x02\u{11b3}\u{11b5}\x03\x02\
	\x02\x02\u{11b4}\u{11a6}\x03\x02\x02\x02\u{11b4}\u{11a8}\x03\x02\x02\x02\
	\u{11b5}\u{11c9}\x03\x02\x02\x02\u{11b6}\u{11b7}\x07\u{184}\x02\x02\u{11b7}\
	\u{11b8}\x07\u{179}\x02\x02\u{11b8}\u{11b9}\x07\u{8c}\x02\x02\u{11b9}\u{11ba}\
	\x07\u{183}\x02\x02\u{11ba}\u{11bb}\x05\u{2f0}\u{179}\x02\u{11bb}\u{11bc}\
	\x07\u{184}\x02\x02\u{11bc}\u{11ca}\x03\x02\x02\x02\u{11bd}\u{11bf}\x07\
	\u{184}\x02\x02\u{11be}\u{11c0}\x05\u{2fe}\u{180}\x02\u{11bf}\u{11be}\x03\
	\x02\x02\x02\u{11bf}\u{11c0}\x03\x02\x02\x02\u{11c0}\u{11c1}\x03\x02\x02\
	\x02\u{11c1}\u{11c2}\x07\u{e1}\x02\x02\u{11c2}\u{11ca}\x05\u{2bc}\u{15f}\
	\x02\u{11c3}\u{11c4}\x05\u{2fe}\u{180}\x02\u{11c4}\u{11c5}\x07\u{184}\x02\
	\x02\u{11c5}\u{11c6}\x07\u{e1}\x02\x02\u{11c6}\u{11c7}\x05\u{2bc}\u{15f}\
	\x02\u{11c7}\u{11ca}\x03\x02\x02\x02\u{11c8}\u{11ca}\x07\u{184}\x02\x02\
	\u{11c9}\u{11b6}\x03\x02\x02\x02\u{11c9}\u{11bd}\x03\x02\x02\x02\u{11c9}\
	\u{11c3}\x03\x02\x02\x02\u{11c9}\u{11c8}\x03\x02\x02\x02\u{11ca}\u{11cc}\
	\x03\x02\x02\x02\u{11cb}\u{11a3}\x03\x02\x02\x02\u{11cb}\u{11a4}\x03\x02\
	\x02\x02\u{11cc}\u{2fd}\x03\x02\x02\x02\u{11cd}\u{11ce}\x07\u{110}\x02\x02\
	\u{11ce}\u{11d2}\x07\u{d3}\x02\x02\u{11cf}\u{11d0}\x07\u{93}\x02\x02\u{11d0}\
	\u{11d2}\x07\u{d3}\x02\x02\u{11d1}\u{11cd}\x03\x02\x02\x02\u{11d1}\u{11cf}\
	\x03\x02\x02\x02\u{11d2}\u{2ff}\x03\x02\x02\x02\u{11d3}\u{11d6}\x05\u{38e}\
	\u{1c8}\x02\u{11d4}\u{11d6}\x05\u{394}\u{1cb}\x02\u{11d5}\u{11d3}\x03\x02\
	\x02\x02\u{11d5}\u{11d4}\x03\x02\x02\x02\u{11d6}\u{301}\x03\x02\x02\x02\
	\u{11d7}\u{11d8}\x07\x26\x02\x02\u{11d8}\u{11d9}\x07\u{183}\x02\x02\u{11d9}\
	\u{11da}\x05\u{328}\u{195}\x02\u{11da}\u{11db}\x07\x13\x02\x02\u{11db}\u{11de}\
	\x05\u{17a}\u{be}\x02\u{11dc}\u{11dd}\x07\u{85}\x02\x02\u{11dd}\u{11df}\
	\x07\u{19d}\x02\x02\u{11de}\u{11dc}\x03\x02\x02\x02\u{11de}\u{11df}\x03\
	\x02\x02\x02\u{11df}\u{11e0}\x03\x02\x02\x02\u{11e0}\u{11e1}\x07\u{184}\
	\x02\x02\u{11e1}\u{303}\x03\x02\x02\x02\u{11e2}\u{11e3}\x07\x25\x02\x02\
	\u{11e3}\u{11e9}\x05\u{328}\u{195}\x02\u{11e4}\u{11e5}\x07\u{174}\x02\x02\
	\u{11e5}\u{11e6}\x05\u{328}\u{195}\x02\u{11e6}\u{11e7}\x07\u{145}\x02\x02\
	\u{11e7}\u{11e8}\x05\u{328}\u{195}\x02\u{11e8}\u{11ea}\x03\x02\x02\x02\u{11e9}\
	\u{11e4}\x03\x02\x02\x02\u{11ea}\u{11eb}\x03\x02\x02\x02\u{11eb}\u{11e9}\
	\x03\x02\x02\x02\u{11eb}\u{11ec}\x03\x02\x02\x02\u{11ec}\u{11ef}\x03\x02\
	\x02\x02\u{11ed}\u{11ee}\x07\x66\x02\x02\u{11ee}\u{11f0}\x05\u{328}\u{195}\
	\x02\u{11ef}\u{11ed}\x03\x02\x02\x02\u{11ef}\u{11f0}\x03\x02\x02\x02\u{11f0}\
	\u{11f1}\x03\x02\x02\x02\u{11f1}\u{11f2}\x07\x68\x02\x02\u{11f2}\u{305}\
	\x03\x02\x02\x02\u{11f3}\u{11f9}\x07\x25\x02\x02\u{11f4}\u{11f5}\x07\u{174}\
	\x02\x02\u{11f5}\u{11f6}\x05\u{328}\u{195}\x02\u{11f6}\u{11f7}\x07\u{145}\
	\x02\x02\u{11f7}\u{11f8}\x05\u{328}\u{195}\x02\u{11f8}\u{11fa}\x03\x02\x02\
	\x02\u{11f9}\u{11f4}\x03\x02\x02\x02\u{11fa}\u{11fb}\x03\x02\x02\x02\u{11fb}\
	\u{11f9}\x03\x02\x02\x02\u{11fb}\u{11fc}\x03\x02\x02\x02\u{11fc}\u{11ff}\
	\x03\x02\x02\x02\u{11fd}\u{11fe}\x07\x66\x02\x02\u{11fe}\u{1200}\x05\u{328}\
	\u{195}\x02\u{11ff}\u{11fd}\x03\x02\x02\x02\u{11ff}\u{1200}\x03\x02\x02\
	\x02\u{1200}\u{1201}\x03\x02\x02\x02\u{1201}\u{1202}\x07\x68\x02\x02\u{1202}\
	\u{307}\x03\x02\x02\x02\u{1203}\u{1204}\x07\u{80}\x02\x02\u{1204}\u{1205}\
	\x07\u{183}\x02\x02\u{1205}\u{1208}\x05\u{328}\u{195}\x02\u{1206}\u{1207}\
	\x07\u{14b}\x02\x02\u{1207}\u{1209}\x05\u{30a}\u{186}\x02\u{1208}\u{1206}\
	\x03\x02\x02\x02\u{1208}\u{1209}\x03\x02\x02\x02\u{1209}\u{120a}\x03\x02\
	\x02\x02\u{120a}\u{120b}\x07\u{184}\x02\x02\u{120b}\u{309}\x03\x02\x02\x02\
	\u{120c}\u{120d}\x09\x22\x02\x02\u{120d}\u{30b}\x03\x02\x02\x02\u{120e}\
	\u{120f}\x07\x78\x02\x02\u{120f}\u{1210}\x07\u{183}\x02\x02\u{1210}\u{1211}\
	\x05\u{30e}\u{188}\x02\u{1211}\u{1212}\x07\u{87}\x02\x02\u{1212}\u{1213}\
	\x05\u{328}\u{195}\x02\u{1213}\u{1214}\x07\u{184}\x02\x02\u{1214}\u{30d}\
	\x03\x02\x02\x02\u{1215}\u{1216}\x09\x22\x02\x02\u{1216}\u{30f}\x03\x02\
	\x02\x02\u{1217}\u{1225}\x05\u{322}\u{192}\x02\u{1218}\u{1225}\x07\u{1a2}\
	\x02\x02\u{1219}\u{1225}\x05\u{31a}\u{18e}\x02\u{121a}\u{1225}\x05\u{31c}\
	\u{18f}\x02\u{121b}\u{1225}\x05\u{31e}\u{190}\x02\u{121c}\u{1225}\x07\u{19d}\
	\x02\x02\u{121d}\u{1225}\x05\u{316}\u{18c}\x02\u{121e}\u{1225}\x07\u{19f}\
	\x02\x02\u{121f}\u{1225}\x07\u{1a0}\x02\x02\u{1220}\u{1225}\x05\u{318}\u{18d}\
	\x02\u{1221}\u{1225}\x05\u{376}\u{1bc}\x02\u{1222}\u{1225}\x07\u{d2}\x02\
	\x02\u{1223}\u{1225}\x05\u{312}\u{18a}\x02\u{1224}\u{1217}\x03\x02\x02\x02\
	\u{1224}\u{1218}\x03\x02\x02\x02\u{1224}\u{1219}\x03\x02\x02\x02\u{1224}\
	\u{121a}\x03\x02\x02\x02\u{1224}\u{121b}\x03\x02\x02\x02\u{1224}\u{121c}\
	\x03\x02\x02\x02\u{1224}\u{121d}\x03\x02\x02\x02\u{1224}\u{121e}\x03\x02\
	\x02\x02\u{1224}\u{121f}\x03\x02\x02\x02\u{1224}\u{1220}\x03\x02\x02\x02\
	\u{1224}\u{1221}\x03\x02\x02\x02\u{1224}\u{1222}\x03\x02\x02\x02\u{1224}\
	\u{1223}\x03\x02\x02\x02\u{1225}\u{311}\x03\x02\x02\x02\u{1226}\u{1227}\
	\x05\u{314}\u{18b}\x02\u{1227}\u{313}\x03\x02\x02\x02\u{1228}\u{1229}\x07\
	\u{19b}\x02\x02\u{1229}\u{315}\x03\x02\x02\x02\u{122a}\u{122c}\x07\u{19d}\
	\x02\x02\u{122b}\u{122d}\x07\u{19d}\x02\x02\u{122c}\u{122b}\x03\x02\x02\
	\x02\u{122d}\u{122e}\x03\x02\x02\x02\u{122e}\u{122c}\x03\x02\x02\x02\u{122e}\
	\u{122f}\x03\x02\x02\x02\u{122f}\u{317}\x03\x02\x02\x02\u{1230}\u{1231}\
	\x07\u{1a4}\x02\x02\u{1231}\u{1232}\x07\u{19e}\x02\x02\u{1232}\u{319}\x03\
	\x02\x02\x02\u{1233}\u{1234}\x07\x49\x02\x02\u{1234}\u{1237}\x07\u{19d}\
	\x02\x02\u{1235}\u{1237}\x07\x41\x02\x02\u{1236}\u{1233}\x03\x02\x02\x02\
	\u{1236}\u{1235}\x03\x02\x02\x02\u{1237}\u{31b}\x03\x02\x02\x02\u{1238}\
	\u{1239}\x07\u{147}\x02\x02\u{1239}\u{123c}\x07\u{19d}\x02\x02\u{123a}\u{123c}\
	\x07\x42\x02\x02\u{123b}\u{1238}\x03\x02\x02\x02\u{123b}\u{123a}\x03\x02\
	\x02\x02\u{123c}\u{31d}\x03\x02\x02\x02\u{123d}\u{123e}\x07\u{148}\x02\x02\
	\u{123e}\u{123f}\x07\u{19d}\x02\x02\u{123f}\u{31f}\x03\x02\x02\x02\u{1240}\
	\u{1241}\x09\x1b\x02\x02\u{1241}\u{321}\x03\x02\x02\x02\u{1242}\u{1243}\
	\x05\u{320}\u{191}\x02\u{1243}\u{1244}\x05\u{326}\u{194}\x02\u{1244}\u{323}\
	\x03\x02\x02\x02\u{1245}\u{1246}\x07\u{183}\x02\x02\u{1246}\u{1247}\x05\
	\u{320}\u{191}\x02\u{1247}\u{1248}\x07\u{184}\x02\x02\u{1248}\u{1249}\x05\
	\u{326}\u{194}\x02\u{1249}\u{1255}\x03\x02\x02\x02\u{124a}\u{1250}\x07\u{9f}\
	\x02\x02\u{124b}\u{1251}\x05\u{320}\u{191}\x02\u{124c}\u{124d}\x07\u{183}\
	\x02\x02\u{124d}\u{124e}\x05\u{328}\u{195}\x02\u{124e}\u{124f}\x07\u{184}\
	\x02\x02\u{124f}\u{1251}\x03\x02\x02\x02\u{1250}\u{124b}\x03\x02\x02\x02\
	\u{1250}\u{124c}\x03\x02\x02\x02\u{1251}\u{1252}\x03\x02\x02\x02\u{1252}\
	\u{1253}\x05\u{326}\u{194}\x02\u{1253}\u{1255}\x03\x02\x02\x02\u{1254}\u{1245}\
	\x03\x02\x02\x02\u{1254}\u{124a}\x03\x02\x02\x02\u{1255}\u{325}\x03\x02\
	\x02\x02\u{1256}\u{1257}\x07\u{17d}\x02\x02\u{1257}\u{1258}\x07\u{14b}\x02\
	\x02\u{1258}\u{1263}\x07\u{c8}\x02\x02\u{1259}\u{125a}\x07\x4b\x02\x02\u{125a}\
	\u{125b}\x07\u{14b}\x02\x02\u{125b}\u{1263}\x07\u{120}\x02\x02\u{125c}\u{1263}\
	\x07\u{17d}\x02\x02\u{125d}\u{1263}\x07\u{c8}\x02\x02\u{125e}\u{1263}\x07\
	\x4b\x02\x02\u{125f}\u{1263}\x07\u{90}\x02\x02\u{1260}\u{1263}\x07\u{c7}\
	\x02\x02\u{1261}\u{1263}\x07\u{120}\x02\x02\u{1262}\u{1256}\x03\x02\x02\
	\x02\u{1262}\u{1259}\x03\x02\x02\x02\u{1262}\u{125c}\x03\x02\x02\x02\u{1262}\
	\u{125d}\x03\x02\x02\x02\u{1262}\u{125e}\x03\x02\x02\x02\u{1262}\u{125f}\
	\x03\x02\x02\x02\u{1262}\u{1260}\x03\x02\x02\x02\u{1262}\u{1261}\x03\x02\
	\x02\x02\u{1263}\u{327}\x03\x02\x02\x02\u{1264}\u{1265}\x05\u{374}\u{1bb}\
	\x02\u{1265}\u{329}\x03\x02\x02\x02\u{1266}\u{1272}\x05\u{310}\u{189}\x02\
	\u{1267}\u{1272}\x05\u{324}\u{193}\x02\u{1268}\u{1272}\x05\u{302}\u{182}\
	\x02\u{1269}\u{1272}\x05\u{30c}\u{187}\x02\u{126a}\u{1272}\x05\u{308}\u{185}\
	\x02\u{126b}\u{1272}\x05\u{304}\u{183}\x02\u{126c}\u{1272}\x05\u{306}\u{184}\
	\x02\u{126d}\u{1272}\x05\u{34e}\u{1a8}\x02\u{126e}\u{1272}\x05\u{2fc}\u{17f}\
	\x02\u{126f}\u{1272}\x05\u{262}\u{132}\x02\u{1270}\u{1272}\x05\u{2de}\u{170}\
	\x02\u{1271}\u{1266}\x03\x02\x02\x02\u{1271}\u{1267}\x03\x02\x02\x02\u{1271}\
	\u{1268}\x03\x02\x02\x02\u{1271}\u{1269}\x03\x02\x02\x02\u{1271}\u{126a}\
	\x03\x02\x02\x02\u{1271}\u{126b}\x03\x02\x02\x02\u{1271}\u{126c}\x03\x02\
	\x02\x02\u{1271}\u{126d}\x03\x02\x02\x02\u{1271}\u{126e}\x03\x02\x02\x02\
	\u{1271}\u{126f}\x03\x02\x02\x02\u{1271}\u{1270}\x03\x02\x02\x02\u{1272}\
	\u{32b}\x03\x02\x02\x02\u{1273}\u{127c}\x05\u{32a}\u{196}\x02\u{1274}\u{1275}\
	\x07\u{185}\x02\x02\u{1275}\u{1276}\x05\u{328}\u{195}\x02\u{1276}\u{1277}\
	\x07\u{186}\x02\x02\u{1277}\u{127b}\x03\x02\x02\x02\u{1278}\u{1279}\x07\
	\u{17f}\x02\x02\u{1279}\u{127b}\x05\u{38c}\u{1c7}\x02\u{127a}\u{1274}\x03\
	\x02\x02\x02\u{127a}\u{1278}\x03\x02\x02\x02\u{127b}\u{127e}\x03\x02\x02\
	\x02\u{127c}\u{127a}\x03\x02\x02\x02\u{127c}\u{127d}\x03\x02\x02\x02\u{127d}\
	\u{32d}\x03\x02\x02\x02\u{127e}\u{127c}\x03\x02\x02\x02\u{127f}\u{1280}\
	\x09\x23\x02\x02\u{1280}\u{32f}\x03\x02\x02\x02\u{1281}\u{1283}\x05\u{32e}\
	\u{198}\x02\u{1282}\u{1281}\x03\x02\x02\x02\u{1283}\u{1286}\x03\x02\x02\
	\x02\u{1284}\u{1282}\x03\x02\x02\x02\u{1284}\u{1285}\x03\x02\x02\x02\u{1285}\
	\u{1287}\x03\x02\x02\x02\u{1286}\u{1284}\x03\x02\x02\x02\u{1287}\u{1288}\
	\x05\u{32c}\u{197}\x02\u{1288}\u{331}\x03\x02\x02\x02\u{1289}\u{128a}\x07\
	\u{19a}\x02\x02\u{128a}\u{333}\x03\x02\x02\x02\u{128b}\u{1291}\x05\u{330}\
	\u{199}\x02\u{128c}\u{128d}\x05\u{332}\u{19a}\x02\u{128d}\u{128e}\x05\u{330}\
	\u{199}\x02\u{128e}\u{1290}\x03\x02\x02\x02\u{128f}\u{128c}\x03\x02\x02\
	\x02\u{1290}\u{1293}\x03\x02\x02\x02\u{1291}\u{128f}\x03\x02\x02\x02\u{1291}\
	\u{1292}\x03\x02\x02\x02\u{1292}\u{335}\x03\x02\x02\x02\u{1293}\u{1291}\
	\x03\x02\x02\x02\u{1294}\u{1295}\x09\x24\x02\x02\u{1295}\u{337}\x03\x02\
	\x02\x02\u{1296}\u{129c}\x05\u{334}\u{19b}\x02\u{1297}\u{1298}\x05\u{336}\
	\u{19c}\x02\u{1298}\u{1299}\x05\u{334}\u{19b}\x02\u{1299}\u{129b}\x03\x02\
	\x02\x02\u{129a}\u{1297}\x03\x02\x02\x02\u{129b}\u{129e}\x03\x02\x02\x02\
	\u{129c}\u{129a}\x03\x02\x02\x02\u{129c}\u{129d}\x03\x02\x02\x02\u{129d}\
	\u{339}\x03\x02\x02\x02\u{129e}\u{129c}\x03\x02\x02\x02\u{129f}\u{12a0}\
	\x09\x25\x02\x02\u{12a0}\u{33b}\x03\x02\x02\x02\u{12a1}\u{12a7}\x05\u{338}\
	\u{19d}\x02\u{12a2}\u{12a3}\x05\u{33a}\u{19e}\x02\u{12a3}\u{12a4}\x05\u{338}\
	\u{19d}\x02\u{12a4}\u{12a6}\x03\x02\x02\x02\u{12a5}\u{12a2}\x03\x02\x02\
	\x02\u{12a6}\u{12a9}\x03\x02\x02\x02\u{12a7}\u{12a5}\x03\x02\x02\x02\u{12a7}\
	\u{12a8}\x03\x02\x02\x02\u{12a8}\u{33d}\x03\x02\x02\x02\u{12a9}\u{12a7}\
	\x03\x02\x02\x02\u{12aa}\u{12ab}\x07\u{199}\x02\x02\u{12ab}\u{33f}\x03\x02\
	\x02\x02\u{12ac}\u{12b2}\x05\u{33c}\u{19f}\x02\u{12ad}\u{12ae}\x05\u{33e}\
	\u{1a0}\x02\u{12ae}\u{12af}\x05\u{33c}\u{19f}\x02\u{12af}\u{12b1}\x03\x02\
	\x02\x02\u{12b0}\u{12ad}\x03\x02\x02\x02\u{12b1}\u{12b4}\x03\x02\x02\x02\
	\u{12b2}\u{12b0}\x03\x02\x02\x02\u{12b2}\u{12b3}\x03\x02\x02\x02\u{12b3}\
	\u{341}\x03\x02\x02\x02\u{12b4}\u{12b2}\x03\x02\x02\x02\u{12b5}\u{12b6}\
	\x07\u{196}\x02\x02\u{12b6}\u{343}\x03\x02\x02\x02\u{12b7}\u{12bd}\x05\u{340}\
	\u{1a1}\x02\u{12b8}\u{12b9}\x05\u{342}\u{1a2}\x02\u{12b9}\u{12ba}\x05\u{340}\
	\u{1a1}\x02\u{12ba}\u{12bc}\x03\x02\x02\x02\u{12bb}\u{12b8}\x03\x02\x02\
	\x02\u{12bc}\u{12bf}\x03\x02\x02\x02\u{12bd}\u{12bb}\x03\x02\x02\x02\u{12bd}\
	\u{12be}\x03\x02\x02\x02\u{12be}\u{345}\x03\x02\x02\x02\u{12bf}\u{12bd}\
	\x03\x02\x02\x02\u{12c0}\u{12c1}\x07\u{198}\x02\x02\u{12c1}\u{347}\x03\x02\
	\x02\x02\u{12c2}\u{12c8}\x05\u{344}\u{1a3}\x02\u{12c3}\u{12c4}\x05\u{346}\
	\u{1a4}\x02\u{12c4}\u{12c5}\x05\u{344}\u{1a3}\x02\u{12c5}\u{12c7}\x03\x02\
	\x02\x02\u{12c6}\u{12c3}\x03\x02\x02\x02\u{12c7}\u{12ca}\x03\x02\x02\x02\
	\u{12c8}\u{12c6}\x03\x02\x02\x02\u{12c8}\u{12c9}\x03\x02\x02\x02\u{12c9}\
	\u{349}\x03\x02\x02\x02\u{12ca}\u{12c8}\x03\x02\x02\x02\u{12cb}\u{12cc}\
	\x09\x26\x02\x02\u{12cc}\u{34b}\x03\x02\x02\x02\u{12cd}\u{12d3}\x05\u{34a}\
	\u{1a6}\x02\u{12ce}\u{12d3}\x07\u{18c}\x02\x02\u{12cf}\u{12d3}\x07\u{18d}\
	\x02\x02\u{12d0}\u{12d3}\x07\u{18e}\x02\x02\u{12d1}\u{12d3}\x07\u{18f}\x02\
	\x02\u{12d2}\u{12cd}\x03\x02\x02\x02\u{12d2}\u{12ce}\x03\x02\x02\x02\u{12d2}\
	\u{12cf}\x03\x02\x02\x02\u{12d2}\u{12d0}\x03\x02\x02\x02\u{12d2}\u{12d1}\
	\x03\x02\x02\x02\u{12d3}\u{34d}\x03\x02\x02\x02\u{12d4}\u{12d5}\x07\u{183}\
	\x02\x02\u{12d5}\u{12d6}\x05\u{196}\u{cc}\x02\u{12d6}\u{12d7}\x07\u{184}\
	\x02\x02\u{12d7}\u{34f}\x03\x02\x02\x02\u{12d8}\u{12dc}\x05\u{352}\u{1aa}\
	\x02\u{12d9}\u{12da}\x07\x71\x02\x02\u{12da}\u{12dc}\x05\u{34e}\u{1a8}\x02\
	\u{12db}\u{12d8}\x03\x02\x02\x02\u{12db}\u{12d9}\x03\x02\x02\x02\u{12dc}\
	\u{351}\x03\x02\x02\x02\u{12dd}\u{12df}\x05\u{348}\u{1a5}\x02\u{12de}\u{12e0}\
	\x05\u{354}\u{1ab}\x02\u{12df}\u{12de}\x03\x02\x02\x02\u{12df}\u{12e0}\x03\
	\x02\x02\x02\u{12e0}\u{353}\x03\x02\x02\x02\u{12e1}\u{12e2}\x05\u{34c}\u{1a7}\
	\x02\u{12e2}\u{12e3}\x05\u{348}\u{1a5}\x02\u{12e3}\u{12e8}\x03\x02\x02\x02\
	\u{12e4}\u{12e8}\x05\u{356}\u{1ac}\x02\u{12e5}\u{12e6}\x07\u{cf}\x02\x02\
	\u{12e6}\u{12e8}\x05\u{35e}\u{1b0}\x02\u{12e7}\u{12e1}\x03\x02\x02\x02\u{12e7}\
	\u{12e4}\x03\x02\x02\x02\u{12e7}\u{12e5}\x03\x02\x02\x02\u{12e8}\u{355}\
	\x03\x02\x02\x02\u{12e9}\u{12ea}\x07\u{95}\x02\x02\u{12ea}\u{12f5}\x05\u{35c}\
	\u{1af}\x02\u{12eb}\u{12ec}\x07\x1b\x02\x02\u{12ec}\u{12ed}\x05\u{348}\u{1a5}\
	\x02\u{12ed}\u{12ee}\x07\x0d\x02\x02\u{12ee}\u{12ef}\x05\u{348}\u{1a5}\x02\
	\u{12ef}\u{12f5}\x03\x02\x02\x02\u{12f0}\u{12f1}\x07\u{b1}\x02\x02\u{12f1}\
	\u{12f2}\x09\x27\x02\x02\u{12f2}\u{12f5}\x05\u{2de}\u{170}\x02\u{12f3}\u{12f5}\
	\x05\u{358}\u{1ad}\x02\u{12f4}\u{12e9}\x03\x02\x02\x02\u{12f4}\u{12eb}\x03\
	\x02\x02\x02\u{12f4}\u{12f0}\x03\x02\x02\x02\u{12f4}\u{12f3}\x03\x02\x02\
	\x02\u{12f5}\u{357}\x03\x02\x02\x02\u{12f6}\u{12f7}\x05\u{386}\u{1c4}\x02\
	\u{12f7}\u{12f8}\x05\u{35a}\u{1ae}\x02\u{12f8}\u{12f9}\x05\u{34e}\u{1a8}\
	\x02\u{12f9}\u{359}\x03\x02\x02\x02\u{12fa}\u{12fb}\x09\x28\x02\x02\u{12fb}\
	\u{35b}\x03\x02\x02\x02\u{12fc}\u{12ff}\x05\u{34e}\u{1a8}\x02\u{12fd}\u{12ff}\
	\x05\u{2de}\u{170}\x02\u{12fe}\u{12fc}\x03\x02\x02\x02\u{12fe}\u{12fd}\x03\
	\x02\x02\x02\u{12ff}\u{35d}\x03\x02\x02\x02\u{1300}\u{1301}\x05\u{34a}\u{1a6}\
	\x02\u{1301}\u{1302}\x05\u{348}\u{1a5}\x02\u{1302}\u{1305}\x03\x02\x02\x02\
	\u{1303}\u{1305}\x05\u{356}\u{1ac}\x02\u{1304}\u{1300}\x03\x02\x02\x02\u{1304}\
	\u{1303}\x03\x02\x02\x02\u{1305}\u{35f}\x03\x02\x02\x02\u{1306}\u{1307}\
	\x07\u{a1}\x02\x02\u{1307}\u{1308}\x07\x5e\x02\x02\u{1308}\u{1309}\x07\u{87}\
	\x02\x02\u{1309}\u{361}\x03\x02\x02\x02\u{130a}\u{1312}\x07\u{189}\x02\x02\
	\u{130b}\u{1312}\x07\u{18a}\x02\x02\u{130c}\u{1312}\x07\u{18b}\x02\x02\u{130d}\
	\u{130e}\x07\u{a1}\x02\x02\u{130e}\u{130f}\x07\u{cf}\x02\x02\u{130f}\u{1310}\
	\x07\x5e\x02\x02\u{1310}\u{1312}\x07\u{87}\x02\x02\u{1311}\u{130a}\x03\x02\
	\x02\x02\u{1311}\u{130b}\x03\x02\x02\x02\u{1311}\u{130c}\x03\x02\x02\x02\
	\u{1311}\u{130d}\x03\x02\x02\x02\u{1312}\u{363}\x03\x02\x02\x02\u{1313}\
	\u{131c}\x05\u{350}\u{1a9}\x02\u{1314}\u{1315}\x05\u{362}\u{1b2}\x02\u{1315}\
	\u{1316}\x05\u{350}\u{1a9}\x02\u{1316}\u{131b}\x03\x02\x02\x02\u{1317}\u{1318}\
	\x05\u{360}\u{1b1}\x02\u{1318}\u{1319}\x05\u{350}\u{1a9}\x02\u{1319}\u{131b}\
	\x03\x02\x02\x02\u{131a}\u{1314}\x03\x02\x02\x02\u{131a}\u{1317}\x03\x02\
	\x02\x02\u{131b}\u{131e}\x03\x02\x02\x02\u{131c}\u{131a}\x03\x02\x02\x02\
	\u{131c}\u{131d}\x03\x02\x02\x02\u{131d}\u{365}\x03\x02\x02\x02\u{131e}\
	\u{131c}\x03\x02\x02\x02\u{131f}\u{132c}\x07\u{d2}\x02\x02\u{1320}\u{132c}\
	\x07\u{154}\x02\x02\u{1321}\u{132c}\x07\x79\x02\x02\u{1322}\u{132c}\x07\
	\u{15e}\x02\x02\u{1323}\u{1324}\x07\u{cf}\x02\x02\u{1324}\u{132c}\x07\u{d2}\
	\x02\x02\u{1325}\u{1326}\x07\u{cf}\x02\x02\u{1326}\u{132c}\x07\u{154}\x02\
	\x02\u{1327}\u{1328}\x07\u{cf}\x02\x02\u{1328}\u{132c}\x07\x79\x02\x02\u{1329}\
	\u{132a}\x07\u{cf}\x02\x02\u{132a}\u{132c}\x07\u{15e}\x02\x02\u{132b}\u{131f}\
	\x03\x02\x02\x02\u{132b}\u{1320}\x03\x02\x02\x02\u{132b}\u{1321}\x03\x02\
	\x02\x02\u{132b}\u{1322}\x03\x02\x02\x02\u{132b}\u{1323}\x03\x02\x02\x02\
	\u{132b}\u{1325}\x03\x02\x02\x02\u{132b}\u{1327}\x03\x02\x02\x02\u{132b}\
	\u{1329}\x03\x02\x02\x02\u{132c}\u{367}\x03\x02\x02\x02\u{132d}\u{1330}\
	\x05\u{364}\u{1b3}\x02\u{132e}\u{132f}\x07\u{a1}\x02\x02\u{132f}\u{1331}\
	\x05\u{366}\u{1b4}\x02\u{1330}\u{132e}\x03\x02\x02\x02\u{1330}\u{1331}\x03\
	\x02\x02\x02\u{1331}\u{369}\x03\x02\x02\x02\u{1332}\u{1333}\x07\u{cf}\x02\
	\x02\u{1333}\u{36b}\x03\x02\x02\x02\u{1334}\u{1336}\x05\u{36a}\u{1b6}\x02\
	\u{1335}\u{1334}\x03\x02\x02\x02\u{1336}\u{1339}\x03\x02\x02\x02\u{1337}\
	\u{1335}\x03\x02\x02\x02\u{1337}\u{1338}\x03\x02\x02\x02\u{1338}\u{133a}\
	\x03\x02\x02\x02\u{1339}\u{1337}\x03\x02\x02\x02\u{133a}\u{133b}\x05\u{368}\
	\u{1b5}\x02\u{133b}\u{36d}\x03\x02\x02\x02\u{133c}\u{133d}\x07\x0d\x02\x02\
	\u{133d}\u{36f}\x03\x02\x02\x02\u{133e}\u{1344}\x05\u{36c}\u{1b7}\x02\u{133f}\
	\u{1340}\x05\u{36e}\u{1b8}\x02\u{1340}\u{1341}\x05\u{36c}\u{1b7}\x02\u{1341}\
	\u{1343}\x03\x02\x02\x02\u{1342}\u{133f}\x03\x02\x02\x02\u{1343}\u{1346}\
	\x03\x02\x02\x02\u{1344}\u{1342}\x03\x02\x02\x02\u{1344}\u{1345}\x03\x02\
	\x02\x02\u{1345}\u{371}\x03\x02\x02\x02\u{1346}\u{1344}\x03\x02\x02\x02\
	\u{1347}\u{1348}\x07\u{db}\x02\x02\u{1348}\u{373}\x03\x02\x02\x02\u{1349}\
	\u{134f}\x05\u{370}\u{1b9}\x02\u{134a}\u{134b}\x05\u{372}\u{1ba}\x02\u{134b}\
	\u{134c}\x05\u{370}\u{1b9}\x02\u{134c}\u{134e}\x03\x02\x02\x02\u{134d}\u{134a}\
	\x03\x02\x02\x02\u{134e}\u{1351}\x03\x02\x02\x02\u{134f}\u{134d}\x03\x02\
	\x02\x02\u{134f}\u{1350}\x03\x02\x02\x02\u{1350}\u{375}\x03\x02\x02\x02\
	\u{1351}\u{134f}\x03\x02\x02\x02\u{1352}\u{1353}\x09\x29\x02\x02\u{1353}\
	\u{377}\x03\x02\x02\x02\u{1354}\u{1355}\x09\x29\x02\x02\u{1355}\u{379}\x03\
	\x02\x02\x02\u{1356}\u{1358}\x05\u{28c}\u{147}\x02\u{1357}\u{1359}\x05\u{37c}\
	\u{1bf}\x02\u{1358}\u{1357}\x03\x02\x02\x02\u{1358}\u{1359}\x03\x02\x02\
	\x02\u{1359}\u{37b}\x03\x02\x02\x02\u{135a}\u{135b}\x07\u{e4}\x02\x02\u{135b}\
	\u{135c}\x07\u{183}\x02\x02\u{135c}\u{1361}\x05\u{37e}\u{1c0}\x02\u{135d}\
	\u{135e}\x07\u{181}\x02\x02\u{135e}\u{1360}\x05\u{37e}\u{1c0}\x02\u{135f}\
	\u{135d}\x03\x02\x02\x02\u{1360}\u{1363}\x03\x02\x02\x02\u{1361}\u{135f}\
	\x03\x02\x02\x02\u{1361}\u{1362}\x03\x02\x02\x02\u{1362}\u{1364}\x03\x02\
	\x02\x02\u{1363}\u{1361}\x03\x02\x02\x02\u{1364}\u{1365}\x07\u{184}\x02\
	\x02\u{1365}\u{37d}\x03\x02\x02\x02\u{1366}\u{1369}\x05\u{38c}\u{1c7}\x02\
	\u{1367}\u{1368}\x07\u{189}\x02\x02\u{1368}\u{136a}\x05\u{310}\u{189}\x02\
	\u{1369}\u{1367}\x03\x02\x02\x02\u{1369}\u{136a}\x03\x02\x02\x02\u{136a}\
	\u{37f}\x03\x02\x02\x02\u{136b}\u{136c}\x07\u{183}\x02\x02\u{136c}\u{1371}\
	\x05\u{382}\u{1c2}\x02\u{136d}\u{136e}\x07\u{181}\x02\x02\u{136e}\u{1370}\
	\x05\u{382}\u{1c2}\x02\u{136f}\u{136d}\x03\x02\x02\x02\u{1370}\u{1373}\x03\
	\x02\x02\x02\u{1371}\u{136f}\x03\x02\x02\x02\u{1371}\u{1372}\x03\x02\x02\
	\x02\u{1372}\u{1374}\x03\x02\x02\x02\u{1373}\u{1371}\x03\x02\x02\x02\u{1374}\
	\u{1375}\x07\u{184}\x02\x02\u{1375}\u{381}\x03\x02\x02\x02\u{1376}\u{1377}\
	\x05\u{38c}\u{1c7}\x02\u{1377}\u{1378}\x05\u{384}\u{1c3}\x02\u{1378}\u{1379}\
	\x05\u{310}\u{189}\x02\u{1379}\u{383}\x03\x02\x02\x02\u{137a}\u{137d}\x07\
	\u{b1}\x02\x02\u{137b}\u{137d}\x05\u{386}\u{1c4}\x02\u{137c}\u{137a}\x03\
	\x02\x02\x02\u{137c}\u{137b}\x03\x02\x02\x02\u{137d}\u{385}\x03\x02\x02\
	\x02\u{137e}\u{137f}\x09\x2a\x02\x02\u{137f}\u{387}\x03\x02\x02\x02\u{1380}\
	\u{1381}\x09\x2b\x02\x02\u{1381}\u{389}\x03\x02\x02\x02\u{1382}\u{1386}\
	\x05\u{388}\u{1c5}\x02\u{1383}\u{1386}\x07\u{19d}\x02\x02\u{1384}\u{1386}\
	\x05\u{38e}\u{1c8}\x02\u{1385}\u{1382}\x03\x02\x02\x02\u{1385}\u{1383}\x03\
	\x02\x02\x02\u{1385}\u{1384}\x03\x02\x02\x02\u{1386}\u{38b}\x03\x02\x02\
	\x02\u{1387}\u{138a}\x07\u{1a3}\x02\x02\u{1388}\u{138a}\x05\u{392}\u{1ca}\
	\x02\u{1389}\u{1387}\x03\x02\x02\x02\u{1389}\u{1388}\x03\x02\x02\x02\u{138a}\
	\u{38d}\x03\x02\x02\x02\u{138b}\u{138e}\x05\u{38c}\u{1c7}\x02\u{138c}\u{138d}\
	\x07\u{17f}\x02\x02\u{138d}\u{138f}\x05\u{38c}\u{1c7}\x02\u{138e}\u{138c}\
	\x03\x02\x02\x02\u{138e}\u{138f}\x03\x02\x02\x02\u{138f}\u{38f}\x03\x02\
	\x02\x02\u{1390}\u{1391}\x05\u{38c}\u{1c7}\x02\u{1391}\u{391}\x03\x02\x02\
	\x02\u{1392}\u{1393}\x09\x2c\x02\x02\u{1393}\u{393}\x03\x02\x02\x02\u{1394}\
	\u{1395}\x09\x2d\x02\x02\u{1395}\u{395}\x03\x02\x02\x02\u{1396}\u{1397}\
	\x05\u{398}\u{1cd}\x02\u{1397}\u{1398}\x07\x02\x02\x03\u{1398}\u{397}\x03\
	\x02\x02\x02\u{1399}\u{139e}\x05\u{39a}\u{1ce}\x02\u{139a}\u{139b}\x07\u{181}\
	\x02\x02\u{139b}\u{139d}\x05\u{39a}\u{1ce}\x02\u{139c}\u{139a}\x03\x02\x02\
	\x02\u{139d}\u{13a0}\x03\x02\x02\x02\u{139e}\u{139c}\x03\x02\x02\x02\u{139e}\
	\u{139f}\x03\x02\x02\x02\u{139f}\u{399}\x03\x02\x02\x02\u{13a0}\u{139e}\
	\x03\x02\x02\x02\u{13a1}\u{13a6}\x05\u{39c}\u{1cf}\x02\u{13a2}\u{13a3}\x07\
	\u{183}\x02\x02\u{13a3}\u{13a4}\x05\u{39e}\u{1d0}\x02\u{13a4}\u{13a5}\x07\
	\u{184}\x02\x02\u{13a5}\u{13a7}\x03\x02\x02\x02\u{13a6}\u{13a2}\x03\x02\
	\x02\x02\u{13a6}\u{13a7}\x03\x02\x02\x02\u{13a7}\u{39b}\x03\x02\x02\x02\
	\u{13a8}\u{13a9}\x09\x2e\x02\x02\u{13a9}\u{39d}\x03\x02\x02\x02\u{13aa}\
	\u{13af}\x05\u{3a0}\u{1d1}\x02\u{13ab}\u{13ac}\x07\u{181}\x02\x02\u{13ac}\
	\u{13ae}\x05\u{3a0}\u{1d1}\x02\u{13ad}\u{13ab}\x03\x02\x02\x02\u{13ae}\u{13b1}\
	\x03\x02\x02\x02\u{13af}\u{13ad}\x03\x02\x02\x02\u{13af}\u{13b0}\x03\x02\
	\x02\x02\u{13b0}\u{39f}\x03\x02\x02\x02\u{13b1}\u{13af}\x03\x02\x02\x02\
	\u{13b2}\u{13b3}\x09\x2f\x02\x02\u{13b3}\u{3a1}\x03\x02\x02\x02\u{13b4}\
	\u{13b5}\x07\u{f0}\x02\x02\u{13b5}\u{13b6}\x05\u{38c}\u{1c7}\x02\u{13b6}\
	\u{13b7}\x07\u{87}\x02\x02\u{13b7}\u{13b8}\x05\u{186}\u{c4}\x02\u{13b8}\
	\u{3a3}\x03\x02\x02\x02\u{13b9}\u{13ba}\x07\x6f\x02\x02\u{13ba}\u{13bb}\
	\x05\u{38c}\u{1c7}\x02\u{13bb}\u{13bc}\x07\u{168}\x02\x02\u{13bc}\u{13bd}\
	\x05\u{3a6}\u{1d4}\x02\u{13bd}\u{3a5}\x03\x02\x02\x02\u{13be}\u{13c3}\x05\
	\u{310}\u{189}\x02\u{13bf}\u{13c0}\x07\u{181}\x02\x02\u{13c0}\u{13c2}\x05\
	\u{310}\u{189}\x02\u{13c1}\u{13bf}\x03\x02\x02\x02\u{13c2}\u{13c5}\x03\x02\
	\x02\x02\u{13c3}\u{13c1}\x03\x02\x02\x02\u{13c3}\u{13c4}\x03\x02\x02\x02\
	\u{13c4}\u{3a7}\x03\x02\x02\x02\u{13c5}\u{13c3}\x03\x02\x02\x02\u{13c6}\
	\u{13d5}\x05\u{3b2}\u{1da}\x02\u{13c7}\u{13d5}\x05\u{3be}\u{1e0}\x02\u{13c8}\
	\u{13d5}\x05\u{3c4}\u{1e3}\x02\u{13c9}\u{13d5}\x05\u{3c0}\u{1e1}\x02\u{13ca}\
	\u{13d5}\x05\u{3c2}\u{1e2}\x02\u{13cb}\u{13d5}\x05\u{3da}\u{1ee}\x02\u{13cc}\
	\u{13d5}\x05\u{3dc}\u{1ef}\x02\u{13cd}\u{13d5}\x05\u{3de}\u{1f0}\x02\u{13ce}\
	\u{13d5}\x05\u{3e4}\u{1f3}\x02\u{13cf}\u{13d5}\x05\u{3e6}\u{1f4}\x02\u{13d0}\
	\u{13d5}\x05\u{3e8}\u{1f5}\x02\u{13d1}\u{13d5}\x05\u{3ea}\u{1f6}\x02\u{13d2}\
	\u{13d5}\x05\u{3ec}\u{1f7}\x02\u{13d3}\u{13d5}\x05\u{3ee}\u{1f8}\x02\u{13d4}\
	\u{13c6}\x03\x02\x02\x02\u{13d4}\u{13c7}\x03\x02\x02\x02\u{13d4}\u{13c8}\
	\x03\x02\x02\x02\u{13d4}\u{13c9}\x03\x02\x02\x02\u{13d4}\u{13ca}\x03\x02\
	\x02\x02\u{13d4}\u{13cb}\x03\x02\x02\x02\u{13d4}\u{13cc}\x03\x02\x02\x02\
	\u{13d4}\u{13cd}\x03\x02\x02\x02\u{13d4}\u{13ce}\x03\x02\x02\x02\u{13d4}\
	\u{13cf}\x03\x02\x02\x02\u{13d4}\u{13d0}\x03\x02\x02\x02\u{13d4}\u{13d1}\
	\x03\x02\x02\x02\u{13d4}\u{13d2}\x03\x02\x02\x02\u{13d4}\u{13d3}\x03\x02\
	\x02\x02\u{13d5}\u{3a9}\x03\x02\x02\x02\u{13d6}\u{13d7}\x07\u{fa}\x02\x02\
	\u{13d7}\u{13d8}\x07\u{189}\x02\x02\u{13d8}\u{13de}\x07\u{1a2}\x02\x02\u{13d9}\
	\u{13da}\x07\x52\x02\x02\u{13da}\u{13db}\x07\u{ed}\x02\x02\u{13db}\u{13dc}\
	\x07\u{189}\x02\x02\u{13dc}\u{13de}\x05\u{3c6}\u{1e4}\x02\u{13dd}\u{13d6}\
	\x03\x02\x02\x02\u{13dd}\u{13d9}\x03\x02\x02\x02\u{13de}\u{3ab}\x03\x02\
	\x02\x02\u{13df}\u{13e4}\x05\u{3aa}\u{1d6}\x02\u{13e0}\u{13e1}\x07\u{181}\
	\x02\x02\u{13e1}\u{13e3}\x05\u{3aa}\u{1d6}\x02\u{13e2}\u{13e0}\x03\x02\x02\
	\x02\u{13e3}\u{13e6}\x03\x02\x02\x02\u{13e4}\u{13e2}\x03\x02\x02\x02\u{13e4}\
	\u{13e5}\x03\x02\x02\x02\u{13e5}\u{3ad}\x03\x02\x02\x02\u{13e6}\u{13e4}\
	\x03\x02\x02\x02\u{13e7}\u{13eb}\x07\u{fa}\x02\x02\u{13e8}\u{13e9}\x07\x52\
	\x02\x02\u{13e9}\u{13eb}\x07\u{ed}\x02\x02\u{13ea}\u{13e7}\x03\x02\x02\x02\
	\u{13ea}\u{13e8}\x03\x02\x02\x02\u{13eb}\u{3af}\x03\x02\x02\x02\u{13ec}\
	\u{13f1}\x05\u{3ae}\u{1d8}\x02\u{13ed}\u{13ee}\x07\u{181}\x02\x02\u{13ee}\
	\u{13f0}\x05\u{3ae}\u{1d8}\x02\u{13ef}\u{13ed}\x03\x02\x02\x02\u{13f0}\u{13f3}\
	\x03\x02\x02\x02\u{13f1}\u{13ef}\x03\x02\x02\x02\u{13f1}\u{13f2}\x03\x02\
	\x02\x02\u{13f2}\u{3b1}\x03\x02\x02\x02\u{13f3}\u{13f1}\x03\x02\x02\x02\
	\u{13f4}\u{13f5}\x07\x3c\x02\x02\u{13f5}\u{13f6}\x07\u{10f}\x02\x02\u{13f6}\
	\u{13f8}\x07\u{ea}\x02\x02\u{13f7}\u{13f9}\x05\x2c\x17\x02\u{13f8}\u{13f7}\
	\x03\x02\x02\x02\u{13f8}\u{13f9}\x03\x02\x02\x02\u{13f9}\u{1403}\x03\x02\
	\x02\x02\u{13fa}\u{13fb}\x05\u{38c}\u{1c7}\x02\u{13fb}\u{13fc}\x07\u{b1}\
	\x02\x02\u{13fc}\u{13fd}\x05\u{38c}\u{1c7}\x02\u{13fd}\u{1404}\x03\x02\x02\
	\x02\u{13fe}\u{1401}\x05\u{38c}\u{1c7}\x02\u{13ff}\u{1400}\x07\u{178}\x02\
	\x02\u{1400}\u{1402}\x05\u{3ac}\u{1d7}\x02\u{1401}\u{13ff}\x03\x02\x02\x02\
	\u{1401}\u{1402}\x03\x02\x02\x02\u{1402}\u{1404}\x03\x02\x02\x02\u{1403}\
	\u{13fa}\x03\x02\x02\x02\u{1403}\u{13fe}\x03\x02\x02\x02\u{1404}\u{3b3}\
	\x03\x02\x02\x02\u{1405}\u{1406}\x07\u{178}\x02\x02\u{1406}\u{1407}\x07\
	\u{10d}\x02\x02\u{1407}\u{3b5}\x03\x02\x02\x02\u{1408}\u{140a}\x07\x04\x02\
	\x02\u{1409}\u{140b}\x05\u{3b4}\u{1db}\x02\u{140a}\u{1409}\x03\x02\x02\x02\
	\u{140a}\u{140b}\x03\x02\x02\x02\u{140b}\u{3b7}\x03\x02\x02\x02\u{140c}\
	\u{140d}\x07\x67\x02\x02\u{140d}\u{3b9}\x03\x02\x02\x02\u{140e}\u{140f}\
	\x07\x5d\x02\x02\u{140f}\u{3bb}\x03\x02\x02\x02\u{1410}\u{1411}\x07\u{160}\
	\x02\x02\u{1411}\u{3bd}\x03\x02\x02\x02\u{1412}\u{1413}\x07\x0b\x02\x02\
	\u{1413}\u{1414}\x07\u{10f}\x02\x02\u{1414}\u{1415}\x07\u{ea}\x02\x02\u{1415}\
	\u{1427}\x05\u{38c}\u{1c7}\x02\u{1416}\u{1428}\x07\u{16b}\x02\x02\u{1417}\
	\u{1428}\x07\x5d\x02\x02\u{1418}\u{1419}\x07\u{126}\x02\x02\u{1419}\u{1428}\
	\x05\u{3ac}\u{1d7}\x02\u{141a}\u{141b}\x07\u{161}\x02\x02\u{141b}\u{1428}\
	\x05\u{3b0}\u{1d9}\x02\u{141c}\u{141d}\x07\u{109}\x02\x02\u{141d}\u{141e}\
	\x07\u{14b}\x02\x02\u{141e}\u{1428}\x05\u{38c}\u{1c7}\x02\u{141f}\u{1421}\
	\x05\u{3b6}\u{1dc}\x02\u{1420}\u{1422}\x05\u{3b8}\u{1dd}\x02\u{1421}\u{1420}\
	\x03\x02\x02\x02\u{1421}\u{1422}\x03\x02\x02\x02\u{1422}\u{1428}\x03\x02\
	\x02\x02\u{1423}\u{1425}\x05\u{3b8}\u{1dd}\x02\u{1424}\u{1426}\x05\u{3b6}\
	\u{1dc}\x02\u{1425}\u{1424}\x03\x02\x02\x02\u{1425}\u{1426}\x03\x02\x02\
	\x02\u{1426}\u{1428}\x03\x02\x02\x02\u{1427}\u{1416}\x03\x02\x02\x02\u{1427}\
	\u{1417}\x03\x02\x02\x02\u{1427}\u{1418}\x03\x02\x02\x02\u{1427}\u{141a}\
	\x03\x02\x02\x02\u{1427}\u{141c}\x03\x02\x02\x02\u{1427}\u{141f}\x03\x02\
	\x02\x02\u{1427}\u{1423}\x03\x02\x02\x02\u{1428}\u{3bf}\x03\x02\x02\x02\
	\u{1429}\u{142a}\x09\x10\x02\x02\u{142a}\u{142b}\x07\u{17b}\x02\x02\u{142b}\
	\u{142c}\x07\u{be}\x02\x02\u{142c}\u{3c1}\x03\x02\x02\x02\u{142d}\u{1439}\
	\x07\u{10d}\x02\x02\u{142e}\u{142f}\x07\x05\x02\x02\u{142f}\u{1430}\x07\
	\u{10f}\x02\x02\u{1430}\u{1431}\x07\u{ea}\x02\x02\u{1431}\u{1432}\x07\u{178}\
	\x02\x02\u{1432}\u{143a}\x05\u{38c}\u{1c7}\x02\u{1433}\u{1434}\x07\u{10f}\
	\x02\x02\u{1434}\u{1435}\x07\u{ea}\x02\x02\u{1435}\u{1436}\x05\u{38c}\u{1c7}\
	\x02\u{1436}\u{1437}\x07\u{178}\x02\x02\u{1437}\u{1438}\x05\u{38c}\u{1c7}\
	\x02\u{1438}\u{143a}\x03\x02\x02\x02\u{1439}\u{142e}\x03\x02\x02\x02\u{1439}\
	\u{1433}\x03\x02\x02\x02\u{143a}\u{3c3}\x03\x02\x02\x02\u{143b}\u{143c}\
	\x07\x63\x02\x02\u{143c}\u{143d}\x07\u{10f}\x02\x02\u{143d}\u{143f}\x07\
	\u{ea}\x02\x02\u{143e}\u{1440}\x05\x28\x15\x02\u{143f}\u{143e}\x03\x02\x02\
	\x02\u{143f}\u{1440}\x03\x02\x02\x02\u{1440}\u{1441}\x03\x02\x02\x02\u{1441}\
	\u{1442}\x05\u{38c}\u{1c7}\x02\u{1442}\u{3c5}\x03\x02\x02\x02\u{1443}\u{1448}\
	\x05\u{38c}\u{1c7}\x02\u{1444}\u{1445}\x07\u{17f}\x02\x02\u{1445}\u{1447}\
	\x05\u{38c}\u{1c7}\x02\u{1446}\u{1444}\x03\x02\x02\x02\u{1447}\u{144a}\x03\
	\x02\x02\x02\u{1448}\u{1446}\x03\x02\x02\x02\u{1448}\u{1449}\x03\x02\x02\
	\x02\u{1449}\u{3c7}\x03\x02\x02\x02\u{144a}\u{1448}\x03\x02\x02\x02\u{144b}\
	\u{144c}\x05\u{3d0}\u{1e9}\x02\u{144c}\u{3c9}\x03\x02\x02\x02\u{144d}\u{144e}\
	\x05\u{3c8}\u{1e5}\x02\u{144e}\u{144f}\x07\x02\x02\x03\u{144f}\u{3cb}\x03\
	\x02\x02\x02\u{1450}\u{1455}\x05\u{3ce}\u{1e8}\x02\u{1451}\u{1452}\x07\u{db}\
	\x02\x02\u{1452}\u{1454}\x05\u{3ce}\u{1e8}\x02\u{1453}\u{1451}\x03\x02\x02\
	\x02\u{1454}\u{1457}\x03\x02\x02\x02\u{1455}\u{1453}\x03\x02\x02\x02\u{1455}\
	\u{1456}\x03\x02\x02\x02\u{1456}\u{3cd}\x03\x02\x02\x02\u{1457}\u{1455}\
	\x03\x02\x02\x02\u{1458}\u{145d}\x05\u{3d0}\u{1e9}\x02\u{1459}\u{145a}\x07\
	\x0d\x02\x02\u{145a}\u{145c}\x05\u{3d0}\u{1e9}\x02\u{145b}\u{1459}\x03\x02\
	\x02\x02\u{145c}\u{145f}\x03\x02\x02\x02\u{145d}\u{145b}\x03\x02\x02\x02\
	\u{145d}\u{145e}\x03\x02\x02\x02\u{145e}\u{3cf}\x03\x02\x02\x02\u{145f}\
	\u{145d}\x03\x02\x02\x02\u{1460}\u{1461}\x05\u{38c}\u{1c7}\x02\u{1461}\u{1462}\
	\x05\u{3d4}\u{1eb}\x02\u{1462}\u{1463}\x05\u{3d2}\u{1ea}\x02\u{1463}\u{3d1}\
	\x03\x02\x02\x02\u{1464}\u{1465}\x09\x1b\x02\x02\u{1465}\u{3d3}\x03\x02\
	\x02\x02\u{1466}\u{1467}\x07\u{18f}\x02\x02\u{1467}\u{3d5}\x03\x02\x02\x02\
	\u{1468}\u{146d}\x07\u{aa}\x02\x02\u{1469}\u{146a}\x07\u{ca}\x02\x02\u{146a}\
	\u{146b}\x07\u{14b}\x02\x02\u{146b}\u{146d}\x05\u{3c6}\u{1e4}\x02\u{146c}\
	\u{1468}\x03\x02\x02\x02\u{146c}\u{1469}\x03\x02\x02\x02\u{146d}\u{3d7}\
	\x03\x02\x02\x02\u{146e}\u{146f}\x05\u{3d6}\u{1ec}\x02\u{146f}\u{1470}\x07\
	\x02\x02\x03\u{1470}\u{3d9}\x03\x02\x02\x02\u{1471}\u{1472}\x07\x3c\x02\
	\x02\u{1472}\u{1473}\x07\u{152}\x02\x02\u{1473}\u{1474}\x05\u{38c}\u{1c7}\
	\x02\u{1474}\u{1475}\x07\u{17f}\x02\x02\u{1475}\u{1476}\x05\u{38c}\u{1c7}\
	\x02\u{1476}\u{1477}\x07\u{174}\x02\x02\u{1477}\u{1478}\x05\u{3c8}\u{1e5}\
	\x02\u{1478}\u{1479}\x07\x61\x02\x02\u{1479}\u{147a}\x05\u{3d6}\u{1ec}\x02\
	\u{147a}\u{3db}\x03\x02\x02\x02\u{147b}\u{147c}\x07\x0b\x02\x02\u{147c}\
	\u{147d}\x07\u{152}\x02\x02\u{147d}\u{147e}\x05\u{38c}\u{1c7}\x02\u{147e}\
	\u{147f}\x07\u{17f}\x02\x02\u{147f}\u{1490}\x05\u{38c}\u{1c7}\x02\u{1480}\
	\u{1481}\x07\u{174}\x02\x02\u{1481}\u{1482}\x05\u{3c8}\u{1e5}\x02\u{1482}\
	\u{1483}\x07\x61\x02\x02\u{1483}\u{1484}\x05\u{3d6}\u{1ec}\x02\u{1484}\u{1491}\
	\x03\x02\x02\x02\u{1485}\u{1486}\x07\x06\x02\x02\u{1486}\u{148a}\x07\u{14b}\
	\x02\x02\u{1487}\u{1488}\x07\x63\x02\x02\u{1488}\u{148a}\x07\u{87}\x02\x02\
	\u{1489}\u{1485}\x03\x02\x02\x02\u{1489}\u{1487}\x03\x02\x02\x02\u{148a}\
	\u{148e}\x03\x02\x02\x02\u{148b}\u{148c}\x07\u{ed}\x02\x02\u{148c}\u{148f}\
	\x05\u{3c6}\u{1e4}\x02\u{148d}\u{148f}\x07\u{160}\x02\x02\u{148e}\u{148b}\
	\x03\x02\x02\x02\u{148e}\u{148d}\x03\x02\x02\x02\u{148f}\u{1491}\x03\x02\
	\x02\x02\u{1490}\u{1480}\x03\x02\x02\x02\u{1490}\u{1489}\x03\x02\x02\x02\
	\u{1491}\u{3dd}\x03\x02\x02\x02\u{1492}\u{1493}\x07\x63\x02\x02\u{1493}\
	\u{1494}\x07\u{152}\x02\x02\u{1494}\u{1495}\x05\u{38c}\u{1c7}\x02\u{1495}\
	\u{1496}\x07\u{17f}\x02\x02\u{1496}\u{1497}\x05\u{38c}\u{1c7}\x02\u{1497}\
	\u{3df}\x03\x02\x02\x02\u{1498}\u{1499}\x07\x0a\x02\x02\u{1499}\u{149a}\
	\x07\u{189}\x02\x02\u{149a}\u{14a5}\x07\u{1a2}\x02\x02\u{149b}\u{149c}\x07\
	\u{fa}\x02\x02\u{149c}\u{149d}\x07\u{189}\x02\x02\u{149d}\u{14a5}\x07\u{1a2}\
	\x02\x02\u{149e}\u{149f}\x07\u{11d}\x02\x02\u{149f}\u{14a0}\x07\u{189}\x02\
	\x02\u{14a0}\u{14a5}\x07\u{19d}\x02\x02\u{14a1}\u{14a2}\x07\u{e7}\x02\x02\
	\u{14a2}\u{14a3}\x07\u{189}\x02\x02\u{14a3}\u{14a5}\x05\u{3c6}\u{1e4}\x02\
	\u{14a4}\u{1498}\x03\x02\x02\x02\u{14a4}\u{149b}\x03\x02\x02\x02\u{14a4}\
	\u{149e}\x03\x02\x02\x02\u{14a4}\u{14a1}\x03\x02\x02\x02\u{14a5}\u{3e1}\
	\x03\x02\x02\x02\u{14a6}\u{14ab}\x05\u{3e0}\u{1f1}\x02\u{14a7}\u{14a8}\x07\
	\u{181}\x02\x02\u{14a8}\u{14aa}\x05\u{3e0}\u{1f1}\x02\u{14a9}\u{14a7}\x03\
	\x02\x02\x02\u{14aa}\u{14ad}\x03\x02\x02\x02\u{14ab}\u{14a9}\x03\x02\x02\
	\x02\u{14ab}\u{14ac}\x03\x02\x02\x02\u{14ac}\u{3e3}\x03\x02\x02\x02\u{14ad}\
	\u{14ab}\x03\x02\x02\x02\u{14ae}\u{14af}\x07\x3c\x02\x02\u{14af}\u{14b0}\
	\x07\u{ed}\x02\x02\u{14b0}\u{14b1}\x05\u{38c}\u{1c7}\x02\u{14b1}\u{14b2}\
	\x07\u{17f}\x02\x02\u{14b2}\u{14b3}\x05\u{3c6}\u{1e4}\x02\u{14b3}\u{14b4}\
	\x07\u{178}\x02\x02\u{14b4}\u{14b5}\x05\u{3e2}\u{1f2}\x02\u{14b5}\u{3e5}\
	\x03\x02\x02\x02\u{14b6}\u{14b7}\x07\x0b\x02\x02\u{14b7}\u{14b8}\x07\u{ed}\
	\x02\x02\u{14b8}\u{14b9}\x05\u{38c}\u{1c7}\x02\u{14b9}\u{14ba}\x07\u{17f}\
	\x02\x02\u{14ba}\u{14c2}\x05\u{3c6}\u{1e4}\x02\u{14bb}\u{14bc}\x07\u{126}\
	\x02\x02\u{14bc}\u{14c3}\x05\u{3e2}\u{1f2}\x02\u{14bd}\u{14be}\x07\u{161}\
	\x02\x02\u{14be}\u{14c3}\x07\u{11d}\x02\x02\u{14bf}\u{14c0}\x09\x30\x02\
	\x02\u{14c0}\u{14c1}\x07\u{152}\x02\x02\u{14c1}\u{14c3}\x05\u{38c}\u{1c7}\
	\x02\u{14c2}\u{14bb}\x03\x02\x02\x02\u{14c2}\u{14bd}\x03\x02\x02\x02\u{14c2}\
	\u{14bf}\x03\x02\x02\x02\u{14c3}\u{3e7}\x03\x02\x02\x02\u{14c4}\u{14c5}\
	\x07\x63\x02\x02\u{14c5}\u{14c6}\x07\u{ed}\x02\x02\u{14c6}\u{14c7}\x05\u{38c}\
	\u{1c7}\x02\u{14c7}\u{14c8}\x07\u{17f}\x02\x02\u{14c8}\u{14c9}\x05\u{3c6}\
	\u{1e4}\x02\u{14c9}\u{3e9}\x03\x02\x02\x02\u{14ca}\u{14cb}\x07\x3c\x02\x02\
	\u{14cb}\u{14cc}\x09\x31\x02\x02\u{14cc}\u{14cd}\x07\u{c1}\x02\x02\u{14cd}\
	\u{14ce}\x07\u{19d}\x02\x02\u{14ce}\u{14cf}\x07\u{95}\x02\x02\u{14cf}\u{14d3}\
	\x05\u{38c}\u{1c7}\x02\u{14d0}\u{14d1}\x07\u{14b}\x02\x02\u{14d1}\u{14d4}\
	\x05\u{3c6}\u{1e4}\x02\u{14d2}\u{14d4}\x05\u{3bc}\u{1df}\x02\u{14d3}\u{14d0}\
	\x03\x02\x02\x02\u{14d3}\u{14d2}\x03\x02\x02\x02\u{14d4}\u{14d8}\x03\x02\
	\x02\x02\u{14d5}\u{14d6}\x07\u{178}\x02\x02\u{14d6}\u{14d7}\x07\u{dc}\x02\
	\x02\u{14d7}\u{14d9}\x07\u{1a2}\x02\x02\u{14d8}\u{14d5}\x03\x02\x02\x02\
	\u{14d8}\u{14d9}\x03\x02\x02\x02\u{14d9}\u{3eb}\x03\x02\x02\x02\u{14da}\
	\u{14db}\x07\x0b\x02\x02\u{14db}\u{14dc}\x09\x31\x02\x02\u{14dc}\u{14dd}\
	\x07\u{c1}\x02\x02\u{14dd}\u{14de}\x07\u{19d}\x02\x02\u{14de}\u{14df}\x07\
	\u{95}\x02\x02\u{14df}\u{14e3}\x05\u{38c}\u{1c7}\x02\u{14e0}\u{14e1}\x07\
	\u{14b}\x02\x02\u{14e1}\u{14e4}\x05\u{3c6}\u{1e4}\x02\u{14e2}\u{14e4}\x05\
	\u{3bc}\u{1df}\x02\u{14e3}\u{14e0}\x03\x02\x02\x02\u{14e3}\u{14e2}\x03\x02\
	\x02\x02\u{14e4}\u{14e8}\x03\x02\x02\x02\u{14e5}\u{14e6}\x07\u{178}\x02\
	\x02\u{14e6}\u{14e7}\x07\u{dc}\x02\x02\u{14e7}\u{14e9}\x07\u{1a2}\x02\x02\
	\u{14e8}\u{14e5}\x03\x02\x02\x02\u{14e8}\u{14e9}\x03\x02\x02\x02\u{14e9}\
	\u{3ed}\x03\x02\x02\x02\u{14ea}\u{14eb}\x07\x63\x02\x02\u{14eb}\u{14ec}\
	\x09\x31\x02\x02\u{14ec}\u{14ed}\x07\u{c1}\x02\x02\u{14ed}\u{14ee}\x07\u{19d}\
	\x02\x02\u{14ee}\u{14ef}\x07\u{95}\x02\x02\u{14ef}\u{14f0}\x05\u{38c}\u{1c7}\
	\x02\u{14f0}\u{3ef}\x03\x02\x02\x02\u{277}\u{3f3}\u{3fa}\u{3fd}\u{403}\u{409}\
	\u{410}\u{41a}\u{41d}\u{421}\u{435}\u{43a}\u{43f}\u{445}\u{449}\u{456}\u{45a}\
	\u{45e}\u{463}\u{46a}\u{46e}\u{473}\u{47a}\u{47e}\u{489}\u{48f}\u{496}\u{4c7}\
	\u{4e4}\u{4e8}\u{4eb}\u{4ee}\u{4f3}\u{4f9}\u{4fd}\u{503}\u{505}\u{516}\u{522}\
	\u{526}\u{52d}\u{535}\u{538}\u{53d}\u{541}\u{544}\u{54e}\u{556}\u{55a}\u{55d}\
	\u{561}\u{565}\u{568}\u{56d}\u{573}\u{578}\u{57d}\u{581}\u{58c}\u{58e}\u{592}\
	\u{59c}\u{5a0}\u{5a6}\u{5a9}\u{5b0}\u{5b5}\u{5bd}\u{5c2}\u{5c6}\u{5ce}\u{5d3}\
	\u{5d9}\u{5df}\u{5e2}\u{5e5}\u{5e8}\u{5f1}\u{5f9}\u{5fe}\u{606}\u{60d}\u{610}\
	\u{613}\u{615}\u{61d}\u{620}\u{623}\u{626}\u{629}\u{62c}\u{62f}\u{632}\u{635}\
	\u{638}\u{63b}\u{63d}\u{649}\u{64d}\u{657}\u{65d}\u{66c}\u{67d}\u{682}\u{686}\
	\u{68a}\u{691}\u{698}\u{69e}\u{6a2}\u{6a5}\u{6ac}\u{6c3}\u{6c8}\u{6cc}\u{6d4}\
	\u{6dd}\u{6e1}\u{6e7}\u{6ed}\u{6f4}\u{6f7}\u{6fd}\u{704}\u{70c}\u{715}\u{71e}\
	\u{732}\u{739}\u{73b}\u{742}\u{74c}\u{754}\u{758}\u{75c}\u{769}\u{772}\u{782}\
	\u{786}\u{78b}\u{790}\u{793}\u{796}\u{79a}\u{79d}\u{7a0}\u{7a5}\u{7ad}\u{7b1}\
	\u{7b8}\u{7bb}\u{7be}\u{7c1}\u{7cd}\u{7d3}\u{7ed}\u{7f5}\u{7f9}\u{7fc}\u{7ff}\
	\u{802}\u{805}\u{808}\u{80b}\u{80e}\u{817}\u{821}\u{824}\u{838}\u{83e}\u{844}\
	\u{847}\u{849}\u{850}\u{857}\u{85b}\u{865}\u{86a}\u{873}\u{87b}\u{883}\u{895}\
	\u{8a2}\u{8b7}\u{8bb}\u{8ca}\u{8d0}\u{8d3}\u{8d6}\u{8d9}\u{8dc}\u{8e0}\u{8ee}\
	\u{8f6}\u{8f9}\u{908}\u{92a}\u{932}\u{937}\u{93f}\u{944}\u{949}\u{953}\u{95b}\
	\u{963}\u{96b}\u{976}\u{97a}\u{982}\u{98b}\u{98e}\u{997}\u{99d}\u{9a1}\u{9a7}\
	\u{9ab}\u{9b7}\u{9c0}\u{9cb}\u{9cf}\u{9d6}\u{9e2}\u{9e9}\u{9f2}\u{9f5}\u{9fc}\
	\u{a02}\u{a08}\u{a0b}\u{a11}\u{a15}\u{a19}\u{a1e}\u{a22}\u{a26}\u{a2a}\u{a32}\
	\u{a36}\u{a3a}\u{a3e}\u{a42}\u{a4a}\u{a4e}\u{a52}\u{a5a}\u{a5f}\u{a64}\u{a68}\
	\u{a6c}\u{a73}\u{a7c}\u{a84}\u{a8f}\u{aa1}\u{aa4}\u{aaa}\u{ac4}\u{ac7}\u{acd}\
	\u{ad5}\u{add}\u{aea}\u{af1}\u{af7}\u{afb}\u{afe}\u{b01}\u{b04}\u{b07}\u{b0a}\
	\u{b11}\u{b15}\u{b18}\u{b1b}\u{b1e}\u{b21}\u{b24}\u{b2b}\u{b2e}\u{b35}\u{b38}\
	\u{b3b}\u{b3e}\u{b41}\u{b44}\u{b47}\u{b4a}\u{b4d}\u{b50}\u{b53}\u{b57}\u{b5a}\
	\u{b5d}\u{b60}\u{b63}\u{b66}\u{b69}\u{b6c}\u{b6f}\u{b72}\u{b75}\u{b77}\u{b7d}\
	\u{b81}\u{b88}\u{b8a}\u{b8d}\u{b92}\u{b95}\u{b99}\u{b9e}\u{ba4}\u{baa}\u{bb2}\
	\u{bba}\u{bc1}\u{bc7}\u{bd0}\u{bd3}\u{bd7}\u{be4}\u{be8}\u{bf3}\u{bfa}\u{bfe}\
	\u{c03}\u{c06}\u{c10}\u{c12}\u{c16}\u{c1d}\u{c22}\u{c36}\u{c3d}\u{c54}\u{c64}\
	\u{c79}\u{c8a}\u{c97}\u{c9b}\u{c9f}\u{ca6}\u{cc2}\u{cc9}\u{cce}\u{cd3}\u{cd8}\
	\u{cdd}\u{ce5}\u{ceb}\u{cef}\u{cf2}\u{cf5}\u{cfb}\u{d02}\u{d0c}\u{d10}\u{d15}\
	\u{d19}\u{d1f}\u{d26}\u{d2d}\u{d35}\u{d3e}\u{d42}\u{d45}\u{d4d}\u{d50}\u{d58}\
	\u{d5b}\u{d63}\u{d67}\u{d6c}\u{d70}\u{d79}\u{d89}\u{d98}\u{d9a}\u{daa}\u{db1}\
	\u{dc2}\u{dc5}\u{dc8}\u{dcb}\u{dd1}\u{de8}\u{df0}\u{dfe}\u{e01}\u{e06}\u{e20}\
	\u{e24}\u{e27}\u{e2a}\u{e2e}\u{e33}\u{e36}\u{e39}\u{e3c}\u{e3f}\u{e45}\u{e48}\
	\u{e4b}\u{e4e}\u{e51}\u{e54}\u{e57}\u{e5a}\u{e5d}\u{e61}\u{e63}\u{e69}\u{e6e}\
	\u{e71}\u{e74}\u{e77}\u{e7d}\u{e80}\u{e83}\u{e86}\u{e89}\u{e8c}\u{e8f}\u{e92}\
	\u{e95}\u{e99}\u{e9b}\u{e9d}\u{ea2}\u{ea8}\u{ead}\u{ebf}\u{ec8}\u{ed3}\u{edb}\
	\u{ee7}\u{eea}\u{ef0}\u{ef7}\u{efe}\u{f05}\u{f0c}\u{f15}\u{f19}\u{f20}\u{f25}\
	\u{f29}\u{f39}\u{f3d}\u{f3f}\u{f42}\u{f4f}\u{f52}\u{f55}\u{f61}\u{f64}\u{f6b}\
	\u{f74}\u{f79}\u{f7b}\u{f7d}\u{f8e}\u{f91}\u{f9a}\u{fa0}\u{fa4}\u{fa7}\u{faa}\
	\u{fad}\u{fb0}\u{fbc}\u{fc0}\u{fc3}\u{fc6}\u{fcd}\u{fd0}\u{fd5}\u{fdd}\u{fe3}\
	\u{fe8}\u{fec}\u{ff1}\u{ff8}\u{1006}\u{1009}\u{100d}\u{101e}\u{1026}\u{1029}\
	\u{1036}\u{103f}\u{1042}\u{1048}\u{104b}\u{1050}\u{1053}\u{105c}\u{106a}\
	\u{1070}\u{1072}\u{107a}\u{1084}\u{1089}\u{108b}\u{1097}\u{109d}\u{109f}\
	\u{10a6}\u{10ad}\u{10b6}\u{10c0}\u{10c3}\u{10c6}\u{10c9}\u{10cd}\u{10d6}\
	\u{10df}\u{10e7}\u{10ed}\u{10f6}\u{10fd}\u{1105}\u{110f}\u{1119}\u{111e}\
	\u{1122}\u{1126}\u{112c}\u{1141}\u{1147}\u{114b}\u{114f}\u{1152}\u{1158}\
	\u{115d}\u{1160}\u{1164}\u{116c}\u{1176}\u{1180}\u{1193}\u{119a}\u{119d}\
	\u{11a8}\u{11af}\u{11b2}\u{11b4}\u{11bf}\u{11c9}\u{11cb}\u{11d1}\u{11d5}\
	\u{11de}\u{11eb}\u{11ef}\u{11fb}\u{11ff}\u{1208}\u{1224}\u{122e}\u{1236}\
	\u{123b}\u{1250}\u{1254}\u{1262}\u{1271}\u{127a}\u{127c}\u{1284}\u{1291}\
	\u{129c}\u{12a7}\u{12b2}\u{12bd}\u{12c8}\u{12d2}\u{12db}\u{12df}\u{12e7}\
	\u{12f4}\u{12fe}\u{1304}\u{1311}\u{131a}\u{131c}\u{132b}\u{1330}\u{1337}\
	\u{1344}\u{134f}\u{1358}\u{1361}\u{1369}\u{1371}\u{137c}\u{1385}\u{1389}\
	\u{138e}\u{139e}\u{13a6}\u{13af}\u{13c3}\u{13d4}\u{13dd}\u{13e4}\u{13ea}\
	\u{13f1}\u{13f8}\u{1401}\u{1403}\u{140a}\u{1421}\u{1425}\u{1427}\u{1439}\
	\u{143f}\u{1448}\u{1455}\u{145d}\u{146c}\u{1489}\u{148e}\u{1490}\u{14a4}\
	\u{14ab}\u{14c2}\u{14d3}\u{14d8}\u{14e3}\u{14e8}";

